{
  "hash": "eb5ee188933973a170f1d79c61b40032",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"In-class Exercise 6: Emerging Hot Spot Analysis\"\nauthor: \"Christover Manafe\"\ndate: \"2024-09-30\"\ndate-modified: \"last-modified\"\nexecute: \n  eval: true\n  echo: true\n  message: false\n  freeze: true\nformat: \n  html:\n    code-fold: false\n    code-summary: \"code chunk\"\n    number-sections: true\n    number-depth: 4\n---\n\n\n# Overview\n\nEmerging Hot Spot Analysis (EHSA) is a spatio-temporal analysis method for revealing and describing how hot spot and cold spot areas evolve over time. The analysis consist of four main steps:\n\n-   Building a space-time cube,\n-   Calculating Getis-Ord local Gi\\* statistic for each bin by using an FDR correction,\n-   Evaluating these hot and cold spot trends by using Mann-Kendall trend test,\n-   Categorising each study area location by referring to the resultant trend z-score and p-value for each location with data, and with the hot spot z-score and p-value for each bin.\n\n# The Data\n\nWe will use following geospatial datasets in this exercise:\n\n| Dataset       | Description                                 | Format         |\n|-------------------|--------------------------------|---------------------|\n| *Hunan*       | Hunan county boundary layer geospatial data | ESRI shapefile |\n| *Hunan_GDPPC* | Contains Hunan’s historical GDPPC data.     | CSV file       |\n\n: {tbl-colwidths=\"\\[15,65,20\\]\"}\n\n# Installing and launching the R packages\n\n::: panel-tabset\n## Packages\n\nWe will use following packages in this exercise:\n\n| Package                                                   | Description                                                                                                                                                                                                          |\n|---------------------------|---------------------------------------------|\n| [**sf**](https://r-spatial.github.io/sf/)                 | Provides functions to manage, processing, and manipulate **Simple Features**, a formal geospatial data standard that specifies a storage and access model of spatial geometries such as points, lines, and polygons. |\n| [sfdep](https://cran.r-project.org/web/packages/sfdep/)   | Provides collection of functions to create spatial weights matrix objects from polygon 'contiguities', from point patterns by distance and tessellations.                                                            |\n| [**tidyverse**](https://www.tidyverse.org/)               | Provides collection of functions for performing data science task such as importing, tidying, wrangling data and visualising data.                                                                                   |\n| [**tmap**](https://cran.r-project.org/web/packages/tmap/) | Provides functions for plotting cartographic quality static point patterns maps or interactive maps by using [leaflet](https://leafletjs.com/) API                                                                   |\n\n: {tbl-colwidths=\"\\[15,85\\]\"}\n\n## Code\n\nTo install and launch the four R packages.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(sf, sfdep, tmap, plotly, tidyverse)\n```\n:::\n\n:::\n\n# Data Import and Preparation\n\n## Loading the data\n\nIn this section, we will learn how to bring a geospatial data and its associated attribute table into R environment. The geospatial data is in ESRI shapefile format and the attribute table is in csv fomat.\n\n::: panel-tabset\n## Import geospatial data\n\nWe use [*st_read()*](https://r-spatial.github.io/sf/reference/st_read.html) of **sf** package to import Hunan shapefile into R. The imported shapefile will be **simple features** Object of **sf**.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `Hunan' from data source \n  `/Users/cham/project/Geospatial-Analytics/chrismanafe/ISSS626-GAA/in_class_ex/in_class_ex06/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 88\nColumns: 8\n$ NAME_2     <chr> \"Changde\", \"Changde\", \"Changde\", \"Changde\", \"Changde\", \"Cha…\n$ ID_3       <int> 21098, 21100, 21101, 21102, 21103, 21104, 21109, 21110, 211…\n$ NAME_3     <chr> \"Anxiang\", \"Hanshou\", \"Jinshi\", \"Li\", \"Linli\", \"Shimen\", \"L…\n$ ENGTYPE_3  <chr> \"County\", \"County\", \"County City\", \"County\", \"County\", \"Cou…\n$ Shape_Leng <dbl> 1.869074, 2.360691, 1.425620, 3.474325, 2.289506, 4.171918,…\n$ Shape_Area <dbl> 0.10056190, 0.19978745, 0.05302413, 0.18908121, 0.11450357,…\n$ County     <chr> \"Anxiang\", \"Hanshou\", \"Jinshi\", \"Li\", \"Linli\", \"Shimen\", \"L…\n$ geometry   <POLYGON [°]> POLYGON ((112.0625 29.75523..., POLYGON ((112.2288 …\n```\n\n\n:::\n:::\n\n\n## Import aspatial data\n\nThen we will import *Hunan_2012.csv* into R by using *read_csv()* of **readr** package. The output is R dataframe class.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nGDPPC <- read_csv(\"data/aspatial/Hunan_GDPPC.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 1496 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): County\ndbl (2): Year, GDPPC\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 1,496\nColumns: 3\n$ Year   <dbl> 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 200…\n$ County <chr> \"Longshan\", \"Changsha\", \"Wangcheng\", \"Ningxiang\", \"Liuyang\", \"Z…\n$ GDPPC  <dbl> 3469, 24612, 14659, 11687, 13406, 8546, 10944, 8040, 7383, 1168…\n```\n\n\n:::\n:::\n\n\n## Creating a Time Series Cube\n\nIn the code chunk below, [`spacetime()`](https://sfdep.josiahparry.com/reference/spacetime.html) of **sfdep** is used to create an spatio-temporal cube.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nGDPPC_st <- spacetime(GDPPC, hunan,\n                      .loc_col = \"County\",\n                      .time_col = \"Year\")\n```\n:::\n\n\nNext, we will use `is_spacetime_cube()` of **sfdep** package to verify if `GDPPC_st` is indeed an space-time cube object.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nis_spacetime_cube(GDPPC_st)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n```\n\n\n:::\n:::\n\n\n> The result confirms that *GDPPC_st* object is indeed an time-space cube.\n:::\n\n# Hot spot and cold spot area analysis\n\n## Computing local Gi\\* statistics\n\nNext, we will compute the local Gi\\* statistics.\n\n### Deriving the spatial weights\n\nAs with most spatial analyses, we first need to derive a spatial weight matrix before computing the local Gi\\* statistics. The code chunk below demonstrates how to derive a spatial weight matrix using functions from the `sfdep` package, combined with the `tidyverse` approach.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nGDPPC_nb <- GDPPC_st %>%\n  activate(\"geometry\") %>%\n  mutate(nb = include_self(st_contiguity(geometry)),\n         wt = st_inverse_distance(nb, geometry,\n                                  scale = 1,\n                                  alpha = 1),\n         .before = 1) %>%\n  set_nbs(\"nb\") %>%\n  set_wts(\"wt\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n! Polygon provided. Using point on surface.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: There was 1 warning in `stopifnot()`.\nℹ In argument: `wt = st_inverse_distance(nb, geometry, scale = 1, alpha = 1)`.\nCaused by warning in `st_point_on_surface.sfc()`:\n! st_point_on_surface may not give correct results for longitude/latitude data\n```\n\n\n:::\n:::\n\n\n> -   `activate()` of dplyr package is used to activate the geometry context\n> -   `mutate()` of dplyr package is used to create two new columns *nb* and *wt*.\n> -   Then we will activate the data context again and copy over the nb and wt columns to each time-slice using `set_nbs()` and `set_wts()`\n>     -   row order is very important so do not rearrange the observations after using `set_nbs()` or `set_wts()`.\n\n### Compute Gi\\*\n\nWe can manually calculate the local Gi\\* for each location using the new columns. This is done by grouping the data by *Year* and applying the `local_gstar_perm()` function from the `sfdep` package. Afterward, we can use `unnest()` to unnest the *gi_star* column from the newly created *gi_stars* data frame.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngi_stars <- GDPPC_nb %>% \n  group_by(Year) %>% \n  mutate(gi_star = local_gstar_perm(\n    GDPPC, nb, wt)) %>% \n  tidyr::unnest(gi_star)\n```\n:::\n\n\n## Mann-Kendall Test\n\nA **monotonic series** or function is one that only increases or decreases and never changes direction. As long as the function either stays flat or continues to increase (or decrease), it is considered monotonic.\n\n-   **H₀ (Null Hypothesis):** There is no monotonic trend.\n\n-   **H₁ (Alternative Hypothesis):** A monotonic trend is present.\n\n**Interpretation:**\n\n-   Reject the null hypothesis (H₀) if the p-value is smaller than the alpha level (i.e., 1 - confidence level).\n\n-   **Tau (τ)** ranges between -1 and 1, where:\n\n    -   **-1** represents a perfectly decreasing series.\n\n    -   **1** represents a perfectly increasing series.\n\n### Mann-Kendall Test on Gi\n\nWith these Gi\\* measures we can then evaluate each location for a trend using the Mann-Kendal test. Let's use it on Changsha county.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncbg <- gi_stars %>% \n  ungroup() %>% \n  filter(County == \"Changsha\") |> \n  select(County, Year, gi_star)\n```\n:::\n\n\n### Visualize Mann-Kendall Test Result\n\nNext, we plot the result by using ggplot2 functions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = cbg, \n       aes(x = Year, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n```\n\n::: {.cell-output-display}\n![](in_class_ex06_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\nWe can also create an interactive plot by using `ggplotly()` of **plotly** package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\np <- ggplot(data = cbg, \n       aes(x = Year, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\nggplotly(p)\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"plotly html-widget html-fill-item\" id=\"htmlwidget-9bf38d86148c68ea54eb\" style=\"width:100%;height:464px;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-9bf38d86148c68ea54eb\">{\"x\":{\"data\":[{\"x\":[2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021],\"y\":[5.0282995066289065,5.1692011079782327,5.2958892892912894,5.6039537096873984,6.2788862246004742,5.9357455762937326,5.7508709054298892,5.6942475830114585,5.7085054237054784,5.760812156173353,6.0971272412571889,6.0036547779673155,6.2028053540357915,6.0371816202738309,6.579432171885526,5.7669155664195504,5.7486534794156494],\"text\":[\"Year: 2005<br />gi_star: 5.028300\",\"Year: 2006<br />gi_star: 5.169201\",\"Year: 2007<br />gi_star: 5.295889\",\"Year: 2008<br />gi_star: 5.603954\",\"Year: 2009<br />gi_star: 6.278886\",\"Year: 2010<br />gi_star: 5.935746\",\"Year: 2011<br />gi_star: 5.750871\",\"Year: 2012<br />gi_star: 5.694248\",\"Year: 2013<br />gi_star: 5.708505\",\"Year: 2014<br />gi_star: 5.760812\",\"Year: 2015<br />gi_star: 6.097127\",\"Year: 2016<br />gi_star: 6.003655\",\"Year: 2017<br />gi_star: 6.202805\",\"Year: 2018<br />gi_star: 6.037182\",\"Year: 2019<br />gi_star: 6.579432\",\"Year: 2020<br />gi_star: 5.766916\",\"Year: 2021<br />gi_star: 5.748653\"],\"type\":\"scatter\",\"mode\":\"lines\",\"line\":{\"width\":1.8897637795275593,\"color\":\"rgba(0,0,0,1)\",\"dash\":\"solid\"},\"hoveron\":\"points\",\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null}],\"layout\":{\"margin\":{\"t\":26.228310502283108,\"r\":7.3059360730593621,\"b\":40.182648401826498,\"l\":43.105022831050235},\"plot_bgcolor\":\"rgba(255,255,255,1)\",\"paper_bgcolor\":\"rgba(255,255,255,1)\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.611872146118724},\"xaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[2004.2,2021.8],\"tickmode\":\"array\",\"ticktext\":[\"2005\",\"2010\",\"2015\",\"2020\"],\"tickvals\":[2005,2010,2015,2020],\"categoryorder\":\"array\",\"categoryarray\":[\"2005\",\"2010\",\"2015\",\"2020\"],\"nticks\":null,\"ticks\":\"outside\",\"tickcolor\":\"rgba(179,179,179,1)\",\"ticklen\":3.6529680365296811,\"tickwidth\":0.33208800332088001,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.68949771689498},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(222,222,222,1)\",\"gridwidth\":0.33208800332088001,\"zeroline\":false,\"anchor\":\"y\",\"title\":{\"text\":\"Year\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.611872146118724}},\"hoverformat\":\".2f\"},\"yaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[4.9507428733660754,6.656988805148357],\"tickmode\":\"array\",\"ticktext\":[\"5.0\",\"5.5\",\"6.0\",\"6.5\"],\"tickvals\":[5,5.5,6,6.5],\"categoryorder\":\"array\",\"categoryarray\":[\"5.0\",\"5.5\",\"6.0\",\"6.5\"],\"nticks\":null,\"ticks\":\"outside\",\"tickcolor\":\"rgba(179,179,179,1)\",\"ticklen\":3.6529680365296811,\"tickwidth\":0.33208800332088001,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.68949771689498},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(222,222,222,1)\",\"gridwidth\":0.33208800332088001,\"zeroline\":false,\"anchor\":\"x\",\"title\":{\"text\":\"gi_star\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.611872146118724}},\"hoverformat\":\".2f\"},\"shapes\":[{\"type\":\"rect\",\"fillcolor\":\"transparent\",\"line\":{\"color\":\"rgba(179,179,179,1)\",\"width\":0.66417600664176002,\"linetype\":\"solid\"},\"yref\":\"paper\",\"xref\":\"paper\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"showlegend\":false,\"legend\":{\"bgcolor\":\"rgba(255,255,255,1)\",\"bordercolor\":\"transparent\",\"borderwidth\":1.8897637795275593,\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":11.68949771689498}},\"hovermode\":\"closest\",\"barmode\":\"relative\"},\"config\":{\"doubleClick\":\"reset\",\"modeBarButtonsToAdd\":[\"hoverclosest\",\"hovercompare\"],\"showSendToCloud\":false},\"source\":\"A\",\"attrs\":{\"86567501a46d\":{\"x\":{},\"y\":{},\"type\":\"scatter\"}},\"cur_data\":\"86567501a46d\",\"visdat\":{\"86567501a46d\":[\"function (y) \",\"x\"]},\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.20000000000000001,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\n### Print Mann-Kendall test report\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncbg %>%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %>%\n  tidyr::unnest_wider(mk)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 5\n    tau      sl     S     D  varS\n  <dbl>   <dbl> <dbl> <dbl> <dbl>\n1 0.485 0.00742    66  136.  589.\n```\n\n\n:::\n:::\n\n\n> In the above result, **sl** is the p-value. With reference to the results, we will reject the null hypothesis and infer there's a slight upward trend.\n\n### Mann-Kendall test data.frame\n\nWe can replicate this for each location by using `group_by()` of **dplyr** package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nehsa <- gi_stars %>%\n  group_by(County) %>%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %>%\n  tidyr::unnest_wider(mk)\nhead(ehsa)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 6\n  County        tau        sl     S     D  varS\n  <chr>       <dbl>     <dbl> <dbl> <dbl> <dbl>\n1 Anhua      0.191  0.303        26  136.  589.\n2 Anren     -0.294  0.108       -40  136.  589.\n3 Anxiang    0      1             0  136.  589.\n4 Baojing   -0.691  0.000128    -94  136.  589.\n5 Chaling   -0.0882 0.650       -12  136.  589.\n6 Changning -0.750  0.0000318  -102  136.  589.\n```\n\n\n:::\n:::\n\n\n#### Arrange significant emerging hot/cold spots\n\nWe can also sort to show significant hot spots using following code chunk.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nemerging <- ehsa %>% \n  arrange(sl, abs(tau)) %>% \n  slice(1:10)\nemerging\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 6\n   County        tau         sl     S     D  varS\n   <chr>       <dbl>      <dbl> <dbl> <dbl> <dbl>\n 1 Shuangfeng  0.868 0.00000143   118  136.  589.\n 2 Xiangtan    0.868 0.00000143   118  136.  589.\n 3 Xiangxiang  0.868 0.00000143   118  136.  589.\n 4 Chengbu    -0.824 0.00000482  -112  136.  589.\n 5 Dongan     -0.824 0.00000482  -112  136.  589.\n 6 Wugang     -0.809 0.00000712  -110  136.  589.\n 7 Huayuan    -0.794 0.0000105   -108  136.  589.\n 8 Shaoshan    0.794 0.0000105    108  136.  589.\n 9 Liuyang     0.779 0.0000153    106  136.  589.\n10 Zhuzhou     0.765 0.0000221    104  136.  589.\n```\n\n\n:::\n:::\n\n\n### Performing Emerging Hotspot Analysis\n\nLastly, we will perform EHSA analysis by using [`emerging_hotspot_analysis()`](https://sfdep.josiahparry.com/reference/emerging_hotspot_analysis.html) of sfdep package. It takes a spacetime object x (i.e. GDPPC_st), and the quoted name of the variable of interest (i.e. GDPPC) for .var argument. The k argument is used to specify the number of time lags which is set to 1 by default. Lastly, nsim map numbers of simulation to be performed.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nehsa <- emerging_hotspot_analysis(\n  x = GDPPC_st, \n  .var = \"GDPPC\", \n  k = 1, \n  nsim = 99\n)\n```\n:::\n\n\n### Visualising the distribution of EHSA classes\n\nWe'll visualise the distribution of EHSA classes using `ggplot2` functions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = ehsa,\n       aes(x = classification)) +\n  geom_bar()\n```\n\n::: {.cell-output-display}\n![](in_class_ex06_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n> The figure above shows that sporadic cold spots class has the high numbers of county.\n\n### Visualising EHSA\n\nIn this section, we will visualise the geographic distribution EHSA classes. However, before we can do so, we need to join both *hunan* and *ehsa* together by using the code chunk below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhunan_ehsa <- hunan %>%\n  left_join(ehsa,\n            by = join_by(County == location))\n```\n:::\n\n\nNext, tmap functions will be used to plot a categorical choropleth map by using the code chunk below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nehsa_sig <- hunan_ehsa  %>%\n  filter(p_value < 0.05)\ntmap_mode(\"plot\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\ntmap mode set to plotting\n```\n\n\n:::\n\n```{.r .cell-code}\ntm_shape(hunan_ehsa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(ehsa_sig) +\n  tm_fill(\"classification\") + \n  tm_borders(alpha = 0.4)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](in_class_ex06_files/figure-html/unnamed-chunk-19-1.png){width=768}\n:::\n:::\n\n\n# Reference\n\nKam, T. S. Emerging Hot Spot Analysis. *ISSS626 Geospatial Analytics and Applications.* <https://isss626-ay2024-25aug.netlify.app/in-class_ex/in-class_ex06/in-class_ex06>\n",
    "supporting": [
      "in_class_ex06_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/htmltools-fill-0.5.8.1/fill.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/htmlwidgets-1.6.4/htmlwidgets.js\"></script>\n<script src=\"../../site_libs/plotly-binding-4.10.4/plotly.js\"></script>\n<script src=\"../../site_libs/typedarray-0.1/typedarray.min.js\"></script>\n<script src=\"../../site_libs/jquery-3.5.1/jquery.min.js\"></script>\n<link href=\"../../site_libs/crosstalk-1.2.1/css/crosstalk.min.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/crosstalk-1.2.1/js/crosstalk.min.js\"></script>\n<link href=\"../../site_libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/plotly-main-2.11.1/plotly-latest.min.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}