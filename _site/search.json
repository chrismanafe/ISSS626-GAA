[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to ISSS626 Geospatial Analytics and Applications",
    "section": "",
    "text": "This website showcases my coursework, featuring exercises and assignments enriched with geospatial visualizations and analytical insights. I invite you to explore the contents I’ve developed throughout the course."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1.1: Geospatial Data Wrangling with R",
    "section": "",
    "text": "In this hands-on exercise, I learn how to import and wrangle geospatial data using appropriate R packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-polygon-feature-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-polygon-feature-data",
    "title": "Hands-on Exercise 1.1: Geospatial Data Wrangling with R",
    "section": "Importing polygon feature data",
    "text": "Importing polygon feature data\nDataset sources:\n\nMaster Plan 2014 Subzone Boundary (Web) from data.gov.sg\nPre-Schools Location from data.gov.sg\nCycling Path from LTADataMall\nLatest version of Singapore Airbnb listing data from Inside Airbnb\n\nUsing st_read() to import the dataset. ### Polygon data in shapefile format\n\nmpsz = st_read(dsn = \"data/geospatial\",\n               layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/cham/project/Geospatial-Analytics/chrismanafe/ISSS626-GAA/Hands-on_Ex/Hands-on_Ex01/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nPolyline data in shapefile format\n\ncyclingpath = st_read(dsn = \"data/geospatial\",\n                      layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `/Users/cham/project/Geospatial-Analytics/chrismanafe/ISSS626-GAA/Hands-on_Ex/Hands-on_Ex01/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3138 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42644.17 ymax: 48948.15\nProjected CRS: SVY21\n\n\n\n\nGIS data in KML format\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `/Users/cham/project/Geospatial-Analytics/chrismanafe/ISSS626-GAA/Hands-on_Ex/Hands-on_Ex01/data/geospatial/PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#checking-content-of-a-simple-dataframe",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#checking-content-of-a-simple-dataframe",
    "title": "Hands-on Exercise 1.1: Geospatial Data Wrangling with R",
    "section": "Checking content of a simple dataframe",
    "text": "Checking content of a simple dataframe\n\nExtracting geometric information using sf_geometry()\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303...\n\n\nData structure overview using glimpse()\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\nData preview using head()\n\nhead(mpsz, n=5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#visualizing-the-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#visualizing-the-geospatial-data",
    "title": "Hands-on Exercise 1.1: Geospatial Data Wrangling with R",
    "section": "Visualizing the geospatial data",
    "text": "Visualizing the geospatial data\n\nUsing plot() of R Graphic to visualize the geospatial features from the data.\n\nplot(mpsz)\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\nPlot only the geometry attributes\n\nplot(st_geometry(mpsz))\n\n\n\n\n\n\n\n\nPlot only specific attributes (e.g.: PLN_AREA_N)\n\nplot(mpsz[\"PLN_AREA_N\"])"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#assigning-epsg-code-to-simple-feature-dataframe",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#assigning-epsg-code-to-simple-feature-dataframe",
    "title": "Hands-on Exercise 1.1: Geospatial Data Wrangling with R",
    "section": "Assigning EPSG code to simple feature dataframe",
    "text": "Assigning EPSG code to simple feature dataframe\nThis is an example the coordinate system of mpsz simple feature data frame by using st_crs() of sf package\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough mpsz dataframe is projected in svy21 but it indicates that the EPSG is 9001. This is a wrong EPSG code because the correct EPSG code for svy21 should be 3414.\nAssign correct EPSG code to mpsz data frame:\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nCheck CSR again\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#transforming-the-projection-of-preschool-from-wgs84-to-svy21",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#transforming-the-projection-of-preschool-from-wgs84-to-svy21",
    "title": "Hands-on Exercise 1.1: Geospatial Data Wrangling with R",
    "section": "Transforming the projection of preschool from wgs84 to svy21",
    "text": "Transforming the projection of preschool from wgs84 to svy21\nReproject preschool from one coordinate system to another coordinate system mathemetically\n\npreschool3414 &lt;- st_transform(preschool,\n                              crs = 3414)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#checking-content-of-a-simple-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#checking-content-of-a-simple-data-frame",
    "title": "Hands-on Exercise 1.1: Geospatial Data Wrangling with R",
    "section": "Checking content of a simple data frame",
    "text": "Checking content of a simple data frame\n\nExtracting geometric information using sf_geometry()\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303...\n\n\nData structure overview using glimpse()\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\nData preview using head()\n\nhead(mpsz, n=5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#assigning-epsg-code-to-simple-feature-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#assigning-epsg-code-to-simple-feature-data-frame",
    "title": "Hands-on Exercise 1.1: Geospatial Data Wrangling with R",
    "section": "Assigning EPSG code to simple feature data frame",
    "text": "Assigning EPSG code to simple feature data frame\nThis is an example the coordinate system of mpsz simple feature data frame by using st_crs() of sf package\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough mpsz data frame is projected in svy21 but it indicates that the EPSG is 9001. This is a wrong EPSG code because the correct EPSG code for svy21 should be 3414.\nAssign correct EPSG code to mpsz data frame:\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nCheck CSR again\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#import-listing-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#import-listing-data",
    "title": "Hands-on Exercise 1.1: Geospatial Data Wrangling with R",
    "section": "Import listing data",
    "text": "Import listing data\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nRows: 3540 Columns: 75\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (26): listing_url, source, name, description, neighborhood_overview, pi...\ndbl  (38): id, scrape_id, host_id, host_listings_count, host_total_listings_...\nlgl   (6): host_is_superhost, host_has_profile_pic, host_identity_verified, ...\ndate  (5): last_scraped, host_since, calendar_last_scraped, first_review, la...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCheck the dataset after importing to see if its imported correctly."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#create-simple-feature-data-frame-from-aspatial-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#create-simple-feature-data-frame-from-aspatial-data-frame",
    "title": "Hands-on Exercise 1.1: Geospatial Data Wrangling with R",
    "section": "Create simple feature data frame from aspatial data frame",
    "text": "Create simple feature data frame from aspatial data frame\nConvert listing data frame into simple feature data frame using st_as_sf()\n\nlistings_sf &lt;- st_as_sf(listings,\n                        coords = c(\"longitude\", \"latitude\"),\n                        crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\nExamine the content of newly created data frame.\n\nglimpse(listings_sf)\n\nRows: 3,540\nColumns: 74\n$ id                                           &lt;dbl&gt; 71609, 71896, 71903, 2753…\n$ listing_url                                  &lt;chr&gt; \"https://www.airbnb.com/r…\n$ scrape_id                                    &lt;dbl&gt; 2.024063e+13, 2.024063e+1…\n$ last_scraped                                 &lt;date&gt; 2024-06-29, 2024-06-29, …\n$ source                                       &lt;chr&gt; \"previous scrape\", \"city …\n$ name                                         &lt;chr&gt; \"Ensuite Room (Room 1 & 2…\n$ description                                  &lt;chr&gt; \"For 3 rooms.Book room 1 …\n$ neighborhood_overview                        &lt;chr&gt; NA, NA, \"Quiet and view o…\n$ picture_url                                  &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_id                                      &lt;dbl&gt; 367042, 367042, 367042, 1…\n$ host_url                                     &lt;chr&gt; \"https://www.airbnb.com/u…\n$ host_name                                    &lt;chr&gt; \"Belinda\", \"Belinda\", \"Be…\n$ host_since                                   &lt;date&gt; 2011-01-29, 2011-01-29, …\n$ host_location                                &lt;chr&gt; \"Singapore\", \"Singapore\",…\n$ host_about                                   &lt;chr&gt; \"Hi My name is Belinda -H…\n$ host_response_time                           &lt;chr&gt; \"within an hour\", \"within…\n$ host_response_rate                           &lt;chr&gt; \"100%\", \"100%\", \"100%\", \"…\n$ host_acceptance_rate                         &lt;chr&gt; \"N/A\", \"N/A\", \"N/A\", \"99%…\n$ host_is_superhost                            &lt;lgl&gt; FALSE, FALSE, FALSE, FALS…\n$ host_thumbnail_url                           &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_picture_url                             &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_neighbourhood                           &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ host_listings_count                          &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49…\n$ host_total_listings_count                    &lt;dbl&gt; 11, 11, 11, 73, 73, 11, 8…\n$ host_verifications                           &lt;chr&gt; \"['email', 'phone']\", \"['…\n$ host_has_profile_pic                         &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ host_identity_verified                       &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ neighbourhood                                &lt;chr&gt; NA, NA, \"Singapore, Singa…\n$ neighbourhood_cleansed                       &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ neighbourhood_group_cleansed                 &lt;chr&gt; \"East Region\", \"East Regi…\n$ property_type                                &lt;chr&gt; \"Private room in villa\", …\n$ room_type                                    &lt;chr&gt; \"Private room\", \"Private …\n$ accommodates                                 &lt;dbl&gt; 3, 1, 2, 1, 1, 4, 2, 1, 1…\n$ bathrooms                                    &lt;dbl&gt; NA, 0.5, 0.5, 2.0, 2.5, N…\n$ bathrooms_text                               &lt;chr&gt; \"1 private bath\", \"Shared…\n$ bedrooms                                     &lt;dbl&gt; 2, 1, 1, 1, 1, 3, 2, 1, 1…\n$ beds                                         &lt;dbl&gt; NA, 1, 2, 1, 1, NA, 1, 1,…\n$ amenities                                    &lt;chr&gt; \"[\\\"Free parking on premi…\n$ price                                        &lt;chr&gt; NA, \"$80.00\", \"$80.00\", \"…\n$ minimum_nights                               &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_nights                               &lt;dbl&gt; 365, 365, 365, 999, 999, …\n$ minimum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ minimum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ maximum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ minimum_nights_avg_ntm                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_nights_avg_ntm                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ calendar_updated                             &lt;lgl&gt; NA, NA, NA, NA, NA, NA, N…\n$ has_availability                             &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ availability_30                              &lt;dbl&gt; 30, 30, 30, 28, 0, 29, 30…\n$ availability_60                              &lt;dbl&gt; 59, 53, 60, 58, 0, 58, 60…\n$ availability_90                              &lt;dbl&gt; 89, 83, 90, 62, 0, 88, 90…\n$ availability_365                             &lt;dbl&gt; 89, 148, 90, 62, 0, 88, 3…\n$ calendar_last_scraped                        &lt;date&gt; 2024-06-29, 2024-06-29, …\n$ number_of_reviews                            &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 1…\n$ number_of_reviews_ltm                        &lt;dbl&gt; 0, 0, 0, 0, 2, 0, 0, 1, 1…\n$ number_of_reviews_l30d                       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ first_review                                 &lt;date&gt; 2011-12-19, 2011-07-30, …\n$ last_review                                  &lt;date&gt; 2020-01-17, 2019-10-13, …\n$ review_scores_rating                         &lt;dbl&gt; 4.44, 4.16, 4.41, 4.40, 4…\n$ review_scores_accuracy                       &lt;dbl&gt; 4.37, 4.22, 4.39, 4.16, 4…\n$ review_scores_cleanliness                    &lt;dbl&gt; 4.00, 4.09, 4.52, 4.26, 4…\n$ review_scores_checkin                        &lt;dbl&gt; 4.63, 4.43, 4.63, 4.47, 4…\n$ review_scores_communication                  &lt;dbl&gt; 4.78, 4.43, 4.64, 4.42, 4…\n$ review_scores_location                       &lt;dbl&gt; 4.26, 4.17, 4.50, 4.53, 4…\n$ review_scores_value                          &lt;dbl&gt; 4.32, 4.04, 4.36, 4.63, 4…\n$ license                                      &lt;chr&gt; NA, NA, NA, \"S0399\", \"S03…\n$ instant_bookable                             &lt;lgl&gt; FALSE, FALSE, FALSE, TRUE…\n$ calculated_host_listings_count               &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49…\n$ calculated_host_listings_count_entire_homes  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 1, 0, 0…\n$ calculated_host_listings_count_private_rooms &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 6, 49…\n$ calculated_host_listings_count_shared_rooms  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ reviews_per_month                            &lt;dbl&gt; 0.12, 0.15, 0.29, 0.15, 0…\n$ geometry                                     &lt;POINT [m]&gt; POINT (41972.5 3639…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#buffering",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#buffering",
    "title": "Hands-on Exercise 1.1: Geospatial Data Wrangling with R",
    "section": "Buffering",
    "text": "Buffering\nThe scenario:\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\nThe solution:\n\nUse st_buffer() of sf package to compute the 5-meter buffers around cycling paths\n\nbuffer_cycling &lt;- st_buffer(cyclingpath,\n                            dist=5,\n                            nQuadSegs = 30)\n\nCalculate the area of the buffers\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nDerive the total land involved using sum() of Base R\n\nsum(buffer_cycling$AREA)\n\n2218855 [m^2]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#point-in-polygon-count",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#point-in-polygon-count",
    "title": "Hands-on Exercise 1.1: Geospatial Data Wrangling with R",
    "section": "Point-in-polygon count",
    "text": "Point-in-polygon count\nThe scenario:\nA pre-school service group want to find out the numbers of pre-schools in each Planning Subzone.\nThe solution:\n\nThe code chunk below performs two operations at one go. Firstly, identify pre-schools located inside each Planning Subzone by using st_intersects(). Then, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\n\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\nCheck the summary statistics of the newly derived PreSch Count field by using summary() function.\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nList the planning subzone with the most number of pre-school using top_n() of dplyr package\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nDIY: Calculate the density of pre-school by planning subzone.\n\nUse st_area() of sf package to derive the area of each planning subzone.\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%\n  st_area()\n\nUse mutate() of dplyr package to compute the density.\n\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.1.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.1.html",
    "title": "Hands-on Exercise 1a: Geospatial Data Wrangling",
    "section": "",
    "text": "In this hands-on exercise, I learn how to import and wrangle geospatial data using appropriate R packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.1.html#importing-polygon-feature-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.1.html#importing-polygon-feature-data",
    "title": "Hands-on Exercise 1a: Geospatial Data Wrangling",
    "section": "3.1 Importing polygon feature data",
    "text": "3.1 Importing polygon feature data\nDataset sources:\n\nMaster Plan 2014 Subzone Boundary (Web) from data.gov.sg\nPre-Schools Location from data.gov.sg\nCycling Path from LTADataMall\nLatest version of Singapore Airbnb listing data from Inside Airbnb\n\nUsing st_read() to import the dataset. ### Polygon data in shapefile format\n\n\ncode chunk\nmpsz = st_read(dsn = \"data/geospatial\",\n               layer = \"MP14_SUBZONE_WEB_PL\")\n\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/cham/project/Geospatial-Analytics/chrismanafe/ISSS626-GAA/Hands-on_Ex/Hands-on_Ex01/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n3.1.1 Polyline data in shapefile format\n\n\ncode chunk\ncyclingpath = st_read(dsn = \"data/geospatial\",\n                      layer = \"CyclingPathGazette\")\n\n\nReading layer `CyclingPathGazette' from data source \n  `/Users/cham/project/Geospatial-Analytics/chrismanafe/ISSS626-GAA/Hands-on_Ex/Hands-on_Ex01/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3138 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42644.17 ymax: 48948.15\nProjected CRS: SVY21\n\n\n\n\n3.1.2 GIS data in KML format\n\n\ncode chunk\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `/Users/cham/project/Geospatial-Analytics/chrismanafe/ISSS626-GAA/Hands-on_Ex/Hands-on_Ex01/data/geospatial/PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.1.html#checking-content-of-a-simple-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.1.html#checking-content-of-a-simple-data-frame",
    "title": "Hands-on Exercise 1a: Geospatial Data Wrangling",
    "section": "3.2 Checking content of a simple data frame",
    "text": "3.2 Checking content of a simple data frame\n\nExtracting geometric information using sf_geometry()\n\n\ncode chunk\nst_geometry(mpsz)\n\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303...\n\n\nData structure overview using glimpse()\n\n\ncode chunk\nglimpse(mpsz)\n\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\nData preview using head()\n\n\ncode chunk\nhead(mpsz, n=5)\n\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.1.html#visualizing-the-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.1.html#visualizing-the-geospatial-data",
    "title": "Hands-on Exercise 1a: Geospatial Data Wrangling",
    "section": "3.3 Visualizing the geospatial data",
    "text": "3.3 Visualizing the geospatial data\n\nUsing plot() of R Graphic to visualize the geospatial features from the data.\n\n\ncode chunk\nplot(mpsz)\n\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\nPlot only the geometry attributes\n\n\ncode chunk\nplot(st_geometry(mpsz))\n\n\n\n\n\n\n\n\n\nPlot only specific attributes (e.g.: PLN_AREA_N)\n\n\ncode chunk\nplot(mpsz[\"PLN_AREA_N\"])"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.1.html#assigning-epsg-code-to-simple-feature-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.1.html#assigning-epsg-code-to-simple-feature-data-frame",
    "title": "Hands-on Exercise 1a: Geospatial Data Wrangling",
    "section": "3.4 Assigning EPSG code to simple feature data frame",
    "text": "3.4 Assigning EPSG code to simple feature data frame\nThis is an example the coordinate system of mpsz simple feature data frame by using st_crs() of sf package\n\n\ncode chunk\nst_crs(mpsz)\n\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough mpsz data frame is projected in svy21 but it indicates that the EPSG is 9001. This is a wrong EPSG code because the correct EPSG code for svy21 should be 3414.\nAssign correct EPSG code to mpsz data frame:\n\n\ncode chunk\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nCheck CSR again\n\n\ncode chunk\nst_crs(mpsz3414)\n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.1.html#transforming-the-projection-of-preschool-from-wgs84-to-svy21",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.1.html#transforming-the-projection-of-preschool-from-wgs84-to-svy21",
    "title": "Hands-on Exercise 1a: Geospatial Data Wrangling",
    "section": "3.5 Transforming the projection of preschool from wgs84 to svy21",
    "text": "3.5 Transforming the projection of preschool from wgs84 to svy21\nReproject preschool from one coordinate system to another coordinate system mathemetically\n\n\ncode chunk\npreschool3414 &lt;- st_transform(preschool,\n                              crs = 3414)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.1.html#import-listing-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.1.html#import-listing-data",
    "title": "Hands-on Exercise 1a: Geospatial Data Wrangling",
    "section": "4.1 Import listing data",
    "text": "4.1 Import listing data\n\n\ncode chunk\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\n\nRows: 3540 Columns: 75\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (26): listing_url, source, name, description, neighborhood_overview, pi...\ndbl  (38): id, scrape_id, host_id, host_listings_count, host_total_listings_...\nlgl   (6): host_is_superhost, host_has_profile_pic, host_identity_verified, ...\ndate  (5): last_scraped, host_since, calendar_last_scraped, first_review, la...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCheck the dataset after importing to see if its imported correctly."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.1.html#create-simple-feature-data-frame-from-aspatial-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.1.html#create-simple-feature-data-frame-from-aspatial-data-frame",
    "title": "Hands-on Exercise 1a: Geospatial Data Wrangling",
    "section": "4.2 Create simple feature data frame from aspatial data frame",
    "text": "4.2 Create simple feature data frame from aspatial data frame\nConvert listing data frame into simple feature data frame using st_as_sf()\n\n\ncode chunk\nlistings_sf &lt;- st_as_sf(listings,\n                        coords = c(\"longitude\", \"latitude\"),\n                        crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\n\nExamine the content of newly created data frame.\n\n\ncode chunk\nglimpse(listings_sf)\n\n\nRows: 3,540\nColumns: 74\n$ id                                           &lt;dbl&gt; 71609, 71896, 71903, 2753…\n$ listing_url                                  &lt;chr&gt; \"https://www.airbnb.com/r…\n$ scrape_id                                    &lt;dbl&gt; 2.024063e+13, 2.024063e+1…\n$ last_scraped                                 &lt;date&gt; 2024-06-29, 2024-06-29, …\n$ source                                       &lt;chr&gt; \"previous scrape\", \"city …\n$ name                                         &lt;chr&gt; \"Ensuite Room (Room 1 & 2…\n$ description                                  &lt;chr&gt; \"For 3 rooms.Book room 1 …\n$ neighborhood_overview                        &lt;chr&gt; NA, NA, \"Quiet and view o…\n$ picture_url                                  &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_id                                      &lt;dbl&gt; 367042, 367042, 367042, 1…\n$ host_url                                     &lt;chr&gt; \"https://www.airbnb.com/u…\n$ host_name                                    &lt;chr&gt; \"Belinda\", \"Belinda\", \"Be…\n$ host_since                                   &lt;date&gt; 2011-01-29, 2011-01-29, …\n$ host_location                                &lt;chr&gt; \"Singapore\", \"Singapore\",…\n$ host_about                                   &lt;chr&gt; \"Hi My name is Belinda -H…\n$ host_response_time                           &lt;chr&gt; \"within an hour\", \"within…\n$ host_response_rate                           &lt;chr&gt; \"100%\", \"100%\", \"100%\", \"…\n$ host_acceptance_rate                         &lt;chr&gt; \"N/A\", \"N/A\", \"N/A\", \"99%…\n$ host_is_superhost                            &lt;lgl&gt; FALSE, FALSE, FALSE, FALS…\n$ host_thumbnail_url                           &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_picture_url                             &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_neighbourhood                           &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ host_listings_count                          &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49…\n$ host_total_listings_count                    &lt;dbl&gt; 11, 11, 11, 73, 73, 11, 8…\n$ host_verifications                           &lt;chr&gt; \"['email', 'phone']\", \"['…\n$ host_has_profile_pic                         &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ host_identity_verified                       &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ neighbourhood                                &lt;chr&gt; NA, NA, \"Singapore, Singa…\n$ neighbourhood_cleansed                       &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ neighbourhood_group_cleansed                 &lt;chr&gt; \"East Region\", \"East Regi…\n$ property_type                                &lt;chr&gt; \"Private room in villa\", …\n$ room_type                                    &lt;chr&gt; \"Private room\", \"Private …\n$ accommodates                                 &lt;dbl&gt; 3, 1, 2, 1, 1, 4, 2, 1, 1…\n$ bathrooms                                    &lt;dbl&gt; NA, 0.5, 0.5, 2.0, 2.5, N…\n$ bathrooms_text                               &lt;chr&gt; \"1 private bath\", \"Shared…\n$ bedrooms                                     &lt;dbl&gt; 2, 1, 1, 1, 1, 3, 2, 1, 1…\n$ beds                                         &lt;dbl&gt; NA, 1, 2, 1, 1, NA, 1, 1,…\n$ amenities                                    &lt;chr&gt; \"[\\\"Free parking on premi…\n$ price                                        &lt;chr&gt; NA, \"$80.00\", \"$80.00\", \"…\n$ minimum_nights                               &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_nights                               &lt;dbl&gt; 365, 365, 365, 999, 999, …\n$ minimum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ minimum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ maximum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ minimum_nights_avg_ntm                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_nights_avg_ntm                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ calendar_updated                             &lt;lgl&gt; NA, NA, NA, NA, NA, NA, N…\n$ has_availability                             &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ availability_30                              &lt;dbl&gt; 30, 30, 30, 28, 0, 29, 30…\n$ availability_60                              &lt;dbl&gt; 59, 53, 60, 58, 0, 58, 60…\n$ availability_90                              &lt;dbl&gt; 89, 83, 90, 62, 0, 88, 90…\n$ availability_365                             &lt;dbl&gt; 89, 148, 90, 62, 0, 88, 3…\n$ calendar_last_scraped                        &lt;date&gt; 2024-06-29, 2024-06-29, …\n$ number_of_reviews                            &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 1…\n$ number_of_reviews_ltm                        &lt;dbl&gt; 0, 0, 0, 0, 2, 0, 0, 1, 1…\n$ number_of_reviews_l30d                       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ first_review                                 &lt;date&gt; 2011-12-19, 2011-07-30, …\n$ last_review                                  &lt;date&gt; 2020-01-17, 2019-10-13, …\n$ review_scores_rating                         &lt;dbl&gt; 4.44, 4.16, 4.41, 4.40, 4…\n$ review_scores_accuracy                       &lt;dbl&gt; 4.37, 4.22, 4.39, 4.16, 4…\n$ review_scores_cleanliness                    &lt;dbl&gt; 4.00, 4.09, 4.52, 4.26, 4…\n$ review_scores_checkin                        &lt;dbl&gt; 4.63, 4.43, 4.63, 4.47, 4…\n$ review_scores_communication                  &lt;dbl&gt; 4.78, 4.43, 4.64, 4.42, 4…\n$ review_scores_location                       &lt;dbl&gt; 4.26, 4.17, 4.50, 4.53, 4…\n$ review_scores_value                          &lt;dbl&gt; 4.32, 4.04, 4.36, 4.63, 4…\n$ license                                      &lt;chr&gt; NA, NA, NA, \"S0399\", \"S03…\n$ instant_bookable                             &lt;lgl&gt; FALSE, FALSE, FALSE, TRUE…\n$ calculated_host_listings_count               &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49…\n$ calculated_host_listings_count_entire_homes  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 1, 0, 0…\n$ calculated_host_listings_count_private_rooms &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 6, 49…\n$ calculated_host_listings_count_shared_rooms  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ reviews_per_month                            &lt;dbl&gt; 0.12, 0.15, 0.29, 0.15, 0…\n$ geometry                                     &lt;POINT [m]&gt; POINT (41972.5 3639…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.1.html#buffering",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.1.html#buffering",
    "title": "Hands-on Exercise 1a: Geospatial Data Wrangling",
    "section": "5.1 Buffering",
    "text": "5.1 Buffering\nThe scenario:\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\nThe solution:\n\nUse st_buffer() of sf package to compute the 5-meter buffers around cycling paths\n\n\ncode chunk\nbuffer_cycling &lt;- st_buffer(cyclingpath,\n                            dist=5,\n                            nQuadSegs = 30)\n\n\nCalculate the area of the buffers\n\n\ncode chunk\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\n\nDerive the total land involved using sum() of Base R\n\n\ncode chunk\nsum(buffer_cycling$AREA)\n\n\n2218855 [m^2]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.1.html#point-in-polygon-count",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.1.html#point-in-polygon-count",
    "title": "Hands-on Exercise 1a: Geospatial Data Wrangling",
    "section": "5.2 Point-in-polygon count",
    "text": "5.2 Point-in-polygon count\nThe scenario:\nA pre-school service group want to find out the numbers of pre-schools in each Planning Subzone.\nThe solution:\n\nThe code chunk below performs two operations at one go. Firstly, identify pre-schools located inside each Planning Subzone by using st_intersects(). Then, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\n\n\ncode chunk\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\n\nCheck the summary statistics of the newly derived PreSch Count field by using summary() function.\n\n\ncode chunk\nsummary(mpsz3414$`PreSch Count`)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nList the planning subzone with the most number of pre-school using top_n() of dplyr package\n\n\ncode chunk\ntop_n(mpsz3414, 1, `PreSch Count`)\n\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nDIY: Calculate the density of pre-school by planning subzone.\n\nUse st_area() of sf package to derive the area of each planning subzone.\n\n\ncode chunk\nmpsz3414$Area &lt;- mpsz3414 %&gt;%\n  st_area()\n\n\nUse mutate() of dplyr package to compute the density.\n\n\ncode chunk\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.2.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.2.html",
    "title": "Hands-on Exercise 1b: Choropleth Mapping",
    "section": "",
    "text": "In this exercise, I learn how to plot functional and truthful choropleth maps by using an R package called tmap package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.2.html#importing-geospatial-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.2.html#importing-geospatial-data-into-r",
    "title": "Hands-on Exercise 1b: Choropleth Mapping",
    "section": "3.1 Importing Geospatial Data into R",
    "text": "3.1 Importing Geospatial Data into R\nUsing st_read() to import the dataset.\n\n\ncode chunk\nmpsz &lt;- st_read(dsn = \"data/geospatial\",layer = \"MP14_SUBZONE_WEB_PL\")\n\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/cham/project/Geospatial-Analytics/chrismanafe/ISSS626-GAA/Hands-on_Ex/Hands-on_Ex01/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nExamine the content of mpsz\n\n\ncode chunk\nmpsz\n\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.2.html#importing-attribute-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.2.html#importing-attribute-data-into-r",
    "title": "Hands-on Exercise 1b: Choropleth Mapping",
    "section": "3.2 Importing Attribute Data into R",
    "text": "3.2 Importing Attribute Data into R\nNow, we will import respopagesextod2011to2020.csv file and store it in a data table named popdata. We’ll use read_csv() function of readr package\n\n\ncode chunk\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\n\nRows: 984656 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.2.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.2.html#data-preparation",
    "title": "Hands-on Exercise 1b: Choropleth Mapping",
    "section": "3.3 Data Preparation",
    "text": "3.3 Data Preparation\nBefore making a thematic map, we need to prepare a data table with year 2020 values. The data table should include following variables:\n\nYOUNG: age group 0 to 4 until age group 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n3.3.1 Data Wrangling\nWe will use following data wrangling and transformation functions to shape our data into the way we want:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\n\ncode chunk\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\n\n\n3.3.2 Joining the Attribute Data and Geospatial Data\nBefore we can perform georelational join, we need to make sure the values in the PA and SZ fields are all in uppercase. This is because these values have a mix of upper- and lowercase, while SUBZONE_N and PLN_AREA_N are all in uppercase.\n\n\ncode chunk\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\n\nNow, we’ll use left_join() from the dplyr package to connect our attribute data and geospatial data using planning subzone name(e.g.: SUBZONE_N and SZ as the common identifier.).\n\n\ncode chunk\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\nleft_join() is used with mpsz simple feature data frame as the left data table to ensure that the output will be a simple features data frame.\nFinally, use write_rds() function to save our combined data into an RDS file.\n\n\ncode chunk\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.2.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.2.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Hands-on Exercise 1b: Choropleth Mapping",
    "section": "3.4 Choropleth Mapping Geospatial Data using tmap",
    "text": "3.4 Choropleth Mapping Geospatial Data using tmap\nThere are two approaches that can be used to prepare thematic map using tmap:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\n3.4.1 Plotting a choropleth map quickly using qtm()\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\nStandard choropleth map can be generated using following code snippet.\n\n\ncode chunk\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\ncode chunk\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\n\n\n3.4.2 Creating a choropleth map by using tmap’s elements\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of qtm() is that it makes aesthetics of individual layers harder to control. It is better to use tmap’s drawing elements to draw a high quality cartographic choropleth map as shown in the figure below.\n\n\ncode chunk\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\nIn the following sub-section, we will use tmap functions that can be used to plot these elements.\n\n3.4.2.1 Drawing a base map\nBase map is created using tm_shape() followed by one or more layer elements such as tm_fill() and tm_polygons()\n\n\ncode chunk\ntm_shape(mpsz_pop2020) + tm_polygons()\n\n\n\n\n\n\n\n\n\n\n\n3.4.2.2 Drawing a choropleth map using tm_polygons()\n\n\ncode chunk\ntm_shape(mpsz_pop2020) + tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThe default interval binning used to draw the choropleth map is called “pretty”.\nThe default colour scheme used is YlOrRd of ColorBrewer.\nBy default, Missing value will be shaded in grey.\n\n\n\n\n\n3.4.2.3 Drawing a choropleth map using tm_fill() and tm_borders()\nBy using tm_fill() alone, we can generate map without any boundary in the planning subzones if the dependency value is the same.\n\n\ncode chunk\ntm_shape(mpsz_pop2020) + tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\nTo add the boundary of the planning subzones, tm_borders() will be used as shown in the code chunk below.\n\n\ncode chunk\ntm_shape(mpsz_pop2020) + tm_fill(\"DEPENDENCY\") + tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nBeside alpha argument, there are three other arguments for tm_borders(): - col = border colour, - lwd = border line width. The default is 1, and - lty = border line type. The default is solid.\n\n\n\n\n\n3.4.3 Data classification methods of tmap\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\n\n3.4.3.1 Plotting choropleth maps with built-in classification methods\n\njenksequalsdprettyquantilehclustfisher\n\n\n\n\ncode chunk\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\ncode chunk\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\ncode chunk\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"sd\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\ncode chunk\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"pretty\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\ncode chunk\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\ncode chunk\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"hclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\ncode chunk\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"fisher\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.4.4 Colour Scheme\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n3.4.4.1 Using ColourBrewer palette\nTo change the colour, we assign the preferred colour to palette argument of tm_fill() as shown in the code chunk below.\n\n\ncode chunk\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\nTo reverse the colour shading, add a “-” prefix.\n\n\ncode chunk\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"-Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n3.4.5 Map Layouts\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\n3.4.5.1 Map Legend\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\n\ncode chunk\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n3.4.5.2 Map style\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\n\ncode chunk\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\ntmap style set to \"classic\"\n\n\nother available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"watercolor\" \n\n\n\n\n\n\n\n\n\n\n\n3.4.5.3 Cartographic Furniture\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\n\ncode chunk\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\nTo reset the default style, refer to the code chunk below.\n\n\ncode chunk\ntmap_style(\"white\")\n\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n3.4.6 Drawing Small Multiple Choropleth Maps\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n3.4.6.1 By assigning multiple values to at least one of the aesthetic arguments\nWe can create small multiple choropleth maps by defining ncols in tm_fill()\n\n\ncode chunk\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\n\n\n\nWe also can create small multiple choropleth maps by assigning multiple values to at least one of the aesthetic arguments.\n\n\ncode chunk\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\n3.4.6.2 By defining a group-by variable in tm_facets()\nWe can also create multiple small choropleth maps by defining a group-by variable in tm_facets()\n\n\ncode chunk\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\nWarning: The argument drop.shapes has been renamed to drop.units, and is\ntherefore deprecated\n\n\n\n\n\n\n\n\n\n\n\n3.4.6.3 By creating multiple stand-alone maps with tmap_arrange()\nWe could also create multiple stand-alone maps with tmap_arrange()\n\n\ncode chunk\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\n3.4.7 Mappping Spatial Object Meeting a Selection Criterion\nInstead of creating small multiple choropleth maps, you can use selection functions to map spatial objects meeting specific criteria. This allows you to focus on specific regions or areas in the map based on your selection criterion. The following code choose Central Region as example\n\n\ncode chunk\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\nWarning in pre_process_gt(x, interactive = interactive, orig_crs =\ngm$shape.orig_crs): legend.width controls the width of the legend within a map.\nPlease use legend.outside.size to control the width of the outside legend"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.2.html#creating-a-choropleth-map-by-using-tmaps-elements",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.2.html#creating-a-choropleth-map-by-using-tmaps-elements",
    "title": "Hands-on Exercise 1.2: Choropleth Mapping with R",
    "section": "Creating a choropleth map by using tmap’s elements",
    "text": "Creating a choropleth map by using tmap’s elements\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of qtm() is that it makes aesthetics of individual layers harder to control. It is better to use tmap’s drawing elements to draw a high quality cartographic choropleth map as shown in the figure below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nIn the following sub-section, we will use tmap functions that can be used to plot these elements.\n\nDrawing a base map\nBase map is created using tm_shape() followed by one or more layer elements such as tm_fill() and tm_polygons()\n\ntm_shape(mpsz_pop2020) + tm_polygons()\n\n\n\n\n\n\n\n\n\n\nDrawing a choropleth map using tm_polygons()\n\ntm_shape(mpsz_pop2020) + tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThe default interval binning used to draw the choropleth map is called “pretty”.\nThe default colour scheme used is YlOrRd of ColorBrewer.\nBy default, Missing value will be shaded in grey."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex01/hands-on_ex01.2.html",
    "href": "hands_on_ex/hands_on_ex01/hands-on_ex01.2.html",
    "title": "Hands-on Exercise 1b: Choropleth Mapping",
    "section": "",
    "text": "In this exercise, I learn how to plot functional and truthful choropleth maps by using an R package called tmap package."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex01/hands-on_ex01.2.html#importing-geospatial-data-into-r",
    "href": "hands_on_ex/hands_on_ex01/hands-on_ex01.2.html#importing-geospatial-data-into-r",
    "title": "Hands-on Exercise 1b: Choropleth Mapping",
    "section": "3.1 Importing Geospatial Data into R",
    "text": "3.1 Importing Geospatial Data into R\nUsing st_read() to import the dataset.\n\n\ncode chunk\nmpsz &lt;- st_read(dsn = \"data/geospatial\",layer = \"MP14_SUBZONE_WEB_PL\")\n\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/cham/project/Geospatial-Analytics/chrismanafe/ISSS626-GAA/hands_on_ex/hands_on_ex01/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nExamine the content of mpsz\n\n\ncode chunk\nmpsz\n\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29..."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex01/hands-on_ex01.2.html#importing-attribute-data-into-r",
    "href": "hands_on_ex/hands_on_ex01/hands-on_ex01.2.html#importing-attribute-data-into-r",
    "title": "Hands-on Exercise 1b: Choropleth Mapping",
    "section": "3.2 Importing Attribute Data into R",
    "text": "3.2 Importing Attribute Data into R\nNow, we will import respopagesextod2011to2020.csv file and store it in a data table named popdata. We’ll use read_csv() function of readr package\n\n\ncode chunk\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\n\nRows: 984656 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex01/hands-on_ex01.2.html#data-preparation",
    "href": "hands_on_ex/hands_on_ex01/hands-on_ex01.2.html#data-preparation",
    "title": "Hands-on Exercise 1b: Choropleth Mapping",
    "section": "3.3 Data Preparation",
    "text": "3.3 Data Preparation\nBefore making a thematic map, we need to prepare a data table with year 2020 values. The data table should include following variables:\n\nYOUNG: age group 0 to 4 until age group 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n3.3.1 Data Wrangling\nWe will use following data wrangling and transformation functions to shape our data into the way we want:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\n\ncode chunk\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\n\n\n3.3.2 Joining the Attribute Data and Geospatial Data\nBefore we can perform georelational join, we need to make sure the values in the PA and SZ fields are all in uppercase. This is because these values have a mix of upper- and lowercase, while SUBZONE_N and PLN_AREA_N are all in uppercase.\n\n\ncode chunk\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\n\nNow, we’ll use left_join() from the dplyr package to connect our attribute data and geospatial data using planning subzone name(e.g.: SUBZONE_N and SZ as the common identifier.).\n\n\ncode chunk\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\nleft_join() is used with mpsz simple feature data frame as the left data table to ensure that the output will be a simple features data frame.\nFinally, use write_rds() function to save our combined data into an RDS file.\n\n\ncode chunk\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex01/hands-on_ex01.2.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "hands_on_ex/hands_on_ex01/hands-on_ex01.2.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Hands-on Exercise 1b: Choropleth Mapping",
    "section": "3.4 Choropleth Mapping Geospatial Data using tmap",
    "text": "3.4 Choropleth Mapping Geospatial Data using tmap\nThere are two approaches that can be used to prepare thematic map using tmap:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\n3.4.1 Plotting a choropleth map quickly using qtm()\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\nStandard choropleth map can be generated using following code snippet.\n\n\ncode chunk\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\ncode chunk\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\n\n\n3.4.2 Creating a choropleth map by using tmap’s elements\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of qtm() is that it makes aesthetics of individual layers harder to control. It is better to use tmap’s drawing elements to draw a high quality cartographic choropleth map as shown in the figure below.\n\n\ncode chunk\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\nIn the following sub-section, we will use tmap functions that can be used to plot these elements.\n\n3.4.2.1 Drawing a base map\nBase map is created using tm_shape() followed by one or more layer elements such as tm_fill() and tm_polygons()\n\n\ncode chunk\ntm_shape(mpsz_pop2020) + tm_polygons()\n\n\n\n\n\n\n\n\n\n\n\n3.4.2.2 Drawing a choropleth map using tm_polygons()\n\n\ncode chunk\ntm_shape(mpsz_pop2020) + tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThe default interval binning used to draw the choropleth map is called “pretty”.\nThe default colour scheme used is YlOrRd of ColorBrewer.\nBy default, Missing value will be shaded in grey.\n\n\n\n\n\n3.4.2.3 Drawing a choropleth map using tm_fill() and tm_borders()\nBy using tm_fill() alone, we can generate map without any boundary in the planning subzones if the dependency value is the same.\n\n\ncode chunk\ntm_shape(mpsz_pop2020) + tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\nTo add the boundary of the planning subzones, tm_borders() will be used as shown in the code chunk below.\n\n\ncode chunk\ntm_shape(mpsz_pop2020) + tm_fill(\"DEPENDENCY\") + tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nBeside alpha argument, there are three other arguments for tm_borders(): - col = border colour, - lwd = border line width. The default is 1, and - lty = border line type. The default is solid.\n\n\n\n\n\n3.4.3 Data classification methods of tmap\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\n\n3.4.3.1 Plotting choropleth maps with built-in classification methods\n\njenksequalsdprettyquantilehclustfisher\n\n\n\n\ncode chunk\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\ncode chunk\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\ncode chunk\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"sd\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\ncode chunk\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"pretty\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\ncode chunk\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\ncode chunk\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"hclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\ncode chunk\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"fisher\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.4.4 Colour Scheme\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n3.4.4.1 Using ColourBrewer palette\nTo change the colour, we assign the preferred colour to palette argument of tm_fill() as shown in the code chunk below.\n\n\ncode chunk\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\nTo reverse the colour shading, add a “-” prefix.\n\n\ncode chunk\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"-Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n3.4.5 Map Layouts\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\n3.4.5.1 Map Legend\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\n\ncode chunk\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n3.4.5.2 Map style\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\n\ncode chunk\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\ntmap style set to \"classic\"\n\n\nother available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"watercolor\" \n\n\n\n\n\n\n\n\n\n\n\n3.4.5.3 Cartographic Furniture\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\n\ncode chunk\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\nTo reset the default style, refer to the code chunk below.\n\n\ncode chunk\ntmap_style(\"white\")\n\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n3.4.6 Drawing Small Multiple Choropleth Maps\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n3.4.6.1 By assigning multiple values to at least one of the aesthetic arguments\nWe can create small multiple choropleth maps by defining ncols in tm_fill()\n\n\ncode chunk\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\n\n\n\nWe also can create small multiple choropleth maps by assigning multiple values to at least one of the aesthetic arguments.\n\n\ncode chunk\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\n3.4.6.2 By defining a group-by variable in tm_facets()\nWe can also create multiple small choropleth maps by defining a group-by variable in tm_facets()\n\n\ncode chunk\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\nWarning: The argument drop.shapes has been renamed to drop.units, and is\ntherefore deprecated\n\n\n\n\n\n\n\n\n\n\n\n3.4.6.3 By creating multiple stand-alone maps with tmap_arrange()\nWe could also create multiple stand-alone maps with tmap_arrange()\n\n\ncode chunk\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\n3.4.7 Mappping Spatial Object Meeting a Selection Criterion\nInstead of creating small multiple choropleth maps, you can use selection functions to map spatial objects meeting specific criteria. This allows you to focus on specific regions or areas in the map based on your selection criterion. The following code choose Central Region as example\n\n\ncode chunk\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\nWarning in pre_process_gt(x, interactive = interactive, orig_crs =\ngm$shape.orig_crs): legend.width controls the width of the legend within a map.\nPlease use legend.outside.size to control the width of the outside legend"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex01/hands_on_ex01.1.html",
    "href": "hands_on_ex/hands_on_ex01/hands_on_ex01.1.html",
    "title": "Hands-on Exercise 1a: Geospatial Data Wrangling",
    "section": "",
    "text": "In this hands-on exercise, I learn how to import and wrangle geospatial data using appropriate R packages."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex01/hands_on_ex01.1.html#importing-polygon-feature-data",
    "href": "hands_on_ex/hands_on_ex01/hands_on_ex01.1.html#importing-polygon-feature-data",
    "title": "Hands-on Exercise 1a: Geospatial Data Wrangling",
    "section": "3.1 Importing polygon feature data",
    "text": "3.1 Importing polygon feature data\nDataset sources:\n\nMaster Plan 2014 Subzone Boundary (Web) from data.gov.sg\nPre-Schools Location from data.gov.sg\nCycling Path from LTADataMall\nLatest version of Singapore Airbnb listing data from Inside Airbnb\n\nUsing st_read() to import the dataset. ### Polygon data in shapefile format\n\n\ncode chunk\nmpsz = st_read(dsn = \"data/geospatial\",\n               layer = \"MP14_SUBZONE_WEB_PL\")\n\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/cham/project/Geospatial-Analytics/chrismanafe/ISSS626-GAA/hands_on_ex/hands_on_ex01/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n3.1.1 Polyline data in shapefile format\n\n\ncode chunk\ncyclingpath = st_read(dsn = \"data/geospatial\",\n                      layer = \"CyclingPathGazette\")\n\n\nReading layer `CyclingPathGazette' from data source \n  `/Users/cham/project/Geospatial-Analytics/chrismanafe/ISSS626-GAA/hands_on_ex/hands_on_ex01/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3138 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42644.17 ymax: 48948.15\nProjected CRS: SVY21\n\n\n\n\n3.1.2 GIS data in KML format\n\n\ncode chunk\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `/Users/cham/project/Geospatial-Analytics/chrismanafe/ISSS626-GAA/hands_on_ex/hands_on_ex01/data/geospatial/PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex01/hands_on_ex01.1.html#checking-content-of-a-simple-data-frame",
    "href": "hands_on_ex/hands_on_ex01/hands_on_ex01.1.html#checking-content-of-a-simple-data-frame",
    "title": "Hands-on Exercise 1a: Geospatial Data Wrangling",
    "section": "3.2 Checking content of a simple data frame",
    "text": "3.2 Checking content of a simple data frame\n\nExtracting geometric information using sf_geometry()\n\n\ncode chunk\nst_geometry(mpsz)\n\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303...\n\n\nData structure overview using glimpse()\n\n\ncode chunk\nglimpse(mpsz)\n\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\nData preview using head()\n\n\ncode chunk\nhead(mpsz, n=5)\n\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30..."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex01/hands_on_ex01.1.html#visualizing-the-geospatial-data",
    "href": "hands_on_ex/hands_on_ex01/hands_on_ex01.1.html#visualizing-the-geospatial-data",
    "title": "Hands-on Exercise 1a: Geospatial Data Wrangling",
    "section": "3.3 Visualizing the geospatial data",
    "text": "3.3 Visualizing the geospatial data\n\nUsing plot() of R Graphic to visualize the geospatial features from the data.\n\n\ncode chunk\nplot(mpsz)\n\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\nPlot only the geometry attributes\n\n\ncode chunk\nplot(st_geometry(mpsz))\n\n\n\n\n\n\n\n\n\nPlot only specific attributes (e.g.: PLN_AREA_N)\n\n\ncode chunk\nplot(mpsz[\"PLN_AREA_N\"])"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex01/hands_on_ex01.1.html#assigning-epsg-code-to-simple-feature-data-frame",
    "href": "hands_on_ex/hands_on_ex01/hands_on_ex01.1.html#assigning-epsg-code-to-simple-feature-data-frame",
    "title": "Hands-on Exercise 1a: Geospatial Data Wrangling",
    "section": "3.4 Assigning EPSG code to simple feature data frame",
    "text": "3.4 Assigning EPSG code to simple feature data frame\nThis is an example the coordinate system of mpsz simple feature data frame by using st_crs() of sf package\n\n\ncode chunk\nst_crs(mpsz)\n\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough mpsz data frame is projected in svy21 but it indicates that the EPSG is 9001. This is a wrong EPSG code because the correct EPSG code for svy21 should be 3414.\nAssign correct EPSG code to mpsz data frame:\n\n\ncode chunk\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nCheck CSR again\n\n\ncode chunk\nst_crs(mpsz3414)\n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex01/hands_on_ex01.1.html#transforming-the-projection-of-preschool-from-wgs84-to-svy21",
    "href": "hands_on_ex/hands_on_ex01/hands_on_ex01.1.html#transforming-the-projection-of-preschool-from-wgs84-to-svy21",
    "title": "Hands-on Exercise 1a: Geospatial Data Wrangling",
    "section": "3.5 Transforming the projection of preschool from wgs84 to svy21",
    "text": "3.5 Transforming the projection of preschool from wgs84 to svy21\nReproject preschool from one coordinate system to another coordinate system mathemetically\n\n\ncode chunk\npreschool3414 &lt;- st_transform(preschool,\n                              crs = 3414)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex01/hands_on_ex01.1.html#import-listing-data",
    "href": "hands_on_ex/hands_on_ex01/hands_on_ex01.1.html#import-listing-data",
    "title": "Hands-on Exercise 1a: Geospatial Data Wrangling",
    "section": "4.1 Import listing data",
    "text": "4.1 Import listing data\n\n\ncode chunk\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\n\nRows: 3540 Columns: 75\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (26): listing_url, source, name, description, neighborhood_overview, pi...\ndbl  (38): id, scrape_id, host_id, host_listings_count, host_total_listings_...\nlgl   (6): host_is_superhost, host_has_profile_pic, host_identity_verified, ...\ndate  (5): last_scraped, host_since, calendar_last_scraped, first_review, la...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCheck the dataset after importing to see if its imported correctly."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex01/hands_on_ex01.1.html#create-simple-feature-data-frame-from-aspatial-data-frame",
    "href": "hands_on_ex/hands_on_ex01/hands_on_ex01.1.html#create-simple-feature-data-frame-from-aspatial-data-frame",
    "title": "Hands-on Exercise 1a: Geospatial Data Wrangling",
    "section": "4.2 Create simple feature data frame from aspatial data frame",
    "text": "4.2 Create simple feature data frame from aspatial data frame\nConvert listing data frame into simple feature data frame using st_as_sf()\n\n\ncode chunk\nlistings_sf &lt;- st_as_sf(listings,\n                        coords = c(\"longitude\", \"latitude\"),\n                        crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\n\nExamine the content of newly created data frame.\n\n\ncode chunk\nglimpse(listings_sf)\n\n\nRows: 3,540\nColumns: 74\n$ id                                           &lt;dbl&gt; 71609, 71896, 71903, 2753…\n$ listing_url                                  &lt;chr&gt; \"https://www.airbnb.com/r…\n$ scrape_id                                    &lt;dbl&gt; 2.024063e+13, 2.024063e+1…\n$ last_scraped                                 &lt;date&gt; 2024-06-29, 2024-06-29, …\n$ source                                       &lt;chr&gt; \"previous scrape\", \"city …\n$ name                                         &lt;chr&gt; \"Ensuite Room (Room 1 & 2…\n$ description                                  &lt;chr&gt; \"For 3 rooms.Book room 1 …\n$ neighborhood_overview                        &lt;chr&gt; NA, NA, \"Quiet and view o…\n$ picture_url                                  &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_id                                      &lt;dbl&gt; 367042, 367042, 367042, 1…\n$ host_url                                     &lt;chr&gt; \"https://www.airbnb.com/u…\n$ host_name                                    &lt;chr&gt; \"Belinda\", \"Belinda\", \"Be…\n$ host_since                                   &lt;date&gt; 2011-01-29, 2011-01-29, …\n$ host_location                                &lt;chr&gt; \"Singapore\", \"Singapore\",…\n$ host_about                                   &lt;chr&gt; \"Hi My name is Belinda -H…\n$ host_response_time                           &lt;chr&gt; \"within an hour\", \"within…\n$ host_response_rate                           &lt;chr&gt; \"100%\", \"100%\", \"100%\", \"…\n$ host_acceptance_rate                         &lt;chr&gt; \"N/A\", \"N/A\", \"N/A\", \"99%…\n$ host_is_superhost                            &lt;lgl&gt; FALSE, FALSE, FALSE, FALS…\n$ host_thumbnail_url                           &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_picture_url                             &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_neighbourhood                           &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ host_listings_count                          &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49…\n$ host_total_listings_count                    &lt;dbl&gt; 11, 11, 11, 73, 73, 11, 8…\n$ host_verifications                           &lt;chr&gt; \"['email', 'phone']\", \"['…\n$ host_has_profile_pic                         &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ host_identity_verified                       &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ neighbourhood                                &lt;chr&gt; NA, NA, \"Singapore, Singa…\n$ neighbourhood_cleansed                       &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ neighbourhood_group_cleansed                 &lt;chr&gt; \"East Region\", \"East Regi…\n$ property_type                                &lt;chr&gt; \"Private room in villa\", …\n$ room_type                                    &lt;chr&gt; \"Private room\", \"Private …\n$ accommodates                                 &lt;dbl&gt; 3, 1, 2, 1, 1, 4, 2, 1, 1…\n$ bathrooms                                    &lt;dbl&gt; NA, 0.5, 0.5, 2.0, 2.5, N…\n$ bathrooms_text                               &lt;chr&gt; \"1 private bath\", \"Shared…\n$ bedrooms                                     &lt;dbl&gt; 2, 1, 1, 1, 1, 3, 2, 1, 1…\n$ beds                                         &lt;dbl&gt; NA, 1, 2, 1, 1, NA, 1, 1,…\n$ amenities                                    &lt;chr&gt; \"[\\\"Free parking on premi…\n$ price                                        &lt;chr&gt; NA, \"$80.00\", \"$80.00\", \"…\n$ minimum_nights                               &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_nights                               &lt;dbl&gt; 365, 365, 365, 999, 999, …\n$ minimum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ minimum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ maximum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ minimum_nights_avg_ntm                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_nights_avg_ntm                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ calendar_updated                             &lt;lgl&gt; NA, NA, NA, NA, NA, NA, N…\n$ has_availability                             &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ availability_30                              &lt;dbl&gt; 30, 30, 30, 28, 0, 29, 30…\n$ availability_60                              &lt;dbl&gt; 59, 53, 60, 58, 0, 58, 60…\n$ availability_90                              &lt;dbl&gt; 89, 83, 90, 62, 0, 88, 90…\n$ availability_365                             &lt;dbl&gt; 89, 148, 90, 62, 0, 88, 3…\n$ calendar_last_scraped                        &lt;date&gt; 2024-06-29, 2024-06-29, …\n$ number_of_reviews                            &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 1…\n$ number_of_reviews_ltm                        &lt;dbl&gt; 0, 0, 0, 0, 2, 0, 0, 1, 1…\n$ number_of_reviews_l30d                       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ first_review                                 &lt;date&gt; 2011-12-19, 2011-07-30, …\n$ last_review                                  &lt;date&gt; 2020-01-17, 2019-10-13, …\n$ review_scores_rating                         &lt;dbl&gt; 4.44, 4.16, 4.41, 4.40, 4…\n$ review_scores_accuracy                       &lt;dbl&gt; 4.37, 4.22, 4.39, 4.16, 4…\n$ review_scores_cleanliness                    &lt;dbl&gt; 4.00, 4.09, 4.52, 4.26, 4…\n$ review_scores_checkin                        &lt;dbl&gt; 4.63, 4.43, 4.63, 4.47, 4…\n$ review_scores_communication                  &lt;dbl&gt; 4.78, 4.43, 4.64, 4.42, 4…\n$ review_scores_location                       &lt;dbl&gt; 4.26, 4.17, 4.50, 4.53, 4…\n$ review_scores_value                          &lt;dbl&gt; 4.32, 4.04, 4.36, 4.63, 4…\n$ license                                      &lt;chr&gt; NA, NA, NA, \"S0399\", \"S03…\n$ instant_bookable                             &lt;lgl&gt; FALSE, FALSE, FALSE, TRUE…\n$ calculated_host_listings_count               &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49…\n$ calculated_host_listings_count_entire_homes  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 1, 0, 0…\n$ calculated_host_listings_count_private_rooms &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 6, 49…\n$ calculated_host_listings_count_shared_rooms  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ reviews_per_month                            &lt;dbl&gt; 0.12, 0.15, 0.29, 0.15, 0…\n$ geometry                                     &lt;POINT [m]&gt; POINT (41972.5 3639…"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex01/hands_on_ex01.1.html#buffering",
    "href": "hands_on_ex/hands_on_ex01/hands_on_ex01.1.html#buffering",
    "title": "Hands-on Exercise 1a: Geospatial Data Wrangling",
    "section": "5.1 Buffering",
    "text": "5.1 Buffering\nThe scenario:\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\nThe solution:\n\nUse st_buffer() of sf package to compute the 5-meter buffers around cycling paths\n\n\ncode chunk\nbuffer_cycling &lt;- st_buffer(cyclingpath,\n                            dist=5,\n                            nQuadSegs = 30)\n\n\nCalculate the area of the buffers\n\n\ncode chunk\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\n\nDerive the total land involved using sum() of Base R\n\n\ncode chunk\nsum(buffer_cycling$AREA)\n\n\n2218855 [m^2]"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex01/hands_on_ex01.1.html#point-in-polygon-count",
    "href": "hands_on_ex/hands_on_ex01/hands_on_ex01.1.html#point-in-polygon-count",
    "title": "Hands-on Exercise 1a: Geospatial Data Wrangling",
    "section": "5.2 Point-in-polygon count",
    "text": "5.2 Point-in-polygon count\nThe scenario:\nA pre-school service group want to find out the numbers of pre-schools in each Planning Subzone.\nThe solution:\n\nThe code chunk below performs two operations at one go. Firstly, identify pre-schools located inside each Planning Subzone by using st_intersects(). Then, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\n\n\ncode chunk\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\n\nCheck the summary statistics of the newly derived PreSch Count field by using summary() function.\n\n\ncode chunk\nsummary(mpsz3414$`PreSch Count`)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nList the planning subzone with the most number of pre-school using top_n() of dplyr package\n\n\ncode chunk\ntop_n(mpsz3414, 1, `PreSch Count`)\n\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nDIY: Calculate the density of pre-school by planning subzone.\n\nUse st_area() of sf package to derive the area of each planning subzone.\n\n\ncode chunk\nmpsz3414$Area &lt;- mpsz3414 %&gt;%\n  st_area()\n\n\nUse mutate() of dplyr package to compute the density.\n\n\ncode chunk\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex01/hands_on_ex01.2.html",
    "href": "hands_on_ex/hands_on_ex01/hands_on_ex01.2.html",
    "title": "Hands-on Exercise 1b: Choropleth Mapping",
    "section": "",
    "text": "In this exercise, I learn how to plot functional and truthful choropleth maps by using an R package called tmap package."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex01/hands_on_ex01.2.html#importing-geospatial-data-into-r",
    "href": "hands_on_ex/hands_on_ex01/hands_on_ex01.2.html#importing-geospatial-data-into-r",
    "title": "Hands-on Exercise 1b: Choropleth Mapping",
    "section": "3.1 Importing Geospatial Data into R",
    "text": "3.1 Importing Geospatial Data into R\nUsing st_read() to import the dataset.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\",layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/cham/project/Geospatial-Analytics/chrismanafe/ISSS626-GAA/hands_on_ex/hands_on_ex01/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nExamine the content of mpsz\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29..."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex01/hands_on_ex01.2.html#importing-attribute-data-into-r",
    "href": "hands_on_ex/hands_on_ex01/hands_on_ex01.2.html#importing-attribute-data-into-r",
    "title": "Hands-on Exercise 1b: Choropleth Mapping",
    "section": "3.2 Importing Attribute Data into R",
    "text": "3.2 Importing Attribute Data into R\nNow, we will import respopagesextod2011to2020.csv file and store it in a data table named popdata. We’ll use read_csv() function of readr package\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\nRows: 984656 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex01/hands_on_ex01.2.html#data-preparation",
    "href": "hands_on_ex/hands_on_ex01/hands_on_ex01.2.html#data-preparation",
    "title": "Hands-on Exercise 1b: Choropleth Mapping",
    "section": "3.3 Data Preparation",
    "text": "3.3 Data Preparation\nBefore making a thematic map, we need to prepare a data table with year 2020 values. The data table should include following variables:\n\nYOUNG: age group 0 to 4 until age group 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n3.3.1 Data Wrangling\nWe will use following data wrangling and transformation functions to shape our data into the way we want:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[14])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\n\n\n3.3.2 Joining the Attribute Data and Geospatial Data\nBefore we can perform georelational join, we need to make sure the values in the PA and SZ fields are all in uppercase. This is because these values have a mix of upper- and lowercase, while SUBZONE_N and PLN_AREA_N are all in uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nNow, we’ll use left_join() from the dplyr package to connect our attribute data and geospatial data using planning subzone name(e.g.: SUBZONE_N and SZ as the common identifier.).\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\nclass(mpsz)\n\n[1] \"sf\"         \"data.frame\"\n\n\nleft_join() is used with mpsz simple feature data frame as the left data table to ensure that the output will be a simple features data frame.\nFinally, use write_rds() function to save our combined data into an RDS file.\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex01/hands_on_ex01.2.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "hands_on_ex/hands_on_ex01/hands_on_ex01.2.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Hands-on Exercise 1b: Choropleth Mapping",
    "section": "3.4 Choropleth Mapping Geospatial Data using tmap",
    "text": "3.4 Choropleth Mapping Geospatial Data using tmap\nThere are two approaches that can be used to prepare thematic map using tmap:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\n3.4.1 Plotting a choropleth map quickly using qtm()\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\nStandard choropleth map can be generated using following code snippet.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\n\n3.4.2 Creating a choropleth map by using tmap’s elements\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of qtm() is that it makes aesthetics of individual layers harder to control. It is better to use tmap’s drawing elements to draw a high quality cartographic choropleth map as shown in the figure below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nIn the following sub-section, we will use tmap functions that can be used to plot these elements.\n\n3.4.2.1 Drawing a base map\nBase map is created using tm_shape() followed by one or more layer elements such as tm_fill() and tm_polygons()\n\ntm_shape(mpsz_pop2020) + tm_polygons()\n\n\n\n\n\n\n\n\n\n\n3.4.2.2 Drawing a choropleth map using tm_polygons()\n\ntm_shape(mpsz_pop2020) + tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThe default interval binning used to draw the choropleth map is called “pretty”.\nThe default colour scheme used is YlOrRd of ColorBrewer.\nBy default, Missing value will be shaded in grey.\n\n\n\n\n\n3.4.2.3 Drawing a choropleth map using tm_fill() and tm_borders()\nBy using tm_fill() alone, we can generate map without any boundary in the planning subzones if the dependency value is the same.\n\ntm_shape(mpsz_pop2020) + tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nTo add the boundary of the planning subzones, tm_borders() will be used as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020) + tm_fill(\"DEPENDENCY\") + tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nBeside alpha argument, there are three other arguments for tm_borders(): - col = border colour, - lwd = border line width. The default is 1, and - lty = border line type. The default is solid.\n\n\n\n\n\n3.4.3 Data classification methods of tmap\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\n\n3.4.3.1 Plotting choropleth maps with built-in classification methods\n\njenksequalsdprettyquantilehclustfisher\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"sd\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"pretty\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"hclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"fisher\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.4.4 Colour Scheme\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n3.4.4.1 Using ColourBrewer palette\nTo change the colour, we assign the preferred colour to palette argument of tm_fill() as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nTo reverse the colour shading, add a “-” prefix.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"-Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n3.4.5 Map Layouts\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\n3.4.5.1 Map Legend\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n3.4.5.2 Map style\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\ntmap style set to \"classic\"\n\n\nother available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"watercolor\" \n\n\n\n\n\n\n\n\n\n\n\n3.4.5.3 Cartographic Furniture\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nTo reset the default style, refer to the code chunk below.\n\ntmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n3.4.6 Drawing Small Multiple Choropleth Maps\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n3.4.6.1 By assigning multiple values to at least one of the aesthetic arguments\nWe can create small multiple choropleth maps by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\n\n\n\nWe also can create small multiple choropleth maps by assigning multiple values to at least one of the aesthetic arguments.\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n3.4.6.2 By defining a group-by variable in tm_facets()\nWe can also create multiple small choropleth maps by defining a group-by variable in tm_facets()\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\nWarning: The argument drop.shapes has been renamed to drop.units, and is\ntherefore deprecated\n\n\n\n\n\n\n\n\n\n\n\n3.4.6.3 By creating multiple stand-alone maps with tmap_arrange()\nWe could also create multiple stand-alone maps with tmap_arrange()\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n3.4.7 Mappping Spatial Object Meeting a Selection Criterion\nInstead of creating small multiple choropleth maps, you can use selection functions to map spatial objects meeting specific criteria. This allows you to focus on specific regions or areas in the map based on your selection criterion. The following code choose Central Region as example\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\nWarning in pre_process_gt(x, interactive = interactive, orig_crs =\ngm$shape.orig_crs): legend.width controls the width of the legend within a map.\nPlease use legend.outside.size to control the width of the outside legend"
  },
  {
    "objectID": "in_class_ex/in_class_ex01/data/MPSZ-2019.html",
    "href": "in_class_ex/in_class_ex01/data/MPSZ-2019.html",
    "title": "ISSS626-GAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "in_class_ex/in_class_ex01/in_class_ex01.html",
    "href": "in_class_ex/in_class_ex01/in_class_ex01.html",
    "title": "In-class Exercise 1: Geospatial Analytics",
    "section": "",
    "text": "Loading following packages in R environment\n\n\ncode chunk\npacman::p_load(sf, tidyverse, tmap, ggstatsplot)"
  },
  {
    "objectID": "in_class_ex/in_class_ex01/in_class_ex01.html#loading-the-kml-file",
    "href": "in_class_ex/in_class_ex01/in_class_ex01.html#loading-the-kml-file",
    "title": "In-class Exercise 1: Geospatial Analytics",
    "section": "3.1 Loading the kml file",
    "text": "3.1 Loading the kml file\n\n\ncode chunk\npreschool_kml &lt;- st_read(\"data/PreSchoolsLocation.kml\")\n\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `/Users/cham/project/Geospatial-Analytics/chrismanafe/ISSS626-GAA/in_class_ex/in_class_ex01/data/PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "in_class_ex/in_class_ex01/in_class_ex01.html#loading-the-geojson-file",
    "href": "in_class_ex/in_class_ex01/in_class_ex01.html#loading-the-geojson-file",
    "title": "In-class Exercise 1: Geospatial Analytics",
    "section": "3.2 Loading the geojson file",
    "text": "3.2 Loading the geojson file\n\n\ncode chunk\npreschool_kml &lt;- st_read(\"data/PreSchoolsLocation.kml\")\n\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `/Users/cham/project/Geospatial-Analytics/chrismanafe/ISSS626-GAA/in_class_ex/in_class_ex01/data/PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "in_class_ex/in_class_ex01/in_class_ex01.html#handling-coordinate-systems",
    "href": "in_class_ex/in_class_ex01/in_class_ex01.html#handling-coordinate-systems",
    "title": "In-class Exercise 1: Geospatial Analytics",
    "section": "4.1 Handling coordinate systems",
    "text": "4.1 Handling coordinate systems\nCheck the project for the imported sf objects.\n\n\ncode chunk\nst_crs(mpsz19_shp)\n\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\nThe CRS of mpsz19 is in WGS 84, which is a Geographical Coordinate System, useful in GPS to pinpoint a specific location, and the unit of measurement is in decimal degree. However, it is not suitable for geospatial analysis as the distance measurement of decimal degree is distorted. We will transform it from geographic coordinate system to projected coordinate system.\n\n\ncode chunk\nmpsz19_shp &lt;- st_read(dsn = \"data/\",\n                layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\n\nReading layer `MPSZ-2019' from data source \n  `/Users/cham/project/Geospatial-Analytics/chrismanafe/ISSS626-GAA/in_class_ex/in_class_ex01/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\ncode chunk\npreschool &lt;- st_read(\"data/PreSchoolsLocation.kml\") %&gt;%\n  st_transform(crs = 3414)\n\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `/Users/cham/project/Geospatial-Analytics/chrismanafe/ISSS626-GAA/in_class_ex/in_class_ex01/data/PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "in_class_ex/in_class_ex01/in_class_ex01.html#geospatial-data-wrangling",
    "href": "in_class_ex/in_class_ex01/in_class_ex01.html#geospatial-data-wrangling",
    "title": "In-class Exercise 1: Geospatial Analytics",
    "section": "4.2 Geospatial Data Wrangling",
    "text": "4.2 Geospatial Data Wrangling\n\n4.2.1 Point-in-polygon count\nWe’ll need to count the number of pre-schools in each planning sub-zone.\n\n\ncode chunk\nmpsz19_shp &lt;- mpsz19_shp %&gt;%\n  mutate(`PreSch Count` = lengths(\n    st_intersects(mpsz19_shp, preschool)))\n\n\nThen to compute the density of pre-school at the planning sub-zone level\n\n\ncode chunk\nmpsz19_shp &lt;- mpsz19_shp %&gt;%\n  mutate(Area = units::drop_units(\n    st_area(.)),\n    `PreSch Density` = `PreSch Count` / Area * 1000000\n  )"
  },
  {
    "objectID": "in_class_ex/in_class_ex01/in_class_ex01.html#data-preparation",
    "href": "in_class_ex/in_class_ex01/in_class_ex01.html#data-preparation",
    "title": "In-class Exercise 1: Geospatial Analytics",
    "section": "9.1 Data preparation",
    "text": "9.1 Data preparation\nFirstly, we’ll exclude records with NA\n\n\ncode chunk\nmpsz_pop2023 &lt;- mpsz_pop2023 %&gt;%\n  drop_na()"
  },
  {
    "objectID": "in_class_ex/in_class_ex01/in_class_ex01.html#define-get-function",
    "href": "in_class_ex/in_class_ex01/in_class_ex01.html#define-get-function",
    "title": "In-class Exercise 1: Geospatial Analytics",
    "section": "9.2 Define get function",
    "text": "9.2 Define get function\nDefines a function to get the input data and field to be used for creating the percentile map.\n\n\ncode chunk\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% \n    st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}"
  },
  {
    "objectID": "in_class_ex/in_class_ex01/in_class_ex01.html#define-percentile-mapping-function",
    "href": "in_class_ex/in_class_ex01/in_class_ex01.html#define-percentile-mapping-function",
    "title": "In-class Exercise 1: Geospatial Analytics",
    "section": "9.3 Define percentile mapping function",
    "text": "9.3 Define percentile mapping function\nDefine function for computing and plotting the percentile map.\n\n\ncode chunk\npercentmap &lt;- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent &lt;- c(0,.01,.1,.5,.9,.99,1)\n  var &lt;- get.var(vnam, df)\n  bperc &lt;- quantile(var, percent)\n  tm_shape(mpsz_pop2023) +\n  tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"&lt; 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"&gt; 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"right\",\"bottom\"))\n}"
  },
  {
    "objectID": "in_class_ex/in_class_ex01/in_class_ex01.html#use-the-functions",
    "href": "in_class_ex/in_class_ex01/in_class_ex01.html#use-the-functions",
    "title": "In-class Exercise 1: Geospatial Analytics",
    "section": "9.4 Use the functions",
    "text": "9.4 Use the functions\nLet’s run the newly created percentile map function.\n\n\ncode chunk\npercentmap(\"DEPENDENCY\", mpsz_pop2023)"
  },
  {
    "objectID": "in_class_ex/in_class_ex01/in_class_ex01.html#define-the-boxbreaks-function",
    "href": "in_class_ex/in_class_ex01/in_class_ex01.html#define-the-boxbreaks-function",
    "title": "In-class Exercise 1: Geospatial Analytics",
    "section": "10.1 Define the boxbreaks function",
    "text": "10.1 Define the boxbreaks function\nLet’s define an R function that creating break points for a box map. The function accepts following arguments: - v: vector with observations - mult: multiplier for IQR (default 1.5)\nThe function returns: - bb: vector with 7 break points compute quartile and fences\n\n\ncode chunk\nboxbreaks &lt;- function(v,mult=1.5) {\n  qv &lt;- unname(quantile(v))\n  iqr &lt;- qv[4] - qv[2]\n  upfence &lt;- qv[4] + mult * iqr\n  lofence &lt;- qv[2] - mult * iqr\n  # initialize break points vector\n  bb &lt;- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence &lt; qv[1]) {  # no lower outliers\n    bb[1] &lt;- lofence\n    bb[2] &lt;- floor(qv[1])\n  } else {\n    bb[2] &lt;- lofence\n    bb[1] &lt;- qv[1]\n  }\n  if (upfence &gt; qv[5]) { # no upper outliers\n    bb[7] &lt;- upfence\n    bb[6] &lt;- ceiling(qv[5])\n  } else {\n    bb[6] &lt;- upfence\n    bb[7] &lt;- qv[5]\n  }\n  bb[3:5] &lt;- qv[2:4]\n  return(bb)\n}\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe’ll reuse the get.var function that we’ve initialized earlier"
  },
  {
    "objectID": "in_class_ex/in_class_ex01/in_class_ex01.html#define-the-boxmap-function",
    "href": "in_class_ex/in_class_ex01/in_class_ex01.html#define-the-boxmap-function",
    "title": "In-class Exercise 1: Geospatial Analytics",
    "section": "10.2 Define the boxmap function",
    "text": "10.2 Define the boxmap function\nLet’s define an R function to create a box map.\n\narguments:\n\nvnam: variable name (as character, in quotes)\ndf: simple features polygon layer\nlegtitle: legend title\nmtitle: map title\nmult: multiplier for IQR\n\nreturns:\n\na tmap-element (plots a map)\n\n\n\ncode chunk\nboxmap &lt;- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var &lt;- get.var(vnam,df)\n  bb &lt;- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Blues\",\n          labels = c(\"lower outlier\", \n                     \"&lt; 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"&gt; 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"left\",\n                               \"top\"))\n}"
  },
  {
    "objectID": "in_class_ex/in_class_ex01/in_class_ex01.html#plotting-box-map",
    "href": "in_class_ex/in_class_ex01/in_class_ex01.html#plotting-box-map",
    "title": "In-class Exercise 1: Geospatial Analytics",
    "section": "10.3 Plotting box map",
    "text": "10.3 Plotting box map\nLet’s use the functions to plot boxmap\n\n\ncode chunk\nboxmap(\"DEPENDENCY\", mpsz_pop2023)"
  },
  {
    "objectID": "in_class_ex/in_class_ex01/in_class_ex01.html#plotting-interactive-box-map",
    "href": "in_class_ex/in_class_ex01/in_class_ex01.html#plotting-interactive-box-map",
    "title": "In-class Exercise 1: Geospatial Analytics",
    "section": "10.4 Plotting interactive box map",
    "text": "10.4 Plotting interactive box map\nWe can also plot interactive box map using tmap and the functions that we’ve created\n\n\ncode chunk\ntmap_options(check.and.fix = TRUE)\ntmap_mode(\"view\")\n\n\ntmap mode set to interactive viewing\n\n\ncode chunk\nboxmap(\"DEPENDENCY\", mpsz_pop2023)\n\n\nWarning: The shape df is invalid (after reprojection). See sf::st_is_valid\nWarning: The shape df is invalid (after reprojection). See sf::st_is_valid"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex02/hands_on_ex02.1.html",
    "href": "hands_on_ex/hands_on_ex02/hands_on_ex02.1.html",
    "title": "Hands-on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "Spatial Point Pattern Analysis is the evaluation of the pattern or distribution, of a set of points on a surface. The point can be location of:\n\nEvents such as crime, traffic accident and disease onset, or\nBusiness services (coffee and fastfood outlets) or facilities such as childcare and eldercare.\n\nWe’ll use appropriate functions from spatstat to discover spatial point processes of childcare centres in Singapore."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex02/hands_on_ex02.1.html#importing-spatial-data",
    "href": "hands_on_ex/hands_on_ex02/hands_on_ex02.1.html#importing-spatial-data",
    "title": "Hands-on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.1 Importing spatial data",
    "text": "4.1 Importing spatial data\nWe will use st_read() of sf package will be used to import these three geospatial data sets into R.\n\nChildcare dataCoastal outline dataMaster Plan 2014 data\n\n\nSince the childcare_sf simple feature data frame is in the WGS84 geodetic CRS, which is not ideal for geospatial analysis, the st_transform() function from the sf package is used to reproject the data to the SVY21 coordinate system during import.\n\n\ncode chunk\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\n\nReading layer `child-care-services-geojson' from data source \n  `/Users/cham/project/Geospatial-Analytics/chrismanafe/ISSS626-GAA/hands_on_ex/hands_on_ex02/data/child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nLet’s verify the crs of the data frame to ensure we’re using EPSG 3414.\n\n\ncode chunk\nst_crs(childcare_sf)\n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\nImport coastal outline data using st_read() function\n\n\ncode chunk\nsg_sf &lt;- st_read(dsn = \"data\", layer=\"CostalOutline\")\n\n\nReading layer `CostalOutline' from data source \n  `/Users/cham/project/Geospatial-Analytics/chrismanafe/ISSS626-GAA/hands_on_ex/hands_on_ex02/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\nLet’s check coordinate system of this data frame\n\n\ncode chunk\nst_crs(sg_sf)\n\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nCoastal outline data frame is using EPSG 9001 instead of 3414 which is suitable for CRS SVY21. Let’s assign correct EPSG code using st_set_crs() then verify the output.\n\n\ncode chunk\nsg_sf = st_set_crs(sg_sf, 3414)\n\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\ncode chunk\nst_crs(sg_sf)\n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\nLet’s load the Master Plan Planning data using st_read() function\n\n\ncode chunk\nmpsz_sf &lt;- st_read(dsn = \"data\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/cham/project/Geospatial-Analytics/chrismanafe/ISSS626-GAA/hands_on_ex/hands_on_ex02/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nLet’s check coordinate system of this data frame\n\n\ncode chunk\nst_crs(mpsz_sf)\n\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nmpsz_sf is also using EPSG 9001 instead of 3414 which is suitable for CRS SVY21. Let’s assign correct EPSG code using st_set_crs() then verify the output.\n\n\ncode chunk\nmpsz_sf &lt;- st_set_crs(mpsz_sf,3414)\n\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\ncode chunk\nst_crs(mpsz_sf)\n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex02/hands_on_ex02.1.html#mapping-the-geospatial-data-sets",
    "href": "hands_on_ex/hands_on_ex02/hands_on_ex02.1.html#mapping-the-geospatial-data-sets",
    "title": "Hands-on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.2 Mapping the geospatial data sets",
    "text": "4.2 Mapping the geospatial data sets\nAfter checking the referencing system of each geospatial data data frame, it is also useful for us to plot a map to show their spatial patterns.\n\n\ncode chunk\ntm_shape(mpsz_sf) +\n  tm_polygons() +\ntm_shape(childcare_sf) +\n  tm_dots()\n\n\n\n\n\n\n\n\n\nNotice that all the geospatial layers are within the same map extend. This shows that their referencing system and coordinate values are referred to similar spatial context. This is very important in any geospatial analysis.\nAlternatively, we can also prepare a pin map by using the code chunk below.\n\n\ncode chunk\ntmap_mode('view')\n\n\ntmap mode set to interactive viewing\n\n\ncode chunk\ntm_shape(childcare_sf)+\n  tm_dots()\n\n\n\n\n\n\n\n\ncode chunk\ntmap_mode('plot')\n\n\ntmap mode set to plotting\n\n\nIn interactive mode, tmap uses the Leaflet for R API. This interactive pin map offers several advantages, including the ability to freely navigate and zoom around the map. We can also query information of each simple feature (i.e. the point) by clicking of them. Additionally, you can change the background of the map layer. Currently, three internet map layers are available: ESRI.WorldGrayCanvas (the default), OpenStreetMap, and ESRI.WorldTopoMap.\n\n\n\n\n\n\nNote\n\n\n\nReminder: After using an interactive map, be sure to switch back to plot mode. Each interactive session consumes a connection, and displaying too many interactive maps (ideally no more than 10) in a single RMarkdown document can cause issues when publishing on Netlify."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex02/hands_on_ex02.1.html#converting-sf-data-frame-into-sps-spatial-class",
    "href": "hands_on_ex/hands_on_ex02/hands_on_ex02.1.html#converting-sf-data-frame-into-sps-spatial-class",
    "title": "Hands-on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "5.1 Converting sf data frame into sp’s Spatial* class",
    "text": "5.1 Converting sf data frame into sp’s Spatial* class\nAlthough simple feature data frame is gaining popularity again sp’s Spatial* classes, there are, however, many geospatial analysis packages require the input geospatial data in sp’s Spatial* classes. In this section, we will learn how to convert simple feature data frame to sp’s Spatial* class.\n\n\ncode chunk\nchildcare &lt;- as_Spatial(childcare_sf)\nmpsz &lt;- as_Spatial(mpsz_sf)\nsg &lt;- as_Spatial(sg_sf)\n\n\nNotice that the geospatial data have been converted into their respective sp’s Spatial* classes now.\n\nChildcare dataCoastal outline dataMaster plan 2014 data\n\n\n\n\ncode chunk\nchildcare\n\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description \nmin values  :   kml_1, &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;1, MARINA BOULEVARD, #B1 - 01, ONE MARINA BOULEVARD, SINGAPORE 018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;THE LITTLE SKOOL-HOUSE INTERNATIONAL PTE. LTD.&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;08F73931F4A691F4&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \nmax values  : kml_999,                  &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;200, PONGGOL SEVENTEENTH AVENUE, SINGAPORE 829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;Child Care Services&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;RAFFLES KIDZ @ PUNGGOL PTE LTD&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;379D017BF244B0FA&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \n\n\n\n\n\n\ncode chunk\nsg\n\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 4\nnames       : GDO_GID, MSLINK, MAPID,              COSTAL_NAM \nmin values  :       1,      1,     0,             ISLAND LINK \nmax values  :      60,     67,     0, SINGAPORE - MAIN ISLAND \n\n\n\n\n\n\ncode chunk\nmpsz\n\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex02/hands_on_ex02.1.html#converting-spatial-class-into-generic-sp-format",
    "href": "hands_on_ex/hands_on_ex02/hands_on_ex02.1.html#converting-spatial-class-into-generic-sp-format",
    "title": "Hands-on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "5.2 Converting Spatial* class into generic sp format",
    "text": "5.2 Converting Spatial* class into generic sp format\nspatstat requires the analytical data in ppp object form. There is no direct way to convert a Spatial* classes into ppp object. We need to convert the Spatial* classes into Spatial object first.\n\n\ncode chunk\nchildcare_sp &lt;- as(childcare, \"SpatialPoints\")\nsg_sp &lt;- as(sg, \"SpatialPolygons\")\n\n\nLet’s display the sp object properties\n\n\ncode chunk\nchildcare_sp\n\n\nclass       : SpatialPoints \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\n\ncode chunk\nsg_sp\n\n\nclass       : SpatialPolygons \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\nThere are key differences between the Spatial* classes and the generic sp objects. For example, let’s compare SpatialPointsDataFrame (a Spatial* class) and SpatialPoints (a generic sp object):\n\nSpatialPoints class: Represents a basic collection of spatial points within a specified coordinate system. This class is focused purely on the geometric data, meaning it only includes the locations (coordinates) of the points.\nSpatialPointsDataFrame class: Builds on the SpatialPoints class by integrating the spatial coordinates with a data frame containing attribute data. This allows for the storage of both spatial (geometric) data and non-spatial (attribute) data in one object, enabling each point to be associated with additional information."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex02/hands_on_ex02.1.html#converting-generic-sp-format-into-spatstats-ppp-format",
    "href": "hands_on_ex/hands_on_ex02/hands_on_ex02.1.html#converting-generic-sp-format-into-spatstats-ppp-format",
    "title": "Hands-on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "5.3 Converting generic sp format into spatstat’s ppp format",
    "text": "5.3 Converting generic sp format into spatstat’s ppp format\nNow let’s use as.ppp() function of spatstat to convert the spatial data into spatstat’s ppp object format.\n\n\ncode chunk\nchildcare_ppp &lt;- as.ppp(childcare_sf)\n\n\nWarning in as.ppp.sf(childcare_sf): only first attribute column is used for\nmarks\n\n\ncode chunk\nchildcare_ppp\n\n\nMarked planar point pattern: 1545 points\nmarks are of storage type  'character'\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\nLet us plot childcare_ppp and examine the difference.\n\n\ncode chunk\nplot(childcare_ppp)\n\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\nWe can take a quick look at the summary statistics of the newly created ppp object\n\n\ncode chunk\nsummary(childcare_ppp)\n\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\n\n\n\n\n\n\nNote\n\n\n\nTake note of the warning message regarding duplicates. In spatial point pattern analysis, the presence of duplicate points is a significant concern. The statistical methods used in analyzing spatial point patterns typically assume that the processes are simple, meaning that no two points should coincide."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex02/hands_on_ex02.1.html#handling-duplicated-points",
    "href": "hands_on_ex/hands_on_ex02/hands_on_ex02.1.html#handling-duplicated-points",
    "title": "Hands-on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "5.4 Handling duplicated points",
    "text": "5.4 Handling duplicated points\nWe can check the duplication in a ppp object by using the code chunk below.\n\n\ncode chunk\nany(duplicated(childcare_ppp))\n\n\n[1] FALSE\n\n\nWe’ll use the multiplicity() function to count the number of coincident points\n\n\ncode chunk\nmultiplicity(childcare_ppp)\n\n\n   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [75] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [112] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [186] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [223] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [260] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [297] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [334] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [371] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [408] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [445] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [482] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [519] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [556] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [593] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [630] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [667] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [704] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [741] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [778] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [815] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [852] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [889] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [926] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [963] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1000] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1037] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1074] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1111] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1148] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1185] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1222] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1259] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1296] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1333] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1370] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1407] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1444] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1481] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1518] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\n\nWe can find out how many locations have more than one point, as shown in the code chunk below.\n\n\ncode chunk\nsum(multiplicity(childcare_ppp) &gt; 1)\n\n\n[1] 0\n\n\nThere is no duplicate points here, but if we want to visualize the locations of duplicate points, we can plot the childcare data using the code chunk below.\n\n\ncode chunk\ntmap_mode('view')\n\n\ntmap mode set to interactive viewing\n\n\ncode chunk\ntm_shape(childcare) +\n  tm_dots(alpha=0.4, \n          size=0.05)\n\n\n\n\n\n\n\n\ncode chunk\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\nThere are three ways to address duplicate issue:\n\nThe simplest approach is to delete the duplicates. However, this will result in the loss of some potentially valuable point events.\nAnother solution is to use jittering, which introduces a small perturbation to the duplicate points so that they no longer occupy the exact same location.\nThe third approach involves making each point “unique” and then attaching the duplicates as marks, or attributes, to the original points. This method requires analytical techniques that account for these marks.\n\nJittering approach can be implemented as follows\n\n\ncode chunk\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\n\n\ncode chunk\nany(duplicated(childcare_ppp_jit))\n\n\n[1] FALSE"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex02/hands_on_ex02.1.html#creating-owin-object",
    "href": "hands_on_ex/hands_on_ex02/hands_on_ex02.1.html#creating-owin-object",
    "title": "Hands-on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "5.5 Creating owin object",
    "text": "5.5 Creating owin object\nWhen analyzing spatial point patterns, it is good practice to confine the analysis within a specific geographical area, such as the boundary of Singapore. In spatstat, an object called owin is specifically designed to represent such polygonal regions.\nThe following code demonstrates how to convert a SpatialPolygon object of Singapore into an owin object in spatstat.\n\n\ncode chunk\nsg_owin &lt;- as.owin(sg_sf)\n\n\nLet’s display the output using plot() and summary() function\n\n\ncode chunk\nplot(sg_owin)\n\n\n\n\n\n\n\n\n\n\n\ncode chunk\nsummary(sg_owin)\n\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex02/hands_on_ex02.1.html#combining-point-events-object-and-owin-object",
    "href": "hands_on_ex/hands_on_ex02/hands_on_ex02.1.html#combining-point-events-object-and-owin-object",
    "title": "Hands-on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "5.6 Combining point events object and owin object",
    "text": "5.6 Combining point events object and owin object\nIn this last step of geospatial data wrangling, we will extract childcare events that are located within Singapore\n\n\ncode chunk\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\n\nThe output object combined both the point and polygon feature in one ppp object class\n\n\ncode chunk\nsummary(childcareSG_ppp)\n\n\nMarked planar point pattern:  1545 points\nAverage intensity 2.129929e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\nLet’s plot the output object\n\n\ncode chunk\nplot(childcareSG_ppp)\n\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex02/hands_on_ex02.1.html#kernel-density-estimation",
    "href": "hands_on_ex/hands_on_ex02/hands_on_ex02.1.html#kernel-density-estimation",
    "title": "Hands-on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "6.1 Kernel Density Estimation",
    "text": "6.1 Kernel Density Estimation\n\n6.1.1 Computing kernel density estimation using automatic bandwidth selection method\nWe will compute a kernel density using following configurations of density() of spatstat:\n\nbw.diggle() automatic bandwidth selection method. Other recommended methods are bw.CvL(), bw.scott() or bw.ppl().\nThe smoothing kernel used is gaussian, which is the default. Other smoothing methods are: “epanechnikov”, “quartic” or “disc”.\nThe intensity estimate is corrected for edge effect bias by using method described by Jones (1993) and Diggle (2010, equation 18.9). The default is FALSE.\n\n\n\ncode chunk\nkde_childcareSG_bw &lt;- density(childcareSG_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\n\nWe’ll use plot() function to display the kernel density derived.\n\n\ncode chunk\nplot(kde_childcareSG_bw)\n\n\n\n\n\n\n\n\n\nThe density values in the output range from 0 to 0.000035, which is difficult to interpret. This is because the default unit of measurement in SVY21 is meters, resulting in density values computed as the “number of points per square meter”.\nIt is helpful to know that you can retrieve the bandwidth used to compute the KDE layer using the following code.\n\n\ncode chunk\nbw &lt;- bw.diggle(childcareSG_ppp)\nbw\n\n\n   sigma \n298.4095 \n\n\n\n\n6.1.2 Rescaling KDE values\nWe’ll use rescale.ppp() function to convert the unit of measurement from meter to kilometer.\n\n\ncode chunk\nchildcareSG_ppp.km &lt;- rescale.ppp(childcareSG_ppp, 1000, \"km\")\n\n\nWe can re-run density() using rescaled data set and plot the output kde map.\n\n\ncode chunk\nkde_childcareSG.bw &lt;- density(childcareSG_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG.bw)\n\n\n\n\n\n\n\n\n\n\nNotice that the output image appears identical to the earlier version; the only difference is in the data values (as shown in the legend)."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex02/hands_on_ex02.1.html#working-with-different-automatic-bandwidth-methods",
    "href": "hands_on_ex/hands_on_ex02/hands_on_ex02.1.html#working-with-different-automatic-bandwidth-methods",
    "title": "Hands-on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "6.2 Working with different automatic bandwidth methods",
    "text": "6.2 Working with different automatic bandwidth methods\nIn addition to bw.diggle(), there are three other spatstat functions that can be used to determine the bandwidth: bw.CvL(), bw.scott(), and bw.ppl().\nLet’s examine the bandwidth values returned by these automatic bandwidth selection methods using the following code.\n\n\ncode chunk\nbw.CvL(childcareSG_ppp.km)\n\n\n   sigma \n4.543278 \n\n\n\n\ncode chunk\nbw.scott(childcareSG_ppp.km)\n\n\n sigma.x  sigma.y \n2.224898 1.450966 \n\n\n\n\ncode chunk\nbw.ppl(childcareSG_ppp.km)\n\n\n    sigma \n0.3897114 \n\n\n\n\ncode chunk\nbw.diggle(childcareSG_ppp.km)\n\n\n    sigma \n0.2984095 \n\n\nBaddeley et al. (2016) recommend using the bw.ppl() algorithm, as it tends to produce more appropriate bandwidth values when the pattern primarily consists of tight clusters. However, they also note that if the goal of a study is to detect a single tight cluster amidst random noise, the bw.diggle() method often performs best.\nThe following code will be used to compare the outputs of the bw.diggle and bw.ppl methods.\n\n\ncode chunk\nkde_childcareSG.ppl &lt;- density(childcareSG_ppp.km, \n                               sigma=bw.ppl, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex02/hands_on_ex02.1.html#working-with-different-kernel-methods",
    "href": "hands_on_ex/hands_on_ex02/hands_on_ex02.1.html#working-with-different-kernel-methods",
    "title": "Hands-on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "6.3 Working with different kernel methods",
    "text": "6.3 Working with different kernel methods\nBy default, the kernel method used in density.ppp() is Gaussian. However, there are three other options available: Epanechnikov, Quartic, and Disc.\nThe following code will be used to compute three additional kernel density estimations using these alternative kernel functions.\n\n\ncode chunk\npar(mfrow=c(2,2))\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")\n\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\n\ncode chunk\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")\n\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\n\ncode chunk\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc\")\n\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex02/hands_on_ex02.1.html#computing-kde-by-using-fixed-bandwidth",
    "href": "hands_on_ex/hands_on_ex02/hands_on_ex02.1.html#computing-kde-by-using-fixed-bandwidth",
    "title": "Hands-on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "7.1 Computing KDE by using fixed bandwidth",
    "text": "7.1 Computing KDE by using fixed bandwidth\nNext, we will compute a KDE layer by defining a bandwidth of 600 meters. &gt; Notice that in the code below, the sigma value is set to 0.6. This is because the unit of measurement for the childcareSG_ppp.km object is in kilometers, so 600 meters is equivalent to 0.6 kilometers.\n\n\ncode chunk\nkde_childcareSG_600 &lt;- density(childcareSG_ppp.km, sigma=0.6, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG_600)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex02/hands_on_ex02.1.html#computing-kde-by-using-adaptive-bandwidth",
    "href": "hands_on_ex/hands_on_ex02/hands_on_ex02.1.html#computing-kde-by-using-adaptive-bandwidth",
    "title": "Hands-on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "7.2 Computing KDE by using adaptive bandwidth",
    "text": "7.2 Computing KDE by using adaptive bandwidth\nThe fixed bandwidth method is highly sensitive to skewed distributions of spatial point patterns across geographical units, such as urban versus rural areas. One way to address this issue is by using adaptive bandwidth instead.\nIn this section, we will learn how to derive adaptive kernel density estimation using the density.adaptive() function from the spatstat package.\n\n\ncode chunk\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\n\n\n\n\nWe can compare the outputs of fixed and adaptive kernel density estimations using the following code.\n\n\ncode chunk\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive bandwidth\")"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex02/hands_on_ex02.1.html#converting-kde-output-into-grid-object",
    "href": "hands_on_ex/hands_on_ex02/hands_on_ex02.1.html#converting-kde-output-into-grid-object",
    "title": "Hands-on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "7.3 Converting KDE output into grid object",
    "text": "7.3 Converting KDE output into grid object\nThe result remains the same; we’ve simply converted it to make it suitable for mapping purposes.\n\n\ncode chunk\ngridded_kde_childcareSG_bw &lt;- as(kde_childcareSG.bw, \"SpatialGridDataFrame\")\nspplot(gridded_kde_childcareSG_bw)\n\n\n\n\n\n\n\n\n\n\n7.3.1 Converting gridded output into raster\nWe will convert the gridded kernel density objects into a RasterLayer object using the raster() function from the raster package.\n\n\ncode chunk\nkde_childcareSG_bw_raster &lt;- raster(kde_childcareSG.bw)\n\n\nLet’s examine the properties of the kde_childcareSG_bw_raster RasterLayer.\n\n\ncode chunk\nkde_childcareSG_bw_raster\n\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : layer \nvalues     : -1.005814e-14, 28.51831  (min, max)\n\n\n\nNotice that the crs property is NA.\n\n\n\n7.3.2 Assigning projection systems\nThe following code will be used to add CRS information to the kde_childcareSG_bw_raster RasterLayer.\n\n\ncode chunk\nprojection(kde_childcareSG_bw_raster) &lt;- CRS(\"+init=EPSG:3414\")\nkde_childcareSG_bw_raster\n\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : -1.005814e-14, 28.51831  (min, max)\n\n\n\nNotice that the crs property is completed now."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex02/hands_on_ex02.1.html#visualising-the-output-in-tmap",
    "href": "hands_on_ex/hands_on_ex02/hands_on_ex02.1.html#visualising-the-output-in-tmap",
    "title": "Hands-on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "7.4 Visualising the output in tmap",
    "text": "7.4 Visualising the output in tmap\nFinally, we will display the raster on a cartographic-quality map using the tmap package.\n\n\ncode chunk\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(\"layer\", palette = \"viridis\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\n\n\n\n\n\n\n\n\n\nNotice that the raster values are explicitly encoded onto the raster pixels using the values in the “v” field."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex02/hands_on_ex02.1.html#comparing-spatial-point-patterns-using-kde",
    "href": "hands_on_ex/hands_on_ex02/hands_on_ex02.1.html#comparing-spatial-point-patterns-using-kde",
    "title": "Hands-on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "7.5 Comparing Spatial Point Patterns using KDE",
    "text": "7.5 Comparing Spatial Point Patterns using KDE\nIn this section, we will learn how to compare the KDE of childcare facilities in the planning areas of Punggol, Tampines, Chua Chu Kang, and Jurong West.\n\n7.5.1 Extracting study area\nLet us extract the target planning areas.\n\n\ncode chunk\npg &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\n\nPlot target planning areas\n\nPunggolTampinesChoa Chu KangJurong West\n\n\n\n\ncode chunk\npar(mfrow=c(2,2))\nplot(pg, main = \"Punggol\")\n\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\n\n\n\ncode chunk\nplot(tm, main = \"Tampines\")\n\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\n\n\n\ncode chunk\nplot(ck, main = \"Choa Chu Kang\")\n\n\nWarning: plotting the first 10 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\n\n\n\ncode chunk\nplot(jw, main = \"Jurong West\")\n\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.5.2 Creating owin object\nWe will convert these sf objects into owin objects that is required by spatstat.\n\n\ncode chunk\npg_owin = as.owin(pg)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\njw_owin = as.owin(jw)\n\n\n\n\n7.5.3 Combining childcare points and the study area\nUsing the code below, we can extract childcare facilities within specific regions for further analysis.\n\n\ncode chunk\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\n\nNext, the rescale.ppp() function is used to transform the unit of measurement from meters to kilometers.\n\n\ncode chunk\nchildcare_pg_ppp.km = rescale.ppp(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale.ppp(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale.ppp(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale.ppp(childcare_jw_ppp, 1000, \"km\")\n\n\nThe following code is used to plot the four study areas along with the locations of the childcare centers.\n\n\ncode chunk\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp.km, main=\"Punggol\")\n\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 61 symbols are shown in the symbol map\n\n\ncode chunk\nplot(childcare_tm_ppp.km, main=\"Tampines\")\n\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 89 symbols are shown in the symbol map\n\n\ncode chunk\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\n\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 61 symbols are shown in the symbol map\n\n\ncode chunk\nplot(childcare_jw_ppp.km, main=\"Jurong West\")\n\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 88 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\n\n\n7.5.4 Computing KDE\nThe following code will compute the KDE for these four planning areas. The bw.diggle method is used to determine the bandwidth for each area.\n\n\ncode chunk\npar(mfrow=c(2,2))\nplot(density(childcare_pg_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\n\n\nWarning: Berman-Diggle Cross-Validation criterion was minimised at right-hand\nend of interval [0, 0.245]; use argument 'hmax' to specify a wider interval for\nbandwidth 'sigma'\n\n\ncode chunk\nplot(density(childcare_tm_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")\nplot(density(childcare_ck_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Jurong West\")\n\n\n\n\n\n\n\n\n\n\n\n7.5.5 Computing fixed bandwidth KDE\nFor comparison purposes, we will use 250m as the bandwidth.\n\n\ncode chunk\npar(mfrow=c(2,2))\nplot(density(childcare_pg_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")\nplot(density(childcare_ck_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Jurong West\")"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex02/hands_on_ex02.1.html#testing-spatial-point-patterns-using-clark-and-evans-test",
    "href": "hands_on_ex/hands_on_ex02/hands_on_ex02.1.html#testing-spatial-point-patterns-using-clark-and-evans-test",
    "title": "Hands-on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "8.1 Testing spatial point patterns using Clark and Evans Test",
    "text": "8.1 Testing spatial point patterns using Clark and Evans Test\n\nSingapore IslandwideChoa Chu KangTampines\n\n\n\n\ncode chunk\nclarkevans.test(childcareSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcareSG_ppp\nR = 0.55631, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\nGiven that the p-value is less than 0.05, we can reject the null hypothesis and conclude that the distribution of childcare centers in Singapore is not random but rather clustered.\n\n\nUsing the clarkevans.test() function from spatstat, we conducted a Clark-Evans test to assess the aggregation of childcare centers in Choa Chu Kang planning area.\n\n\ncode chunk\nclarkevans.test(childcare_ck_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_ck_ppp\nR = 0.9208, p-value = 0.2367\nalternative hypothesis: two-sided\n\n\nThe locations of childcare in Choa Chu Kang appear to be randomly distributed, with no strong evidence of them being concentrated in specific areas or evenly spaced apart.\n\n\nUsing the clarkevans.test() function from spatstat, we conducted a Clark-Evans test to assess the aggregation of childcare centers in Tampines planning area.\n\n\ncode chunk\nclarkevans.test(childcare_tm_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_tm_ppp\nR = 0.78493, p-value = 0.0001038\nalternative hypothesis: two-sided\n\n\nThe locations of childcare centers in Tampines are significantly clustered, with strong evidence suggesting that they tend to be closer together rather than being randomly distributed or evenly spaced apart."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex02/hands_on_ex02.2.html",
    "href": "hands_on_ex/hands_on_ex02/hands_on_ex02.2.html",
    "title": "Hands-on Exercise 2b: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "Spatial Point Pattern Analysis is the evaluation of the pattern or distribution, of a set of points on a surface. The point can be location of:\n\nEvents such as crime, traffic accident and disease onset, or\nBusiness services (coffee and fastfood outlets) or facilities such as childcare and eldercare.\n\nWe’ll use appropriate functions from spatstat to discover spatial point processes of childcare centres in Singapore."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex02/hands_on_ex02.2.html#importing-spatial-data",
    "href": "hands_on_ex/hands_on_ex02/hands_on_ex02.2.html#importing-spatial-data",
    "title": "Hands-on Exercise 2b: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "4.1 Importing spatial data",
    "text": "4.1 Importing spatial data\nWe will use st_read() of sf package will be used to import these three geospatial data sets into R.\n\nChildcare dataCoastal outline dataMaster Plan 2014 data\n\n\nSince the childcare_sf simple feature data frame is in the WGS84 geodetic CRS, which is not ideal for geospatial analysis, the st_transform() function from the sf package is used to reproject the data to the SVY21 coordinate system during import.\n\n\ncode chunk\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\n\nReading layer `child-care-services-geojson' from data source \n  `/Users/cham/project/Geospatial-Analytics/chrismanafe/ISSS626-GAA/hands_on_ex/hands_on_ex02/data/child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nLet’s verify the crs of the data frame to ensure we’re using EPSG 3414.\n\n\ncode chunk\nst_crs(childcare_sf)\n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\nImport coastal outline data using st_read() function\n\n\ncode chunk\nsg_sf &lt;- st_read(dsn = \"data\", layer=\"CostalOutline\")\n\n\nReading layer `CostalOutline' from data source \n  `/Users/cham/project/Geospatial-Analytics/chrismanafe/ISSS626-GAA/hands_on_ex/hands_on_ex02/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\nLet’s check coordinate system of this data frame\n\n\ncode chunk\nst_crs(sg_sf)\n\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nCoastal outline data frame is using EPSG 9001 instead of 3414 which is suitable for CRS SVY21. Let’s assign correct EPSG code using st_set_crs() then verify the output.\n\n\ncode chunk\nsg_sf = st_set_crs(sg_sf, 3414)\n\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\ncode chunk\nst_crs(sg_sf)\n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\nLet’s load the Master Plan Planning data using st_read() function\n\n\ncode chunk\nmpsz_sf &lt;- st_read(dsn = \"data\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/cham/project/Geospatial-Analytics/chrismanafe/ISSS626-GAA/hands_on_ex/hands_on_ex02/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nLet’s check coordinate system of this data frame\n\n\ncode chunk\nst_crs(mpsz_sf)\n\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nmpsz_sf is also using EPSG 9001 instead of 3414 which is suitable for CRS SVY21. Let’s assign correct EPSG code using st_set_crs() then verify the output.\n\n\ncode chunk\nmpsz_sf &lt;- st_set_crs(mpsz_sf,3414)\n\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\ncode chunk\nst_crs(mpsz_sf)\n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex02/hands_on_ex02.2.html#mapping-the-geospatial-data-sets",
    "href": "hands_on_ex/hands_on_ex02/hands_on_ex02.2.html#mapping-the-geospatial-data-sets",
    "title": "Hands-on Exercise 2b: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "4.2 Mapping the geospatial data sets",
    "text": "4.2 Mapping the geospatial data sets\nAfter checking the referencing system of each geospatial data data frame, it is also useful for us to plot a map to show their spatial patterns.\n\n\ncode chunk\ntm_shape(mpsz_sf) +\n  tm_polygons() +\ntm_shape(childcare_sf) +\n  tm_dots()\n\n\n\n\n\n\n\n\n\nNotice that all the geospatial layers are within the same map extend. This shows that their referencing system and coordinate values are referred to similar spatial context. This is very important in any geospatial analysis.\nAlternatively, we can also prepare a pin map by using the code chunk below.\n\n\ncode chunk\ntmap_mode('view')\n\n\ntmap mode set to interactive viewing\n\n\ncode chunk\ntm_shape(childcare_sf)+\n  tm_dots()\n\n\n\n\n\n\n\n\ncode chunk\ntmap_mode('plot')\n\n\ntmap mode set to plotting\n\n\nIn interactive mode, tmap uses the Leaflet for R API. This interactive pin map offers several advantages, including the ability to freely navigate and zoom around the map. We can also query information of each simple feature (i.e. the point) by clicking of them. Additionally, we can change the background of the map layer. Currently, three internet map layers are available: ESRI.WorldGrayCanvas (the default), OpenStreetMap, and ESRI.WorldTopoMap.\n\n\n\n\n\n\nNote\n\n\n\nReminder: After using an interactive map, be sure to switch back to plot mode. Each interactive session consumes a connection, and displaying too many interactive maps (ideally no more than 10) in a single RMarkdown document can cause issues when publishing on Netlify."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex02/hands_on_ex02.2.html#converting-sf-data-frame-into-sps-spatial-class",
    "href": "hands_on_ex/hands_on_ex02/hands_on_ex02.2.html#converting-sf-data-frame-into-sps-spatial-class",
    "title": "Hands-on Exercise 2b: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.1 Converting sf data frame into sp’s Spatial* class",
    "text": "5.1 Converting sf data frame into sp’s Spatial* class\nAlthough simple feature data frame is gaining popularity again sp’s Spatial* classes, there are, however, many geospatial analysis packages require the input geospatial data in sp’s Spatial* classes. In this section, we will learn how to convert simple feature data frame to sp’s Spatial* class.\n\n\ncode chunk\nchildcare &lt;- as_Spatial(childcare_sf)\nmpsz &lt;- as_Spatial(mpsz_sf)\nsg &lt;- as_Spatial(sg_sf)\n\n\nNotice that the geospatial data have been converted into their respective sp’s Spatial* classes now.\n\nChildcare dataCoastal outline dataMaster plan 2014 data\n\n\n\n\ncode chunk\nchildcare\n\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description \nmin values  :   kml_1, &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;1, MARINA BOULEVARD, #B1 - 01, ONE MARINA BOULEVARD, SINGAPORE 018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;THE LITTLE SKOOL-HOUSE INTERNATIONAL PTE. LTD.&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;08F73931F4A691F4&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \nmax values  : kml_999,                  &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;200, PONGGOL SEVENTEENTH AVENUE, SINGAPORE 829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;Child Care Services&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;RAFFLES KIDZ @ PUNGGOL PTE LTD&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;379D017BF244B0FA&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \n\n\n\n\n\n\ncode chunk\nsg\n\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 4\nnames       : GDO_GID, MSLINK, MAPID,              COSTAL_NAM \nmin values  :       1,      1,     0,             ISLAND LINK \nmax values  :      60,     67,     0, SINGAPORE - MAIN ISLAND \n\n\n\n\n\n\ncode chunk\nmpsz\n\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex02/hands_on_ex02.2.html#converting-generic-sp-format-into-spatstats-ppp-format",
    "href": "hands_on_ex/hands_on_ex02/hands_on_ex02.2.html#converting-generic-sp-format-into-spatstats-ppp-format",
    "title": "Hands-on Exercise 2b: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.2 Converting generic sp format into spatstat’s ppp format",
    "text": "5.2 Converting generic sp format into spatstat’s ppp format\nWe can use as.ppp() function of spatstat to convert the spatial data into spatstat’s ppp object format.\n\n\ncode chunk\nchildcare_ppp &lt;- as.ppp(childcare_sf)\n\n\nWarning in as.ppp.sf(childcare_sf): only first attribute column is used for\nmarks\n\n\ncode chunk\nchildcare_ppp\n\n\nMarked planar point pattern: 1545 points\nmarks are of storage type  'character'\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\nLet us plot childcare_ppp and examine the difference.\n\n\ncode chunk\nplot(childcare_ppp)\n\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\nWe can take a quick look at the summary statistics of the newly created ppp object\n\n\ncode chunk\nsummary(childcare_ppp)\n\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\n\n\n\n\n\n\nNote\n\n\n\nTake note of the warning message regarding duplicates. In spatial point pattern analysis, the presence of duplicate points is a significant concern. The statistical methods used in analyzing spatial point patterns typically assume that the processes are simple, meaning that no two points should coincide."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex02/hands_on_ex02.2.html#handling-duplicated-points",
    "href": "hands_on_ex/hands_on_ex02/hands_on_ex02.2.html#handling-duplicated-points",
    "title": "Hands-on Exercise 2b: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.3 Handling duplicated points",
    "text": "5.3 Handling duplicated points\nWe can check the duplication in a ppp object by using the code chunk below.\n\n\ncode chunk\nany(duplicated(childcare_ppp))\n\n\n[1] FALSE\n\n\nWe’ll use the multiplicity() function to count the number of coincident points\n\n\ncode chunk\nmultiplicity(childcare_ppp)\n\n\n   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [75] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [112] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [186] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [223] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [260] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [297] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [334] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [371] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [408] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [445] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [482] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [519] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [556] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [593] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [630] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [667] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [704] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [741] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [778] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [815] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [852] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [889] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [926] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [963] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1000] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1037] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1074] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1111] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1148] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1185] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1222] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1259] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1296] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1333] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1370] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1407] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1444] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1481] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1518] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\n\nWe can find out how many locations have more than one point, as shown in the code chunk below.\n\n\ncode chunk\nsum(multiplicity(childcare_ppp) &gt; 1)\n\n\n[1] 0\n\n\nThere is no duplicate points here, but if we want to visualize the locations of duplicate points, we can plot the childcare data using the code chunk below.\n\n\ncode chunk\ntmap_mode('view')\n\n\ntmap mode set to interactive viewing\n\n\ncode chunk\ntm_shape(childcare_sf) +\n  tm_dots(alpha=0.4, \n          size=0.05)\n\n\n\n\n\n\n\n\ncode chunk\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\nThere are three ways to address duplicate issue:\n\nThe simplest approach is to delete the duplicates. However, this will result in the loss of some potentially valuable point events.\nAnother solution is to use jittering, which introduces a small perturbation to the duplicate points so that they no longer occupy the exact same location.\nThe third approach involves making each point “unique” and then attaching the duplicates as marks, or attributes, to the original points. This method requires analytical techniques that account for these marks.\n\nJittering approach can be implemented as follows\n\n\ncode chunk\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\n\n\ncode chunk\nany(duplicated(childcare_ppp_jit))\n\n\n[1] FALSE"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex02/hands_on_ex02.2.html#creating-owin-object",
    "href": "hands_on_ex/hands_on_ex02/hands_on_ex02.2.html#creating-owin-object",
    "title": "Hands-on Exercise 2b: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.4 Creating owin object",
    "text": "5.4 Creating owin object\nWhen analyzing spatial point patterns, it is good practice to confine the analysis within a specific geographical area, such as the boundary of Singapore. In spatstat, an object called owin is specifically designed to represent such polygonal regions.\nThe following code demonstrates how to convert a SpatialPolygon object of Singapore into an owin object in spatstat.\n\n\ncode chunk\nsg_owin &lt;- as.owin(sg_sf)\n\n\nLet’s display the output using plot() and summary() function\n\n\ncode chunk\nplot(sg_owin)\n\n\n\n\n\n\n\n\n\n\n\ncode chunk\nsummary(sg_owin)\n\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex02/hands_on_ex02.2.html#combining-point-events-object-and-owin-object",
    "href": "hands_on_ex/hands_on_ex02/hands_on_ex02.2.html#combining-point-events-object-and-owin-object",
    "title": "Hands-on Exercise 2b: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.5 Combining point events object and owin object",
    "text": "5.5 Combining point events object and owin object\nIn this last step of geospatial data wrangling, we will extract childcare events that are located within Singapore\n\n\ncode chunk\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\n\nThe output object combined both the point and polygon feature in one ppp object class\n\n\ncode chunk\nsummary(childcareSG_ppp)\n\n\nMarked planar point pattern:  1545 points\nAverage intensity 2.129929e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\nLet’s plot the output object\n\n\ncode chunk\nplot(childcareSG_ppp)\n\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\n\n5.5.1 Extracting study area\nLet us extract the target planning areas.\n\n\ncode chunk\npg &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\n\nPlot target planning areas\n\nPunggolTampinesChoa Chu KangJurong West\n\n\n\n\ncode chunk\npar(mfrow=c(2,2))\nplot(pg, main = \"Punggol\")\n\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\n\n\n\ncode chunk\nplot(tm, main = \"Tampines\")\n\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\n\n\n\ncode chunk\nplot(ck, main = \"Choa Chu Kang\")\n\n\nWarning: plotting the first 10 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\n\n\n\ncode chunk\nplot(jw, main = \"Jurong West\")\n\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.5.2 Creating owin object\nWe will convert these sf objects into owin objects that is required by spatstat.\n\n\ncode chunk\npg_owin = as.owin(pg)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\njw_owin = as.owin(jw)\n\n\n\n\n5.5.3 Combining childcare points and the study area\nUsing the code below, we can extract childcare facilities within specific regions for further analysis.\n\n\ncode chunk\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\n\nNext, the rescale.ppp() function is used to transform the unit of measurement from meters to kilometers.\n\n\ncode chunk\nchildcare_pg_ppp.km = rescale.ppp(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale.ppp(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale.ppp(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale.ppp(childcare_jw_ppp, 1000, \"km\")\n\n\nThe following code is used to plot the four study areas along with the locations of the childcare centers.\n\n\ncode chunk\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp.km, main=\"Punggol\")\n\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 61 symbols are shown in the symbol map\n\n\ncode chunk\nplot(childcare_tm_ppp.km, main=\"Tampines\")\n\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 89 symbols are shown in the symbol map\n\n\ncode chunk\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\n\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 61 symbols are shown in the symbol map\n\n\ncode chunk\nplot(childcare_jw_ppp.km, main=\"Jurong West\")\n\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 88 symbols are shown in the symbol map"
  },
  {
    "objectID": "in_class_ex/in_class_ex02/in_class_ex02.html",
    "href": "in_class_ex/in_class_ex02/in_class_ex02.html",
    "title": "In-class Exercise 2: Spatial Point Patterns Analysis",
    "section": "",
    "text": "maptools is retired and its binary is removed from CRAN. However, we can download it from Posit Public Package Manager snapshots by using following code\n\n\ncode chunk\ninstall.packages(\"maptools\",\n                 repos = \"https://packagemanager.posit.co/cran/2023-10-13\")\n\n\n\nInclude #| eval: false in the code chunk to avoid maptools being downloaded and installed repetitively every time the Quarto document is rendered.\n\n\n\n\nThe code chunk below install and load following packages into R environment:\n\nsf, a relatively new R package specially designed to import, manage and process vector-based geospatial data in R.\nspatstat, which has a wide range of useful functions for point pattern analysis. In this hands-on exercise, it will be used to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer.\nraster which reads, writes, manipulates, analyses and model of gridded spatial data (i.e. raster). In this hands-on exercise, it will be used to convert image output generate by spatstat into raster format.\nmaptools which provides a set of tools for manipulating geographic data. In this hands-on exercise, we mainly use it to convert Spatial objects into ppp format of spatstat.\ntmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\n\n\n\ncode chunk\npacman::p_load(sf, raster, spatstat, tmap, tidyverse)"
  },
  {
    "objectID": "in_class_ex/in_class_ex02/in_class_ex02.html#install-maptools-package",
    "href": "in_class_ex/in_class_ex02/in_class_ex02.html#install-maptools-package",
    "title": "In-class Exercise 2: Spatial Point Patterns Analysis",
    "section": "",
    "text": "maptools is retired and its binary is removed from CRAN. However, we can download it from Posit Public Package Manager snapshots by using following code\n\n\ncode chunk\ninstall.packages(\"maptools\",\n                 repos = \"https://packagemanager.posit.co/cran/2023-10-13\")\n\n\n\nInclude #| eval: false in the code chunk to avoid maptools being downloaded and installed repetitively every time the Quarto document is rendered."
  },
  {
    "objectID": "in_class_ex/in_class_ex02/in_class_ex02.html#install-remaining-packages",
    "href": "in_class_ex/in_class_ex02/in_class_ex02.html#install-remaining-packages",
    "title": "In-class Exercise 2: Spatial Point Patterns Analysis",
    "section": "",
    "text": "The code chunk below install and load following packages into R environment:\n\nsf, a relatively new R package specially designed to import, manage and process vector-based geospatial data in R.\nspatstat, which has a wide range of useful functions for point pattern analysis. In this hands-on exercise, it will be used to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer.\nraster which reads, writes, manipulates, analyses and model of gridded spatial data (i.e. raster). In this hands-on exercise, it will be used to convert image output generate by spatstat into raster format.\nmaptools which provides a set of tools for manipulating geographic data. In this hands-on exercise, we mainly use it to convert Spatial objects into ppp format of spatstat.\ntmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\n\n\n\ncode chunk\npacman::p_load(sf, raster, spatstat, tmap, tidyverse)"
  },
  {
    "objectID": "in_class_ex/in_class_ex02/in_class_ex02.html#working-with-st_union",
    "href": "in_class_ex/in_class_ex02/in_class_ex02.html#working-with-st_union",
    "title": "In-class Exercise 2: Spatial Point Patterns Analysis",
    "section": "2.1 working with st_union()",
    "text": "2.1 working with st_union()\nis used to derive the coastal outline sf tibble data.frame\n\n\ncode chunk\nsg_sf &lt;- mpsz_sf %&gt;%\n  st_union()\n\n\nsg_sf will look similar to the figure below.\n\n\ncode chunk\nplot(sg_sf)"
  },
  {
    "objectID": "in_class_ex/in_class_ex02/in_class_ex02.html#visualising-kde-using-tmap",
    "href": "in_class_ex/in_class_ex02/in_class_ex02.html#visualising-kde-using-tmap",
    "title": "In-class Exercise 2: Spatial Point Patterns Analysis",
    "section": "7.1 Visualising KDE using tmap",
    "text": "7.1 Visualising KDE using tmap\nWe can plot the output raster by using tmap functions.\n\n\ncode chunk\nkde_childcareSG_ad_raster &lt;- raster(gridded_kde_childcareSG_ad)\nprojection(kde_childcareSG_ad_raster) &lt;- CRS(\"+init=EPSG:3414\")\n\n\n\n\ncode chunk\ntm_shape(kde_childcareSG_ad_raster) + \n  tm_raster(palette = \"viridis\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), \n            frame = FALSE,\n            bg.color = \"#E4D5C9\")"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex03/hands_on_ex03.html",
    "href": "hands_on_ex/hands_on_ex03/hands_on_ex03.html",
    "title": "Hands-on Exercise 3: Network Constrained Spatial Point Patterns Analysis",
    "section": "",
    "text": "Network constrained Spatial Point Pattern Analysis (NetSPAA) is a collection of specialized methods designed for analyzing spatial point events that occur on or alongside a network. These events could include, for example, the locations of traffic accidents or childcare centers, while the network itself might represent road systems, river networks, or other linear infrastructures.\nIn this hands-on exercise, we will learn practical experience with the key functions of the spNetwork package, specifically:\n\nDeriving Network Kernel Density Estimation (NKDE)\nPerforming Network-based G-function and K-function analysis"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex03/hands_on_ex03.html#import",
    "href": "hands_on_ex/hands_on_ex03/hands_on_ex03.html#import",
    "title": "Hands-on Exercise 3: Network Constrained Spatial Point Patterns Analysis",
    "section": "4.1 Import",
    "text": "4.1 Import\nThe code chunk below uses st_read() of sf package to important Punggol_St and Punggol_CC geospatial data sets into RStudio as sf data frames.\n\nnetwork &lt;- st_read(dsn=\"data/geospatial\", \n                   layer=\"Punggol_St\")\n\nReading layer `Punggol_St' from data source \n  `/Users/cham/project/Geospatial-Analytics/chrismanafe/ISSS626-GAA/hands_on_ex/hands_on_ex03/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2642 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 34038.56 ymin: 40941.11 xmax: 38882.85 ymax: 44801.27\nProjected CRS: SVY21 / Singapore TM\n\n\n\nchildcare &lt;- st_read(dsn=\"data/geospatial\",\n                     layer=\"Punggol_CC\")\n\nReading layer `Punggol_CC' from data source \n  `/Users/cham/project/Geospatial-Analytics/chrismanafe/ISSS626-GAA/hands_on_ex/hands_on_ex03/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 61 features and 1 field\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 34423.98 ymin: 41503.6 xmax: 37619.47 ymax: 44685.77\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex03/hands_on_ex03.html#examine-data-structure",
    "href": "hands_on_ex/hands_on_ex03/hands_on_ex03.html#examine-data-structure",
    "title": "Hands-on Exercise 3: Network Constrained Spatial Point Patterns Analysis",
    "section": "4.2 Examine data structure",
    "text": "4.2 Examine data structure\n\nChildcareNetwork\n\n\n\nchildcare\n\nSimple feature collection with 61 features and 1 field\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 34423.98 ymin: 41503.6 xmax: 37619.47 ymax: 44685.77\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n      Name                      geometry\n1   kml_10 POINT Z (36173.81 42550.33 0)\n2   kml_99 POINT Z (36479.56 42405.21 0)\n3  kml_100 POINT Z (36618.72 41989.13 0)\n4  kml_101 POINT Z (36285.37 42261.42 0)\n5  kml_122  POINT Z (35414.54 42625.1 0)\n6  kml_161 POINT Z (36545.16 42580.09 0)\n7  kml_172 POINT Z (35289.44 44083.57 0)\n8  kml_188 POINT Z (36520.56 42844.74 0)\n9  kml_205  POINT Z (36924.01 41503.6 0)\n10 kml_222 POINT Z (37141.76 42326.36 0)\n\n\nWe noticed that geometry attribute of childcare has 3D point, but we require 2D points for NKDE function. So we need to drop the Z-dimension of geometry attribute.\n\nchildcare &lt;- st_zm(childcare,\n                   drop = T,\n                   what = \"ZM\")\n\n\nst_crs(childcare)\n\nCoordinate Reference System:\n  User input: SVY21 / Singapore TM \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\nnetwork\n\nSimple feature collection with 2642 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 34038.56 ymin: 40941.11 xmax: 38882.85 ymax: 44801.27\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n     LINK_ID                   ST_NAME                       geometry\n1  116130894                PUNGGOL RD LINESTRING (36546.89 44574....\n2  116130897 PONGGOL TWENTY-FOURTH AVE LINESTRING (36546.89 44574....\n3  116130901   PONGGOL SEVENTEENTH AVE LINESTRING (36012.73 44154....\n4  116130902   PONGGOL SEVENTEENTH AVE LINESTRING (36062.81 44197....\n5  116130907           PUNGGOL CENTRAL LINESTRING (36131.85 42755....\n6  116130908                PUNGGOL RD LINESTRING (36112.93 42752....\n7  116130909           PUNGGOL CENTRAL LINESTRING (36127.4 42744.5...\n8  116130910               PUNGGOL FLD LINESTRING (35994.98 42428....\n9  116130911               PUNGGOL FLD LINESTRING (35984.97 42407....\n10 116130912            EDGEFIELD PLNS LINESTRING (36200.87 42219....\n\n\n\nst_crs(network)\n\nCoordinate Reference System:\n  User input: SVY21 / Singapore TM \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex03/hands_on_ex03.html#preparing-the-lixels-object",
    "href": "hands_on_ex/hands_on_ex03/hands_on_ex03.html#preparing-the-lixels-object",
    "title": "Hands-on Exercise 3: Network Constrained Spatial Point Patterns Analysis",
    "section": "6.1 Preparing the lixels object",
    "text": "6.1 Preparing the lixels object\nBefore computing NKDE, the SpatialLines object need to be split into lixels with a specified minimal distance. This operation can be accomplished using lixelize_lines() function from the spNetwork package.\n\nlixels &lt;- lixelize_lines(network, \n                         700, \n                         mindist = 350)\n\n\n\n\n\n\n\nNote\n\n\n\nIn above code, we set the length of a lixel to 700m and set the minimum length of a lixel to 350m.\nAdditional Notes:\n\nIf the final lixel after splitting is shorter than the specified minimal distance, it is combined with preceding lixel.\nIf the minimum distance is not specified (NULL), it defaults to \\(\\frac{\\text{maxdist}}{10}\\).\nIf the segments that are already shorter than the minimum distance are not modified.\nAnother function, lixelize_lines.mc(), is available, which provides multicore support for processing."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex03/hands_on_ex03.html#generate-line-centre-points",
    "href": "hands_on_ex/hands_on_ex03/hands_on_ex03.html#generate-line-centre-points",
    "title": "Hands-on Exercise 3: Network Constrained Spatial Point Patterns Analysis",
    "section": "6.2 Generate line centre points",
    "text": "6.2 Generate line centre points\nlines_center() of spNetwork is used to generate a SpatialPointsDataFrame with line centre points. The points are located at center of the line based on the length of the line.\n\nsamples &lt;- lines_center(lixels)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex03/hands_on_ex03.html#performing-nkde",
    "href": "hands_on_ex/hands_on_ex03/hands_on_ex03.html#performing-nkde",
    "title": "Hands-on Exercise 3: Network Constrained Spatial Point Patterns Analysis",
    "section": "6.3 Performing NKDE",
    "text": "6.3 Performing NKDE\nTo compute NKDE:\n\ndensities &lt;- nkde(network, \n                  events = childcare,\n                  w = rep(1, nrow(childcare)),\n                  samples = samples,\n                  kernel_name = \"quartic\",\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5, \n                  sparse = TRUE,\n                  verbose = FALSE)\n\n\n\n\n\n\n\nNote\n\n\n\nIt is recommended to read the documentation of nkde() function to understand various parameters too calibrate NKDE model."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex03/hands_on_ex03.html#visualising-nkde",
    "href": "hands_on_ex/hands_on_ex03/hands_on_ex03.html#visualising-nkde",
    "title": "Hands-on Exercise 3: Network Constrained Spatial Point Patterns Analysis",
    "section": "6.4 Visualising NKDE",
    "text": "6.4 Visualising NKDE\n\n6.4.1 Insert computed density values into samples and lixels object as density field\n\nsamples$density &lt;- densities\nlixels$density &lt;- densities"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex03/hands_on_ex03.html#rescale-density-values",
    "href": "hands_on_ex/hands_on_ex03/hands_on_ex03.html#rescale-density-values",
    "title": "Hands-on Exercise 3: Network Constrained Spatial Point Patterns Analysis",
    "section": "6.5 Rescale density values",
    "text": "6.5 Rescale density values\nSince svy21 projection system is in meter, the computed density values are very small i.e. 0.0000005. We can rescale the density values from number of events per meter to number of events per kilometer using following code:\n\n# rescaling to help the mapping\nsamples$density &lt;- samples$density*1000\nlixels$density &lt;- lixels$density*1000"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex03/hands_on_ex03.html#visualise-using-tmap-package",
    "href": "hands_on_ex/hands_on_ex03/hands_on_ex03.html#visualise-using-tmap-package",
    "title": "Hands-on Exercise 3: Network Constrained Spatial Point Patterns Analysis",
    "section": "6.6 Visualise using tmap package",
    "text": "6.6 Visualise using tmap package\nWe use tmap package to prepare interactive and high cartographic quality map visualisation.\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(lixels)+\n  tm_lines(col=\"density\")+\ntm_shape(childcare)+\n  tm_dots()\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\n\n\n\n\n\n\nRoad segments with relatively higher density of childcare centres is highlighted with darker color. Road segments with relatively lower density of childcare centres is highlighted with lighter color."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex03/hands_on_ex03.html#visualise-ggplot2-object-of-k-function",
    "href": "hands_on_ex/hands_on_ex03/hands_on_ex03.html#visualise-ggplot2-object-of-k-function",
    "title": "Hands-on Exercise 3: Network Constrained Spatial Point Patterns Analysis",
    "section": "Visualise ggplot2 object of k-function",
    "text": "Visualise ggplot2 object of k-function\n\nkfun_childcare$plotk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation\n\n\n\n\nObservations\n\nThe blue line is the empirical network K-function of the childcare centres in Punggol planning area.\nThe gray envelop represents the results of the 50 simulations in the interval 2.5% - 97.5%.\nThe blue line between the distance of 250m-400m are below the gray area.\n\n\n\nInference\n\nThe childcare centres in Punggol planning area resemble regular pattern at the distance of 250m-400m."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex03/hands_on_ex03.html#inference",
    "href": "hands_on_ex/hands_on_ex03/hands_on_ex03.html#inference",
    "title": "Hands-on Exercise 3: Network Constrained Spatial Point Patterns Analysis",
    "section": "Inference",
    "text": "Inference\n\nThe childcare centres in Punggol planning area resemble regular pattern at the distance of 250m-400m."
  },
  {
    "objectID": "in_class_ex/in_class_ex03/in_class_ex03.html",
    "href": "in_class_ex/in_class_ex03/in_class_ex03.html",
    "title": "In-class Exercise 3: Advanced Spatial Point Patterns Analysis",
    "section": "",
    "text": "Network constrained Spatial Point Pattern Analysis (NetSPAA) is a collection of specialized methods designed for analyzing spatial point events that occur on or alongside a network. These events could include, for example, the locations of traffic accidents or childcare centers, while the network itself might represent road systems, river networks, or other linear infrastructures.\nIn this in-class exercise, we will learn practical experience with the key functions of the spNetwork package, specifically:\n\nDeriving Network Kernel Density Estimation (NKDE)\nPerforming Network-based G-function and K-function analysis"
  },
  {
    "objectID": "in_class_ex/in_class_ex03/in_class_ex03.html#import",
    "href": "in_class_ex/in_class_ex03/in_class_ex03.html#import",
    "title": "In-class Exercise 3: Advanced Spatial Point Patterns Analysis",
    "section": "4.1 Import",
    "text": "4.1 Import\nThe code chunk below uses st_read() of sf package to important Punggol_St and Punggol_CC geospatial data sets into RStudio as sf data frames.\n\nnetwork &lt;- st_read(dsn=\"data/geospatial\", \n                   layer=\"Punggol_St\")\n\nReading layer `Punggol_St' from data source \n  `/Users/cham/project/Geospatial-Analytics/chrismanafe/ISSS626-GAA/in_class_ex/in_class_ex03/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2642 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 34038.56 ymin: 40941.11 xmax: 38882.85 ymax: 44801.27\nProjected CRS: SVY21 / Singapore TM\n\n\n\nchildcare &lt;- st_read(dsn=\"data/geospatial\",\n                     layer=\"Punggol_CC\") %&gt;%\n  st_zm(drop = T,\n        what = \"ZM\")\n\nReading layer `Punggol_CC' from data source \n  `/Users/cham/project/Geospatial-Analytics/chrismanafe/ISSS626-GAA/in_class_ex/in_class_ex03/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 61 features and 1 field\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 34423.98 ymin: 41503.6 xmax: 37619.47 ymax: 44685.77\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\n\n\nWe noticed that geometry attribute of childcare has 3D point, but we require 2D points for NKDE function. So we need to drop the Z-dimension of geometry attribute."
  },
  {
    "objectID": "in_class_ex/in_class_ex03/in_class_ex03.html#examine-data-structure",
    "href": "in_class_ex/in_class_ex03/in_class_ex03.html#examine-data-structure",
    "title": "In-class Exercise 3: Advanced Spatial Point Patterns Analysis",
    "section": "4.2 Examine data structure",
    "text": "4.2 Examine data structure\n\nChildcareNetwork\n\n\n\nchildcare\n\nSimple feature collection with 61 features and 1 field\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 34423.98 ymin: 41503.6 xmax: 37619.47 ymax: 44685.77\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n      Name                  geometry\n1   kml_10 POINT (36173.81 42550.33)\n2   kml_99 POINT (36479.56 42405.21)\n3  kml_100 POINT (36618.72 41989.13)\n4  kml_101 POINT (36285.37 42261.42)\n5  kml_122  POINT (35414.54 42625.1)\n6  kml_161 POINT (36545.16 42580.09)\n7  kml_172 POINT (35289.44 44083.57)\n8  kml_188 POINT (36520.56 42844.74)\n9  kml_205  POINT (36924.01 41503.6)\n10 kml_222 POINT (37141.76 42326.36)\n\n\n\nst_crs(childcare)\n\nCoordinate Reference System:\n  User input: SVY21 / Singapore TM \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\nnetwork\n\nSimple feature collection with 2642 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 34038.56 ymin: 40941.11 xmax: 38882.85 ymax: 44801.27\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n     LINK_ID                   ST_NAME                       geometry\n1  116130894                PUNGGOL RD LINESTRING (36546.89 44574....\n2  116130897 PONGGOL TWENTY-FOURTH AVE LINESTRING (36546.89 44574....\n3  116130901   PONGGOL SEVENTEENTH AVE LINESTRING (36012.73 44154....\n4  116130902   PONGGOL SEVENTEENTH AVE LINESTRING (36062.81 44197....\n5  116130907           PUNGGOL CENTRAL LINESTRING (36131.85 42755....\n6  116130908                PUNGGOL RD LINESTRING (36112.93 42752....\n7  116130909           PUNGGOL CENTRAL LINESTRING (36127.4 42744.5...\n8  116130910               PUNGGOL FLD LINESTRING (35994.98 42428....\n9  116130911               PUNGGOL FLD LINESTRING (35984.97 42407....\n10 116130912            EDGEFIELD PLNS LINESTRING (36200.87 42219....\n\n\n\nst_crs(network)\n\nCoordinate Reference System:\n  User input: SVY21 / Singapore TM \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "in_class_ex/in_class_ex03/in_class_ex03.html#preparing-the-lixels-object",
    "href": "in_class_ex/in_class_ex03/in_class_ex03.html#preparing-the-lixels-object",
    "title": "In-class Exercise 3: Advanced Spatial Point Patterns Analysis",
    "section": "7.1 Preparing the lixels object",
    "text": "7.1 Preparing the lixels object\nBefore computing NKDE, the SpatialLines object need to be split into lixels with a specified minimal distance. This operation can be accomplished using lixelize_lines() function from the spNetwork package.\n\nlixels &lt;- lixelize_lines(network, \n                         700, \n                         mindist = 350)\n\n\n\n\n\n\n\nNote\n\n\n\nIn above code, we set the length of a lixel to 700m and set the minimum length of a lixel to 350m.\nAdditional Notes:\n\nIf the final lixel after splitting is shorter than the specified minimal distance, it is combined with preceding lixel.\nIf the minimum distance is not specified (NULL), it defaults to \\(\\frac{\\text{maxdist}}{10}\\).\nIf the segments that are already shorter than the minimum distance are not modified.\nAnother function, lixelize_lines.mc(), is available, which provides multicore support for processing."
  },
  {
    "objectID": "in_class_ex/in_class_ex03/in_class_ex03.html#generate-line-centre-points",
    "href": "in_class_ex/in_class_ex03/in_class_ex03.html#generate-line-centre-points",
    "title": "In-class Exercise 3: Advanced Spatial Point Patterns Analysis",
    "section": "7.2 Generate line centre points",
    "text": "7.2 Generate line centre points\nlines_center() of spNetwork is used to generate a SpatialPointsDataFrame with line centre points. The points are located at center of the line based on the length of the line.\n\nsamples &lt;- lines_center(lixels)"
  },
  {
    "objectID": "in_class_ex/in_class_ex03/in_class_ex03.html#visualize-line-center-points",
    "href": "in_class_ex/in_class_ex03/in_class_ex03.html#visualize-line-center-points",
    "title": "In-class Exercise 3: Advanced Spatial Point Patterns Analysis",
    "section": "7.3 Visualize line center points",
    "text": "7.3 Visualize line center points\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(lixels) +\n  tm_lines() +\ntm_shape(samples) +\ntm_dots(size = 0.01)\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting"
  },
  {
    "objectID": "in_class_ex/in_class_ex03/in_class_ex03.html#performing-nkde",
    "href": "in_class_ex/in_class_ex03/in_class_ex03.html#performing-nkde",
    "title": "In-class Exercise 3: Advanced Spatial Point Patterns Analysis",
    "section": "7.4 Performing NKDE",
    "text": "7.4 Performing NKDE\nTo compute NKDE:\n\ndensities &lt;- nkde(network, \n                  events = childcare,\n                  w = rep(1, nrow(childcare)),\n                  samples = samples,\n                  kernel_name = \"quartic\",\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5, \n                  sparse = TRUE,\n                  verbose = FALSE)\n\n\n\n\n\n\n\nNote\n\n\n\nIt is recommended to read the documentation of nkde() function to understand various parameters too calibrate NKDE model."
  },
  {
    "objectID": "in_class_ex/in_class_ex03/in_class_ex03.html#visualising-nkde",
    "href": "in_class_ex/in_class_ex03/in_class_ex03.html#visualising-nkde",
    "title": "In-class Exercise 3: Advanced Spatial Point Patterns Analysis",
    "section": "7.5 Visualising NKDE",
    "text": "7.5 Visualising NKDE\n\n7.5.1 Insert computed density values into samples and lixels object as density field\n\nsamples$density &lt;- densities\nlixels$density &lt;- densities"
  },
  {
    "objectID": "in_class_ex/in_class_ex03/in_class_ex03.html#rescale-density-values",
    "href": "in_class_ex/in_class_ex03/in_class_ex03.html#rescale-density-values",
    "title": "In-class Exercise 3: Advanced Spatial Point Patterns Analysis",
    "section": "7.6 Rescale density values",
    "text": "7.6 Rescale density values\nSince svy21 projection system is in meter, the computed density values are very small i.e. 0.0000005. We can rescale the density values from number of events per meter to number of events per kilometer using following code:\n\n# rescaling to help the mapping\nsamples$density &lt;- samples$density*1000\nlixels$density &lt;- lixels$density*1000"
  },
  {
    "objectID": "in_class_ex/in_class_ex03/in_class_ex03.html#visualise-using-tmap-package",
    "href": "in_class_ex/in_class_ex03/in_class_ex03.html#visualise-using-tmap-package",
    "title": "In-class Exercise 3: Advanced Spatial Point Patterns Analysis",
    "section": "7.7 Visualise using tmap package",
    "text": "7.7 Visualise using tmap package\nWe use tmap package to prepare interactive and high cartographic quality map visualisation.\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(lixels)+\n  tm_lines(col=\"density\")+\ntm_shape(childcare)+\n  tm_dots()\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\n\n\n\n\n\n\nRoad segments with relatively higher density of childcare centres is highlighted with darker color. Road segments with relatively lower density of childcare centres is highlighted with lighter color."
  },
  {
    "objectID": "in_class_ex/in_class_ex03/in_class_ex03.html#visualise-ggplot2-object-of-k-function",
    "href": "in_class_ex/in_class_ex03/in_class_ex03.html#visualise-ggplot2-object-of-k-function",
    "title": "In-class Exercise 3: Advanced Spatial Point Patterns Analysis",
    "section": "Visualise ggplot2 object of k-function",
    "text": "Visualise ggplot2 object of k-function\n\nkfun_childcare$plotk"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04.html",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04.html",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to compute spatial weights using R."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04.html#import",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04.html#import",
    "title": "In-class Exercise 3: Advanced Spatial Point Patterns Analysis",
    "section": "4.1 Import",
    "text": "4.1 Import"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04.html#computing-contiguity-using-poly2nb",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04.html#computing-contiguity-using-poly2nb",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "6.1 Computing contiguity using poly2nb()",
    "text": "6.1 Computing contiguity using poly2nb()\n\n\n\n\n\n\npoly2nb\n\n\n\nWe will explore how to use the poly2nb() function from the spdep package to compute contiguity weight matrices for the study area. This function generates a neighbors list based on regions with shared boundaries.\nKey Parameters\n\nqueen:\nDetermines the contiguity criteria:\n\nTRUE (default): Implements the Queen contiguity, where regions are considered neighbors if they share either a border or a corner.\nFALSE: Implements the Rook contiguity, where regions are neighbors only if they share a border.\n\n\n\nNote: If we do not specify the queen argument, it defaults to TRUE, meaning the function will return a list of first-order neighbors using the Queen contiguity rule.\n\n\n\n\nQueen contiguityRook contiguity\n\n\n\nwm_q &lt;- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nWe found out that:\n\nThere are 88 area units in Hunan.\nThe most connected area unit has 11 neighbours.\nThere are 2 area units with only one neighbours.\n\n\n\n\nwm_r &lt;- poly2nb(hunan, queen=FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nWe found out that:\n\nThere are 88 area units in Hunan.\nThe most connected area unit has 10 neighbours.\nThere are 2 area units with only one neighbours.\n\n\n\n\n\n6.1.1 Display neighbour(s) of a county\nFor each polygon in our polygon object, wm_q lists all neighboring polygons. For example, to see the neighbors for the first polygon in the object, we can type:\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\nWe see that Polygon 1 has 5 neighbors. The numbers represent the polygon IDs as stored in hunan SpatialPolygonsDataFrame class.\n\n\n6.1.2 Retrieve County Name by polygon ID\nWe can retrive the county name of Polygon ID=1 by using following code:\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\nThe output reveals that Polygon ID=1 is Anxiang county.\nTo reveal the county names of the five neighboring polygons, we can use following code:\n\nhunan$NAME_3[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\n\n\n6.1.3 Retrieve GDPPC\nWe can retrieve the GDPPC of these five countries by using following code:\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\n\n\n6.1.4 Display complete weight matrix using str()\n\nstr(wm_q)\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"sym\")= logi TRUE"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04.html#visualising-contiguity-weights",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04.html#visualising-contiguity-weights",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "6.2 Visualising contiguity weights",
    "text": "6.2 Visualising contiguity weights\nA connectivity graph connects each point to its neighboring points with lines. Since we are working with polygons, we need to derive points to create these graphs. The most common approach is to use polygon centroids.\n\nCalculate these in the sf package before moving onto the graphs.\nGet Latitude and Longitude of Polygon Centroids.\nIt is a little more complicated than just running st_centroid on the sfobject, because we need to extract the latitude and longitude coordinates into a separate data frame.\nWe also need map_dbl() function as a mapping function from the purrr package. This function applies a given function to each element of a vector and returns a vector of the same length. The argument will be:\n\nInput Vector: The geometry column.\nFunction: st_centroid()\n\n\nThis process will give us the latitude and longitude of the centroids in a format we can use for further analysis.\n\nFor more details: Refer to the purrr map documentation.\n\n\n6.2.1 Get Latitude and Longitude of Polygon Centroids\n\nLongitudeLatitudeCoordinates\n\n\nTo get our longitude values we map the st_centroid function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\n\n\nWe do the same for latitude with one key difference. We access the second value per each centroid.\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\n\n\nNow that we have latitude and longitude, we use cbind() to put longitude and latitude into the same object.\n\ncoords &lt;- cbind(longitude, latitude)\n\nLet’s verify the first few observations to see if coords are formatted correctly.\n\nhead(coords)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\n\n\n\n\n\n6.2.2 Plotting contiguity-based neighbours map\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"Queen Contiguity\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\nplot(hunan$geometry, border=\"lightgrey\", main=\"Rook Contiguity\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04.html#determine-the-cut-off-distance",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04.html#determine-the-cut-off-distance",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "7.1 Determine the cut-off distance",
    "text": "7.1 Determine the cut-off distance\nWe need to determine the upper limit for distance band by using following steps:\n\n\n\n\n\n\n\n\nStep\nDescription\nFunction\n\n\n\n\n1\nReturn a matrix with the indices of points belonging to the set of the k-nearest neighbours (knn) of each other.\nknearneigh() of spdep\n\n\n2\nConvert the knn object into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids.\nknn2nb() of spdep\n\n\n3\nReturn the length of neighbour relationship edges.\nnbdists() of spdep\n\n\n4\nRemove the list structure of the returned object.\nunlist()\n\n\n\n\n#coords &lt;- coordinates(hunan)\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04.html#computing-fixed-distance-weight-matrix",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04.html#computing-fixed-distance-weight-matrix",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "7.2 Computing fixed distance weight matrix",
    "text": "7.2 Computing fixed distance weight matrix\nWe will compute the distance weight matrix by using dnearneigh() function\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\n\nThe “Average number of links: 3.681818” means that, on average, each region is connected to approximately 3.68 neighboring regions based on the specified distance criteria.\n\nWe’ll display the content of wm_d62 weight matrix.\n\nUsing str()Using table() and card()\n\n\n\nstr(wm_d62)\n\nList of 88\n $ : int [1:5] 3 4 5 57 64\n $ : int [1:4] 57 58 78 85\n $ : int [1:4] 1 4 5 57\n $ : int [1:3] 1 3 5\n $ : int [1:4] 1 3 4 85\n $ : int 69\n $ : int [1:2] 67 84\n $ : int [1:4] 9 46 47 78\n $ : int [1:4] 8 46 68 84\n $ : int [1:4] 16 22 70 72\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:2] 11 17\n $ : int 13\n $ : int [1:4] 10 17 22 83\n $ : int [1:3] 11 14 16\n $ : int [1:3] 20 22 63\n $ : int [1:5] 20 21 73 74 82\n $ : int [1:5] 18 19 21 22 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:4] 10 16 18 20\n $ : int [1:3] 41 77 82\n $ : int [1:4] 25 28 31 54\n $ : int [1:4] 24 28 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:2] 26 29\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:2] 27 37\n $ : int 33\n $ : int [1:2] 24 36\n $ : int 50\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:5] 31 34 45 56 80\n $ : int [1:2] 29 42\n $ : int [1:3] 44 77 79\n $ : int [1:4] 40 42 43 81\n $ : int [1:3] 39 45 79\n $ : int [1:5] 23 35 45 79 82\n $ : int [1:5] 26 37 39 43 81\n $ : int [1:3] 39 42 44\n $ : int [1:2] 38 43\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:5] 8 9 35 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:4] 48 49 50 52\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:2] 48 55\n $ : int [1:5] 24 28 49 50 52\n $ : int [1:4] 48 50 53 75\n $ : int 36\n $ : int [1:5] 1 2 3 58 64\n $ : int [1:5] 2 57 64 66 68\n $ : int [1:3] 60 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:5] 12 60 62 63 87\n $ : int [1:4] 61 63 77 87\n $ : int [1:5] 12 18 61 62 83\n $ : int [1:4] 1 57 58 76\n $ : int 76\n $ : int [1:5] 58 67 68 76 84\n $ : int [1:2] 7 66\n $ : int [1:4] 9 58 66 84\n $ : int [1:2] 6 75\n $ : int [1:3] 10 72 73\n $ : int [1:2] 73 74\n $ : int [1:3] 10 11 70\n $ : int [1:4] 19 70 71 74\n $ : int [1:5] 19 21 71 73 86\n $ : int [1:2] 55 69\n $ : int [1:3] 64 65 66\n $ : int [1:3] 23 38 62\n $ : int [1:2] 2 8\n $ : int [1:4] 38 40 41 45\n $ : int [1:5] 34 35 36 45 47\n $ : int [1:5] 25 26 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:4] 12 13 16 63\n $ : int [1:4] 7 9 66 68\n $ : int [1:2] 2 5\n $ : int [1:4] 21 46 47 74\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language dnearneigh(x = coords, d1 = 0, d2 = 62, longlat = TRUE)\n - attr(*, \"dnn\")= num [1:2] 0 62\n - attr(*, \"bounds\")= chr [1:2] \"GE\" \"LE\"\n - attr(*, \"nbtype\")= chr \"distance\"\n - attr(*, \"sym\")= logi TRUE\n\n\n\n\n\ntable(hunan$County, card(wm_d62))\n\n               \n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\n\n\n\nLet us the number of disjoint connected subgraphs in the graph.\n\nn_comp &lt;- n.comp.nb(wm_d62)\nn_comp$nc\n\n[1] 1\n\n\n\ntable(n_comp$comp.id)\n\n\n 1 \n88 \n\n\n\n7.2.1 Plotting fixed distance weight matrix\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE)\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\n\n\n\n\n\n\n\n\nThe red lines show the links of 1st nearest neighbours and the black lines show the links of neighbours within the cut-off distance of 62km.\nAlternatively, we can plot both of them next to each other.\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"1st nearest neighbours\")\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\nplot(hunan$geometry, border=\"lightgrey\", main=\"Distance link\")\nplot(wm_d62, coords, add=TRUE, pch = 19, cex = 0.6)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04.html#computing-adaptive-distance-weight-matrix",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04.html#computing-adaptive-distance-weight-matrix",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "7.3 Computing adaptive distance weight matrix",
    "text": "7.3 Computing adaptive distance weight matrix\nFor fixed distance weight matrix, more densely settled areas (usually urban areas) tend to have more neighbours and the less densely settled areas (usually rural counties) tend to have lesser neighbours.\nHaving many neighbours smoothes the neighbour relationship across more neighbours.\n\nControl the number of neighboursPlotting distance based neighbours\n\n\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry.\n\nknn6 &lt;- knn2nb(knearneigh(coords, k=6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\n\nNotice that each county has at most 6 neighbours.\n\n\nstr(knn6)\n\nList of 88\n $ : int [1:6] 2 3 4 5 57 64\n $ : int [1:6] 1 3 57 58 78 85\n $ : int [1:6] 1 2 4 5 57 85\n $ : int [1:6] 1 3 5 6 69 85\n $ : int [1:6] 1 3 4 6 69 85\n $ : int [1:6] 3 4 5 69 75 85\n $ : int [1:6] 9 66 67 71 74 84\n $ : int [1:6] 9 46 47 78 80 86\n $ : int [1:6] 8 46 66 68 84 86\n $ : int [1:6] 16 19 22 70 72 73\n $ : int [1:6] 10 14 16 17 70 72\n $ : int [1:6] 13 15 60 61 63 83\n $ : int [1:6] 12 15 60 61 63 83\n $ : int [1:6] 11 15 16 17 72 83\n $ : int [1:6] 12 13 14 17 60 83\n $ : int [1:6] 10 11 17 22 72 83\n $ : int [1:6] 10 11 14 16 72 83\n $ : int [1:6] 20 22 23 63 77 83\n $ : int [1:6] 10 20 21 73 74 82\n $ : int [1:6] 18 19 21 22 23 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:6] 10 16 18 19 20 83\n $ : int [1:6] 18 20 41 77 79 82\n $ : int [1:6] 25 28 31 52 54 81\n $ : int [1:6] 24 28 31 33 54 81\n $ : int [1:6] 25 27 29 33 42 81\n $ : int [1:6] 26 29 30 37 42 81\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:6] 26 27 37 42 43 81\n $ : int [1:6] 26 27 28 33 49 81\n $ : int [1:6] 24 25 36 39 40 54\n $ : int [1:6] 24 31 50 54 55 56\n $ : int [1:6] 25 26 28 30 49 81\n $ : int [1:6] 36 40 41 45 56 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:6] 26 27 29 42 43 44\n $ : int [1:6] 23 43 44 62 77 79\n $ : int [1:6] 25 40 42 43 44 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:6] 26 27 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:6] 37 38 39 42 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:6] 8 9 35 47 78 86\n $ : int [1:6] 8 21 35 46 80 86\n $ : int [1:6] 49 50 51 52 53 55\n $ : int [1:6] 28 33 48 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:6] 28 48 49 50 52 54\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:6] 48 50 51 52 55 75\n $ : int [1:6] 24 28 49 50 51 52\n $ : int [1:6] 32 48 50 52 53 75\n $ : int [1:6] 32 34 36 78 80 85\n $ : int [1:6] 1 2 3 58 64 68\n $ : int [1:6] 2 57 64 66 68 78\n $ : int [1:6] 12 13 60 61 87 88\n $ : int [1:6] 12 13 59 61 63 87\n $ : int [1:6] 12 13 60 62 63 87\n $ : int [1:6] 12 38 61 63 77 87\n $ : int [1:6] 12 18 60 61 62 83\n $ : int [1:6] 1 3 57 58 68 76\n $ : int [1:6] 58 64 66 67 68 76\n $ : int [1:6] 9 58 67 68 76 84\n $ : int [1:6] 7 65 66 68 76 84\n $ : int [1:6] 9 57 58 66 78 84\n $ : int [1:6] 4 5 6 32 75 85\n $ : int [1:6] 10 16 19 22 72 73\n $ : int [1:6] 7 19 73 74 84 86\n $ : int [1:6] 10 11 14 16 17 70\n $ : int [1:6] 10 19 21 70 71 74\n $ : int [1:6] 19 21 71 73 84 86\n $ : int [1:6] 6 32 50 53 55 69\n $ : int [1:6] 58 64 65 66 67 68\n $ : int [1:6] 18 23 38 61 62 63\n $ : int [1:6] 2 8 9 46 58 68\n $ : int [1:6] 38 40 41 43 44 45\n $ : int [1:6] 34 35 36 41 45 47\n $ : int [1:6] 25 26 28 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:6] 12 13 15 16 22 63\n $ : int [1:6] 7 9 66 68 71 74\n $ : int [1:6] 2 3 4 5 56 69\n $ : int [1:6] 8 9 21 46 47 74\n $ : int [1:6] 59 60 61 62 63 88\n $ : int [1:6] 59 60 61 62 63 87\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language knearneigh(x = coords, k = 6)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 6\n - attr(*, \"class\")= chr \"nb\"\n\n\n\n\nWe can plot the weight matrix using following code:\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04.html#step-1-compute-the-distance-between-areas-using-nbdists-of-spdep.",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04.html#step-1-compute-the-distance-between-areas-using-nbdists-of-spdep.",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "8.1 Step 1: Compute the distance between areas using nbdists() of spdep.",
    "text": "8.1 Step 1: Compute the distance between areas using nbdists() of spdep.\n\ndist &lt;- nbdists(wm_q, coords, longlat = TRUE)\nids &lt;- lapply(dist, function(x) 1/(x))\nids\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n[[2]]\n[1] 0.01535405 0.01764308 0.01925924 0.02323898 0.01719350\n\n[[3]]\n[1] 0.03916350 0.02822040 0.03695795 0.01395765\n\n[[4]]\n[1] 0.01820896 0.02822040 0.03414741 0.01539065\n\n[[5]]\n[1] 0.03695795 0.03414741 0.01524598 0.01618354\n\n[[6]]\n[1] 0.015390649 0.015245977 0.021748129 0.011883901 0.009810297\n\n[[7]]\n[1] 0.01708612 0.01473997 0.01150924 0.01872915\n\n[[8]]\n[1] 0.02022144 0.03453056 0.02529256 0.01036340 0.02284457 0.01500600 0.01515314\n\n[[9]]\n[1] 0.02022144 0.01574888 0.02109502 0.01508028 0.02902705 0.01502980\n\n[[10]]\n[1] 0.02281552 0.01387777 0.01538326 0.01346650 0.02100510 0.02631658 0.01874863\n[8] 0.01500046\n\n[[11]]\n[1] 0.01882869 0.02243492 0.02247473\n\n[[12]]\n[1] 0.02779227 0.02419652 0.02333385 0.02986130 0.02335429\n\n[[13]]\n[1] 0.02779227 0.02650020 0.02670323 0.01714243\n\n[[14]]\n[1] 0.01882869 0.01233868 0.02098555\n\n[[15]]\n[1] 0.02650020 0.01233868 0.01096284 0.01562226\n\n[[16]]\n[1] 0.02281552 0.02466962 0.02765018 0.01476814 0.01671430\n\n[[17]]\n[1] 0.01387777 0.02243492 0.02098555 0.01096284 0.02466962 0.01593341 0.01437996\n\n[[18]]\n[1] 0.02039779 0.02032767 0.01481665 0.01473691 0.01459380\n\n[[19]]\n[1] 0.01538326 0.01926323 0.02668415 0.02140253 0.01613589 0.01412874\n\n[[20]]\n[1] 0.01346650 0.02039779 0.01926323 0.01723025 0.02153130 0.01469240 0.02327034\n\n[[21]]\n[1] 0.02668415 0.01723025 0.01766299 0.02644986 0.02163800\n\n[[22]]\n[1] 0.02100510 0.02765018 0.02032767 0.02153130 0.01489296\n\n[[23]]\n[1] 0.01481665 0.01469240 0.01401432 0.02246233 0.01880425 0.01530458 0.01849605\n\n[[24]]\n[1] 0.02354598 0.01837201 0.02607264 0.01220154 0.02514180\n\n[[25]]\n[1] 0.02354598 0.02188032 0.01577283 0.01949232 0.02947957\n\n[[26]]\n[1] 0.02155798 0.01745522 0.02212108 0.02220532\n\n[[27]]\n[1] 0.02155798 0.02490625 0.01562326\n\n[[28]]\n[1] 0.01837201 0.02188032 0.02229549 0.03076171 0.02039506\n\n[[29]]\n[1] 0.02490625 0.01686587 0.01395022\n\n[[30]]\n[1] 0.02090587\n\n[[31]]\n[1] 0.02607264 0.01577283 0.01219005 0.01724850 0.01229012 0.01609781 0.01139438\n[8] 0.01150130\n\n[[32]]\n[1] 0.01220154 0.01219005 0.01712515 0.01340413 0.01280928 0.01198216 0.01053374\n[8] 0.01065655\n\n[[33]]\n[1] 0.01949232 0.01745522 0.02229549 0.02090587 0.01979045\n\n[[34]]\n[1] 0.03113041 0.03589551 0.02882915\n\n[[35]]\n[1] 0.01766299 0.02185795 0.02616766 0.02111721 0.02108253 0.01509020\n\n[[36]]\n[1] 0.01724850 0.03113041 0.01571707 0.01860991 0.02073549 0.01680129\n\n[[37]]\n[1] 0.01686587 0.02234793 0.01510990 0.01550676\n\n[[38]]\n[1] 0.01401432 0.02407426 0.02276151 0.01719415\n\n[[39]]\n[1] 0.01229012 0.02172543 0.01711924 0.02629732 0.01896385\n\n[[40]]\n[1] 0.01609781 0.01571707 0.02172543 0.01506473 0.01987922 0.01894207\n\n[[41]]\n[1] 0.02246233 0.02185795 0.02205991 0.01912542 0.01601083 0.01742892\n\n[[42]]\n[1] 0.02212108 0.01562326 0.01395022 0.02234793 0.01711924 0.01836831 0.01683518\n\n[[43]]\n[1] 0.01510990 0.02629732 0.01506473 0.01836831 0.03112027 0.01530782\n\n[[44]]\n[1] 0.01550676 0.02407426 0.03112027 0.01486508\n\n[[45]]\n[1] 0.03589551 0.01860991 0.01987922 0.02205991 0.02107101 0.01982700\n\n[[46]]\n[1] 0.03453056 0.04033752 0.02689769\n\n[[47]]\n[1] 0.02529256 0.02616766 0.04033752 0.01949145 0.02181458\n\n[[48]]\n[1] 0.02313819 0.03370576 0.02289485 0.01630057 0.01818085\n\n[[49]]\n[1] 0.03076171 0.02138091 0.02394529 0.01990000\n\n[[50]]\n[1] 0.01712515 0.02313819 0.02551427 0.02051530 0.02187179\n\n[[51]]\n[1] 0.03370576 0.02138091 0.02873854\n\n[[52]]\n[1] 0.02289485 0.02394529 0.02551427 0.02873854 0.03516672\n\n[[53]]\n[1] 0.01630057 0.01979945 0.01253977\n\n[[54]]\n[1] 0.02514180 0.02039506 0.01340413 0.01990000 0.02051530 0.03516672\n\n[[55]]\n[1] 0.01280928 0.01818085 0.02187179 0.01979945 0.01882298\n\n[[56]]\n[1] 0.01036340 0.01139438 0.01198216 0.02073549 0.01214479 0.01362855 0.01341697\n\n[[57]]\n[1] 0.028079221 0.017643082 0.031423501 0.029114131 0.013520292 0.009903702\n\n[[58]]\n[1] 0.01925924 0.03142350 0.02722997 0.01434859 0.01567192\n\n[[59]]\n[1] 0.01696711 0.01265572 0.01667105 0.01785036\n\n[[60]]\n[1] 0.02419652 0.02670323 0.01696711 0.02343040\n\n[[61]]\n[1] 0.02333385 0.01265572 0.02343040 0.02514093 0.02790764 0.01219751 0.02362452\n\n[[62]]\n[1] 0.02514093 0.02002219 0.02110260\n\n[[63]]\n[1] 0.02986130 0.02790764 0.01407043 0.01805987\n\n[[64]]\n[1] 0.02911413 0.01689892\n\n[[65]]\n[1] 0.02471705\n\n[[66]]\n[1] 0.01574888 0.01726461 0.03068853 0.01954805 0.01810569\n\n[[67]]\n[1] 0.01708612 0.01726461 0.01349843 0.01361172\n\n[[68]]\n[1] 0.02109502 0.02722997 0.03068853 0.01406357 0.01546511\n\n[[69]]\n[1] 0.02174813 0.01645838 0.01419926\n\n[[70]]\n[1] 0.02631658 0.01963168 0.02278487\n\n[[71]]\n[1] 0.01473997 0.01838483 0.03197403\n\n[[72]]\n[1] 0.01874863 0.02247473 0.01476814 0.01593341 0.01963168\n\n[[73]]\n[1] 0.01500046 0.02140253 0.02278487 0.01838483 0.01652709\n\n[[74]]\n[1] 0.01150924 0.01613589 0.03197403 0.01652709 0.01342099 0.02864567\n\n[[75]]\n[1] 0.011883901 0.010533736 0.012539774 0.018822977 0.016458383 0.008217581\n\n[[76]]\n[1] 0.01352029 0.01434859 0.01689892 0.02471705 0.01954805 0.01349843 0.01406357\n\n[[77]]\n[1] 0.014736909 0.018804247 0.022761507 0.012197506 0.020022195 0.014070428\n[7] 0.008440896\n\n[[78]]\n[1] 0.02323898 0.02284457 0.01508028 0.01214479 0.01567192 0.01546511 0.01140779\n\n[[79]]\n[1] 0.01530458 0.01719415 0.01894207 0.01912542 0.01530782 0.01486508 0.02107101\n\n[[80]]\n[1] 0.01500600 0.02882915 0.02111721 0.01680129 0.01601083 0.01982700 0.01949145\n[8] 0.01362855\n\n[[81]]\n[1] 0.02947957 0.02220532 0.01150130 0.01979045 0.01896385 0.01683518\n\n[[82]]\n[1] 0.02327034 0.02644986 0.01849605 0.02108253 0.01742892\n\n[[83]]\n[1] 0.023354289 0.017142433 0.015622258 0.016714303 0.014379961 0.014593799\n[7] 0.014892965 0.018059871 0.008440896\n\n[[84]]\n[1] 0.01872915 0.02902705 0.01810569 0.01361172 0.01342099 0.01297994\n\n[[85]]\n [1] 0.011451133 0.017193502 0.013957649 0.016183544 0.009810297 0.010656545\n [7] 0.013416965 0.009903702 0.014199260 0.008217581 0.011407794\n\n[[86]]\n[1] 0.01515314 0.01502980 0.01412874 0.02163800 0.01509020 0.02689769 0.02181458\n[8] 0.02864567 0.01297994\n\n[[87]]\n[1] 0.01667105 0.02362452 0.02110260 0.02058034\n\n[[88]]\n[1] 0.01785036 0.02058034"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04.html#step-2-row-standardised-weights-matrix",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04.html#step-2-row-standardised-weights-matrix",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "8.2 Step 2: Row-standardised Weights Matrix",
    "text": "8.2 Step 2: Row-standardised Weights Matrix\nThen we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(# of neighbors) to each neighboring county then summing the weighted income values.\nWhile this is the most intuitive way to summaries the neighbors’ values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data.\n\nFor this example, we’ll use style=“W” option for simplicity’s sake but more robust options are available, notably style=“B”.\n\n\nrswm_q &lt;- nb2listw(wm_q, style=\"W\", zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\nzero.policy = TRUE option allows for lists of non-neighbors. This should be used with caution since the user may not be aware of missing neighbors in their dataset however, a zero.policy = FALSE would return an error.\n\nTo see the weight of the first polygon’s eight neighbors:\n\nrswm_q$weights[10]\n\n[[1]]\n[1] 0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125\n\n\nEach neighbor is assigned a 0.125 of the total weight. This means that when R computes the average neighboring income values, each neighbor’s income will be multiplied by 0.125 before being tallied.\nUsing the same method, we can also derive a row standardised distance weight matrix by using following code:\n\nrswm_ids &lt;- nb2listw(wm_q, glist=ids, style=\"B\", zero.policy=TRUE)\nrswm_ids\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn       S0        S1     S2\nB 88 7744 8.786867 0.3776535 3.8137\n\n\n\nrswm_ids$weights[1]\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n\n\nsummary(unlist(rswm_ids$weights))\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.008218 0.015088 0.018739 0.019614 0.022823 0.040338"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04.html#spatial-lag-with-row-standardized-weights",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04.html#spatial-lag-with-row-standardized-weights",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "9.1 Spatial lag with row-standardized weights",
    "text": "9.1 Spatial lag with row-standardized weights\nWe will compute the average neighbor GDPPC value for each polygon. These values are often referred to as spatially lagged values.\n\nGDPPC.lag &lt;- lag.listw(rswm_q, hunan$GDPPC)\nGDPPC.lag\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\nThen we can append the spatially lag GDPPC values onto hunan sf data frame.\n\nlag.list &lt;- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag.list)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag GDPPC\")\nhunan &lt;- left_join(hunan,lag.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\nThe following table shows the average neighboring income values (stored in the Inc.lag object) for each county.\n\nhead(hunan)\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3  County GDPPC lag GDPPC\n1 Changde 21098 Anxiang      County Anxiang 23667  24847.20\n2 Changde 21100 Hanshou      County Hanshou 20981  22724.80\n3 Changde 21101  Jinshi County City  Jinshi 34592  24143.25\n4 Changde 21102      Li      County      Li 24473  27737.50\n5 Changde 21103   Linli      County   Linli 25554  27270.25\n6 Changde 21104  Shimen      County  Shimen 27137  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\nNext, we will plot both the GDPPC and spatial lag GDPPC for comparison.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_gdppc &lt;- qtm(hunan, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04.html#spatial-lag-as-a-sum-of-neighboring-values",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04.html#spatial-lag-as-a-sum-of-neighboring-values",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "9.2 Spatial lag as a sum of neighboring values",
    "text": "9.2 Spatial lag as a sum of neighboring values\nWe can calculate spatial lag as a sum of neighboring values by assigning binary weights. This requires us to go back to our neighbors list, then apply a function that will assign binary weights, then we use glist = in the nb2listw function to explicitly assign these weights.\nWe start by applying a function that will assign a value of 1 per each neighbor. This is done with lapply, which we have been using to manipulate the neighbors structure throughout the past notebooks. Basically it applies a function across each value in the neighbors structure.\n\nb_weights &lt;- lapply(wm_q, function(x) 0*x + 1)\nb_weights2 &lt;- nb2listw(wm_q, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nWith the proper weights assigned, we can use lag.listw to compute a lag variable from our weight and GDPPC.\n\nlag_sum &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag_sum)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag_sum GDPPC\")\n\n\nlag_sum\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\nNext, we will append the lag_sum GDPPC field into hunan sf data frame.\n\nhunan &lt;- left_join(hunan, lag.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\nNow, we can plot both the GDPPC and Spatial Lag Sum GDPPC for comparison.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_sum_gdppc &lt;- qtm(hunan, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04.html#spatial-window-average",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04.html#spatial-window-average",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "9.3 Spatial window average",
    "text": "9.3 Spatial window average\nThe spatial window average uses row-standardized weights and includes the diagonal element. To do this in R, we need to go back to the neighbors structure and add the diagonal element before assigning weights.\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\nwm_qs &lt;- include.self(wm_q)\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nNotice that the Number of nonzero links, Percentage nonzero weights and Average number of links are 536, 6.921488 and 6.090909 respectively as compared to wm_q of 448, 5.785124 and 5.090909.\nLet us take a good look at the neighbour list of area [1].\n\nwm_qs[[1]]\n\n[1]  1  2  3  4 57 85\n\n\nNotice that now [1] has six neighbours instead of five.\nNow we obtain weights with nb2listw()\n\nwm_qs &lt;- nb2listw(wm_qs)\nwm_qs\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\n\n\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\nLastly, we just need to create the lag variable from our weight structure and GDPPC variable.\n\nlag_w_avg_gpdpc &lt;- lag.listw(wm_qs, \n                             hunan$GDPPC)\nlag_w_avg_gpdpc\n\n [1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17 47621.20 37160.12\n [9] 49224.71 29886.89 26627.50 22690.17 25366.40 25825.75 30329.00 32682.83\n[17] 25948.62 23987.67 25463.14 21904.38 23127.50 25949.83 20018.75 19524.17\n[25] 18955.00 17800.40 15883.00 18831.33 14832.50 17965.00 17159.89 16199.44\n[33] 18764.50 26878.75 23188.86 20788.14 12365.20 15985.00 13764.83 11907.43\n[41] 17128.14 14593.62 11644.29 12706.00 21712.29 43548.25 35049.00 16226.83\n[49] 19294.40 18156.00 19954.75 18145.17 12132.75 18419.29 14050.83 23619.75\n[57] 24552.71 24733.67 16762.60 20932.60 19467.75 18334.00 22541.00 26028.00\n[65] 29128.50 46569.00 47576.60 36545.50 20838.50 22531.00 42115.50 27619.00\n[73] 27611.33 44523.29 18127.43 28746.38 20734.50 33880.62 14716.38 28516.22\n[81] 18086.14 21244.50 29568.80 48119.71 22310.75 43151.60 17133.40 17009.33\n\n\nNext, we will convert the lag variable listw object into a data.frame by using as.data.frame().\n\nlag.list.wm_qs &lt;- list(hunan$NAME_3, lag.listw(wm_qs, hunan$GDPPC))\nlag_wm_qs.res &lt;- as.data.frame(lag.list.wm_qs)\ncolnames(lag_wm_qs.res) &lt;- c(\"NAME_3\", \"lag_window_avg GDPPC\")\n\nNote: The third command line on the code chunk above renames the field names of lag_wm_q1.res object into NAME_3 and lag_window_avg GDPPC respectively.\nNext, the code chunk below will be used to append lag_window_avg GDPPC values onto hunan sf data.frame by using left_join() of dplyr package.\n\nhunan &lt;- left_join(hunan, lag_wm_qs.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table using the code chunk below.\n\nhunan %&gt;%\n  select(\"County\", \n         \"lag GDPPC\", \n         \"lag_window_avg GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag GDPPC\nlag_window_avg GDPPC\ngeometry\n\n\n\n\nAnxiang\n24847.20\n24650.50\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n22724.80\n22434.17\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n24143.25\n26233.00\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n27737.50\n27084.60\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n27270.25\n26927.00\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n21248.80\n22230.17\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n43747.00\n47621.20\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n33582.71\n37160.12\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n45651.17\n49224.71\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n32027.62\n29886.89\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n32671.00\n26627.50\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n20810.00\n22690.17\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n25711.50\n25366.40\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n30672.33\n25825.75\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n33457.75\n30329.00\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n31689.20\n32682.83\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n20269.00\n25948.62\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n23901.60\n23987.67\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n25126.17\n25463.14\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n21903.43\n21904.38\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n22718.60\n23127.50\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n25918.80\n25949.83\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n20307.00\n20018.75\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n20023.80\n19524.17\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n16576.80\n18955.00\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n18667.00\n17800.40\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n14394.67\n15883.00\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n19848.80\n18831.33\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n15516.33\n14832.50\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518.00\n17965.00\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n17572.00\n17159.89\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n15200.12\n16199.44\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n18413.80\n18764.50\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n14419.33\n26878.75\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n24094.50\n23188.86\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n22019.83\n20788.14\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n12923.50\n12365.20\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n14756.00\n15985.00\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n13869.80\n13764.83\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n12296.67\n11907.43\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n15775.17\n17128.14\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n14382.86\n14593.62\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n11566.33\n11644.29\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n13199.50\n12706.00\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n23412.00\n21712.29\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n39541.00\n43548.25\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n36186.60\n35049.00\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n16559.60\n16226.83\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n20772.50\n19294.40\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n19471.20\n18156.00\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n19827.33\n19954.75\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n15466.80\n18145.17\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n12925.67\n12132.75\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n18577.17\n18419.29\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n14943.00\n14050.83\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n24913.00\n23619.75\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n25093.00\n24552.71\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n24428.80\n24733.67\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n17003.00\n16762.60\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n21143.75\n20932.60\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n20435.00\n19467.75\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n17131.33\n18334.00\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n24569.75\n22541.00\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n23835.50\n26028.00\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360.00\n29128.50\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n47383.40\n46569.00\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n55157.75\n47576.60\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n37058.00\n36545.50\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n21546.67\n20838.50\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n23348.67\n22531.00\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n42323.67\n42115.50\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n28938.60\n27619.00\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n25880.80\n27611.33\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n47345.67\n44523.29\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n18711.33\n18127.43\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n29087.29\n28746.38\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n20748.29\n20734.50\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n35933.71\n33880.62\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n15439.71\n14716.38\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n29787.50\n28516.22\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n18145.00\n18086.14\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n21617.00\n21244.50\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n29203.89\n29568.80\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n41363.67\n48119.71\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n22259.09\n22310.75\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n44939.56\n43151.60\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n16902.00\n17133.40\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n16930.00\n17009.33\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_gdppc and w_ave_gdppc maps next to each other for quick comparison.\n\nw_avg_gdppc &lt;- qtm(hunan, \"lag_window_avg GDPPC\")\ntmap_arrange(lag_gdppc, w_avg_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\nNote: For more effective comparison, it is advisable to use the core tmap mapping functions."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04.html#spatial-window-sum",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04.html#spatial-window-sum",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "9.4 Spatial window sum",
    "text": "9.4 Spatial window sum\nThe spatial window sum is the counter part of the window average, but without using row-standardized weights.\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\nwm_qs &lt;- include.self(wm_q)\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nNext, we will assign binary weights to the neighbour structure that includes the diagonal element.\n\nb_weights &lt;- lapply(wm_qs, function(x) 0*x + 1)\nb_weights[1]\n\n[[1]]\n[1] 1 1 1 1 1 1\n\n\nNotice that now [1] has six neighbours instead of five.\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\n\nb_weights2 &lt;- nb2listw(wm_qs, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 536 1072 14160\n\n\nWith our new weight structure, we can compute the lag variable with lag.listw().\n\nw_sum_gdppc &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nw_sum_gdppc\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 147903 134605 131165 135423 134635 133381 238106 297281 344573 268982\n[11] 106510 136141 126832 103303 151645 196097 207589 143926 178242 175235\n[21] 138765 155699 160150 117145 113730  89002  63532 112988  59330  35930\n[31] 154439 145795 112587 107515 162322 145517  61826  79925  82589  83352\n[41] 119897 116749  81510  63530 151986 174193 210294  97361  96472 108936\n[51]  79819 108871  48531 128935  84305 188958 171869 148402  83813 104663\n[61] 155742  73336 112705  78084  58257 279414 237883 219273  83354  90124\n[71] 168462 165714 165668 311663 126892 229971 165876 271045 117731 256646\n[81] 126603 127467 295688 336838 267729 431516  85667  51028\n\n\nNext, we will convert the lag variable listw object into a data.frame by using as.data.frame().\n\nw_sum_gdppc.res &lt;- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) &lt;- c(\"NAME_3\", \"w_sum GDPPC\")\n\n\nNote: The second command line on the code chunk above renames the field names ofw_sum_gdppc.res object into NAME_3 and w_sum GDPPC respectively.\n\nNext, the code chunk below will be used to append w_sum GDPPC values onto hunan sf data.frame by using left_join() of dplyr package.\n\nhunan &lt;- left_join(hunan, w_sum_gdppc.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table using the code chunk below.\n\nhunan %&gt;%\n  select(\"County\", \"lag_sum GDPPC\", \"w_sum GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag_sum GDPPC\nw_sum GDPPC\ngeometry\n\n\n\n\nAnxiang\n124236\n147903\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n113624\n134605\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n96573\n131165\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n110950\n135423\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n109081\n134635\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n106244\n133381\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n174988\n238106\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n235079\n297281\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n273907\n344573\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n256221\n268982\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n98013\n106510\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n104050\n136141\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n102846\n126832\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n92017\n103303\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n133831\n151645\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n158446\n196097\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n141883\n207589\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n119508\n143926\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n150757\n178242\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n153324\n175235\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n113593\n138765\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n129594\n155699\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n142149\n160150\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n100119\n117145\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n82884\n113730\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n74668\n89002\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n43184\n63532\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n99244\n112988\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n46549\n59330\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518\n35930\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n140576\n154439\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n121601\n145795\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n92069\n112587\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n43258\n107515\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n144567\n162322\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n132119\n145517\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n51694\n61826\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n59024\n79925\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n69349\n82589\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n73780\n83352\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n94651\n119897\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n100680\n116749\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n69398\n81510\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n52798\n63530\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n140472\n151986\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n118623\n174193\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n180933\n210294\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n82798\n97361\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n83090\n96472\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n97356\n108936\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n59482\n79819\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n77334\n108871\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n38777\n48531\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n111463\n128935\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n74715\n84305\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n174391\n188958\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n150558\n171869\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n122144\n148402\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n68012\n83813\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n84575\n104663\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n143045\n155742\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n51394\n73336\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n98279\n112705\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n47671\n78084\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360\n58257\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n236917\n279414\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n220631\n237883\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n185290\n219273\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n64640\n83354\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n70046\n90124\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n126971\n168462\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n144693\n165714\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n129404\n165668\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n284074\n311663\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n112268\n126892\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n203611\n229971\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n145238\n165876\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n251536\n271045\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n108078\n117731\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n238300\n256646\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n108870\n126603\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n108085\n127467\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n262835\n295688\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n248182\n336838\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n244850\n267729\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n404456\n431516\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n67608\n85667\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n33860\n51028\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_sum GDPPC and w_sum_gdppc maps next to each other for quick comparison.\n\nw_sum_gdppc &lt;- qtm(hunan, \"w_sum GDPPC\")\ntmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\nNote: For more effective comparison, it is advisable to use the core tmap mapping functions."
  },
  {
    "objectID": "take_home_ex/take_home_ex1/take_home_ex01.html",
    "href": "take_home_ex/take_home_ex1/take_home_ex01.html",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "",
    "text": "Vehicles on a busy street in the Bangkok Metropolitan Region\n\n\nRoad traffic accidents are a global concern, causing around 1.19 million deaths and leaving millions injured annually. These accidents disproportionately affect vulnerable road users, including pedestrians, cyclists, and motorcyclists. Low- and middle-income countries, which hold 60% of the world’s vehicles, account for 90% of fatalities. Beyond human suffering, road accidents also pose a significant economic burden, costing nations 3% of their GDP.\nThailand, with one of the highest road fatality rates in Southeast Asia, reports approximately 20,000 deaths annually, or 56 deaths each day. Between 2014 and 2021, the frequency of road accidents increased, particularly on national highways. Accident-prone areas, often referred to as “black spots,” are primarily found on straight roads (66%), curves (13%), intersections, bridges, and slopes.\nThis analysis will focus on the Bangkok Metropolitan Region (BMR), exploring the causes and patterns of road accidents using geospatial analytics. The study will consider both behavioral and environmental factors, and integrate temporal aspects, such as time of day, day of the week, and season, to provide a comprehensive understanding of road traffic accidents in the BMR."
  },
  {
    "objectID": "take_home_ex/take_home_ex1/take_home_ex01.html#the-packages",
    "href": "take_home_ex/take_home_ex1/take_home_ex01.html#the-packages",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "2.1 The Packages",
    "text": "2.1 The Packages\nIn this exercise, we will use following packages:\n\n\n\nPackage\nDescription\n\n\n\n\nsf\nProvides functions to manage, processing, and manipulate Simple Features, a formal geospatial data standard that specifies a storage and access model of spatial geometries such as points, lines, and polygons.\n\n\nspNetwork\nProvides functions to perform Spatial Point Patterns Analysis such as kernel density estimation (KDE) and K-function on network. It also can be used to build spatial matrices (‘listw’ objects like in ‘spdep’ package) to conduct any kind of traditional spatial analysis with spatial weights based on reticular distances.\n\n\nspatstat\nProvides functions for spatial statistics with a strong focus on analysing spatial point patterns.\n\n\nraster\nProvides functions which reads, writes, manipulates, analyses and model of gridded spatial data (i.e. raster). In this hands-on exercise, it will be used to convert image output generate by spatstat into raster format.\n\n\ntidyverse\nProvides collection of functions for performing data science task such as importing, tidying, wrangling data and visualising data.\n\n\ntmap\nProvides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API\n\n\n\n\npacman::p_load(sf, spNetwork, spatstat, raster, tmap, tidyverse)"
  },
  {
    "objectID": "take_home_ex/take_home_ex1/take_home_ex01.html#the-data",
    "href": "take_home_ex/take_home_ex1/take_home_ex01.html#the-data",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "2.2 The Data",
    "text": "2.2 The Data\n\n\n\nDataset Name\nDescription\nFormat\nSource\n\n\n\n\nThailand Road Accident [2019-2022]\nData on road accidents in Thailand, including accident location and severity\nCSV\nKaggle\n\n\nThailand Roads (OpenStreetMap Export)\nA detailed export of road networks in Thailand from OpenStreetMap\nESRI Shapefile\nHumanitarian Data Exchange (HDX)\n\n\nThailand - Subnational Administrative Boundaries\nAdministrative boundary data for Thailand’s subnational divisions\nESRI Shapefile\nHumanitarian Data Exchange (HDX)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05.html",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05.html",
    "title": "In-class Exercise 3: Advanced Spatial Point Patterns Analysis",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to compute spatial weights using R."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05.html#import",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05.html#import",
    "title": "In-class Exercise 3: Advanced Spatial Point Patterns Analysis",
    "section": "4.1 Import",
    "text": "4.1 Import"
  },
  {
    "objectID": "take_home_ex/take_home_ex1/take_home_ex01.html#importing-the-data",
    "href": "take_home_ex/take_home_ex1/take_home_ex01.html#importing-the-data",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "2.3 Importing the data",
    "text": "2.3 Importing the data\n\n2.3.1 Thailand Road Accident data\nWe will load Thailand Road Accident data using read_csv() function of readr package.\n\nroad_acc &lt;- read_csv(\"data/aspatial/thai_road_accident_2019_2022.csv\")\n\nRows: 81735 Columns: 18\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (10): province_th, province_en, agency, route, vehicle_type, presumed_c...\ndbl   (6): acc_code, number_of_vehicles_involved, number_of_fatalities, numb...\ndttm  (2): incident_datetime, report_datetime\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nglimpse(road_acc)\n\nRows: 81,735\nColumns: 18\n$ acc_code                    &lt;dbl&gt; 571905, 3790870, 599075, 571924, 599523, 5…\n$ incident_datetime           &lt;dttm&gt; 2019-01-01 00:00:00, 2019-01-01 00:03:00,…\n$ report_datetime             &lt;dttm&gt; 2019-01-02 06:11:00, 2020-02-20 13:48:00,…\n$ province_th                 &lt;chr&gt; \"ลพบุรี\", \"อุบลราชธานี\", \"ประจวบคีรีขันธ์\", \"เชียงใ…\n$ province_en                 &lt;chr&gt; \"Loburi\", \"Ubon Ratchathani\", \"Prachuap Kh…\n$ agency                      &lt;chr&gt; \"department of rural roads\", \"department o…\n$ route                       &lt;chr&gt; \"แยกทางหลวงหมายเลข 21 (กม.ที่ 31+000) - บ้านวั…\n$ vehicle_type                &lt;chr&gt; \"motorcycle\", \"private/passenger car\", \"mo…\n$ presumed_cause              &lt;chr&gt; \"driving under the influence of alcohol\", …\n$ accident_type               &lt;chr&gt; \"other\", \"rollover/fallen on straight road…\n$ number_of_vehicles_involved &lt;dbl&gt; 1, 1, 2, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, …\n$ number_of_fatalities        &lt;dbl&gt; 0, 0, 1, 0, 0, 0, 0, 1, 3, 0, 0, 1, 0, 0, …\n$ number_of_injuries          &lt;dbl&gt; 2, 2, 0, 1, 0, 2, 2, 0, 0, 1, 1, 0, 1, 1, …\n$ weather_condition           &lt;chr&gt; \"clear\", \"clear\", \"clear\", \"clear\", \"clear…\n$ latitude                    &lt;dbl&gt; 14.959105, 15.210738, 12.374259, 18.601721…\n$ longitude                   &lt;dbl&gt; 100.87346, 104.86269, 99.90795, 98.80420, …\n$ road_description            &lt;chr&gt; \"straight road\", \"straight road\", \"wide cu…\n$ slope_description           &lt;chr&gt; \"no slope\", \"no slope\", \"slope area\", \"no …\n\n\nThe dataset consists of 81,735 rows and 18 columns. Below is a detailed description of each column, as provided on Kaggle:\n\n\n\n\n\n\n\nColumn\nDescription\n\n\n\n\nacc_code\nThe accident code or identifier.\n\n\nincident_datetime\nThe date and time of the accident occurrence.\n\n\nreport_datetime\nThe date and time when the accident was reported.\n\n\nprovince_th\nThe name of the province in Thailand, written in Thai.\n\n\nprovince_en\nThe name of the province in Thailand, written in English.\n\n\nagency\nThe government agency responsible for the road and traffic management.\n\n\nroute\nThe route or road segment where the accident occurred.\n\n\nvehicle_type\nThe type of vehicle involved in the accident.\n\n\npresumed_cause\nThe presumed cause or reason for the accident.\n\n\naccident_type\nThe type or nature of the accident.\n\n\nnumber_of_vehicles_involved\nThe number of vehicles involved in the accident.\n\n\nnumber_of_fatalities\nThe number of fatalities resulting from the accident.\n\n\nnumber_of_injuries\nThe number of injuries resulting from the accident.\n\n\nweather_condition\nThe weather condition at the time of the accident.\n\n\nlatitude\nThe latitude coordinate of the accident location.\n\n\nlongitude\nThe longitude coordinate of the accident location.\n\n\nroad_description\nThe description of the road type or configuration where the accident occurred.\n\n\nslope_description\nThe description of the slope condition at the accident location.\n\n\n\n\ncolSums(is.na(road_acc))\n\n                   acc_code           incident_datetime \n                          0                           0 \n            report_datetime                 province_th \n                          0                           0 \n                province_en                      agency \n                          0                           0 \n                      route                vehicle_type \n                          0                           0 \n             presumed_cause               accident_type \n                          0                           0 \nnumber_of_vehicles_involved        number_of_fatalities \n                          0                           0 \n         number_of_injuries           weather_condition \n                          0                           0 \n                   latitude                   longitude \n                        359                         359 \n           road_description           slope_description \n                          0                           0 \n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThere are 359 rows with missing values in the latitude and longitude columns. We will drop rows with missing latitude and longitude values, as they represent a small portion(&lt;1%) of the dataset.\nWe will remove the agency, province_th, route, and report_datetime columns, because of following reasons:\n\nThe agency column contains irrelevant information.\nThe province_th column is redundant because the English equivalent is already provided in the province_en column.\nThe route column, which lists road segment names in Thai, can be replaced with information provided by the latitude and longitude coordinates.\nThe report_datetime column is redundant because incident_datetime column already captures the time of the accident.\n\nSince the Bangkok Metropolitan Region consists of six provinces — Bangkok, Nonthaburi, Nakhon Pathom, Pathum Thani, Samut Prakan, and Samut Sakhon — we will filter the dataset using the province_en column to focus on these specific provinces.\nWe will use the latitude and longitude columns to convert the data into a spatial (sf) object by specifying the appropriate Coordinate Reference System (CRS). The EPSG code for the latitude-longitude projection (WGS 84) is 4326, which uses degrees for measurement.\n\nFor spatial analysis in Thailand, the preferred CRS is EPSG:32647, which uses meters as units and is based on the UTM Zone 47N projection.\n\nWe will extend the dataset by extracting the year, month, day of the week, and hour of each incident from the *incident_datetime* column to enhance temporal analysis.\n\n\n\n\nbmr_provinces &lt;- c(\"Bangkok\", \"Nonthaburi\", \"Nakhon Pathom\", \"Pathum Thani\", \"Samut Prakan\", \"Samut Sakhon\")\nroad_acc_bmr &lt;- road_acc %&gt;% \n  filter(!is.na(longitude) & longitude != \"\",\n         !is.na(latitude) & latitude != \"\") %&gt;%\n  select(-c(province_th, route, report_datetime, agency)) %&gt;%\n  filter(province_en %in% bmr_provinces) %&gt;%\n  mutate(\n    Year = year(incident_datetime),\n    Month_num = month(incident_datetime),\n    Month_lab = month(incident_datetime, label = TRUE),\n    Day_of_Week_num = wday(incident_datetime),\n    Day_of_Week_lab = wday(incident_datetime, label = TRUE),\n    Hour = hour(incident_datetime)\n  ) %&gt;%\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs=4326) %&gt;%\n  st_transform(crs = 32647)\n\nWe will simplify the presumed_clause column, as it currently contains 40 categories, making it too complex for effective analysis.\n\n# Define the categories\ndriver_behavior &lt;- c(\"speeding\", \"running red lights/traffic signals\", \"tailgating\", \n                     \"illegal overtaking\", \"failure to yield/signal\", \"abrupt lane change\", \n                     \"driving in the wrong lane\", \"failure to signal enter/exit parking\", \n                     \"failure to yield right of way\", \"ignoring stop sign while leaving intersection\", \n                     \"reversing vehicle\", \"straddling lanes\", \"using mobile phone while driving\", \n                     \"using psychoactive substances\", \"loss of control\", \n                     \"driving under the influence of alcohol\", \"falling asleep\", \"medical condition\")\n\nroad_environmental &lt;- c(\"dangerous curve\", \"slippery road\", \"road in poor condition\", \n                        \"inadequate visibility\", \"obstruction in sight\", \"no traffic signs\", \n                        \"no road divider lines\", \"repair/construction on the road\", \n                        \"debris/obstruction on the road\", \"cutting in closely by people/vehicles/animals\", \n                        \"unfamiliarity with the route/unskilled driving\", \"sudden stop\", \n                        \"no presumed cause related to driver\")\n\nvehicle_related &lt;- c(\"vehicle equipment failure\", \"worn-out/tire blowout\", \n                     \"disabled vehicle without proper signals/signs\", \"vehicle electrical system failure\", \n                     \"brake/anti-lock brake system failure\", \"overloaded vehicle\", \"insufficient light\")\n\nroad_acc_bmr$presumed_cause_category &lt;- ifelse(road_acc_bmr$presumed_cause %in% driver_behavior, \"Driver Behavior\",\n                                               ifelse(road_acc_bmr$presumed_cause %in% road_environmental, \"Road/Environmental Conditions\",\n                                                      ifelse(road_acc_bmr$presumed_cause %in% vehicle_related, \"Vehicle-Related Violations\", \"Other\")))\n\nWe will also simplify vehicle_type column.\n\n# Define vehicle categories\nmotorcycles_bicycles &lt;- c(\"motorcycle\", \"motorized tricycle\", \"bicycle\")\npassenger_vehicles &lt;- c(\"private/passenger car\", \"passenger pickup truck\", \"van\", \"large passenger vehicle\")\nlight_trucks &lt;- c(\"4-wheel pickup truck\")\nheavy_trucks &lt;- c(\"6-wheel truck\", \"7-10-wheel truck\", \"large truck with trailer\")\nnon_motorized &lt;- c(\"pedestrian\")\nspecialized_vehicles &lt;- c(\"tractor/agricultural vehicle\", \"other\")\n\n# Update the vehicle_type column based on the new categories\nroad_acc_bmr$vehicle_type &lt;- ifelse(road_acc_bmr$vehicle_type %in% motorcycles_bicycles, \n                                    \"Motorcycles and Bicycles\",\n                             ifelse(road_acc_bmr$vehicle_type %in% passenger_vehicles, \n                                    \"Passenger Vehicles\",\n                             ifelse(road_acc_bmr$vehicle_type %in% light_trucks, \n                                    \"Light Trucks\",\n                             ifelse(road_acc_bmr$vehicle_type %in% heavy_trucks, \n                                    \"Heavy Trucks\",\n                             ifelse(road_acc_bmr$vehicle_type %in% non_motorized, \n                                    \"Non-motorized Road Users\",\n                             ifelse(road_acc_bmr$vehicle_type %in% specialized_vehicles, \n                                    \"Specialized/Other Vehicles\", \n                                    \"Unknown\"))))))\n\nBefore saving the dataset in RDS format, let’s check for any duplicated records to ensure data integrity.\n\nany(duplicated(road_acc_bmr))\n\n[1] FALSE\n\n\nNo duplicated records were found, so we can proceed to save the dataset in RDS format.\n\nwrite_rds(road_acc_bmr, \"data/rds/road_accident_bmr.rds\")\n\n\nroad_acc_bmr &lt;- read_rds(\"data/rds/road_accident_bmr.rds\")\n\nLet’s visualize the accident points in Bangkok Metropolitan Region.\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\ntm_shape(road_acc_bmr) +\n  tm_dots(col='red',\n          alpha=0.4, \n          size=0.04)\n\n\n\n\n\n\n\n\n\n\n2.3.2 Thailand Subnational Administration Boundary\nThe Thailand subnational administrative boundaries dataset is available at four levels: administrative level 0 (country), level 1 (province), level 2 (district), and level 3 (sub-district or tambon). For this analysis, we will use administrative level 1 (province) and filter the data to focus on the Bangkok Metropolitan Region (BMR).\nWe will load the province-level boundaries using the st_read() function and filter the dataset to include only the provinces in the BMR. The boundaries will then be transformed into EPSG:32647, which uses meters as units and is based on the UTM Zone 47N projection.\n\nadmin_boundary_bmr &lt;- st_read(dsn = \"data/geospatial/\",\n                           layer = \"tha_admbnda_adm1_rtsd_20220121\") %&gt;%\n  filter(ADM1_EN %in% bmr_provinces) %&gt;%\n  st_transform(crs = 32647)\n\nReading layer `tha_admbnda_adm1_rtsd_20220121' from data source \n  `/Users/cham/project/Geospatial-Analytics/chrismanafe/ISSS626-GAA/take_home_ex/take_home_ex1/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 77 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n\n\nLet’s verify the coordinate reference system of admin_boundary_bmr.\n\nst_crs(admin_boundary_bmr)\n\nCoordinate Reference System:\n  User input: EPSG:32647 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 47N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 47N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",99,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Engineering survey, topographic mapping.\"],\n        AREA[\"Between 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\"],\n        BBOX[0,96,84,102]],\n    ID[\"EPSG\",32647]]\n\n\n\nwrite_rds(admin_boundary_bmr, \"data/rds/admin_boundary_bmr.rds\")\n\n\nadmin_boundary_bmr &lt;- read_rds(\"data/rds/admin_boundary_bmr.rds\")\n\nLet’s visualize the administrative boundaries map using tmap.\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\ntm_shape(admin_boundary_bmr) +\n  tm_polygons() +\n  tm_text(\"ADM1_EN\", size = 0.8) +\n  tm_layout(title = \"Bangkok Metropolitan Region (BMR) Administrative Boundaries\",\n            frame = FALSE)\n\n\n\n\n\n\n\n\nLet’s plot the administrative boundaries along with the accident points from the earlier dataset to visualize their spatial distribution.\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\ntm_shape(admin_boundary_bmr) +\n  tm_polygons() +\n  tm_shape(road_acc_bmr) +\n  tm_dots(col='red',\n          alpha=0.4, \n          size=0.04) +\n  tm_layout(title = \"BMR Administrative Boundaries and Road Accidents\",\n            frame = FALSE)\n\n\n\n\n\n\n\n\n\nvehicle_categories &lt;- unique(road_acc_bmr$vehicle_type)\nvehicle_categories\n\n[1] \"Motorcycles and Bicycles\"   \"Passenger Vehicles\"        \n[3] \"Specialized/Other Vehicles\" \"Light Trucks\"              \n[5] \"Heavy Trucks\"               \"Non-motorized Road Users\""
  },
  {
    "objectID": "take_home_ex/take_home_ex1/take_home_ex01.html#data-wrangling",
    "href": "take_home_ex/take_home_ex1/take_home_ex01.html#data-wrangling",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "2.3 Data Wrangling",
    "text": "2.3 Data Wrangling\n\n2.3.1 Thailand Road Accident data\nWe will load Thailand Road Accident data using read_csv() function of readr package.\n\naccidents &lt;- read_csv(\"data/aspatial/thai_road_accident_2019_2022.csv\")\n\nRows: 81735 Columns: 18\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (10): province_th, province_en, agency, route, vehicle_type, presumed_c...\ndbl   (6): acc_code, number_of_vehicles_involved, number_of_fatalities, numb...\ndttm  (2): incident_datetime, report_datetime\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nglimpse(accidents)\n\nRows: 81,735\nColumns: 18\n$ acc_code                    &lt;dbl&gt; 571905, 3790870, 599075, 571924, 599523, 5…\n$ incident_datetime           &lt;dttm&gt; 2019-01-01 00:00:00, 2019-01-01 00:03:00,…\n$ report_datetime             &lt;dttm&gt; 2019-01-02 06:11:00, 2020-02-20 13:48:00,…\n$ province_th                 &lt;chr&gt; \"ลพบุรี\", \"อุบลราชธานี\", \"ประจวบคีรีขันธ์\", \"เชียงใ…\n$ province_en                 &lt;chr&gt; \"Loburi\", \"Ubon Ratchathani\", \"Prachuap Kh…\n$ agency                      &lt;chr&gt; \"department of rural roads\", \"department o…\n$ route                       &lt;chr&gt; \"แยกทางหลวงหมายเลข 21 (กม.ที่ 31+000) - บ้านวั…\n$ vehicle_type                &lt;chr&gt; \"motorcycle\", \"private/passenger car\", \"mo…\n$ presumed_cause              &lt;chr&gt; \"driving under the influence of alcohol\", …\n$ accident_type               &lt;chr&gt; \"other\", \"rollover/fallen on straight road…\n$ number_of_vehicles_involved &lt;dbl&gt; 1, 1, 2, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, …\n$ number_of_fatalities        &lt;dbl&gt; 0, 0, 1, 0, 0, 0, 0, 1, 3, 0, 0, 1, 0, 0, …\n$ number_of_injuries          &lt;dbl&gt; 2, 2, 0, 1, 0, 2, 2, 0, 0, 1, 1, 0, 1, 1, …\n$ weather_condition           &lt;chr&gt; \"clear\", \"clear\", \"clear\", \"clear\", \"clear…\n$ latitude                    &lt;dbl&gt; 14.959105, 15.210738, 12.374259, 18.601721…\n$ longitude                   &lt;dbl&gt; 100.87346, 104.86269, 99.90795, 98.80420, …\n$ road_description            &lt;chr&gt; \"straight road\", \"straight road\", \"wide cu…\n$ slope_description           &lt;chr&gt; \"no slope\", \"no slope\", \"slope area\", \"no …\n\n\nThe dataset consists of 81,735 rows and 18 columns. Below is a detailed description of each column, as provided on Kaggle:\n\n\n\n\n\n\n\nColumn\nDescription\n\n\n\n\nacc_code\nThe accident code or identifier.\n\n\nincident_datetime\nThe date and time of the accident occurrence.\n\n\nreport_datetime\nThe date and time when the accident was reported.\n\n\nprovince_th\nThe name of the province in Thailand, written in Thai.\n\n\nprovince_en\nThe name of the province in Thailand, written in English.\n\n\nagency\nThe government agency responsible for the road and traffic management.\n\n\nroute\nThe route or road segment where the accident occurred.\n\n\nvehicle_type\nThe type of vehicle involved in the accident.\n\n\npresumed_cause\nThe presumed cause or reason for the accident.\n\n\naccident_type\nThe type or nature of the accident.\n\n\nnumber_of_vehicles_involved\nThe number of vehicles involved in the accident.\n\n\nnumber_of_fatalities\nThe number of fatalities resulting from the accident.\n\n\nnumber_of_injuries\nThe number of injuries resulting from the accident.\n\n\nweather_condition\nThe weather condition at the time of the accident.\n\n\nlatitude\nThe latitude coordinate of the accident location.\n\n\nlongitude\nThe longitude coordinate of the accident location.\n\n\nroad_description\nThe description of the road type or configuration where the accident occurred.\n\n\nslope_description\nThe description of the slope condition at the accident location.\n\n\n\n\ncolSums(is.na(accidents))\n\n                   acc_code           incident_datetime \n                          0                           0 \n            report_datetime                 province_th \n                          0                           0 \n                province_en                      agency \n                          0                           0 \n                      route                vehicle_type \n                          0                           0 \n             presumed_cause               accident_type \n                          0                           0 \nnumber_of_vehicles_involved        number_of_fatalities \n                          0                           0 \n         number_of_injuries           weather_condition \n                          0                           0 \n                   latitude                   longitude \n                        359                         359 \n           road_description           slope_description \n                          0                           0 \n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThere are 359 rows with missing values in the latitude and longitude columns. We will drop rows with missing latitude and longitude values, as they represent a small portion(&lt;1%) of the dataset.\nWe will remove the agency, province_th, route, and report_datetime columns, because of following reasons:\n\nThe agency column contains irrelevant information.\nThe province_th column is redundant because the English equivalent is already provided in the province_en column.\nThe route column, which lists road segment names in Thai, can be replaced with information provided by the latitude and longitude coordinates.\nThe report_datetime column is redundant because incident_datetime column already captures the time of the accident.\n\nSince the Bangkok Metropolitan Region consists of six provinces — Bangkok, Nonthaburi, Nakhon Pathom, Pathum Thani, Samut Prakan, and Samut Sakhon — we will filter the dataset using the province_en column to focus on these specific provinces.\nWe will use the latitude and longitude columns to convert the data into a spatial (sf) object by specifying the appropriate Coordinate Reference System (CRS). The EPSG code for the latitude-longitude projection (WGS 84) is 4326, which uses degrees for measurement.\n\nFor spatial analysis in Thailand, the preferred CRS is EPSG:32647, which uses meters as units and is based on the UTM Zone 47N projection.\n\nWe will extend the dataset by extracting the year, month, day of the week, and hour of each incident from the *incident_datetime* column to enhance temporal analysis.\n\n\n\n\nbmr_provinces &lt;- c(\"Bangkok\", \"Nonthaburi\", \"Nakhon Pathom\", \"Pathum Thani\", \"Samut Prakan\", \"Samut Sakhon\")\naccidents_bmr &lt;- accidents %&gt;% \n  filter(!is.na(longitude) & longitude != \"\",\n         !is.na(latitude) & latitude != \"\") %&gt;%\n  select(-c(province_th, route, report_datetime, agency)) %&gt;%\n  filter(province_en %in% bmr_provinces) %&gt;%\n  mutate(\n    Year = year(incident_datetime),\n    Month_num = month(incident_datetime),\n    Month_lab = month(incident_datetime, label = TRUE),\n    Day_of_Week_num = wday(incident_datetime),\n    Day_of_Week_lab = wday(incident_datetime, label = TRUE),\n    Hour = hour(incident_datetime)\n  ) %&gt;%\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs=4326) %&gt;%\n  st_transform(crs = 32647)\n\nUsing the extracted time data, we will classify each incident by season, identify whether it occurred during rush hours, determine if it took place on a weekday or weekend, and check if it coincided with Thailand’s major festival, Songkran.\n\naccidents_bmr &lt;- accidents_bmr %&gt;%\n  mutate(\n    season = case_when(\n      Month_num %in% c(3, 4, 5) ~ \"summer\",\n      Month_num %in% c(6, 7, 8, 9, 10) ~ \"rainy\",\n      Month_num %in% c(11, 12, 1, 2) ~ \"winter\"\n    ),\n    is_songkran = case_when(\n      Year == 2019 & Month_num == 4 & day(incident_datetime) %in% c(12:16) ~ TRUE,  # Songkran in 2019 (12-16 April)\n      Year != 2019 & Month_num == 4 & day(incident_datetime) %in% c(13:15) ~ TRUE,  # Songkran in other years (13-15 April)\n      TRUE ~ FALSE\n    ),\n    rush_hour = case_when(\n      wday(incident_datetime) %in% c(2:6) & hour(incident_datetime) %in% c(7:9) ~ TRUE,  # 7-9 AM on weekdays\n      wday(incident_datetime) %in% c(2:6) & hour(incident_datetime) %in% c(16:19) ~ TRUE,  # 4-7 PM on weekdays\n      TRUE ~ FALSE\n    ),\n    weekday_or_weekend = case_when(\n      wday(incident_datetime) %in% c(2:6) ~ \"weekday\",  # Monday to Friday\n      TRUE ~ \"weekend\"                      # Saturday and Sunday\n    )\n  )\n\nWe will simplify the presumed_clause column, as it currently contains 40 categories, making it too complex for effective analysis.\n\n# Define the categories\ndriver_behavior &lt;- c(\"speeding\", \"running red lights/traffic signals\", \"tailgating\", \n                     \"illegal overtaking\", \"failure to yield/signal\", \"abrupt lane change\", \n                     \"driving in the wrong lane\", \"failure to signal enter/exit parking\", \n                     \"failure to yield right of way\", \"ignoring stop sign while leaving intersection\", \n                     \"reversing vehicle\", \"straddling lanes\", \"using mobile phone while driving\", \n                     \"using psychoactive substances\", \"loss of control\", \n                     \"driving under the influence of alcohol\", \"falling asleep\", \"medical condition\")\n\nroad_environmental &lt;- c(\"dangerous curve\", \"slippery road\", \"road in poor condition\", \n                        \"inadequate visibility\", \"obstruction in sight\", \"no traffic signs\", \n                        \"no road divider lines\", \"repair/construction on the road\", \n                        \"debris/obstruction on the road\", \"cutting in closely by people/vehicles/animals\", \n                        \"unfamiliarity with the route/unskilled driving\", \"sudden stop\", \n                        \"no presumed cause related to driver\")\n\nvehicle_related &lt;- c(\"vehicle equipment failure\", \"worn-out/tire blowout\", \n                     \"disabled vehicle without proper signals/signs\", \"vehicle electrical system failure\", \n                     \"brake/anti-lock brake system failure\", \"overloaded vehicle\", \"insufficient light\")\n\naccidents_bmr$presumed_cause_category &lt;- ifelse(accidents_bmr$presumed_cause %in% driver_behavior, \"Driver Behavior\",\n                                               ifelse(accidents_bmr$presumed_cause %in% road_environmental, \"Road/Environmental Conditions\",\n                                                      ifelse(accidents_bmr$presumed_cause %in% vehicle_related, \"Vehicle-Related Violations\", \"Other\")))\n\nWe will also simplify vehicle_type column.\n\nmotorcycles_bicycles &lt;- c(\"motorcycle\", \"motorized tricycle\", \"bicycle\")\npassenger_vehicles &lt;- c(\"private/passenger car\", \"passenger pickup truck\", \"van\", \"large passenger vehicle\")\nlight_trucks &lt;- c(\"4-wheel pickup truck\")\nheavy_trucks &lt;- c(\"6-wheel truck\", \"7-10-wheel truck\", \"large truck with trailer\")\nnon_motorized &lt;- c(\"pedestrian\")\nspecialized_vehicles &lt;- c(\"tractor/agricultural vehicle\", \"other\")\n\naccidents_bmr$vehicle_category &lt;- ifelse(accidents_bmr$vehicle_type %in% motorcycles_bicycles, \n                                    \"2-wheeled\",\n                             ifelse(accidents_bmr$vehicle_type %in% passenger_vehicles, \n                                    \"Passenger Vehicles\",\n                             ifelse(accidents_bmr$vehicle_type %in% light_trucks, \n                                    \"Light Trucks\",\n                             ifelse(accidents_bmr$vehicle_type %in% heavy_trucks, \n                                    \"Heavy Trucks\",\n                             ifelse(accidents_bmr$vehicle_type %in% non_motorized, \n                                    \"Pedestrian\",\n                             ifelse(accidents_bmr$vehicle_type %in% specialized_vehicles, \n                                    \"SpecializedVehicles\", \n                                    \"Unknown\"))))))\n\nBefore saving the dataset in RDS format, let’s check for any duplicated records to ensure data integrity.\n\nany(duplicated(accidents_bmr))\n\n[1] FALSE\n\n\nNo duplicated records were found, so we can proceed to save the dataset in RDS format.\n\nwrite_rds(accidents_bmr, \"data/rds/road_accident_bmr.rds\")\n\n\naccidents_bmr &lt;- read_rds(\"data/rds/road_accident_bmr.rds\")\n\nLet’s visualize the accident points in Bangkok Metropolitan Region.\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\ntm_shape(accidents_bmr) +\n  tm_dots(col='red',\n          alpha=0.4, \n          size=0.04)\n\n\n\n\n\n\n\n\n\n\n2.3.2 Thailand Subnational Administration Boundary\nThe Thailand subnational administrative boundaries dataset is available at four levels: administrative level 0 (country), level 1 (province), level 2 (district), and level 3 (sub-district or tambon). For this analysis, we will use administrative level 1 (province) and filter the data to focus on the Bangkok Metropolitan Region (BMR).\nWe will load the province-level boundaries using the st_read() function and filter the dataset to include only the provinces in the BMR. The boundaries will then be transformed into EPSG:32647, which uses meters as units and is based on the UTM Zone 47N projection.\n\nadmin_boundary_bmr &lt;- st_read(dsn = \"data/geospatial/\",\n                           layer = \"tha_admbnda_adm1_rtsd_20220121\") %&gt;%\n  filter(ADM1_EN %in% bmr_provinces) %&gt;%\n  st_transform(crs = 32647)\n\nReading layer `tha_admbnda_adm1_rtsd_20220121' from data source \n  `/Users/cham/project/Geospatial-Analytics/chrismanafe/ISSS626-GAA/take_home_ex/take_home_ex1/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 77 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n\n\nLet’s verify the coordinate reference system of admin_boundary_bmr.\n\nst_crs(admin_boundary_bmr)\n\nCoordinate Reference System:\n  User input: EPSG:32647 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 47N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 47N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",99,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Engineering survey, topographic mapping.\"],\n        AREA[\"Between 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\"],\n        BBOX[0,96,84,102]],\n    ID[\"EPSG\",32647]]\n\n\n\nwrite_rds(admin_boundary_bmr, \"data/rds/admin_boundary_bmr.rds\")\n\n\nadmin_boundary_bmr &lt;- read_rds(\"data/rds/admin_boundary_bmr.rds\")\n\nLet’s visualize the administrative boundaries map using tmap.\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\ntm_shape(admin_boundary_bmr) +\n  tm_polygons() +\n  tm_text(\"ADM1_EN\", size = 0.8) +\n  tm_layout(title = \"Bangkok Metropolitan Region (BMR) Administrative Boundaries\",\n            frame = FALSE)\n\n\n\n\n\n\n\n\nLet’s plot the administrative boundaries along with the accident points from the earlier dataset to visualize their spatial distribution.\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\ntm_shape(admin_boundary_bmr) +\n  tm_polygons() +\n  tm_shape(accidents_bmr) +\n  tm_dots(col='red',\n          alpha=0.4, \n          size=0.04) +\n  tm_layout(title = \"BMR Administrative Boundaries and Road Accidents\",\n            frame = FALSE)\n\n\n\n\n\n\n\n\n\n\n2.3.3 Thailand Roads\nLet us load Thailand Roads data using st_read() of sf package.\n\nroads_sf &lt;- st_read(dsn = \"data/geospatial\",\n                    layer = \"hotosm_tha_roads_lines_shp\")\n\nWe observed that road_sf lacks a CRS. To correct this, we’ll first use st_set_crs() to assign the correct EPSG code, then apply st_transform() to project the data into the appropriate coordinate reference system. This dataset contains geometries in the form of MULTILINESTRING. We will apply st_cast() function to convert it into LINESTRING.\n\nroads_sf &lt;- st_set_crs(roads_sf, 4326)  %&gt;%\n  st_transform(crs = 32647) %&gt;% \n  st_cast(\"LINESTRING\")\n\nLet us verify the CRS on `roads_sf`.\n\nst_crs(roads_sf)\n\nSince the OpenStreetMap data includes a wide range of road types, we will filter the dataset to keep only the road classes that are relevant to our analysis.\n\nroads_sf &lt;- roads_sf %&gt;%\n  filter(highway %in% c(\"motorway\", \"trunk\", \"primary\", \"secondary\", \"tertiary\", \"unclassified\",\n                        \"residential\", \"motorway_link\", \"trunk_link\", \"primary_link\", \n                        \"secondary_link\", \"tertiary_link\", \"living_street\", \"service\"))\n\n\nunique(roads_sf$highway)\n\nThe roads_sf dataset contains all road information across Thailand. Since our analysis focuses on the Bangkok Metropolitan Region (BMR), we will filter out roads located outside this area using st_intersection() function from sf package.\n\nroads_bmr &lt;- st_intersection(roads_sf, admin_boundary_bmr)\n\nLet us check for any invalid geometries from roads_bmr.\n\ninvalid_geometries &lt;- st_is_valid(roads_bmr, reason=TRUE)\n\n\nlength(which(invalid_geometries != \"Valid Geometry\"))\n\n\nwrite_rds(roads_bmr, \"data/rds/roads_bmr.rds\")\n\n\nroads_bmr &lt;- read_rds(\"data/rds/roads_bmr.rds\")\n\nNow, let’s visualize the road network within the Bangkok Metropolitan Region (BMR).\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(roads_bmr) +\n  tm_lines(col = \"blue\", lwd = 0.5) +\n  tm_layout(title = \"Bangkok Metropolitan Region Road Network\",\n            frame = FALSE)\n\n\n\n\n\n\n\n\n\n\n2.3.4 Converting sf data frame into spatstat’s ppp format\nAs we plan to carry out spatial point pattern analysis with the spatstat package, we need to convert the spatial data from the sf format into the ppp format.\nFirst, we create ppp objects from accidents_bmr data frame.\n\naccidents_bmr_ppp &lt;- as.ppp(accidents_bmr)\n\nWarning in as.ppp.sf(accidents_bmr): only first attribute column is used for\nmarks\n\nsummary(accidents_bmr_ppp)\n\nMarked planar point pattern:  12986 points\nAverage intensity 1.218049e-06 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 571882 3788970 3834532 4314457 6092694 7570954 \n\nWindow: rectangle = [591277.5, 710166.1] x [1486845.7, 1576520.5] units\n                    (118900 x 89670 units)\nWindow area = 10661300000 square units\n\n\nThen we create owin objects from admin_boundary_bmr data frame.\n\nadmin_boundary_bmr_owin &lt;- as.owin(admin_boundary_bmr)\n\nNow, we can create a ppp object by combining accidents_bmr_ppp and admin_boundary_bmr_owin.\n\naccidents_bmr_ppp = accidents_bmr_ppp[admin_boundary_bmr_owin]\nplot(accidents_bmr_ppp)\n\n\n\n\n\n\n\n\nLet us re-scale the unit of measurement from metre to kilometre before performing KDE.\n\naccidents_bmr_ppp.km &lt;- rescale.ppp(accidents_bmr_ppp,\n                                    1000, \n                                    \"km\")"
  },
  {
    "objectID": "take_home_ex/take_home_ex1/take_home_ex01.html#first-order-spatial-point-pattern-analysis",
    "href": "take_home_ex/take_home_ex1/take_home_ex01.html#first-order-spatial-point-pattern-analysis",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "4.1 First-order spatial point pattern analysis",
    "text": "4.1 First-order spatial point pattern analysis\n\n4.1.1 Computing kernel density estimation using automatic bandwidth selection method\nWe will compute the kernel density estimate (KDE) using different automatic bandwidth selection methods. Specifically, we will use bw.diggle and bw.ppl for the analysis to compare their results.\n\nkde_accidents_bmr_bw_diggle &lt;- density(accidents_bmr_ppp.km,\n                                       sigma=bw.diggle,\n                                       edge=TRUE,\n                                       kernel=\"gaussian\") \n\nkde_accidents_bmr_bw_ppl &lt;- density(accidents_bmr_ppp.km,\n                                    sigma=bw.ppl, \n                                    edge=TRUE,\n                                    kernel=\"gaussian\")\npar(mfrow=c(1,2))\nplot(kde_accidents_bmr_bw_diggle, main = \"bw.diggle\")\nplot(kde_accidents_bmr_bw_ppl, main = \"bw.ppl\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\n\nBoth bw.diggle and bw.ppl methods produce similar overall density patterns, with high-density areas highlighted in yellow and low-density areas in blue.\nHigh-density zones appear to cluster along key road networks or points of interest in both estimates, indicating consistency between the two methods.\n\n\n\n\n\n4.1.2 Computing kernel density estimation using adaptive bandwidth\nGiven the varying densities in our data and the consistent results from automatic bandwidth methods such as bw.diggle and bw.ppl, we will try to compute the density by using adaptive.density() of spatstat package. Adaptive bandwidth methods are often better suited to capture both global trends and local variations, providing a more accurate and nuanced understanding of the spatial patterns without the risk of oversmoothing or undersmoothing.\n\nkde_accidents_adaptive_kernel &lt;- adaptive.density(accidents_bmr_ppp.km, method=\"kernel\")\n\npar(mfrow=c(1,2))\nplot(kde_accidents_bmr_bw_diggle, main = \"automatic - bw.diggle\")\nplot(kde_accidents_adaptive_kernel, main = \"adaptive - kernel\")\n\n\n\n\n\n\n\n\n\nVisually, these results are very similar because both bw.diggle and the adaptive kernel method adjust the bandwidth based on the local density of points in the dataset. Since both methods are adaptive in nature, they capture the same underlying spatial patterns and point densities, leading to similar visual outcomes. This consistency indicates that the spatial distribution of accidents is being accurately reflected by both approaches.\n\n\n\n4.1.3 Plotting Interactive KDE Maps\nWe will create interactive map of the KDE (Kernel Density Estimate) map displayed over an OpenStreetMap basemap with a color palette ranging from yellow to red to represent density. It includes BMR boundary polygons, a scale bar, and sets the map projection to the UTM Zone 47N (EPSG:32647).\n\n\ncode chunk\nraster_kde_adaptive &lt;- raster(kde_accidents_adaptive_kernel)\nprojection(raster_kde_adaptive) &lt;- CRS(\"+init=EPSG:32647 +units=km\")\n\ntmap_mode('view')\n\n\ntmap mode set to interactive viewing\n\n\ncode chunk\nkde_diggle_tmap &lt;- tm_basemap(server = \"OpenStreetMap\") +\n  tm_shape(admin_boundary_bmr, ) +\n    tm_polygons(alpha=0.1, id=\"ADM1_EN\") +\n  tm_shape(raster_kde_adaptive) +\n    tm_raster(\"layer\",\n              n = 7,\n              title = \"KDE Adaptive\",\n              style = \"pretty\",\n              alpha = 0.6,\n              palette = \"YlOrRd\") +\n  tm_scale_bar()\n\nbase_tmap &lt;- tm_basemap(server = \"OpenStreetMap\")+\n  tm_shape(admin_boundary_bmr) +\n    tm_polygons(alpha=0.1, id=\"ADM1_EN\") +\n  tm_scale_bar()\n\ntmap_arrange(kde_diggle_tmap, \n             base_tmap,\n             ncol=1,\n             nrow=2,\n             sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\ncode chunk\ntmap_mode('plot')\n\n\ntmap mode set to plotting\n\n\n\n\n\n\n\n\nObservation\n\n\n\n\nThe interactive map reveals that accidents are most concentrated in Bangkok, followed by Samut Prakan and Pathum Thani provinces.\nThe highest concentration of accidents occurs along Motorway Route 7 (Bangkok–Ban Chang Motorway), with significant densities also observed on other major highways, including Motorway Route 9 (Kanchanaphisek Road, also known as the Bangkok Outer Ring Road) and Highway 338 (Borommaratchachonnani Road).\nThe concentration of accidents along these highways indicates that targeted safety interventions, such as traffic management, road safety improvements, or enhanced enforcement in these regions, may be effective in reducing accident rates.\n\n\n\n\n\n4.1.4 Nearest neighbour analysis\nIn this section, we will perform the Clark-Evans test of aggregation for a spatial point pattern using the clarkevans.test() function from the spatstat package.\nThe test hypotheses are:\n\nH₀: The spatial distribution of road accidents in BMR are randomly distributed.\nH₁: The spatial distribution of road accidents in BMR are not randomly distributed.\n\nWe will use a 95% confidence interval.\n\nclarkevans.test(accidents_bmr_ppp,\n                correction=\"none\",\n                clipregion=\"admin_boundary_bmr_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  accidents_bmr_ppp\nR = 0.19109, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\n\nInterpretations:\n\nThe Clark-Evans test result (R = 0.19109, p-value &lt; 2.2e-16) suggests that road accidents in the dataset are not randomly distributed. Instead, they exhibit significant clustering, meaning accidents tend to occur in close proximity to each other rather than being spread out randomly across the region.\nThis clustering is likely tied to underlying factors such as high traffic volumes or specific road types (e.g., intersections, highways)."
  },
  {
    "objectID": "take_home_ex/take_home_ex1/take_home_ex01.html#network-kernel-density-estimation-nkde",
    "href": "take_home_ex/take_home_ex1/take_home_ex01.html#network-kernel-density-estimation-nkde",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "4.2 Network Kernel Density Estimation (NKDE)",
    "text": "4.2 Network Kernel Density Estimation (NKDE)"
  },
  {
    "objectID": "take_home_ex/take_home_ex1/take_home_ex01.html#temporal-network-kernel-density-estimate-tnkde",
    "href": "take_home_ex/take_home_ex1/take_home_ex01.html#temporal-network-kernel-density-estimate-tnkde",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "4.3 Temporal Network Kernel Density Estimate (TNKDE)",
    "text": "4.3 Temporal Network Kernel Density Estimate (TNKDE)"
  },
  {
    "objectID": "in_class_ex/in_class_ex04/in_class_ex04.html#geographically-weighted-summary-statistics-with-adaptive-bandwidth",
    "href": "in_class_ex/in_class_ex04/in_class_ex04.html#geographically-weighted-summary-statistics-with-adaptive-bandwidth",
    "title": "In-class Exercise 4: Geographically Weighted Summary Statistics - gwModel methods",
    "section": "5.1 Geographically weighted summary statistics with adaptive bandwidth",
    "text": "5.1 Geographically weighted summary statistics with adaptive bandwidth"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05.1.html",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05.1.html",
    "title": "Hands-on Exercise 5a: Global Measures of Spatial Autocorrelation",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to compute Global Measures of Spatial Autocorrelation (GMSA) by using spdep package. By the end to this hands-on exercise, we will be able to:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of spdep package,\n\nplot Moran scatterplot,\ncompute and plot spatial correlogram using appropriate function of spdep package.\n\nprovide statistically correct interpretation of GSA statistics."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05.1.html#import",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05.1.html#import",
    "title": "Hands-on Exercise 5a: Global Measures of Spatial Autocorrelation",
    "section": "4.1 Import",
    "text": "4.1 Import"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05.2.html",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05.2.html",
    "title": "Hands-on Exercise 5b: Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "Local Measures of Spatial Autocorrelation (LMSA) focus on the relationships between individual observations and their surroundings, rather than providing a single summary statistic for the entire map. In this sense, they do not offer an overall summary but provide scores that help us explore the spatial structure in the data. Despite this difference, the general intuition behind these metrics is similar to that of global ones. In fact, some LMSA metrics are mathematically connected to their global counterparts, where the global measure can be decomposed into a set of local values. One such example is the Local Indicators of Spatial Association (LISA). In addition to LISA, we will also introduce Getis-Ord’s Gi-statistics, another LMSA metric that provides complementary information and allows us to derive similar insights for geographically referenced data.\nIn this hands-on exercise, we will learn how to compute Local Measures of Spatial Autocorrelation (LMSA) using the spdep package in R."
  },
  {
    "objectID": "in_class_ex/in_class_ex04/in_class_ex04.html",
    "href": "in_class_ex/in_class_ex04/in_class_ex04.html",
    "title": "In-class Exercise 4: Geographically Weighted Summary Statistics - GWmodel methods",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to compute spatial weights, particularly using GWmodel methods."
  },
  {
    "objectID": "in_class_ex/in_class_ex04/in_class_ex04.html#determine-adaptive-bandwidth",
    "href": "in_class_ex/in_class_ex04/in_class_ex04.html#determine-adaptive-bandwidth",
    "title": "In-class Exercise 4: Geographically Weighted Summary Statistics - GWmodel methods",
    "section": "6.1 Determine adaptive bandwidth",
    "text": "6.1 Determine adaptive bandwidth\n\nCross-validationAIC\n\n\n\nbw_CV &lt;- bw.gwr(GDPPC ~ 1,\n                data = hunan_sp,\n                approach = \"CV\",\n                adaptive = TRUE,\n                kernel = \"bisquare\",\n                longlat = TRUE)\n\nAdaptive bandwidth: 62 CV score: 15515442343 \nAdaptive bandwidth: 46 CV score: 14937956887 \nAdaptive bandwidth: 36 CV score: 14408561608 \nAdaptive bandwidth: 29 CV score: 14198527496 \nAdaptive bandwidth: 26 CV score: 13898800611 \nAdaptive bandwidth: 22 CV score: 13662299974 \nAdaptive bandwidth: 22 CV score: 13662299974 \n\n\n\nbw_CV\n\n[1] 22\n\n\n\n\n\nbw_AIC &lt;- bw.gwr(GDPPC ~ 1,\n                 data = hunan_sp,\n                 approach = \"AIC\",\n                 adaptive = TRUE,\n                 kernel = \"bisquare\",\n                 longlat = TRUE)\n\nAdaptive bandwidth (number of nearest neighbours): 62 AICc value: 1923.156 \nAdaptive bandwidth (number of nearest neighbours): 46 AICc value: 1920.469 \nAdaptive bandwidth (number of nearest neighbours): 36 AICc value: 1917.324 \nAdaptive bandwidth (number of nearest neighbours): 29 AICc value: 1916.661 \nAdaptive bandwidth (number of nearest neighbours): 26 AICc value: 1914.897 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \n\n\n\nbw_AIC\n\n[1] 22\n\n\n\n\n\nThe number of optimum neighbour for GDPPC is 22, and apparently it is the same for both CV and AIC this time."
  },
  {
    "objectID": "in_class_ex/in_class_ex04/in_class_ex04.html#determine-adaptive-bandwidth-1",
    "href": "in_class_ex/in_class_ex04/in_class_ex04.html#determine-adaptive-bandwidth-1",
    "title": "In-class Exercise 4: Geographically Weighted Summary Statistics - GWmodel methods",
    "section": "7.1 Determine adaptive bandwidth",
    "text": "7.1 Determine adaptive bandwidth\n\nCross-validationAIC\n\n\n\nbw_CV &lt;- bw.gwr(GDPPC ~ 1,\n                data = hunan_sp,\n                approach = \"CV\",\n                adaptive = FALSE,\n                kernel = \"bisquare\",\n                longlat = TRUE)\n\nFixed bandwidth: 357.4897 CV score: 16265191728 \nFixed bandwidth: 220.985 CV score: 14954930931 \nFixed bandwidth: 136.6204 CV score: 14134185837 \nFixed bandwidth: 84.48025 CV score: 13693362460 \nFixed bandwidth: 52.25585 CV score: Inf \nFixed bandwidth: 104.396 CV score: 13891052305 \nFixed bandwidth: 72.17162 CV score: 13577893677 \nFixed bandwidth: 64.56447 CV score: 14681160609 \nFixed bandwidth: 76.8731 CV score: 13444716890 \nFixed bandwidth: 79.77877 CV score: 13503296834 \nFixed bandwidth: 75.07729 CV score: 13452450771 \nFixed bandwidth: 77.98296 CV score: 13457916138 \nFixed bandwidth: 76.18716 CV score: 13442911302 \nFixed bandwidth: 75.76323 CV score: 13444600639 \nFixed bandwidth: 76.44916 CV score: 13442994078 \nFixed bandwidth: 76.02523 CV score: 13443285248 \nFixed bandwidth: 76.28724 CV score: 13442844774 \nFixed bandwidth: 76.34909 CV score: 13442864995 \nFixed bandwidth: 76.24901 CV score: 13442855596 \nFixed bandwidth: 76.31086 CV score: 13442847019 \nFixed bandwidth: 76.27264 CV score: 13442846793 \nFixed bandwidth: 76.29626 CV score: 13442844829 \nFixed bandwidth: 76.28166 CV score: 13442845238 \nFixed bandwidth: 76.29068 CV score: 13442844678 \nFixed bandwidth: 76.29281 CV score: 13442844691 \nFixed bandwidth: 76.28937 CV score: 13442844698 \nFixed bandwidth: 76.2915 CV score: 13442844676 \nFixed bandwidth: 76.292 CV score: 13442844679 \nFixed bandwidth: 76.29119 CV score: 13442844676 \nFixed bandwidth: 76.29099 CV score: 13442844676 \nFixed bandwidth: 76.29131 CV score: 13442844676 \nFixed bandwidth: 76.29138 CV score: 13442844676 \nFixed bandwidth: 76.29126 CV score: 13442844676 \nFixed bandwidth: 76.29123 CV score: 13442844676 \n\n\n\nbw_CV\n\n[1] 76.29126\n\n\n\n\n\nbw_AIC_fixed &lt;- bw.gwr(GDPPC ~ 1,\n                       data = hunan_sp,\n                       approach = \"AIC\",\n                       adaptive = FALSE,\n                       kernel = \"bisquare\",\n                       longlat = TRUE)\n\nFixed bandwidth: 357.4897 AICc value: 1927.631 \nFixed bandwidth: 220.985 AICc value: 1921.547 \nFixed bandwidth: 136.6204 AICc value: 1919.993 \nFixed bandwidth: 84.48025 AICc value: 1940.603 \nFixed bandwidth: 168.8448 AICc value: 1919.457 \nFixed bandwidth: 188.7606 AICc value: 1920.007 \nFixed bandwidth: 156.5362 AICc value: 1919.41 \nFixed bandwidth: 148.929 AICc value: 1919.527 \nFixed bandwidth: 161.2377 AICc value: 1919.392 \nFixed bandwidth: 164.1433 AICc value: 1919.403 \nFixed bandwidth: 159.4419 AICc value: 1919.393 \nFixed bandwidth: 162.3475 AICc value: 1919.394 \nFixed bandwidth: 160.5517 AICc value: 1919.391 \n\n\n\nbw_AIC_fixed\n\n[1] 160.5517\n\n\n\n\n\nThe fixed bandwidth is different this time for CV and AIC."
  },
  {
    "objectID": "in_class_ex/in_class_ex04/in_class_ex04.html#computing-geographically-weighted-summary-statistics",
    "href": "in_class_ex/in_class_ex04/in_class_ex04.html#computing-geographically-weighted-summary-statistics",
    "title": "In-class Exercise 4: Geographically Weighted Summary Statistics - GWmodel methods",
    "section": "7.2 Computing geographically weighted summary statistics",
    "text": "7.2 Computing geographically weighted summary statistics\n\ngwstat &lt;- gwss(data = hunan_sp,\n               vars = \"GDPPC\",\n               bw = bw_AIC,\n               kernel = \"bisquare\",\n               adaptive = TRUE,\n               longlat = TRUE)\n\nLet us prepare the output data. We will extract SDF data table from gwss object output from gwss(). It will be converted into data.frame by using as.data.frame() function.\n\ngwstat_df &lt;- as.data.frame(gwstat$SDF)\n\nNext, cbind() is used to append the newly derived data.frame onto hunan sf data.frame.\n\nhunan_gstat &lt;- cbind(hunan, gwstat_df)"
  },
  {
    "objectID": "in_class_ex/in_class_ex04/in_class_ex04.html#visualising-geographically-weighted-summary-statistics",
    "href": "in_class_ex/in_class_ex04/in_class_ex04.html#visualising-geographically-weighted-summary-statistics",
    "title": "In-class Exercise 4: Geographically Weighted Summary Statistics - GWmodel methods",
    "section": "7.3 Visualising geographically weighted summary statistics",
    "text": "7.3 Visualising geographically weighted summary statistics\nLet us visualize the geographically weighted mean.\n\ntm_shape(hunan_gstat) +\n  tm_fill(\"GDPPC_LM\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Distribution of geographically weighted mean\",\n            main.title.position = \"center\",\n            main.title.size = 1.8,\n            legend.text.size = 1.2,\n            legend.height = 1.50,\n            legend.width = 1.50,\n            frame = TRUE)\n\n\n\n\n\n\n\n\nLet us find out whether is there any relationship between GDP per capita and Gross Industry Output?\n\nggscatterstats(\n  data = hunan2012, \n  x = Agri, \n  y = GDPPC,\n  xlab = \"Gross Agriculture Output\", ## label for the x-axis\n  ylab = \"GDP per capita\", \n  label.var = County, \n  label.expression = Agri &gt; 10000 & GDPPC &gt; 50000, \n  point.label.args = list(alpha = 0.7, size = 4, color = \"grey50\"),\n  xfill = \"#CC79A7\", \n  yfill = \"#009E73\", \n  title = \"Relationship between GDP PC and Gross Agriculture Output\")\n\nRegistered S3 method overwritten by 'ggside':\n  method from   \n  +.gg   ggplot2\n\n\n`stat_xsidebin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_ysidebin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "take_home_ex/take_home_ex01/take_home_ex01.html",
    "href": "take_home_ex/take_home_ex01/take_home_ex01.html",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "",
    "text": "Vehicles on a busy street in the Bangkok Metropolitan Region\n\n\nRoad traffic accidents are a global concern, causing around 1.19 million deaths and leaving millions injured annually. These accidents disproportionately affect vulnerable road users, including pedestrians, cyclists, and motorcyclists. Low- and middle-income countries, which hold 60% of the world’s vehicles, account for 90% of fatalities. Beyond human suffering, road accidents also pose a significant economic burden, costing nations 3% of their GDP.\nThailand, with one of the highest road fatality rates in Southeast Asia, reports approximately 20,000 deaths annually, or 56 deaths each day. Between 2014 and 2021, the frequency of road accidents increased, particularly on national highways. Accident-prone areas, often referred to as “black spots,” are primarily found on straight roads (66%), curves (13%), intersections, bridges, and slopes.\nThis analysis will focus on the Bangkok Metropolitan Region (BMR), exploring the causes and patterns of road accidents using geospatial analytics. The study will consider both behavioral and environmental factors, and integrate temporal aspects, such as time of day, day of the week, and season, to provide a comprehensive understanding of road traffic accidents in the BMR."
  },
  {
    "objectID": "take_home_ex/take_home_ex01/take_home_ex01.html#the-packages",
    "href": "take_home_ex/take_home_ex01/take_home_ex01.html#the-packages",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "2.1 The Packages",
    "text": "2.1 The Packages\nIn this exercise, we will use following packages:\n\n\n\n\n\n\n\nPackage\nDescription\n\n\n\n\nsf\nProvides functions to manage, processing, and manipulate Simple Features, a formal geospatial data standard that specifies a storage and access model of spatial geometries such as points, lines, and polygons.\n\n\nspNetwork\nProvides functions to perform Spatial Point Patterns Analysis such as kernel density estimation (KDE) and K-function on network. It also can be used to build spatial matrices (‘listw’ objects like in ‘spdep’ package) to conduct any kind of traditional spatial analysis with spatial weights based on reticular distances.\n\n\nspatstat\nProvides functions for spatial statistics with a strong focus on analysing spatial point patterns.\n\n\nraster\nProvides functions which reads, writes, manipulates, analyses and model of gridded spatial data (i.e. raster). In this hands-on exercise, it will be used to convert image output generate by spatstat into raster format.\n\n\ntidyverse\nProvides collection of functions for performing data science task such as importing, tidying, wrangling data and visualising data.\n\n\ntmap\nProvides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API\n\n\nclassInt\nProvides functions for choosing univariate class intervals for mapping or other graphics purposes.\n\n\ngifski\nProvides functions to converts images to GIF animations using pngquant’s efficient cross-frame palettes and temporal dithering with thousands of colors per frame.\n\n\n\n\npacman::p_load(sf, spNetwork, spatstat, raster, tmap, tidyverse, classInt, gifski)"
  },
  {
    "objectID": "take_home_ex/take_home_ex01/take_home_ex01.html#the-data",
    "href": "take_home_ex/take_home_ex01/take_home_ex01.html#the-data",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "2.2 The Data",
    "text": "2.2 The Data\n\n\n\nDataset Name\nDescription\nFormat\nSource\n\n\n\n\nThailand Road Accident [2019-2022]\nData on road accidents in Thailand, including accident location and severity\nCSV\nKaggle\n\n\nThailand Roads (OpenStreetMap Export)\nA detailed export of road networks in Thailand from OpenStreetMap\nESRI Shapefile\nHumanitarian Data Exchange (HDX)\n\n\nThailand - Subnational Administrative Boundaries\nAdministrative boundary data for Thailand’s subnational divisions\nESRI Shapefile\nHumanitarian Data Exchange (HDX)"
  },
  {
    "objectID": "take_home_ex/take_home_ex01/take_home_ex01.html#data-wrangling",
    "href": "take_home_ex/take_home_ex01/take_home_ex01.html#data-wrangling",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "2.3 Data Wrangling",
    "text": "2.3 Data Wrangling\n\n2.3.1 Thailand Road Accident data\nWe will load Thailand Road Accident data using read_csv() function of readr package.\n\naccidents &lt;- read_csv(\"data/aspatial/thai_road_accident_2019_2022.csv\")\n\nRows: 81735 Columns: 18\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (10): province_th, province_en, agency, route, vehicle_type, presumed_c...\ndbl   (6): acc_code, number_of_vehicles_involved, number_of_fatalities, numb...\ndttm  (2): incident_datetime, report_datetime\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nglimpse(accidents)\n\nRows: 81,735\nColumns: 18\n$ acc_code                    &lt;dbl&gt; 571905, 3790870, 599075, 571924, 599523, 5…\n$ incident_datetime           &lt;dttm&gt; 2019-01-01 00:00:00, 2019-01-01 00:03:00,…\n$ report_datetime             &lt;dttm&gt; 2019-01-02 06:11:00, 2020-02-20 13:48:00,…\n$ province_th                 &lt;chr&gt; \"ลพบุรี\", \"อุบลราชธานี\", \"ประจวบคีรีขันธ์\", \"เชียงใ…\n$ province_en                 &lt;chr&gt; \"Loburi\", \"Ubon Ratchathani\", \"Prachuap Kh…\n$ agency                      &lt;chr&gt; \"department of rural roads\", \"department o…\n$ route                       &lt;chr&gt; \"แยกทางหลวงหมายเลข 21 (กม.ที่ 31+000) - บ้านวั…\n$ vehicle_type                &lt;chr&gt; \"motorcycle\", \"private/passenger car\", \"mo…\n$ presumed_cause              &lt;chr&gt; \"driving under the influence of alcohol\", …\n$ accident_type               &lt;chr&gt; \"other\", \"rollover/fallen on straight road…\n$ number_of_vehicles_involved &lt;dbl&gt; 1, 1, 2, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, …\n$ number_of_fatalities        &lt;dbl&gt; 0, 0, 1, 0, 0, 0, 0, 1, 3, 0, 0, 1, 0, 0, …\n$ number_of_injuries          &lt;dbl&gt; 2, 2, 0, 1, 0, 2, 2, 0, 0, 1, 1, 0, 1, 1, …\n$ weather_condition           &lt;chr&gt; \"clear\", \"clear\", \"clear\", \"clear\", \"clear…\n$ latitude                    &lt;dbl&gt; 14.959105, 15.210738, 12.374259, 18.601721…\n$ longitude                   &lt;dbl&gt; 100.87346, 104.86269, 99.90795, 98.80420, …\n$ road_description            &lt;chr&gt; \"straight road\", \"straight road\", \"wide cu…\n$ slope_description           &lt;chr&gt; \"no slope\", \"no slope\", \"slope area\", \"no …\n\n\nThe dataset consists of 81,735 rows and 18 columns. Below is a detailed description of each column, as provided on Kaggle:\n\n\n\n\n\n\n\nColumn\nDescription\n\n\n\n\nacc_code\nThe accident code or identifier.\n\n\nincident_datetime\nThe date and time of the accident occurrence.\n\n\nreport_datetime\nThe date and time when the accident was reported.\n\n\nprovince_th\nThe name of the province in Thailand, written in Thai.\n\n\nprovince_en\nThe name of the province in Thailand, written in English.\n\n\nagency\nThe government agency responsible for the road and traffic management.\n\n\nroute\nThe route or road segment where the accident occurred.\n\n\nvehicle_type\nThe type of vehicle involved in the accident.\n\n\npresumed_cause\nThe presumed cause or reason for the accident.\n\n\naccident_type\nThe type or nature of the accident.\n\n\nnumber_of_vehicles_involved\nThe number of vehicles involved in the accident.\n\n\nnumber_of_fatalities\nThe number of fatalities resulting from the accident.\n\n\nnumber_of_injuries\nThe number of injuries resulting from the accident.\n\n\nweather_condition\nThe weather condition at the time of the accident.\n\n\nlatitude\nThe latitude coordinate of the accident location.\n\n\nlongitude\nThe longitude coordinate of the accident location.\n\n\nroad_description\nThe description of the road type or configuration where the accident occurred.\n\n\nslope_description\nThe description of the slope condition at the accident location.\n\n\n\n\ncolSums(is.na(accidents))\n\n                   acc_code           incident_datetime \n                          0                           0 \n            report_datetime                 province_th \n                          0                           0 \n                province_en                      agency \n                          0                           0 \n                      route                vehicle_type \n                          0                           0 \n             presumed_cause               accident_type \n                          0                           0 \nnumber_of_vehicles_involved        number_of_fatalities \n                          0                           0 \n         number_of_injuries           weather_condition \n                          0                           0 \n                   latitude                   longitude \n                        359                         359 \n           road_description           slope_description \n                          0                           0 \n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThere are 359 rows with missing values in the latitude and longitude columns. We will drop rows with missing latitude and longitude values, as they represent a small portion(&lt;1%) of the dataset.\nWe will remove the agency, province_th, route, and report_datetime columns, because of following reasons:\n\nThe agency column contains irrelevant information.\nThe province_th column is redundant because the English equivalent is already provided in the province_en column.\nThe route column, which lists road segment names in Thai, can be replaced with information provided by the latitude and longitude coordinates.\nThe report_datetime column is redundant because incident_datetime column already captures the time of the accident.\n\nSince the Bangkok Metropolitan Region consists of six provinces — Bangkok, Nonthaburi, Nakhon Pathom, Pathum Thani, Samut Prakan, and Samut Sakhon — we will filter the dataset using the province_en column to focus on these specific provinces.\nWe will use the latitude and longitude columns to convert the data into a spatial (sf) object by specifying the appropriate Coordinate Reference System (CRS). The EPSG code for the latitude-longitude projection (WGS 84) is 4326, which uses degrees for measurement.\n\nFor spatial analysis in Thailand, the preferred CRS is EPSG:32647, which uses meters as units and is based on the UTM Zone 47N projection.\n\nWe will extend the dataset by extracting the year, month, day of the week, and hour of each incident from the *incident_datetime* column to enhance temporal analysis.\n\n\n\n\nbmr_provinces &lt;- c(\"Bangkok\", \"Nonthaburi\", \"Nakhon Pathom\", \"Pathum Thani\", \"Samut Prakan\", \"Samut Sakhon\")\naccidents_bmr &lt;- accidents %&gt;% \n  filter(!is.na(longitude) & longitude != \"\",\n         !is.na(latitude) & latitude != \"\") %&gt;%\n  select(-c(province_th, route, report_datetime, agency)) %&gt;%\n  filter(province_en %in% bmr_provinces) %&gt;%\n  mutate(\n    Year = year(incident_datetime),\n    Month_num = month(incident_datetime),\n    Month_lab = month(incident_datetime, label = TRUE),\n    Day_of_Week_num = wday(incident_datetime),\n    Day_of_Week_lab = wday(incident_datetime, label = TRUE),\n    Day_of_year = yday(incident_datetime),\n    Hour = hour(incident_datetime)\n  ) %&gt;%\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs=4326) %&gt;%\n  st_transform(crs = 32647)\n\nUsing the extracted time data, we will classify each incident by season, identify whether it occurred during rush hours, determine if it took place on a weekday or weekend, and check if it coincided with Thailand’s major festival, Songkran.\n\naccidents_bmr &lt;- accidents_bmr %&gt;%\n  mutate(\n    season = case_when(\n      Month_num %in% c(3, 4, 5) ~ \"summer\",\n      Month_num %in% c(6, 7, 8, 9, 10) ~ \"rainy\",\n      Month_num %in% c(11, 12, 1, 2) ~ \"winter\"\n    ),\n    is_songkran = case_when(\n      Year == 2019 & Month_num == 4 & day(incident_datetime) %in% c(12:16) ~ TRUE,  # Songkran in 2019 (12-16 April)\n      Year != 2019 & Month_num == 4 & day(incident_datetime) %in% c(13:15) ~ TRUE,  # Songkran in other years (13-15 April)\n      TRUE ~ FALSE\n    ),\n    rush_hour = case_when(\n      wday(incident_datetime) %in% c(2:6) & hour(incident_datetime) %in% c(7:9) ~ TRUE,  # 7-9 AM on weekdays\n      wday(incident_datetime) %in% c(2:6) & hour(incident_datetime) %in% c(16:19) ~ TRUE,  # 4-7 PM on weekdays\n      TRUE ~ FALSE\n    ),\n    weekday_or_weekend = case_when(\n      wday(incident_datetime) %in% c(2:6) ~ \"weekday\",  # Monday to Friday\n      TRUE ~ \"weekend\"                      # Saturday and Sunday\n    )\n  )\n\nWe will simplify the presumed_clause column, as it currently contains 40 categories, making it too complex for effective analysis.\n\n# Define the categories\ndriver_behavior &lt;- c(\"speeding\", \"running red lights/traffic signals\", \"tailgating\", \n                     \"illegal overtaking\", \"failure to yield/signal\", \"abrupt lane change\", \n                     \"driving in the wrong lane\", \"failure to signal enter/exit parking\", \n                     \"failure to yield right of way\", \"ignoring stop sign while leaving intersection\", \n                     \"reversing vehicle\", \"straddling lanes\", \"using mobile phone while driving\", \n                     \"using psychoactive substances\", \"loss of control\", \n                     \"driving under the influence of alcohol\", \"falling asleep\", \"medical condition\")\n\nroad_environmental &lt;- c(\"dangerous curve\", \"slippery road\", \"road in poor condition\", \n                        \"inadequate visibility\", \"obstruction in sight\", \"no traffic signs\", \n                        \"no road divider lines\", \"repair/construction on the road\", \n                        \"debris/obstruction on the road\", \"cutting in closely by people/vehicles/animals\", \n                        \"unfamiliarity with the route/unskilled driving\", \"sudden stop\", \n                        \"no presumed cause related to driver\")\n\nvehicle_related &lt;- c(\"vehicle equipment failure\", \"worn-out/tire blowout\", \n                     \"disabled vehicle without proper signals/signs\", \"vehicle electrical system failure\", \n                     \"brake/anti-lock brake system failure\", \"overloaded vehicle\", \"insufficient light\")\n\naccidents_bmr$presumed_cause_category &lt;- ifelse(accidents_bmr$presumed_cause %in% driver_behavior, \"Driver Behavior\",\n                                               ifelse(accidents_bmr$presumed_cause %in% road_environmental, \"Road/Environmental Conditions\",\n                                                      ifelse(accidents_bmr$presumed_cause %in% vehicle_related, \"Vehicle-Related Violations\", \"Other\")))\n\nWe will also simplify vehicle_type column.\n\nmotorcycles_bicycles &lt;- c(\"motorcycle\", \"motorized tricycle\", \"bicycle\")\npassenger_vehicles &lt;- c(\"private/passenger car\", \"passenger pickup truck\", \"van\", \"large passenger vehicle\")\nlight_trucks &lt;- c(\"4-wheel pickup truck\")\nheavy_trucks &lt;- c(\"6-wheel truck\", \"7-10-wheel truck\", \"large truck with trailer\")\nnon_motorized &lt;- c(\"pedestrian\")\nspecialized_vehicles &lt;- c(\"tractor/agricultural vehicle\", \"other\")\n\naccidents_bmr$vehicle_category &lt;- ifelse(accidents_bmr$vehicle_type %in% motorcycles_bicycles, \n                                    \"2-wheeled\",\n                             ifelse(accidents_bmr$vehicle_type %in% passenger_vehicles, \n                                    \"Passenger Vehicles\",\n                             ifelse(accidents_bmr$vehicle_type %in% light_trucks, \n                                    \"Light Trucks\",\n                             ifelse(accidents_bmr$vehicle_type %in% heavy_trucks, \n                                    \"Heavy Trucks\",\n                             ifelse(accidents_bmr$vehicle_type %in% non_motorized, \n                                    \"Pedestrian\",\n                             ifelse(accidents_bmr$vehicle_type %in% specialized_vehicles, \n                                    \"SpecializedVehicles\", \n                                    \"Unknown\"))))))\n\nBefore saving the dataset in RDS format, let’s check for any duplicated records to ensure data integrity.\n\nany(duplicated(accidents_bmr))\n\n[1] FALSE\n\n\nNo duplicated records were found, so we can proceed to save the dataset in RDS format.\n\nwrite_rds(accidents_bmr, \"data/rds/road_accident_bmr.rds\")\n\n\naccidents_bmr &lt;- read_rds(\"data/rds/road_accident_bmr.rds\")\n\nLet’s visualize the accident points in Bangkok Metropolitan Region.\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\ntm_shape(accidents_bmr) +\n  tm_dots(col='red',\n          alpha=0.4, \n          size=0.04)\n\n\n\n\n\n\n\n\n\n\n2.3.2 Thailand Subnational Administration Boundary\nThe Thailand subnational administrative boundaries dataset is available at four levels: administrative level 0 (country), level 1 (province), level 2 (district), and level 3 (sub-district or tambon). For this analysis, we will use administrative level 1 (province) and filter the data to focus on the Bangkok Metropolitan Region (BMR).\nWe will load the province-level boundaries using the st_read() function and filter the dataset to include only the provinces in the BMR. The boundaries will then be transformed into EPSG:32647, which uses meters as units and is based on the UTM Zone 47N projection.\n\nadmin_boundary_bmr &lt;- st_read(dsn = \"data/geospatial/\",\n                           layer = \"tha_admbnda_adm1_rtsd_20220121\") %&gt;%\n  filter(ADM1_EN %in% bmr_provinces) %&gt;%\n  st_transform(crs = 32647)\n\nReading layer `tha_admbnda_adm1_rtsd_20220121' from data source \n  `/Users/cham/project/Geospatial-Analytics/chrismanafe/ISSS626-GAA/take_home_ex/take_home_ex01/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 77 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n\n\nLet’s verify the coordinate reference system of admin_boundary_bmr.\n\nst_crs(admin_boundary_bmr)\n\nCoordinate Reference System:\n  User input: EPSG:32647 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 47N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 47N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",99,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Engineering survey, topographic mapping.\"],\n        AREA[\"Between 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\"],\n        BBOX[0,96,84,102]],\n    ID[\"EPSG\",32647]]\n\n\n\nwrite_rds(admin_boundary_bmr, \"data/rds/admin_boundary_bmr.rds\")\n\n\nadmin_boundary_bmr &lt;- read_rds(\"data/rds/admin_boundary_bmr.rds\")\n\nLet’s visualize the administrative boundaries map using tmap.\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\ntm_shape(admin_boundary_bmr) +\n  tm_polygons(col = \"ADM1_EN\", palette = \"Pastel1\") +\n  tm_text(\"ADM1_EN\", size = 0.8) +\n  tm_layout(main.title = \"Bangkok Metropolitan Region (BMR) Administrative Boundaries\",\n            main.title.position = \"center\",\n            frame = FALSE)\n\n\n\n\n\n\n\n\nLet’s plot the administrative boundaries along with the accident points from the earlier dataset to visualize their spatial distribution.\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\ntm_shape(admin_boundary_bmr) +\n  tm_polygons(col = \"ADM1_EN\", palette = \"Pastel1\") +\n  tm_shape(accidents_bmr) +\n  tm_dots(col='red',\n          alpha=0.4, \n          size=0.04) +\n  tm_layout(main.title = \"BMR Administrative Boundaries and Road Accidents\",\n            main.title.position = \"center\",\n            frame = FALSE)\n\n\n\n\n\n\n\n\n\n\n2.3.3 Thailand Roads\nLet us load Thailand Roads data using st_read() of sf package.\n\nroads_sf &lt;- st_read(dsn = \"data/geospatial\",\n                    layer = \"hotosm_tha_roads_lines_shp\")\n\nWe observed that road_sf lacks a CRS. To correct this, we’ll first use st_set_crs() to assign the correct EPSG code, then apply st_transform() to project the data into the appropriate coordinate reference system. This dataset contains geometries in the form of MULTILINESTRING. We will apply st_cast() function to convert it into LINESTRING.\n\nroads_sf &lt;- st_set_crs(roads_sf, 4326)  %&gt;%\n  st_transform(crs = 32647) %&gt;% \n  st_cast(\"LINESTRING\")\n\nLet us verify the CRS on `roads_sf`.\n\nst_crs(roads_sf)\n\n\nroads_sf has the correct CRS, EPSG:32647.\n\nSince the OpenStreetMap data includes a wide range of road types, we will filter the dataset to keep only the road classes that are relevant to our analysis. Based on the definition, we’ll select the following road types:\n\nmotorway\ntrunk\nprimary\nsecondary\ntertiary\nmotorway_link\ntrunk_link\nprimary_link\nsecondary_link\ntertiary_link.\n\n\nroads_sf &lt;- roads_sf %&gt;%\n  filter(highway %in% c(\"motorway\", \"trunk\", \"primary\", \"secondary\", \"tertiary\",\n                        \"motorway_link\", \"trunk_link\", \"primary_link\", \n                        \"secondary_link\", \"tertiary_link\"))\n\n\nunique(roads_sf$highway)\n\nThe roads_sf dataset contains all road information across Thailand. Since our analysis focuses on the Bangkok Metropolitan Region (BMR), we will filter out roads located outside this area using st_intersection() function from sf package.\n\nroads_bmr &lt;- st_intersection(roads_sf, admin_boundary_bmr) %&gt;%\n  filter(st_geometry_type(.) == \"LINESTRING\")\n\nLet us check for any invalid geometries from roads_bmr.\n\ninvalid_geometries &lt;- st_is_valid(roads_bmr, reason=TRUE)\n\n\nlength(which(invalid_geometries != \"Valid Geometry\"))\n\n[1] 0\n\n\nThere’s no record with invalid geometries found in roads_bmr.\n\nwrite_rds(roads_bmr, \"data/rds/roads_bmr.rds\")\n\nNow, let’s visualize the road network along with accident locations within the Bangkok Metropolitan Region (BMR) for a clearer understanding of high-risk areas.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(roads_bmr) +\n  tm_lines(col = \"gray\", lwd = 0.7) +\n  tm_shape(accidents_bmr) +\n  tm_dots(col = \"red\", size = 0.1, alpha = 0.7) +\n  tm_layout(main.title = \"Bangkok Metropolitan Region Road Network with Accident Locations\",\n            main.title.position = \"center\",\n            frame = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nInitial Observations:\n\nAccidents are highly concentrated along major roads and highways, particularly in central urban areas.\nPeripheral areas show fewer accidents, suggesting lower traffic volumes outside the city center.\nContinuous accident clusters along key corridors indicate potential high-risk areas for traffic incidents.\n\n\n\n\n\n2.3.4 Converting sf data frame into spatstat’s ppp format\nAs we plan to carry out spatial point pattern analysis with the spatstat package, we need to convert the spatial data from the sf format into the ppp format.\nFirst, we create ppp objects from accidents_bmr data frame.\n\naccidents_bmr_ppp &lt;- as.ppp(accidents_bmr)\n\nWarning in as.ppp.sf(accidents_bmr): only first attribute column is used for\nmarks\n\nsummary(accidents_bmr_ppp)\n\nMarked planar point pattern:  12986 points\nAverage intensity 1.218049e-06 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 571882 3788970 3834532 4314457 6092694 7570954 \n\nWindow: rectangle = [591277.5, 710166.1] x [1486845.7, 1576520.5] units\n                    (118900 x 89670 units)\nWindow area = 10661300000 square units\n\n\nThen we create owin objects from admin_boundary_bmr data frame.\n\nadmin_boundary_bmr_owin &lt;- as.owin(admin_boundary_bmr)\n\nNow, we can create a ppp object by combining accidents_bmr_ppp and admin_boundary_bmr_owin.\n\naccidents_bmr_ppp = accidents_bmr_ppp[admin_boundary_bmr_owin]\nplot(accidents_bmr_ppp)\n\n\n\n\n\n\n\n\nLet us re-scale the unit of measurement from metre to kilometre before performing KDE.\n\naccidents_bmr_ppp.km &lt;- rescale.ppp(accidents_bmr_ppp,\n                                    1000, \n                                    \"km\")"
  },
  {
    "objectID": "take_home_ex/take_home_ex01/take_home_ex01.html#first-order-spatial-point-pattern-analysis",
    "href": "take_home_ex/take_home_ex01/take_home_ex01.html#first-order-spatial-point-pattern-analysis",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "4.1 First-order spatial point pattern analysis",
    "text": "4.1 First-order spatial point pattern analysis\n\n4.1.1 Computing kernel density estimation using automatic bandwidth selection method\nWe will compute the kernel density estimate (KDE) using different automatic bandwidth selection methods. Specifically, we will use bw.diggle and bw.ppl for the analysis to compare their results.\n\nkde_accidents_bmr_bw_diggle &lt;- density(accidents_bmr_ppp.km,\n                                       sigma=bw.diggle,\n                                       edge=TRUE,\n                                       kernel=\"gaussian\") \n\nkde_accidents_bmr_bw_ppl &lt;- density(accidents_bmr_ppp.km,\n                                    sigma=bw.ppl, \n                                    edge=TRUE,\n                                    kernel=\"gaussian\")\npar(mfrow=c(1,2))\nplot(kde_accidents_bmr_bw_diggle, main = \"bw.diggle\")\nplot(kde_accidents_bmr_bw_ppl, main = \"bw.ppl\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\n\nBoth bw.diggle and bw.ppl methods produce similar overall density patterns, with high-density areas highlighted in yellow and low-density areas in blue.\nHigh-density zones appear to cluster along key road networks or points of interest in both estimates, indicating consistency between the two methods.\n\n\n\n\n\n4.1.2 Computing kernel density estimation using adaptive bandwidth\nGiven the varying densities in our data and the consistent results from automatic bandwidth methods such as bw.diggle and bw.ppl, we will try to compute the density by using adaptive.density() of spatstat package. Adaptive bandwidth methods are often better suited to capture both global trends and local variations, providing a more accurate and nuanced understanding of the spatial patterns without the risk of oversmoothing or undersmoothing.\n\nkde_accidents_adaptive_kernel &lt;- adaptive.density(accidents_bmr_ppp.km, method=\"kernel\")\n\npar(mfrow=c(1,2))\nplot(kde_accidents_bmr_bw_diggle, main = \"automatic - bw.diggle\")\nplot(kde_accidents_adaptive_kernel, main = \"adaptive - kernel\")\n\n\n\n\n\n\n\n\n\nVisually, these results are very similar because both bw.diggle and the adaptive kernel method adjust the bandwidth based on the local density of points in the dataset. Since both methods are adaptive in nature, they capture the same underlying spatial patterns and point densities, leading to similar visual outcomes. This consistency indicates that the spatial distribution of accidents is being accurately reflected by both approaches.\n\n\n\n4.1.3 Plotting KDE Maps\nWe will visualise KDE (Kernel Density Estimate) map with a color palette ranging from yellow to red to represent density. It includes BMR boundary polygons, a scale bar, and sets the map projection to the UTM Zone 47N (EPSG:32647).\n\n\ncode chunk\nraster_kde_adaptive &lt;- raster(kde_accidents_adaptive_kernel)\nprojection(raster_kde_adaptive) &lt;- CRS(\"+init=EPSG:32647 +units=km\")\n\ntmap_mode('plot')\n\n\ntmap mode set to plotting\n\n\ncode chunk\nkde_diggle_tmap &lt;- tm_basemap(server = \"OpenStreetMap\") +\n  tm_shape(admin_boundary_bmr, ) +\n    tm_polygons(alpha=0.1, id=\"ADM1_EN\") +\n  tm_shape(raster_kde_adaptive) +\n    tm_raster(\"layer\",\n              n = 7,\n              title = \"KDE Adaptive\",\n              style = \"pretty\",\n              alpha = 0.6,\n              palette = \"YlOrRd\") +\n  tm_layout(main.title = \"KDE of Road Accidents in Bangkok Metropolitan Region\",\n            main.title.position = \"center\",\n            frame = FALSE)\n\nkde_diggle_tmap\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\n\nThe map reveals that accidents are most concentrated in Bangkok, followed by Samut Prakan and Pathum Thani provinces.\nThe highest concentration of accidents occurs along Motorway Route 7 (Bangkok–Ban Chang Motorway), with significant densities also observed on other major highways, including Motorway Route 9 (Kanchanaphisek Road, also known as the Bangkok Outer Ring Road) and Highway 338 (Borommaratchachonnani Road).\nThe concentration of accidents along these highways indicates that targeted safety interventions, such as traffic management, road safety improvements, or enhanced enforcement in these regions, may be effective in reducing accident rates.\n\n\n\n\n\n4.1.4 Nearest neighbour analysis\nIn this section, we will perform the Clark-Evans test of aggregation for a spatial point pattern using the clarkevans.test() function from the spatstat package.\nThe test hypotheses are:\n\nH₀: The spatial distribution of road accidents in BMR are randomly distributed.\nH₁: The spatial distribution of road accidents in BMR are not randomly distributed.\n\nWe will use a 95% confidence interval.\n\nclarkevans.test(accidents_bmr_ppp,\n                correction=\"none\",\n                clipregion=\"admin_boundary_bmr_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  accidents_bmr_ppp\nR = 0.19109, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\n\nInterpretations:\n\nThe Clark-Evans test result (R = 0.19109, p-value &lt; 2.2e-16) suggests that road accidents in the dataset are not randomly distributed. Instead, they exhibit significant clustering, meaning accidents tend to occur in close proximity to each other rather than being spread out randomly across the region.\nThis clustering is likely tied to underlying factors such as high traffic volumes or specific road types (e.g., intersections, highways)."
  },
  {
    "objectID": "take_home_ex/take_home_ex01/take_home_ex01.html#network-kernel-density-estimation-nkde",
    "href": "take_home_ex/take_home_ex01/take_home_ex01.html#network-kernel-density-estimation-nkde",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "4.2 Network Kernel Density Estimation (NKDE)",
    "text": "4.2 Network Kernel Density Estimation (NKDE)"
  },
  {
    "objectID": "take_home_ex/take_home_ex01/take_home_ex01.html#temporal-network-kernel-density-estimate-tnkde",
    "href": "take_home_ex/take_home_ex01/take_home_ex01.html#temporal-network-kernel-density-estimate-tnkde",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "4.3 Temporal Network Kernel Density Estimate (TNKDE)",
    "text": "4.3 Temporal Network Kernel Density Estimate (TNKDE)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05.1.html#loading-the-data",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05.1.html#loading-the-data",
    "title": "Hands-on Exercise 5a: Global Measures of Spatial Autocorrelation",
    "section": "4.1 Loading the data",
    "text": "4.1 Loading the data\nIn this section, we will learn how to bring a geospatial data and its associated attribute table into R environment. The geospatial data is in ESRI shapefile format and the attribute table is in csv fomat.\n\nImport geospatial dataImport aspatial dataPerform relational join\n\n\nWe use st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be simple features Object of sf.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/Users/cham/project/Geospatial-Analytics/chrismanafe/ISSS626-GAA/hands_on_ex/hands_on_ex05/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\nRows: 88\nColumns: 8\n$ NAME_2     &lt;chr&gt; \"Changde\", \"Changde\", \"Changde\", \"Changde\", \"Changde\", \"Cha…\n$ ID_3       &lt;int&gt; 21098, 21100, 21101, 21102, 21103, 21104, 21109, 21110, 211…\n$ NAME_3     &lt;chr&gt; \"Anxiang\", \"Hanshou\", \"Jinshi\", \"Li\", \"Linli\", \"Shimen\", \"L…\n$ ENGTYPE_3  &lt;chr&gt; \"County\", \"County\", \"County City\", \"County\", \"County\", \"Cou…\n$ Shape_Leng &lt;dbl&gt; 1.869074, 2.360691, 1.425620, 3.474325, 2.289506, 4.171918,…\n$ Shape_Area &lt;dbl&gt; 0.10056190, 0.19978745, 0.05302413, 0.18908121, 0.11450357,…\n$ County     &lt;chr&gt; \"Anxiang\", \"Hanshou\", \"Jinshi\", \"Li\", \"Linli\", \"Shimen\", \"L…\n$ geometry   &lt;POLYGON [°]&gt; POLYGON ((112.0625 29.75523..., POLYGON ((112.2288 …\n\n\n\n\nThen we will import Hunan_2012.csv into R by using read_csv() of readr package. The output is R dataframe class.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nRows: 88\nColumns: 29\n$ County      &lt;chr&gt; \"Anhua\", \"Anren\", \"Anxiang\", \"Baojing\", \"Chaling\", \"Changn…\n$ City        &lt;chr&gt; \"Yiyang\", \"Chenzhou\", \"Changde\", \"Hunan West\", \"Zhuzhou\", …\n$ avg_wage    &lt;dbl&gt; 30544, 28058, 31935, 30843, 31251, 28518, 54540, 28597, 33…\n$ deposite    &lt;dbl&gt; 10967.0, 4598.9, 5517.2, 2250.0, 8241.4, 10860.0, 24332.0,…\n$ FAI         &lt;dbl&gt; 6831.7, 6386.1, 3541.0, 1005.4, 6508.4, 7920.0, 33624.0, 1…\n$ Gov_Rev     &lt;dbl&gt; 456.72, 220.57, 243.64, 192.59, 620.19, 769.86, 5350.00, 1…\n$ Gov_Exp     &lt;dbl&gt; 2703.0, 1454.7, 1779.5, 1379.1, 1947.0, 2631.6, 7885.5, 11…\n$ GDP         &lt;dbl&gt; 13225.0, 4941.2, 12482.0, 4087.9, 11585.0, 19886.0, 88009.…\n$ GDPPC       &lt;dbl&gt; 14567, 12761, 23667, 14563, 20078, 24418, 88656, 10132, 17…\n$ GIO         &lt;dbl&gt; 9276.90, 4189.20, 5108.90, 3623.50, 9157.70, 37392.00, 513…\n$ Loan        &lt;dbl&gt; 3954.90, 2555.30, 2806.90, 1253.70, 4287.40, 4242.80, 4053…\n$ NIPCR       &lt;dbl&gt; 3528.3, 3271.8, 7693.7, 4191.3, 3887.7, 9528.0, 17070.0, 3…\n$ Bed         &lt;dbl&gt; 2718, 970, 1931, 927, 1449, 3605, 3310, 582, 2170, 2179, 1…\n$ Emp         &lt;dbl&gt; 494.310, 290.820, 336.390, 195.170, 330.290, 548.610, 670.…\n$ EmpR        &lt;dbl&gt; 441.4, 255.4, 270.5, 145.6, 299.0, 415.1, 452.0, 127.6, 21…\n$ EmpRT       &lt;dbl&gt; 338.0, 99.4, 205.9, 116.4, 154.0, 273.7, 219.4, 94.4, 174.…\n$ Pri_Stu     &lt;dbl&gt; 54.175, 33.171, 19.584, 19.249, 33.906, 81.831, 59.151, 18…\n$ Sec_Stu     &lt;dbl&gt; 32.830, 17.505, 17.819, 11.831, 20.548, 44.485, 39.685, 7.…\n$ Household   &lt;dbl&gt; 290.4, 104.6, 148.1, 73.2, 148.7, 211.2, 300.3, 76.1, 139.…\n$ Household_R &lt;dbl&gt; 234.5, 121.9, 135.4, 69.9, 139.4, 211.7, 248.4, 59.6, 110.…\n$ NOIP        &lt;dbl&gt; 101, 34, 53, 18, 106, 115, 214, 17, 55, 70, 44, 84, 74, 17…\n$ Pop_R       &lt;dbl&gt; 670.3, 243.2, 346.0, 184.1, 301.6, 448.2, 475.1, 189.6, 31…\n$ RSCG        &lt;dbl&gt; 5760.60, 2386.40, 3957.90, 768.04, 4009.50, 5220.40, 22604…\n$ Pop_T       &lt;dbl&gt; 910.8, 388.7, 528.3, 281.3, 578.4, 816.3, 998.6, 256.7, 45…\n$ Agri        &lt;dbl&gt; 4942.253, 2357.764, 4524.410, 1118.561, 3793.550, 6430.782…\n$ Service     &lt;dbl&gt; 5414.5, 3814.1, 14100.0, 541.8, 5444.0, 13074.6, 17726.6, …\n$ Disp_Inc    &lt;dbl&gt; 12373, 16072, 16610, 13455, 20461, 20868, 183252, 12379, 1…\n$ RORP        &lt;dbl&gt; 0.7359464, 0.6256753, 0.6549309, 0.6544614, 0.5214385, 0.5…\n$ ROREmp      &lt;dbl&gt; 0.8929619, 0.8782065, 0.8041262, 0.7460163, 0.9052651, 0.7…\n\n\n\n\nWe will also update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe. This is performed by using left_join() of dplyr package.\n\ncolnames(hunan)\n\n[1] \"NAME_2\"     \"ID_3\"       \"NAME_3\"     \"ENGTYPE_3\"  \"Shape_Leng\"\n[6] \"Shape_Area\" \"County\"     \"geometry\"  \n\n\n\ncolnames(hunan2012)\n\n [1] \"County\"      \"City\"        \"avg_wage\"    \"deposite\"    \"FAI\"        \n [6] \"Gov_Rev\"     \"Gov_Exp\"     \"GDP\"         \"GDPPC\"       \"GIO\"        \n[11] \"Loan\"        \"NIPCR\"       \"Bed\"         \"Emp\"         \"EmpR\"       \n[16] \"EmpRT\"       \"Pri_Stu\"     \"Sec_Stu\"     \"Household\"   \"Household_R\"\n[21] \"NOIP\"        \"Pop_R\"       \"RSCG\"        \"Pop_T\"       \"Agri\"       \n[26] \"Service\"     \"Disp_Inc\"    \"RORP\"        \"ROREmp\"     \n\n\n\nhunan &lt;- left_join(hunan,hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`\n\n\n\n\nRows: 88\nColumns: 7\n$ NAME_2    &lt;chr&gt; \"Changde\", \"Changde\", \"Changde\", \"Changde\", \"Changde\", \"Chan…\n$ ID_3      &lt;int&gt; 21098, 21100, 21101, 21102, 21103, 21104, 21109, 21110, 2111…\n$ NAME_3    &lt;chr&gt; \"Anxiang\", \"Hanshou\", \"Jinshi\", \"Li\", \"Linli\", \"Shimen\", \"Li…\n$ ENGTYPE_3 &lt;chr&gt; \"County\", \"County\", \"County City\", \"County\", \"County\", \"Coun…\n$ County    &lt;chr&gt; \"Anxiang\", \"Hanshou\", \"Jinshi\", \"Li\", \"Linli\", \"Shimen\", \"Li…\n$ GDPPC     &lt;dbl&gt; 23667, 20981, 34592, 24473, 25554, 27137, 63118, 62202, 7066…\n$ geometry  &lt;POLYGON [°]&gt; POLYGON ((112.0625 29.75523..., POLYGON ((112.2288 2…"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05.1.html#visualising-regional-development-indicator",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05.1.html#visualising-regional-development-indicator",
    "title": "Hands-on Exercise 5a: Global Measures of Spatial Autocorrelation",
    "section": "4.2 Visualising Regional Development Indicator",
    "text": "4.2 Visualising Regional Development Indicator\nNow, we are going to prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\nequal &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05.1.html#morans-i-correlogram",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05.1.html#morans-i-correlogram",
    "title": "Hands-on Exercise 5a: Global Measures of Spatial Autocorrelation",
    "section": "8.1 Moran’s I correlogram",
    "text": "8.1 Moran’s I correlogram\nWe will use the sp.correlogram() function from the spdep package to compute a 6-lag spatial correlogram for GDPPC, using Moran’s I to assess global spatial autocorrelation. The results will then be plotted using the base plot() function in R.\n\nMI_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\n\n\n\n\n\nPlotting the output alone might not provide a complete interpretation, as not all autocorrelation values may be statistically significant. Therefore, it’s important to examine the full analysis by printing the detailed results, as shown in the code chunk below.\n\n\nprint(MI_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nNote\n\n\n\nQuestion: What statistical observation can we draw from the plot above?\n\nPositive Moran’s I values for shorter lags (1–3), reflecting spatial clustering of similar values.\nNegative Moran’s I values for longer lags (5–6), indicating spatial divergence of values.\nError bars help visualize the variability and significance of these estimates. Significant values (lags 1, 2, 3, 5, and 6) stand out more due to their separation from zero, while lag 4 hovers around zero and is not statistically significant.\n\nThis pattern suggests that similar GDP per capita values are clustered spatially at short distances, but regions farther apart are more likely to have contrasting GDP per capita values."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05.1.html#gearys-c-correlogram",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05.1.html#gearys-c-correlogram",
    "title": "Hands-on Exercise 5a: Global Measures of Spatial Autocorrelation",
    "section": "8.2 Geary’s C correlogram",
    "text": "8.2 Geary’s C correlogram\nWe will use sp.correlogram() function from the spdep package to compute a 6-lag spatial correlogram for GDPPC, using Geary’s C to assess global spatial autocorrelation. The results will then be plotted using the base plot() function in R.\n\nGC_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\n\n\n\n\nLet us see the analysis report\n\nprint(GC_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05.2.html#loading-the-data",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05.2.html#loading-the-data",
    "title": "Hands-on Exercise 5b: Local Measures of Spatial Autocorrelation",
    "section": "5.1 Loading the data",
    "text": "5.1 Loading the data\nIn this section, we will learn how to bring a geospatial data and its associated attribute table into R environment. The geospatial data is in ESRI shapefile format and the attribute table is in csv fomat.\n\nImport geospatial dataImport aspatial dataPerform relational join\n\n\nWe use st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be simple features Object of sf.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/Users/cham/project/Geospatial-Analytics/chrismanafe/ISSS626-GAA/hands_on_ex/hands_on_ex05/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\nRows: 88\nColumns: 8\n$ NAME_2     &lt;chr&gt; \"Changde\", \"Changde\", \"Changde\", \"Changde\", \"Changde\", \"Cha…\n$ ID_3       &lt;int&gt; 21098, 21100, 21101, 21102, 21103, 21104, 21109, 21110, 211…\n$ NAME_3     &lt;chr&gt; \"Anxiang\", \"Hanshou\", \"Jinshi\", \"Li\", \"Linli\", \"Shimen\", \"L…\n$ ENGTYPE_3  &lt;chr&gt; \"County\", \"County\", \"County City\", \"County\", \"County\", \"Cou…\n$ Shape_Leng &lt;dbl&gt; 1.869074, 2.360691, 1.425620, 3.474325, 2.289506, 4.171918,…\n$ Shape_Area &lt;dbl&gt; 0.10056190, 0.19978745, 0.05302413, 0.18908121, 0.11450357,…\n$ County     &lt;chr&gt; \"Anxiang\", \"Hanshou\", \"Jinshi\", \"Li\", \"Linli\", \"Shimen\", \"L…\n$ geometry   &lt;POLYGON [°]&gt; POLYGON ((112.0625 29.75523..., POLYGON ((112.2288 …\n\n\n\n\nThen we will import Hunan_2012.csv into R by using read_csv() of readr package. The output is R dataframe class.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nRows: 88\nColumns: 29\n$ County      &lt;chr&gt; \"Anhua\", \"Anren\", \"Anxiang\", \"Baojing\", \"Chaling\", \"Changn…\n$ City        &lt;chr&gt; \"Yiyang\", \"Chenzhou\", \"Changde\", \"Hunan West\", \"Zhuzhou\", …\n$ avg_wage    &lt;dbl&gt; 30544, 28058, 31935, 30843, 31251, 28518, 54540, 28597, 33…\n$ deposite    &lt;dbl&gt; 10967.0, 4598.9, 5517.2, 2250.0, 8241.4, 10860.0, 24332.0,…\n$ FAI         &lt;dbl&gt; 6831.7, 6386.1, 3541.0, 1005.4, 6508.4, 7920.0, 33624.0, 1…\n$ Gov_Rev     &lt;dbl&gt; 456.72, 220.57, 243.64, 192.59, 620.19, 769.86, 5350.00, 1…\n$ Gov_Exp     &lt;dbl&gt; 2703.0, 1454.7, 1779.5, 1379.1, 1947.0, 2631.6, 7885.5, 11…\n$ GDP         &lt;dbl&gt; 13225.0, 4941.2, 12482.0, 4087.9, 11585.0, 19886.0, 88009.…\n$ GDPPC       &lt;dbl&gt; 14567, 12761, 23667, 14563, 20078, 24418, 88656, 10132, 17…\n$ GIO         &lt;dbl&gt; 9276.90, 4189.20, 5108.90, 3623.50, 9157.70, 37392.00, 513…\n$ Loan        &lt;dbl&gt; 3954.90, 2555.30, 2806.90, 1253.70, 4287.40, 4242.80, 4053…\n$ NIPCR       &lt;dbl&gt; 3528.3, 3271.8, 7693.7, 4191.3, 3887.7, 9528.0, 17070.0, 3…\n$ Bed         &lt;dbl&gt; 2718, 970, 1931, 927, 1449, 3605, 3310, 582, 2170, 2179, 1…\n$ Emp         &lt;dbl&gt; 494.310, 290.820, 336.390, 195.170, 330.290, 548.610, 670.…\n$ EmpR        &lt;dbl&gt; 441.4, 255.4, 270.5, 145.6, 299.0, 415.1, 452.0, 127.6, 21…\n$ EmpRT       &lt;dbl&gt; 338.0, 99.4, 205.9, 116.4, 154.0, 273.7, 219.4, 94.4, 174.…\n$ Pri_Stu     &lt;dbl&gt; 54.175, 33.171, 19.584, 19.249, 33.906, 81.831, 59.151, 18…\n$ Sec_Stu     &lt;dbl&gt; 32.830, 17.505, 17.819, 11.831, 20.548, 44.485, 39.685, 7.…\n$ Household   &lt;dbl&gt; 290.4, 104.6, 148.1, 73.2, 148.7, 211.2, 300.3, 76.1, 139.…\n$ Household_R &lt;dbl&gt; 234.5, 121.9, 135.4, 69.9, 139.4, 211.7, 248.4, 59.6, 110.…\n$ NOIP        &lt;dbl&gt; 101, 34, 53, 18, 106, 115, 214, 17, 55, 70, 44, 84, 74, 17…\n$ Pop_R       &lt;dbl&gt; 670.3, 243.2, 346.0, 184.1, 301.6, 448.2, 475.1, 189.6, 31…\n$ RSCG        &lt;dbl&gt; 5760.60, 2386.40, 3957.90, 768.04, 4009.50, 5220.40, 22604…\n$ Pop_T       &lt;dbl&gt; 910.8, 388.7, 528.3, 281.3, 578.4, 816.3, 998.6, 256.7, 45…\n$ Agri        &lt;dbl&gt; 4942.253, 2357.764, 4524.410, 1118.561, 3793.550, 6430.782…\n$ Service     &lt;dbl&gt; 5414.5, 3814.1, 14100.0, 541.8, 5444.0, 13074.6, 17726.6, …\n$ Disp_Inc    &lt;dbl&gt; 12373, 16072, 16610, 13455, 20461, 20868, 183252, 12379, 1…\n$ RORP        &lt;dbl&gt; 0.7359464, 0.6256753, 0.6549309, 0.6544614, 0.5214385, 0.5…\n$ ROREmp      &lt;dbl&gt; 0.8929619, 0.8782065, 0.8041262, 0.7460163, 0.9052651, 0.7…\n\n\n\n\nWe will also update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe. This is performed by using left_join() of dplyr package.\n\ncolnames(hunan)\n\n[1] \"NAME_2\"     \"ID_3\"       \"NAME_3\"     \"ENGTYPE_3\"  \"Shape_Leng\"\n[6] \"Shape_Area\" \"County\"     \"geometry\"  \n\n\n\ncolnames(hunan2012)\n\n [1] \"County\"      \"City\"        \"avg_wage\"    \"deposite\"    \"FAI\"        \n [6] \"Gov_Rev\"     \"Gov_Exp\"     \"GDP\"         \"GDPPC\"       \"GIO\"        \n[11] \"Loan\"        \"NIPCR\"       \"Bed\"         \"Emp\"         \"EmpR\"       \n[16] \"EmpRT\"       \"Pri_Stu\"     \"Sec_Stu\"     \"Household\"   \"Household_R\"\n[21] \"NOIP\"        \"Pop_R\"       \"RSCG\"        \"Pop_T\"       \"Agri\"       \n[26] \"Service\"     \"Disp_Inc\"    \"RORP\"        \"ROREmp\"     \n\n\n\nhunan &lt;- left_join(hunan,hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`\n\n\n\n\nRows: 88\nColumns: 7\n$ NAME_2    &lt;chr&gt; \"Changde\", \"Changde\", \"Changde\", \"Changde\", \"Changde\", \"Chan…\n$ ID_3      &lt;int&gt; 21098, 21100, 21101, 21102, 21103, 21104, 21109, 21110, 2111…\n$ NAME_3    &lt;chr&gt; \"Anxiang\", \"Hanshou\", \"Jinshi\", \"Li\", \"Linli\", \"Shimen\", \"Li…\n$ ENGTYPE_3 &lt;chr&gt; \"County\", \"County\", \"County City\", \"County\", \"County\", \"Coun…\n$ County    &lt;chr&gt; \"Anxiang\", \"Hanshou\", \"Jinshi\", \"Li\", \"Linli\", \"Shimen\", \"Li…\n$ GDPPC     &lt;dbl&gt; 23667, 20981, 34592, 24473, 25554, 27137, 63118, 62202, 7066…\n$ geometry  &lt;POLYGON [°]&gt; POLYGON ((112.0625 29.75523..., POLYGON ((112.2288 2…"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05.2.html#visualising-regional-development-indicator",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05.2.html#visualising-regional-development-indicator",
    "title": "Hands-on Exercise 5b: Local Measures of Spatial Autocorrelation",
    "section": "5.2 Visualising Regional Development Indicator",
    "text": "5.2 Visualising Regional Development Indicator\nNow, we are going to prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\nequal &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05.2.html#computing-contiguity-spatial-weights",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05.2.html#computing-contiguity-spatial-weights",
    "title": "Hands-on Exercise 5b: Local Measures of Spatial Autocorrelation",
    "section": "6.1 Computing Contiguity Spatial Weights",
    "text": "6.1 Computing Contiguity Spatial Weights\nBefore we can compute the local spatial autocorrelation statistics, we need to construct a spatial weights of the study area. The spatial weights is used to define the neighbourhood relationships between the geographical units (i.e. county) in the study area.\n\npoly2nb() of spdep package is used to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. If you look at the documentation you will see that you can pass a “queen” argument that takes TRUE or FALSE as options. If you do not specify this argument the default is set to TRUE, that is, if you don’t specify queen = FALSE this function will return a list of first order neighbours using the Queen criteria.\n\nMore specifically, the code chunk below is used to compute Queen contiguity weight matrix.\n\nwm_q &lt;- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThere are 88 area units in Hunan.\nThe most connected area unit has 11 neighbours.\nThere are two area units with only one neighbour."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05.2.html#row-standardised-weights-matrix",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05.2.html#row-standardised-weights-matrix",
    "title": "Hands-on Exercise 5b: Local Measures of Spatial Autocorrelation",
    "section": "6.2 Row-standardised weights matrix",
    "text": "6.2 Row-standardised weights matrix\nNext, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values.\n\nWhile this is the most intuitive way to summaries the neighbors’ values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data.\nFor this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.\n\n\nrswm_q &lt;- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\n\n\n\n\n\nImportant\n\n\n\n\nThe input of nb2listw() must be an object of class nb. The syntax of the function has two major arguments, namely style and zero.poly.\nstyle can take values “W”, “B”, “C”, “U”, “minmax” and “S”.\n\nB is the basic binary coding,\nW is row standardised (sums over all links to n),\nC is globally standardised (sums over all links to n),\nU is equal to C divided by the number of neighbours (sums over all links to unity),\nS is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).\n\nIf zero policy is set to TRUE, weights vectors of zero length are inserted for regions without neighbour in the neighbours list. These will in turn generate lag values of zero, equivalent to the sum of products of the zero row t(rep(0, length=length(neighbours))) %*% x, for arbitrary numerical vector x of length length(neighbours). The spatially lagged value of x for the zero-neighbour region will then be zero, which may (or may not) be a sensible choice."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05.2.html#computing-local-morans-i",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05.2.html#computing-local-morans-i",
    "title": "Hands-on Exercise 5b: Local Measures of Spatial Autocorrelation",
    "section": "6.3 Computing local Moran’s I",
    "text": "6.3 Computing local Moran’s I\nTo compute local Moran’s I, we will use the localmoran() function from the spdep package. This function computes the Ii values for each observation, given a set of zi values (the variable of interest) and a listw object, which provides the spatial weights for the neighboring polygons associated with the zi values.\nThe code chunks below illustrate how to compute local Moran’s I for GDP per capita in 2012 (GDPPC2012) at the county level.\n\nfips &lt;- order(hunan$County)\nlocalMI &lt;- localmoran(hunan$GDPPC, rswm_q)\nhead(localMI)\n\n            Ii          E.Ii       Var.Ii        Z.Ii Pr(z != E(Ii))\n1 -0.001468468 -2.815006e-05 4.723841e-04 -0.06626904      0.9471636\n2  0.025878173 -6.061953e-04 1.016664e-02  0.26266425      0.7928094\n3 -0.011987646 -5.366648e-03 1.133362e-01 -0.01966705      0.9843090\n4  0.001022468 -2.404783e-07 5.105969e-06  0.45259801      0.6508382\n5  0.014814881 -6.829362e-05 1.449949e-03  0.39085814      0.6959021\n6 -0.038793829 -3.860263e-04 6.475559e-03 -0.47728835      0.6331568\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe localmoran() function returns a matrix of values, with the following columns:\n\nIi: The local Moran’s I statistic.\nE.Ii: The expected value of the local Moran’s I statistic under the randomization hypothesis.\nVar.Ii: The variance of the local Moran’s I statistic under the randomization hypothesis.\nZ.Ii: The standardized deviate (z-score) of the local Moran’s I statistic.\nPr(): The p-value associated with the local Moran’s I statistic.\n\n\n\nThe code chunk below lists the contents of the local Moran’s I matrix using printCoefmat() to display the results.\n\nprintCoefmat(data.frame(\n  localMI[fips,], \n  row.names=hunan$County[fips]),\n  check.names=FALSE)\n\n                       Ii        E.Ii      Var.Ii        Z.Ii Pr.z....E.Ii..\nAnhua         -2.2493e-02 -5.0048e-03  5.8235e-02 -7.2467e-02         0.9422\nAnren         -3.9932e-01 -7.0111e-03  7.0348e-02 -1.4791e+00         0.1391\nAnxiang       -1.4685e-03 -2.8150e-05  4.7238e-04 -6.6269e-02         0.9472\nBaojing        3.4737e-01 -5.0089e-03  8.3636e-02  1.2185e+00         0.2230\nChaling        2.0559e-02 -9.6812e-04  2.7711e-02  1.2932e-01         0.8971\nChangning     -2.9868e-05 -9.0010e-09  1.5105e-07 -7.6828e-02         0.9388\nChangsha       4.9022e+00 -2.1348e-01  2.3194e+00  3.3590e+00         0.0008\nChengbu        7.3725e-01 -1.0534e-02  2.2132e-01  1.5895e+00         0.1119\nChenxi         1.4544e-01 -2.8156e-03  4.7116e-02  6.8299e-01         0.4946\nCili           7.3176e-02 -1.6747e-03  4.7902e-02  3.4200e-01         0.7324\nDao            2.1420e-01 -2.0824e-03  4.4123e-02  1.0297e+00         0.3032\nDongan         1.5210e-01 -6.3485e-04  1.3471e-02  1.3159e+00         0.1882\nDongkou        5.2918e-01 -6.4461e-03  1.0748e-01  1.6338e+00         0.1023\nFenghuang      1.8013e-01 -6.2832e-03  1.3257e-01  5.1198e-01         0.6087\nGuidong       -5.9160e-01 -1.3086e-02  3.7003e-01 -9.5104e-01         0.3416\nGuiyang        1.8240e-01 -3.6908e-03  3.2610e-02  1.0305e+00         0.3028\nGuzhang        2.8466e-01 -8.5054e-03  1.4152e-01  7.7931e-01         0.4358\nHanshou        2.5878e-02 -6.0620e-04  1.0167e-02  2.6266e-01         0.7928\nHengdong       9.9964e-03 -4.9063e-04  6.7742e-03  1.2742e-01         0.8986\nHengnan        2.8064e-02 -3.2160e-04  3.7597e-03  4.6294e-01         0.6434\nHengshan      -5.8201e-03 -3.0437e-05  5.1076e-04 -2.5618e-01         0.7978\nHengyang       6.2997e-02 -1.3046e-03  2.1865e-02  4.3486e-01         0.6637\nHongjiang      1.8790e-01 -2.3019e-03  3.1725e-02  1.0678e+00         0.2856\nHuarong       -1.5389e-02 -1.8667e-03  8.1030e-02 -4.7503e-02         0.9621\nHuayuan        8.3772e-02 -8.5569e-04  2.4495e-02  5.4072e-01         0.5887\nHuitong        2.5997e-01 -5.2447e-03  1.1077e-01  7.9685e-01         0.4255\nJiahe         -1.2431e-01 -3.0550e-03  5.1111e-02 -5.3633e-01         0.5917\nJianghua       2.8651e-01 -3.8280e-03  8.0968e-02  1.0204e+00         0.3076\nJiangyong      2.4337e-01 -2.7082e-03  1.1746e-01  7.1800e-01         0.4728\nJingzhou       1.8270e-01 -8.5106e-04  2.4363e-02  1.1759e+00         0.2396\nJinshi        -1.1988e-02 -5.3666e-03  1.1334e-01 -1.9667e-02         0.9843\nJishou        -2.8680e-01 -2.6305e-03  4.4028e-02 -1.3543e+00         0.1756\nLanshan        6.3334e-02 -9.6365e-04  2.0441e-02  4.4972e-01         0.6529\nLeiyang        1.1581e-02 -1.4948e-04  2.5082e-03  2.3422e-01         0.8148\nLengshuijiang -1.7903e+00 -8.2129e-02  2.1598e+00 -1.1623e+00         0.2451\nLi             1.0225e-03 -2.4048e-07  5.1060e-06  4.5260e-01         0.6508\nLianyuan      -1.4672e-01 -1.8983e-03  1.9145e-02 -1.0467e+00         0.2952\nLiling         1.3774e+00 -1.5097e-02  4.2601e-01  2.1335e+00         0.0329\nLinli          1.4815e-02 -6.8294e-05  1.4499e-03  3.9086e-01         0.6959\nLinwu         -2.4621e-03 -9.0703e-06  1.9258e-04 -1.7676e-01         0.8597\nLinxiang       6.5904e-02 -2.9028e-03  2.5470e-01  1.3634e-01         0.8916\nLiuyang        3.3688e+00 -7.7502e-02  1.5180e+00  2.7972e+00         0.0052\nLonghui        8.0801e-01 -1.1377e-02  1.5538e-01  2.0787e+00         0.0376\nLongshan       7.5663e-01 -1.1100e-02  3.1449e-01  1.3690e+00         0.1710\nLuxi           1.8177e-01 -2.4855e-03  3.4249e-02  9.9561e-01         0.3194\nMayang         2.1852e-01 -5.8773e-03  9.8049e-02  7.1663e-01         0.4736\nMiluo          1.8704e+00 -1.6927e-02  2.7925e-01  3.5715e+00         0.0004\nNan           -9.5789e-03 -4.9497e-04  6.8341e-03 -1.0988e-01         0.9125\nNingxiang      1.5607e+00 -7.3878e-02  8.0012e-01  1.8274e+00         0.0676\nNingyuan       2.0910e-01 -7.0884e-03  8.2306e-02  7.5356e-01         0.4511\nPingjiang     -9.8964e-01 -2.6457e-03  5.6027e-02 -4.1698e+00         0.0000\nQidong         1.1806e-01 -2.1207e-03  2.4747e-02  7.6396e-01         0.4449\nQiyang         6.1966e-02 -7.3374e-04  8.5743e-03  6.7712e-01         0.4983\nRucheng       -3.6992e-01 -8.8999e-03  2.5272e-01 -7.1814e-01         0.4727\nSangzhi        2.5053e-01 -4.9470e-03  6.8000e-02  9.7972e-01         0.3272\nShaodong      -3.2659e-02 -3.6592e-05  5.0546e-04 -1.4510e+00         0.1468\nShaoshan       2.1223e+00 -5.0227e-02  1.3668e+00  1.8583e+00         0.0631\nShaoyang       5.9499e-01 -1.1253e-02  1.3012e-01  1.6807e+00         0.0928\nShimen        -3.8794e-02 -3.8603e-04  6.4756e-03 -4.7729e-01         0.6332\nShuangfeng     9.2835e-03 -2.2867e-03  3.1516e-02  6.5174e-02         0.9480\nShuangpai      8.0591e-02 -3.1366e-04  8.9838e-03  8.5358e-01         0.3933\nSuining        3.7585e-01 -3.5933e-03  4.1870e-02  1.8544e+00         0.0637\nTaojiang      -2.5394e-01 -1.2395e-03  1.4477e-02 -2.1002e+00         0.0357\nTaoyuan        1.4729e-02 -1.2039e-04  8.5103e-04  5.0903e-01         0.6107\nTongdao        4.6482e-01 -6.9870e-03  1.9879e-01  1.0582e+00         0.2900\nWangcheng      4.4220e+00 -1.1067e-01  1.3596e+00  3.8873e+00         0.0001\nWugang         7.1003e-01 -7.8144e-03  1.0710e-01  2.1935e+00         0.0283\nXiangtan       2.4530e-01 -3.6457e-04  3.2319e-03  4.3213e+00         0.0000\nXiangxiang     2.6271e-01 -1.2703e-03  2.1290e-02  1.8092e+00         0.0704\nXiangyin       5.4525e-01 -4.7442e-03  7.9236e-02  1.9539e+00         0.0507\nXinhua         1.1810e-01 -6.2649e-03  8.6001e-02  4.2409e-01         0.6715\nXinhuang       1.5725e-01 -4.1820e-03  3.6648e-01  2.6667e-01         0.7897\nXinning        6.8928e-01 -9.6674e-03  2.0328e-01  1.5502e+00         0.1211\nXinshao        5.7578e-02 -8.5932e-03  1.1769e-01  1.9289e-01         0.8470\nXintian       -7.4050e-03 -5.1493e-03  1.0877e-01 -6.8395e-03         0.9945\nXupu           3.2406e-01 -5.7468e-03  5.7735e-02  1.3726e+00         0.1699\nYanling       -6.9021e-02 -5.9211e-04  9.9306e-03 -6.8667e-01         0.4923\nYizhang       -2.6844e-01 -2.2463e-03  4.7588e-02 -1.2202e+00         0.2224\nYongshun       6.3064e-01 -1.1350e-02  1.8830e-01  1.4795e+00         0.1390\nYongxing       4.3411e-01 -9.0735e-03  1.5088e-01  1.1409e+00         0.2539\nYou            7.8750e-02 -7.2728e-03  1.2116e-01  2.4714e-01         0.8048\nYuanjiang      2.0004e-04 -1.7760e-04  2.9798e-03  6.9181e-03         0.9945\nYuanling       8.7298e-03 -2.2981e-06  2.3221e-05  1.8121e+00         0.0700\nYueyang        4.1189e-02 -1.9768e-04  2.3113e-03  8.6085e-01         0.3893\nZhijiang       1.0476e-01 -7.8123e-04  1.3100e-02  9.2214e-01         0.3565\nZhongfang     -2.2685e-01 -2.1455e-03  3.5927e-02 -1.1855e+00         0.2358\nZhuzhou        3.2864e-01 -5.2432e-04  7.2391e-03  3.8688e+00         0.0001\nZixing        -7.6849e-01 -8.8210e-02  9.4057e-01 -7.0144e-01         0.4830\n\n\n\n6.3.1 Mapping the local Moran’s I\nBefore mapping the local Moran’s I results, it is advisable to append the local Moran’s I dataframe (i.e., localMI) to the hunan SpatialPolygonDataFrame. The code chunk below demonstrates how to perform this task. The resulting SpatialPolygonDataFrame is named hunan.localMI.\n\nhunan.localMI &lt;- cbind(hunan,localMI) %&gt;%\n  rename(Pr.Ii = Pr.z....E.Ii..)\n\n\n\n6.3.2 Mapping local Moran’s I values\nUsing the choropleth mapping functions from the tmap package, we can plot the local Moran’s I values. The code chunk below illustrates how to create this map.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\",\n          palette = \"RdBu\",\n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\nVariable(s) \"Ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n6.3.3 Mapping local Moran’s I p-values\nThe choropleth map shows evidence of both positive and negative Ii values. However, it is important to also consider the p-values associated with these values.\nThe code chunk below demonstrates how to produce a choropleth map of Moran’s I p-values using the functions from the tmap package.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n6.3.4 Mapping both local Moran’s I values and p-values\nFor effective interpretation, it is beneficial to plot both the local Moran’s I values map and the corresponding p-values map side by side.\nThe code chunk below demonstrates how to create this visualization.\n\nlocalMI.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)\n\nVariable(s) \"Ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05.2.html#plotting-moran-scatterplot",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05.2.html#plotting-moran-scatterplot",
    "title": "Hands-on Exercise 5b: Local Measures of Spatial Autocorrelation",
    "section": "7.1 Plotting Moran scatterplot",
    "text": "7.1 Plotting Moran scatterplot\nThe Moran scatterplot illustrates the relationship between the values of a chosen attribute at each location and the average value of the same attribute at neighboring locations.\nThe code chunk below plots the Moran scatterplot for GDPPC 2012 using the moran.plot() function from the spdep package.\n\nnci &lt;- moran.plot(hunan$GDPPC, rswm_q,\n                  labels=as.character(hunan$County), \n                  xlab=\"GDPPC 2012\", \n                  ylab=\"Spatially Lag GDPPC 2012\")\n\n\n\n\n\n\n\n\n\nNotice that the plot is split into four quadrants. The top right quadrant represents areas with high GDPPC, surrounded by other areas with similarly high average GDPPC. These are referred to as the high-high locations, as shown in the lesson slide."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05.2.html#plotting-moran-scatterplot-with-standardised-variable",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05.2.html#plotting-moran-scatterplot-with-standardised-variable",
    "title": "Hands-on Exercise 5b: Local Measures of Spatial Autocorrelation",
    "section": "7.2 Plotting Moran scatterplot with standardised variable",
    "text": "7.2 Plotting Moran scatterplot with standardised variable\nFirst, we will use the scale() function to center and scale the variable. Centering is performed by subtracting the mean (ignoring NAs) from each value in the corresponding columns, while scaling is done by dividing the centered values by their standard deviations.\n\nhunan$Z.GDPPC &lt;- scale(hunan$GDPPC) %&gt;% \n  as.vector \n\n\nThe as.vector() function at the end ensures that the output is a vector, which integrates smoothly into our dataframe.\n\nNow, we are ready to plot the Moran scatterplot again using the code chunk below.\n\nnci2 &lt;- moran.plot(hunan$Z.GDPPC, rswm_q,\n                   labels=as.character(hunan$County),\n                   xlab=\"z-GDPPC 2012\", \n                   ylab=\"Spatially Lag z-GDPPC 2012\")"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05.2.html#preparing-lisa-map-classes",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05.2.html#preparing-lisa-map-classes",
    "title": "Hands-on Exercise 5b: Local Measures of Spatial Autocorrelation",
    "section": "7.3 Preparing LISA map classes",
    "text": "7.3 Preparing LISA map classes\nThe code chunks below demonstrate the steps required to prepare a LISA cluster map.\n\nquadrant &lt;- vector(mode=\"numeric\",length=nrow(localMI))\n\nNext, we derive the spatially lagged variable of interest (i.e., GDPPC) and center it around its mean.\n\nhunan$lag_GDPPC &lt;- lag.listw(rswm_q, hunan$GDPPC)\nDV &lt;- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \n\nThis is followed by centering the local Moran’s I values around their mean.\n\nLM_I &lt;- localMI[,1] - mean(localMI[,1])    \n\nNext, we will set a statistical significance level for the local Moran’s I.\n\nsignif &lt;- 0.05\n\nThese four command lines define the low-low (1), low-high (2), high-low (3), and high-high (4) spatial autocorrelation categories.\n\nquadrant[DV &lt;0 & LM_I&gt;0] &lt;- 1\nquadrant[DV &gt;0 & LM_I&lt;0] &lt;- 2\nquadrant[DV &lt;0 & LM_I&lt;0] &lt;- 3\nquadrant[DV &gt;0 & LM_I&gt;0] &lt;- 4\n\nLastly, non-significant Moran’s I values are placed in category 0.\n\nquadrant[localMI[,5]&gt;signif] &lt;- 0"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05.2.html#plotting-lisa-map",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05.2.html#plotting-lisa-map",
    "title": "Hands-on Exercise 5b: Local Measures of Spatial Autocorrelation",
    "section": "7.4 Plotting LISA map",
    "text": "7.4 Plotting LISA map\nNow, we can build the LISA map using the code chunks below.\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\n\n\n\n\n\n\n\nFor effective interpretation, it is helpful to plot both the local Moran’s I values map and the corresponding p-values map side by side.\nThe code chunk below demonstrates how to create this visualization.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\ntmap_arrange(gdppc, LISAmap, \n             asp=1, ncol=2)\n\n\n\n\n\n\n\n\nWe can also include the local Moran’s I map and the p-values map together, as shown below, to facilitate easy comparison.\n\ntmap_arrange(localMI.map, pvalue.map, \n             asp=1, ncol=2)\n\nVariable(s) \"Ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nLISA Cluster Map Observations:\n\nHigh-High Clusters (Red): Concentrated in the eastern part of the province, indicating areas of high GDPPC surrounded by similarly prosperous regions.\nLow-Low Clusters (Dark Blue): Found in the south-central areas, representing underdeveloped regions with low GDPPC.\nLow-High Areas (Light Blue): Highlight economic disparities, where low GDPPC regions are adjacent to high GDPPC regions.\nInsignificant Regions (White): These areas show no significant spatial autocorrelation.\n\nOverall, economic development is uneven, with clear clusters of both prosperity and underdevelopment."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05.2.html#getis-and-ords-g-statistics",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05.2.html#getis-and-ords-g-statistics",
    "title": "Hands-on Exercise 5b: Local Measures of Spatial Autocorrelation",
    "section": "8.1 Getis and Ord’s G-Statistics",
    "text": "8.1 Getis and Ord’s G-Statistics\nAn alternative spatial statistics method for detecting spatial anomalies is the Getis and Ord’s G-statistics (Getis and Ord, 1972; Ord and Getis, 1995). This method evaluates neighbors within a defined proximity to identify areas where high or low values cluster spatially. Statistically significant hot spots are recognized as areas with high values surrounded by neighborhoods with similarly high values.\nThe analysis involves three key steps:\n\nDeriving a spatial weight matrix.\nComputing Gi statistics.\nMapping Gi statistics."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05.2.html#deriving-distance-based-weight-matrix",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05.2.html#deriving-distance-based-weight-matrix",
    "title": "Hands-on Exercise 5b: Local Measures of Spatial Autocorrelation",
    "section": "8.2 Deriving distance-based weight matrix",
    "text": "8.2 Deriving distance-based weight matrix\nFirst, we need to define a new set of neighbors. While spatial autocorrelation considers units that share borders, the Getis-Ord G-statistics method defines neighbors based on distance.\nThere are two types of distance-based proximity matrices:\n\nFixed distance weight matrix\nAdaptive distance weight matrix\n\n\n8.2.1 Deriving the centroid\nWe need to associate points with each polygon before creating our connectivity graph. This involves more than just running st_centroid() on the sf object us.bound. The centroid coordinates must be stored in a separate dataframe. To achieve this, we use a mapping function, which applies a function to each element of a vector and returns a vector of the same length.\nIn this case, our input vector is the geometry column of us.bound, and our function is st_centroid(). We will use map_dbl() from the purrr package to extract the centroid coordinates. For documentation, refer to the map documentation.\nTo get the longitude values, we map the st_centroid() function over the geometry column and use double bracket notation [[ ]] and 1 to access the first value (longitude) in each centroid.\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nWe apply the same process for latitude, with one key difference: we access the second value of each centroid using [[2]].\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have both latitude and longitude, we use cbind() to combine them into a single object.\n\ncoords &lt;- cbind(longitude, latitude)\n\n\n\n8.2.2 Determine the cut-off distance\nFirstly, we need to determine the upper limit for distance band by using the steps below:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\n\nThe summary report indicates that the largest first nearest neighbor distance is 61.79 km. Using this as the upper threshold ensures that every unit will have at least one neighbor.\n\n\n\n8.2.3 Computing fixed distance weight matrix\nNow, we will compute the distance weight matrix by using dnearneigh() as shown in the code chunk below.\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nNext, nb2listw() is used to convert the nb object into spatial weights object.\n\nwm62_lw &lt;- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440\n\n\n\nThe output spatial weights object is called wm62_lw.\n\n\n\n8.2.4 Computing adaptive distance weight matrix\nOne characteristic of a fixed distance weight matrix is that densely settled areas (typically urban areas) tend to have more neighbors, while less densely settled areas (typically rural counties) have fewer neighbors. Having many neighbors smoothes the spatial relationships across a broader range of neighbors.\nIt is also possible to directly control the number of neighbors using k-nearest neighbors, either accepting asymmetric neighbors or enforcing symmetry, as demonstrated in the code chunk below.\n\nknn &lt;- knn2nb(knearneigh(coords, k=8))\nknn\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\nNext, nb2listw() is used to convert the nb object into spatial weights object.\n\nknn_lw &lt;- nb2listw(knn, style = 'B')\nsummary(knn_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05.2.html#gi-statistics-using-fixed-distance",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05.2.html#gi-statistics-using-fixed-distance",
    "title": "Hands-on Exercise 5b: Local Measures of Spatial Autocorrelation",
    "section": "9.1 Gi statistics using fixed distance",
    "text": "9.1 Gi statistics using fixed distance\n\nfips &lt;- order(hunan$County)\ngi.fixed &lt;- localG(hunan$GDPPC, wm62_lw)\ngi.fixed\n\n [1]  0.436075843 -0.265505650 -0.073033665  0.413017033  0.273070579\n [6] -0.377510776  2.863898821  2.794350420  5.216125401  0.228236603\n[11]  0.951035346 -0.536334231  0.176761556  1.195564020 -0.033020610\n[16]  1.378081093 -0.585756761 -0.419680565  0.258805141  0.012056111\n[21] -0.145716531 -0.027158687 -0.318615290 -0.748946051 -0.961700582\n[26] -0.796851342 -1.033949773 -0.460979158 -0.885240161 -0.266671512\n[31] -0.886168613 -0.855476971 -0.922143185 -1.162328599  0.735582222\n[36] -0.003358489 -0.967459309 -1.259299080 -1.452256513 -1.540671121\n[41] -1.395011407 -1.681505286 -1.314110709 -0.767944457 -0.192889342\n[46]  2.720804542  1.809191360 -1.218469473 -0.511984469 -0.834546363\n[51] -0.908179070 -1.541081516 -1.192199867 -1.075080164 -1.631075961\n[56] -0.743472246  0.418842387  0.832943753 -0.710289083 -0.449718820\n[61] -0.493238743 -1.083386776  0.042979051  0.008596093  0.136337469\n[66]  2.203411744  2.690329952  4.453703219 -0.340842743 -0.129318589\n[71]  0.737806634 -1.246912658  0.666667559  1.088613505 -0.985792573\n[76]  1.233609606 -0.487196415  1.626174042 -1.060416797  0.425361422\n[81] -0.837897118 -0.314565243  0.371456331  4.424392623 -0.109566928\n[86]  1.364597995 -1.029658605 -0.718000620\nattr(,\"internals\")\n               Gi      E(Gi)        V(Gi)        Z(Gi) Pr(z != E(Gi))\n [1,] 0.064192949 0.05747126 2.375922e-04  0.436075843   6.627817e-01\n [2,] 0.042300020 0.04597701 1.917951e-04 -0.265505650   7.906200e-01\n [3,] 0.044961480 0.04597701 1.933486e-04 -0.073033665   9.417793e-01\n [4,] 0.039475779 0.03448276 1.461473e-04  0.413017033   6.795941e-01\n [5,] 0.049767939 0.04597701 1.927263e-04  0.273070579   7.847990e-01\n [6,] 0.008825335 0.01149425 4.998177e-05 -0.377510776   7.057941e-01\n [7,] 0.050807266 0.02298851 9.435398e-05  2.863898821   4.184617e-03\n [8,] 0.083966739 0.04597701 1.848292e-04  2.794350420   5.200409e-03\n [9,] 0.115751554 0.04597701 1.789361e-04  5.216125401   1.827045e-07\n[10,] 0.049115587 0.04597701 1.891013e-04  0.228236603   8.194623e-01\n[11,] 0.045819180 0.03448276 1.420884e-04  0.951035346   3.415864e-01\n[12,] 0.049183846 0.05747126 2.387633e-04 -0.536334231   5.917276e-01\n[13,] 0.048429181 0.04597701 1.924532e-04  0.176761556   8.596957e-01\n[14,] 0.034733752 0.02298851 9.651140e-05  1.195564020   2.318667e-01\n[15,] 0.011262043 0.01149425 4.945294e-05 -0.033020610   9.736582e-01\n[16,] 0.065131196 0.04597701 1.931870e-04  1.378081093   1.681783e-01\n[17,] 0.027587075 0.03448276 1.385862e-04 -0.585756761   5.580390e-01\n[18,] 0.029409313 0.03448276 1.461397e-04 -0.419680565   6.747188e-01\n[19,] 0.061466754 0.05747126 2.383385e-04  0.258805141   7.957856e-01\n[20,] 0.057656917 0.05747126 2.371303e-04  0.012056111   9.903808e-01\n[21,] 0.066518379 0.06896552 2.820326e-04 -0.145716531   8.841452e-01\n[22,] 0.045599896 0.04597701 1.928108e-04 -0.027158687   9.783332e-01\n[23,] 0.030646753 0.03448276 1.449523e-04 -0.318615290   7.500183e-01\n[24,] 0.035635552 0.04597701 1.906613e-04 -0.748946051   4.538897e-01\n[25,] 0.032606647 0.04597701 1.932888e-04 -0.961700582   3.362000e-01\n[26,] 0.035001352 0.04597701 1.897172e-04 -0.796851342   4.255374e-01\n[27,] 0.012746354 0.02298851 9.812587e-05 -1.033949773   3.011596e-01\n[28,] 0.061287917 0.06896552 2.773884e-04 -0.460979158   6.448136e-01\n[29,] 0.014277403 0.02298851 9.683314e-05 -0.885240161   3.760271e-01\n[30,] 0.009622875 0.01149425 4.924586e-05 -0.266671512   7.897221e-01\n[31,] 0.014258398 0.02298851 9.705244e-05 -0.886168613   3.755267e-01\n[32,] 0.005453443 0.01149425 4.986245e-05 -0.855476971   3.922871e-01\n[33,] 0.043283712 0.05747126 2.367109e-04 -0.922143185   3.564539e-01\n[34,] 0.020763514 0.03448276 1.393165e-04 -1.162328599   2.451020e-01\n[35,] 0.081261843 0.06896552 2.794398e-04  0.735582222   4.619850e-01\n[36,] 0.057419907 0.05747126 2.338437e-04 -0.003358489   9.973203e-01\n[37,] 0.013497133 0.02298851 9.624821e-05 -0.967459309   3.333145e-01\n[38,] 0.019289310 0.03448276 1.455643e-04 -1.259299080   2.079223e-01\n[39,] 0.025996272 0.04597701 1.892938e-04 -1.452256513   1.464303e-01\n[40,] 0.016092694 0.03448276 1.424776e-04 -1.540671121   1.233968e-01\n[41,] 0.035952614 0.05747126 2.379439e-04 -1.395011407   1.630124e-01\n[42,] 0.031690963 0.05747126 2.350604e-04 -1.681505286   9.266481e-02\n[43,] 0.018750079 0.03448276 1.433314e-04 -1.314110709   1.888090e-01\n[44,] 0.015449080 0.02298851 9.638666e-05 -0.767944457   4.425202e-01\n[45,] 0.065760689 0.06896552 2.760533e-04 -0.192889342   8.470456e-01\n[46,] 0.098966900 0.05747126 2.326002e-04  2.720804542   6.512325e-03\n[47,] 0.085415780 0.05747126 2.385746e-04  1.809191360   7.042128e-02\n[48,] 0.038816536 0.05747126 2.343951e-04 -1.218469473   2.230456e-01\n[49,] 0.038931873 0.04597701 1.893501e-04 -0.511984469   6.086619e-01\n[50,] 0.055098610 0.06896552 2.760948e-04 -0.834546363   4.039732e-01\n[51,] 0.033405005 0.04597701 1.916312e-04 -0.908179070   3.637836e-01\n[52,] 0.043040784 0.06896552 2.829941e-04 -1.541081516   1.232969e-01\n[53,] 0.011297699 0.02298851 9.615920e-05 -1.192199867   2.331829e-01\n[54,] 0.040968457 0.05747126 2.356318e-04 -1.075080164   2.823388e-01\n[55,] 0.023629663 0.04597701 1.877170e-04 -1.631075961   1.028743e-01\n[56,] 0.006281129 0.01149425 4.916619e-05 -0.743472246   4.571958e-01\n[57,] 0.063918654 0.05747126 2.369553e-04  0.418842387   6.753313e-01\n[58,] 0.070325003 0.05747126 2.381374e-04  0.832943753   4.048765e-01\n[59,] 0.025947288 0.03448276 1.444058e-04 -0.710289083   4.775249e-01\n[60,] 0.039752578 0.04597701 1.915656e-04 -0.449718820   6.529132e-01\n[61,] 0.049934283 0.05747126 2.334965e-04 -0.493238743   6.218439e-01\n[62,] 0.030964195 0.04597701 1.920248e-04 -1.083386776   2.786368e-01\n[63,] 0.058129184 0.05747126 2.343319e-04  0.042979051   9.657182e-01\n[64,] 0.046096514 0.04597701 1.932637e-04  0.008596093   9.931414e-01\n[65,] 0.012459080 0.01149425 5.008051e-05  0.136337469   8.915545e-01\n[66,] 0.091447733 0.05747126 2.377744e-04  2.203411744   2.756574e-02\n[67,] 0.049575872 0.02298851 9.766513e-05  2.690329952   7.138140e-03\n[68,] 0.107907212 0.04597701 1.933581e-04  4.453703219   8.440175e-06\n[69,] 0.019616151 0.02298851 9.789454e-05 -0.340842743   7.332220e-01\n[70,] 0.032923393 0.03448276 1.454032e-04 -0.129318589   8.971056e-01\n[71,] 0.030317663 0.02298851 9.867859e-05  0.737806634   4.606320e-01\n[72,] 0.019437582 0.03448276 1.455870e-04 -1.246912658   2.124295e-01\n[73,] 0.055245460 0.04597701 1.932838e-04  0.666667559   5.049845e-01\n[74,] 0.074278054 0.05747126 2.383538e-04  1.088613505   2.763244e-01\n[75,] 0.013269580 0.02298851 9.719982e-05 -0.985792573   3.242349e-01\n[76,] 0.049407829 0.03448276 1.463785e-04  1.233609606   2.173484e-01\n[77,] 0.028605749 0.03448276 1.455139e-04 -0.487196415   6.261191e-01\n[78,] 0.039087662 0.02298851 9.801040e-05  1.626174042   1.039126e-01\n[79,] 0.031447120 0.04597701 1.877464e-04 -1.060416797   2.889550e-01\n[80,] 0.064005294 0.05747126 2.359641e-04  0.425361422   6.705732e-01\n[81,] 0.044606529 0.05747126 2.357330e-04 -0.837897118   4.020885e-01\n[82,] 0.063700493 0.06896552 2.801427e-04 -0.314565243   7.530918e-01\n[83,] 0.051142205 0.04597701 1.933560e-04  0.371456331   7.102977e-01\n[84,] 0.102121112 0.04597701 1.610278e-04  4.424392623   9.671399e-06\n[85,] 0.021901462 0.02298851 9.843172e-05 -0.109566928   9.127528e-01\n[86,] 0.064931813 0.04597701 1.929430e-04  1.364597995   1.723794e-01\n[87,] 0.031747344 0.04597701 1.909867e-04 -1.029658605   3.031703e-01\n[88,] 0.015893319 0.02298851 9.765131e-05 -0.718000620   4.727569e-01\nattr(,\"cluster\")\n [1] Low  Low  High High High High High High High Low  Low  High Low  Low  Low \n[16] High High High High Low  High High Low  Low  High Low  Low  Low  Low  Low \n[31] Low  Low  Low  High Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  High Low  Low  Low  Low  Low  High Low  Low \n[61] Low  Low  Low  High High High Low  High Low  Low  High Low  High High Low \n[76] High Low  Low  Low  Low  Low  Low  High High Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = hunan$GDPPC, listw = wm62_lw)\nattr(,\"class\")\n[1] \"localG\"\n\n\nThe output of localG() is a vector of G or Gstar values, with attributes \"gstari\" set to TRUE or FALSE, \"call\" representing the function call, and class \"localG\".\nThe Gi statistic is represented as a Z-score, where higher values indicate greater clustering intensity. The direction (positive or negative) reveals whether the cluster is high or low.\nNext, we will join the Gi values to their corresponding hunan sf data frame using the code chunk below.\n\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.fixed)) %&gt;%\n  rename(gstat_fixed = as.matrix.gi.fixed.)\n\nIn fact, the code chunk above performs three tasks:\n\nFirst, it converts the output vector (gi.fixed) into an R matrix using as.matrix().\nNext, cbind() is used to join hunan@data with the gi.fixed matrix, creating a new SpatialPolygonDataFrame called hunan.gi.\nFinally, the field name for the Gi values is renamed to gstat_fixed using rename()."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05.2.html#mapping-gi-values-with-fixed-distance-weights",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05.2.html#mapping-gi-values-with-fixed-distance-weights",
    "title": "Hands-on Exercise 5b: Local Measures of Spatial Autocorrelation",
    "section": "9.2 Mapping Gi values with fixed distance weights",
    "text": "9.2 Mapping Gi values with fixed distance weights\nThe code chunk below demonstrates the functions used to map the Gi values derived from the fixed distance weight matrix.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nGimap &lt;-tm_shape(hunan.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap, asp=1, ncol=2)\n\nVariable(s) \"gstat_fixed\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nGi Map Observations:\n\nHot Spots (Red): Significant high GDPPC clusters in the central and northeastern regions.\nCold Spots (Blue): Significant low GDPPC clusters in the southern and southwestern regions.\nNeutral Areas (White/Grey): No significant clustering of high or low GDPPC.\n\nThese clusters indicate economic disparities, with stronger economies in the hot spot areas and weaker ones in the cold spots."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05.2.html#gi-statistics-using-adaptive-distance",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05.2.html#gi-statistics-using-adaptive-distance",
    "title": "Hands-on Exercise 5b: Local Measures of Spatial Autocorrelation",
    "section": "9.3 Gi statistics using adaptive distance",
    "text": "9.3 Gi statistics using adaptive distance\nThe code chunk below are used to compute the Gi values for GDPPC2012 by using an adaptive distance weight matrix (i.e knb_lw).\n\nfips &lt;- order(hunan$County)\ngi.adaptive &lt;- localG(hunan$GDPPC, knn_lw)\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.adaptive)) %&gt;%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05.2.html#mapping-gi-values-with-adaptive-distance-weights",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05.2.html#mapping-gi-values-with-adaptive-distance-weights",
    "title": "Hands-on Exercise 5b: Local Measures of Spatial Autocorrelation",
    "section": "9.4 Mapping Gi values with adaptive distance weights",
    "text": "9.4 Mapping Gi values with adaptive distance weights\nIt’s time to visualize the locations of hot spots and cold spots. We will use the choropleth mapping functions from the tmap package to map the Gi values.\nThe code chunk below demonstrates the functions used to map the Gi values derived from the fixed distance weight matrix.\n\ngdppc&lt;- qtm(hunan, \"GDPPC\")\n\nGimap &lt;- tm_shape(hunan.gi) + \n  tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\", \n          palette=\"-RdBu\", \n          title = \"local Gi\") + \n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, \n             Gimap, \n             asp=1, \n             ncol=2)\n\nVariable(s) \"gstat_adaptive\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nGi Map Observations:\n\nHot Spots (Red): Significant high GDPPC clusters in the northeastern region, indicating strong economic performance.\nCold Spots (Blue): Significant low GDPPC clusters in the southern region, reflecting weaker economic performance.\nThe map highlights distinct areas of economic prosperity and underperformance, with clear clustering of GDPPC values."
  },
  {
    "objectID": "index.html#hands-on-exercise",
    "href": "index.html#hands-on-exercise",
    "title": "Welcome to ISSS626 Geospatial Analytics and Applications",
    "section": "Hands-on Exercise",
    "text": "Hands-on Exercise\n\n\n\n\n\n\n\n\nHands-on Exercise 9: Modelling Geographical Accessibility\n\n\n19 min\n\n\n\nOct 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 8: Geographically Weighted Predictive Models\n\n\n70 min\n\n\n\nOct 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method\n\n\n32 min\n\n\n\nSep 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques\n\n\n49 min\n\n\n\nSep 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 5b: Local Measures of Spatial Autocorrelation\n\n\n23 min\n\n\n\nSep 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 5a: Global Measures of Spatial Autocorrelation\n\n\n17 min\n\n\n\nSep 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 9b: Calibrating Spatial Interaction Models with R\n\n\n1 min\n\n\n\nSep 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 9a: Processing and Visualising Flow Data\n\n\n1 min\n\n\n\nSep 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 4: Spatial Weights and Applications\n\n\n20 min\n\n\n\nSep 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 3: Network Constrained Spatial Point Patterns Analysis\n\n\n22 min\n\n\n\nSep 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 2b: 2nd Order Spatial Point Patterns Analysis Methods\n\n\n16 min\n\n\n\nAug 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods\n\n\n19 min\n\n\n\nAug 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 1b: Choropleth Mapping\n\n\n14 min\n\n\n\nAug 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 1a: Geospatial Data Wrangling\n\n\n7 min\n\n\n\nAug 24, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#in-class-exercise",
    "href": "index.html#in-class-exercise",
    "title": "Welcome to ISSS626 Geospatial Analytics and Applications",
    "section": "In-class Exercise",
    "text": "In-class Exercise\n\n\n\n\n\n\n\n\nIn-class Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method\n\n\n17 min\n\n\n\nOct 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-class Exercise 6: Emerging Hot Spot Analysis\n\n\n10 min\n\n\n\nSep 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-class Exercise 5: Global and Local Measures of Spatial Association: sfdep methods\n\n\n14 min\n\n\n\nSep 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-class Exercise 4: Geographically Weighted Summary Statistics - GWmodel methods\n\n\n11 min\n\n\n\nSep 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-class Exercise 3: Advanced Spatial Point Patterns Analysis\n\n\n22 min\n\n\n\nSep 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-class Exercise 2: Spatial Point Patterns Analysis\n\n\n5 min\n\n\n\nSep 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-class Exercise 1: Geospatial Analytics\n\n\n11 min\n\n\n\nAug 26, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex06/hands_on_ex06.html",
    "href": "hands_on_ex/hands_on_ex06/hands_on_ex06.html",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to delineate homogeneous regions using geographically referenced multivariate data. The exercise involves two major analyses:\n\nHierarchical cluster analysis, and\nSpatially constrained cluster analysis.\n\n\n\nBy the end of this hands-on exercise, we’d like to be able to:\n\nConvert GIS polygon data into an R simple feature data frame using the appropriate functions from the sf package;\nConvert a simple feature data frame into an R SpatialPolygonDataFrame object using the sf package;\nPerform cluster analysis using hclust() from Base R;\nPerform spatially constrained cluster analysis using skater() from Base R;\nVisualize the analysis output using the ggplot2 and tmap packages."
  },
  {
    "objectID": "hands_on_ex/index.html",
    "href": "hands_on_ex/index.html",
    "title": "Hands-on Exercise",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\nHands-on Exercise 9: Modelling Geographical Accessibility\n\n\n\nOct 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 8: Geographically Weighted Predictive Models\n\n\n\nOct 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method\n\n\n\nSep 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques\n\n\nIn this exercise, we will learn to delineate homogeneous regions using hierarchical and spatially constrained clustering techniques on geographically referenced multivariate data.\n\n\n\nSep 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 5b: Local Measures of Spatial Autocorrelation\n\n\nIn this exercise, we will learn to compute Local Measures of Spatial Autocorrelation (LMSA) using the spdep package, including Local Moran’s I, Getis-Ord’s Gi-statistics, and their visualizations.\n\n\n\nSep 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 5a: Global Measures of Spatial Autocorrelation\n\n\nIn this exercise, we will learn to compute Global Measures of Spatial Autocorrelation using the spdep package, including Moran’s I and Geary’s C tests, spatial correlograms, and their statistical interpretation.\n\n\n\nSep 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 9b: Calibrating Spatial Interaction Models with R\n\n\n\nSep 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 9a: Processing and Visualising Flow Data\n\n\n\nSep 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 4: Spatial Weights and Applications\n\n\nIn this exercise, we will learn to compute spatial weights, visualize spatial distributions, and create spatially lagged variables using various functions from R packages such as sf,spdep, and tmap.\n\n\n\nSep 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 3: Network Constrained Spatial Point Patterns Analysis\n\n\nIn this exercise, we will learn to use R and the spNetwork package for analyzing network-constrained spatial point patterns, focusing on kernel density estimation and G- and K-function analysis.\n\n\n\nSep 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 2b: 2nd Order Spatial Point Patterns Analysis Methods\n\n\nIn this exercise, we will learn to apply 2nd-order spatial point pattern analysis methods in R, including G, F, K, and L functions, to evaluate spatial point distributions and perform hypothesis testing using the spatstat package.\n\n\n\nAug 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods\n\n\nIn this exercise, we will learn to analyze spatial point patterns in R, including importing geospatial data, performing kernel density estimation and nearest neighbor analysis, and visualizing results using spatstat, sf, and tmap packages.\n\n\n\nAug 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 1b: Choropleth Mapping\n\n\nIn this exercise, we will learn to create thematic maps and perform geovisualization in R using the tmap package, including data preparation, classification, color schemes, and advanced mapping techniques.\n\n\n\nAug 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 1a: Geospatial Data Wrangling\n\n\nIn this exercise, we will learn to use R for geospatial data handling, including importing, transforming, wrangling, and visualizing data with sf, tidyverse, and ggplot2.\n\n\n\nAug 24, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "in_class_ex/in_class_ex05/in_class_ex05.html",
    "href": "in_class_ex/in_class_ex05/in_class_ex05.html",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Association: sfdep methods",
    "section": "",
    "text": "In this in-class exercise, we will learn how to compute Global Measures of Spatial Autocorrelation (GMSA) by using sfdep package.\n\nsfdep creates an sf and tidyverse friendly interface to the package as well as introduces new functionality that is not present in spdep.\nsfdep utilizes list columns extensively to make this interface possible."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#learning-outcome",
    "href": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#learning-outcome",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "",
    "text": "By the end of this hands-on exercise, we’d like to be able to:\n\nConvert GIS polygon data into an R simple feature data frame using the appropriate functions from the sf package;\nConvert a simple feature data frame into an R SpatialPolygonDataFrame object using the sf package;\nPerform cluster analysis using hclust() from Base R;\nPerform spatially constrained cluster analysis using skater() from Base R;\nVisualize the analysis output using the ggplot2 and tmap packages."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#the-analytical-question",
    "href": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#the-analytical-question",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "2.1 The analytical question",
    "text": "2.1 The analytical question\nIn geobusiness and spatial policy, it is common practice to delineate market or planning areas into homogeneous regions using multivariate data. In this hands-on exercise, we aim to delineate Shan State, Myanmar, into homogeneous regions based on multiple Information and Communication Technology (ICT) measures, including: radio, television, landline phone, mobile phone, computer, and internet access at home."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#the-data",
    "href": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#the-data",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "2.2 The data",
    "text": "2.2 The data\n\n\n\n\n\n\n\n\nDataset Name\nDescription\nFormat\n\n\n\n\nMyanmar Township Boundary Data (myanmar_township_boundaries)\nGIS data that contain township boundary information of Myanmar with spatial polygon features.\nESRI Shapefile\nSource: Myanmar Information Management Unit (MIMU)\n\n\nShan-ICT\nExtract from The 2014 Myanmar Population and Housing Census Myanmar, providing ICT data at the township level.\nCSV\nSource: Myanmar Information Management Unit (MIMU)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#installing-and-loading-r-packages",
    "href": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#installing-and-loading-r-packages",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "2.3 Installing and loading R packages",
    "text": "2.3 Installing and loading R packages\n\nPackagesCode\n\n\nWe will use following packages in this exercise:\n\n\n\n\n\n\n\nPackage\nDescription\n\n\n\n\nsf\nProvides functions to manage, process, and manipulate Simple Features, a formal geospatial data standard that specifies a storage and access model of spatial geometries such as points, lines, and polygons.\n\n\nspdep\nProvides a collection of functions to create spatial weights matrix objects from polygon ‘contiguities’, point patterns by distance, and tessellations.\n\n\ntidyverse\nA collection of R packages for data science tasks such as importing, tidying, wrangling, and visualizing data.\n\n\ntmap\nProvides functions for creating cartographic-quality static maps or interactive maps using the leaflet API.\n\n\nClustGeo\nProvides hierarchical clustering with spatial/geographical constraints, useful for regionalization.\n\n\nggpubr\nA collection of ‘ggplot2’-based functions to easily create and customize publication-ready plots.\n\n\ncluster\nProvides functions for cluster analysis, including hierarchical, k-means, and partitioning clustering.\n\n\nfactoextra\nProvides functions to extract and visualize the output of multivariate data analysis, such as PCA and clustering.\n\n\nNbClust\nProvides 30 indices for determining the optimal number of clusters in a dataset.\n\n\nheatmaply\nProvides an easy-to-use interface for creating interactive heatmaps.\n\n\ncorrplot\nProvides functions for visualizing correlation matrices.\n\n\npsych\nProvides functions for multivariate analysis, including factor analysis and principal component analysis.\n\n\nGGally\nExtends ‘ggplot2’ by adding support for additional plot types, especially helpful for visualizing pairwise relationships.\n\n\n\n\n\nTo install and launch the four R packages.\n\npacman::p_load(spdep, tmap, sf, ClustGeo, \n               ggpubr, cluster, factoextra, NbClust,\n               heatmaply, corrplot, psych, tidyverse, GGally)"
  },
  {
    "objectID": "in_class_ex/index.html",
    "href": "in_class_ex/index.html",
    "title": "In-class Exercise",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\nIn-class Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method\n\n\n\nOct 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-class Exercise 6: Emerging Hot Spot Analysis\n\n\n\nSep 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-class Exercise 5: Global and Local Measures of Spatial Association: sfdep methods\n\n\n\nSep 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-class Exercise 4: Geographically Weighted Summary Statistics - GWmodel methods\n\n\n\nSep 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-class Exercise 3: Advanced Spatial Point Patterns Analysis\n\n\n\nSep 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-class Exercise 2: Spatial Point Patterns Analysis\n\n\n\nSep 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-class Exercise 1: Geospatial Analytics\n\n\n\nAug 26, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#derive-new-variables-using-dplyr-package",
    "href": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#derive-new-variables-using-dplyr-package",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "3.1 Derive new variables using dplyr package",
    "text": "3.1 Derive new variables using dplyr package\nThe unit of measurement for the values is the number of households. Using these values directly can introduce bias due to variations in the total number of households across townships. Typically, townships with a higher total number of households will also show higher counts of households owning radios, TVs, etc.\nTo address this issue, we will calculate the penetration rate for each ICT variable using the code chunk below.\n\nict_derived &lt;- ict %&gt;%\n  mutate(`RADIO_PR` = `Radio`/`Total households`*1000) %&gt;%\n  mutate(`TV_PR` = `Television`/`Total households`*1000) %&gt;%\n  mutate(`LLPHONE_PR` = `Land line phone`/`Total households`*1000) %&gt;%\n  mutate(`MPHONE_PR` = `Mobile phone`/`Total households`*1000) %&gt;%\n  mutate(`COMPUTER_PR` = `Computer`/`Total households`*1000) %&gt;%\n  mutate(`INTERNET_PR` = `Internet at home`/`Total households`*1000) %&gt;%\n  rename(`DT_PCODE` =`District Pcode`,`DT`=`District Name`,\n         `TS_PCODE`=`Township Pcode`, `TS`=`Township Name`,\n         `TT_HOUSEHOLDS`=`Total households`,\n         `RADIO`=`Radio`, `TV`=`Television`, \n         `LLPHONE`=`Land line phone`, `MPHONE`=`Mobile phone`,\n         `COMPUTER`=`Computer`, `INTERNET`=`Internet at home`)\n\nLet’s review the summary statistics of the newly derived penetration rates using the code chunk below.\n\nsummary(ict_derived)\n\n   DT_PCODE              DT              TS_PCODE              TS           \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n TT_HOUSEHOLDS       RADIO             TV           LLPHONE      \n Min.   : 3318   Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711   1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685   Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369   Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471   3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604   Max.   :30176   Max.   :62388   Max.   :6736.0  \n     MPHONE         COMPUTER         INTERNET         RADIO_PR     \n Min.   :  150   Min.   :  20.0   Min.   :   8.0   Min.   : 21.05  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0   1st Qu.:138.95  \n Median : 3559   Median : 244.0   Median : 316.0   Median :210.95  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2   Mean   :215.68  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5   3rd Qu.:268.07  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0   Max.   :484.52  \n     TV_PR         LLPHONE_PR       MPHONE_PR       COMPUTER_PR    \n Min.   :116.0   Min.   :  2.78   Min.   : 36.42   Min.   : 3.278  \n 1st Qu.:450.2   1st Qu.: 22.84   1st Qu.:190.14   1st Qu.:11.832  \n Median :517.2   Median : 37.59   Median :305.27   Median :18.970  \n Mean   :509.5   Mean   : 51.09   Mean   :314.05   Mean   :24.393  \n 3rd Qu.:606.4   3rd Qu.: 69.72   3rd Qu.:428.43   3rd Qu.:29.897  \n Max.   :842.5   Max.   :181.49   Max.   :735.43   Max.   :92.402  \n  INTERNET_PR     \n Min.   :  1.041  \n 1st Qu.:  8.617  \n Median : 22.829  \n Mean   : 30.644  \n 3rd Qu.: 41.281  \n Max.   :117.985  \n\n\n\nNotice that six new fields have been added to the data frame: RADIO_PR, TV_PR, LLPHONE_PR, MPHONE_PR, COMPUTER_PR, and INTERNET_PR."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#eda-using-statistical-graphics",
    "href": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#eda-using-statistical-graphics",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "4.1 EDA using statistical graphics",
    "text": "4.1 EDA using statistical graphics\nWe can plot the distribution of the variables (e.g., the number of households with a radio) by using appropriate Exploratory Data Analysis (EDA) techniques, as shown in the code chunk below.\nHistograms are useful for identifying the overall distribution of data values, such as left skew, right skew, or normal distribution.\n\nggplot(data=ict_derived, \n       aes(x=`RADIO`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\n\n\n\n\n\n\n\nBoxplots are useful for detecting the presence of outliers in the data.\n\nggplot(data=ict_derived, \n       aes(x=`RADIO`)) +\n  geom_boxplot(color=\"black\", \n               fill=\"light blue\")\n\n\n\n\n\n\n\n\nNext, we will plot the distribution of the newly derived variables (e.g., radio penetration rate) using the code chunk below.\n\nggplot(data=ict_derived, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\n\n\n\n\n\n\n\n\nggplot(data=ict_derived, \n       aes(x=`RADIO_PR`)) +\n  geom_boxplot(color=\"black\", \n               fill=\"light blue\")\n\n\n\n\n\n\n\n\nThe code chunks below are used to create the data visualizations. They consist of two main parts. First, we will create individual histograms using the code chunk below.\n\nradio &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ntv &lt;- ggplot(data=ict_derived, \n             aes(x= `TV_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nllphone &lt;- ggplot(data=ict_derived, \n             aes(x= `LLPHONE_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nmphone &lt;- ggplot(data=ict_derived, \n             aes(x= `MPHONE_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ncomputer &lt;- ggplot(data=ict_derived, \n             aes(x= `COMPUTER_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ninternet &lt;- ggplot(data=ict_derived, \n             aes(x= `INTERNET_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nNext, the ggarrange() function from the ggpubr package will be used to group these histograms together.\n\nggarrange(radio, tv, llphone, mphone, computer, internet, \n          ncol = 3, \n          nrow = 2)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#eda-using-choropleth-map",
    "href": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#eda-using-choropleth-map",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "4.2 EDA using choropleth map",
    "text": "4.2 EDA using choropleth map\n\n4.2.1 Joining geospatial data with aspatial data\nBefore preparing the choropleth map, we need to combine the geospatial data object (shan_sf) with the aspatial data frame (ict_derived). This will be done using the left_join function from the dplyr package.\nThe shan_sf simple feature data frame will serve as the base data object, and the ict_derived data frame will be the join table.\nThe unique identifier used to join both data objects is TS_PCODE.\n\nshan_sf &lt;- left_join(shan_sf, \n                     ict_derived, by=c(\"TS_PCODE\"=\"TS_PCODE\"))\n  \nwrite_rds(shan_sf, \"data/rds/shan_sf.rds\")\n\nIt is important to note that no new output data is created. Instead, the data fields from the ict_derived data frame are now incorporated into the data frame of shan_sf.\n\nshan_sf &lt;- read_rds(\"data/rds/shan_sf.rds\")\n\n\n\n4.2.2 Preparing a choropleth map\nTo quickly examine the distribution of the radio penetration rate in Shan State at the township level, a choropleth map will be prepared.\nThe code chunks below use the qtm() function from the tmap package to create the choropleth map.\n\nqtm(shan_sf, \"RADIO_PR\")\n\n\n\n\n\n\n\n\nTo reveal whether the distribution shown in the choropleth map above is biased by the underlying total number of households in each township, we will create two choropleth maps: one for the total number of households (TT_HOUSEHOLDS.map) and one for the total number of households with a radio (RADIO.map). The code chunk below will be used to generate these maps.\n\nTT_HOUSEHOLDS.map &lt;- tm_shape(shan_sf) + \n  tm_fill(col = \"TT_HOUSEHOLDS\",\n          n = 5,\n          style = \"jenks\", \n          title = \"Total households\") + \n  tm_borders(alpha = 0.5) \n\nRADIO.map &lt;- tm_shape(shan_sf) + \n  tm_fill(col = \"RADIO\",\n          n = 5,\n          style = \"jenks\",\n          title = \"Number Radio \") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(TT_HOUSEHOLDS.map, RADIO.map,\n             asp=NA, ncol=2)\n\n\n\n\n\n\n\n\nNotice that the choropleth maps above clearly demonstrate that townships with a relatively larger number of households also exhibit a relatively higher number of radio ownership.\nNow, let us plot the choropleth maps showing the distribution of the total number of households and the radio penetration rate using the code chunk below.\n\ntm_shape(shan_sf) +\n    tm_polygons(c(\"TT_HOUSEHOLDS\", \"RADIO_PR\"),\n                style=\"jenks\") +\n    tm_facets(sync = TRUE, ncol = 2) +\n  tm_legend(legend.position = c(\"right\", \"bottom\"))+\n  tm_layout(outer.margins=0, asp=0)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe two choropleth maps compare the total number of households and the radio penetration rate across townships in Shan State, Myanmar:\n\nTotal Households Map: Shows that areas with darker shades (mostly in the west and south) have more households, while lighter areas have fewer households.\nRadio Penetration Rate Map: Depicts higher radio penetration rates in some townships with fewer households, particularly in the north and southeast, highlighting that these areas have a higher percentage of households owning radios despite smaller populations.\n\nIn summary, while townships with more households tend to show higher radio ownership, the penetration rate map reveals that some smaller townships have a disproportionately higher percentage of radio ownership. This emphasizes the importance of using penetration rates to avoid bias from household size."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#prepare-variables",
    "href": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#prepare-variables",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6.1 Prepare variables",
    "text": "6.1 Prepare variables\n\n6.1.1 Extracting clustering variables\nThe code chunk below will be used to extract the clustering variables from the shan_sf simple feature object into a data frame.\n\ncluster_vars &lt;- shan_sf %&gt;%\n  st_set_geometry(NULL) %&gt;%\n  select(\"TS.x\", \"RADIO_PR\", \"TV_PR\", \"LLPHONE_PR\", \"MPHONE_PR\", \"COMPUTER_PR\")\nhead(cluster_vars,10)\n\n        TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\n1    Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\n2    Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\n3    Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\n4   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\n5     Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\n6      Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\n7      Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\n8   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\n9  Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\n10   Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\n\nNotice that the final list of clustering variables does not include the INTERNET_PR variable because it is highly correlated with COMPUTER_PR.\n\nNext, we will change the row identifiers to township names instead of row numbers using the code chunk below.\n\nrow.names(cluster_vars) &lt;- cluster_vars$\"TS.x\"\nhead(cluster_vars,10)\n\n               TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit     Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya     Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan     Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\nMabein       Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw         Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\nPekon         Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme     Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\n\nNotice that the row numbers have been replaced with township names.\n\nNext, we will delete the TS.x field using the code chunk below.\n\nshan_ict &lt;- select(cluster_vars, c(2:6))\nhead(shan_ict, 10)\n\n          RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit   286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya   417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan   484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung  231.6499 541.7189   28.54454  249.4903    13.76255\nMabein    449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw     280.7624 611.6204   42.06478  408.7951    29.63160\nPekon     318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk  387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme   210.9548 601.1773   39.58267  372.4930    30.94709"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#data-standardization",
    "href": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#data-standardization",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6.2 Data standardization",
    "text": "6.2 Data standardization\nIn general, multiple variables are used in cluster analysis, and it is not unusual for their value ranges to differ. To avoid bias in the cluster analysis results toward variables with larger values, it is essential to standardize the input variables before performing the analysis.\n\n6.2.1 Min-Max standardisation\nIn the code chunk below, the normalize() function from the heatmaply package is used to standardize the clustering variables using the Min-Max method. The summary() function is then used to display the summary statistics of the standardized clustering variables.\n\nshan_ict.std &lt;- normalize(shan_ict)\nsummary(shan_ict.std)\n\n    RADIO_PR          TV_PR          LLPHONE_PR       MPHONE_PR     \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.2544   1st Qu.:0.4600   1st Qu.:0.1123   1st Qu.:0.2199  \n Median :0.4097   Median :0.5523   Median :0.1948   Median :0.3846  \n Mean   :0.4199   Mean   :0.5416   Mean   :0.2703   Mean   :0.3972  \n 3rd Qu.:0.5330   3rd Qu.:0.6750   3rd Qu.:0.3746   3rd Qu.:0.5608  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n  COMPUTER_PR     \n Min.   :0.00000  \n 1st Qu.:0.09598  \n Median :0.17607  \n Mean   :0.23692  \n 3rd Qu.:0.29868  \n Max.   :1.00000  \n\n\n\nNotice that the values range of the Min-max standardised clustering variables are 0-1 now.\n\n\n\n6.2.2 Z-score standardisation\nZ-score standardization can be easily performed using the scale() function from Base R. The code chunk below will standardize the clustering variables using the Z-score method.\n\nshan_ict.z &lt;- scale(shan_ict)\ndescribe(shan_ict.z)\n\n            vars  n mean sd median trimmed  mad   min  max range  skew kurtosis\nRADIO_PR       1 55    0  1  -0.04   -0.06 0.94 -1.85 2.55  4.40  0.48    -0.27\nTV_PR          2 55    0  1   0.05    0.04 0.78 -2.47 2.09  4.56 -0.38    -0.23\nLLPHONE_PR     3 55    0  1  -0.33   -0.15 0.68 -1.19 3.20  4.39  1.37     1.49\nMPHONE_PR      4 55    0  1  -0.05   -0.06 1.01 -1.58 2.40  3.98  0.48    -0.34\nCOMPUTER_PR    5 55    0  1  -0.26   -0.18 0.64 -1.03 3.31  4.34  1.80     2.96\n              se\nRADIO_PR    0.13\nTV_PR       0.13\nLLPHONE_PR  0.13\nMPHONE_PR   0.13\nCOMPUTER_PR 0.13\n\n\n\nNotice that the mean and standard deviation of the Z-score standardized clustering variables are 0 and 1, respectively.\n\n\n\n\n\n\n\nWarning\n\n\n\nNote: describe() from the psych package is used here instead of summary() from Base R, as it provides the standard deviation.\nWarning: The Z-score standardization method should only be used if we assume that all variables come from a normal distribution.\n\n\n\n\n6.2.3 Visualising the standardised clustering variables\nBesides reviewing the summary statistics of the standardized clustering variables, it is also a good practice to visualize their distribution graphically.\nThe code chunk below plots the scaled Radio_PR field.\n\nr &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Raw values without standardisation\")\n\nshan_ict_s_df &lt;- as.data.frame(shan_ict.std)\ns &lt;- ggplot(data=shan_ict_s_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nshan_ict_z_df &lt;- as.data.frame(shan_ict.z)\nz &lt;- ggplot(data=shan_ict_z_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations:\n\n\n\n\nSkewness: All three histograms show a right-skewed distribution, indicating that most townships have a relatively moderate penetration rate, with a few townships having very high rates.\nImpact of Standardization: Both standardization methods (Min-Max and Z-score) preserve the shape of the distribution but adjust the scale. Min-Max brings values into a [0, 1] range, while Z-score centers the data and scales it based on the standard deviation.\n\n\n\n\nr &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Raw values without standardisation\")\n\nshan_ict_s_df &lt;- as.data.frame(shan_ict.std)\ns &lt;- ggplot(data=shan_ict_s_df, \n       aes(x=`RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nshan_ict_z_df &lt;- as.data.frame(shan_ict.z)\nz &lt;- ggplot(data=shan_ict_z_df, \n       aes(x=`RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#computing-the-proximity-matrix",
    "href": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#computing-the-proximity-matrix",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6.3 Computing the proximity matrix",
    "text": "6.3 Computing the proximity matrix\nIn R, many packages provide functions to calculate a distance matrix. We will compute the proximity matrix using the dist() function in Base R.\nThe dist() function supports six distance measures: Euclidean, Maximum, Manhattan, Canberra, Binary, and Minkowski. By default, the Euclidean distance is used to calculate the proximity matrix.\nThe code chunk below computes the proximity matrix using the Euclidean method.\n\nproxmat &lt;- dist(shan_ict, method = 'euclidean')\nproxmat\n\n             Mongmit   Pindaya   Ywangan  Pinlaung    Mabein     Kalaw\nPindaya    171.86828                                                  \nYwangan    381.88259 257.31610                                        \nPinlaung    57.46286 208.63519 400.05492                              \nMabein     263.37099 313.45776 529.14689 312.66966                    \nKalaw      160.05997 302.51785 499.53297 181.96406 198.14085          \nPekon       59.61977 117.91580 336.50410  94.61225 282.26877 211.91531\nLawksawk   140.11550 204.32952 432.16535 192.57320 130.36525 140.01101\nNawnghkio   89.07103 180.64047 377.87702 139.27495 204.63154 127.74787\nKyaukme    144.02475 311.01487 505.89191 139.67966 264.88283  79.42225\nMuse       563.01629 704.11252 899.44137 571.58335 453.27410 412.46033\nLaihka     141.87227 298.61288 491.83321 101.10150 345.00222 197.34633\nMongnai    115.86190 258.49346 422.71934  64.52387 358.86053 200.34668\nMawkmai    434.92968 437.99577 397.03752 398.11227 693.24602 562.59200\nKutkai      97.61092 212.81775 360.11861  78.07733 340.55064 204.93018\nMongton    192.67961 283.35574 361.23257 163.42143 425.16902 267.87522\nMongyai    256.72744 287.41816 333.12853 220.56339 516.40426 386.74701\nMongkaing  503.61965 481.71125 364.98429 476.29056 747.17454 625.24500\nLashio     251.29457 398.98167 602.17475 262.51735 231.28227 106.69059\nMongpan    193.32063 335.72896 483.68125 192.78316 301.52942 114.69105\nMatman     401.25041 354.39039 255.22031 382.40610 637.53975 537.63884\nTachileik  529.63213 635.51774 807.44220 555.01039 365.32538 373.64459\nNarphan    406.15714 474.50209 452.95769 371.26895 630.34312 463.53759\nMongkhet   349.45980 391.74783 408.97731 305.86058 610.30557 465.52013\nHsipaw     118.18050 245.98884 388.63147  76.55260 366.42787 212.36711\nMonghsat   214.20854 314.71506 432.98028 160.44703 470.48135 317.96188\nMongmao    242.54541 402.21719 542.85957 217.58854 384.91867 195.18913\nNansang    104.91839 275.44246 472.77637  85.49572 287.92364 124.30500\nLaukkaing  568.27732 726.85355 908.82520 563.81750 520.67373 427.77791\nPangsang   272.67383 428.24958 556.82263 244.47146 418.54016 224.03998\nNamtu      179.62251 225.40822 444.66868 170.04533 366.16094 307.27427\nMonghpyak  177.76325 221.30579 367.44835 222.20020 212.69450 167.08436\nKonkyan    403.39082 500.86933 528.12533 365.44693 613.51206 444.75859\nMongping   265.12574 310.64850 337.94020 229.75261 518.16310 375.64739\nHopong     136.93111 223.06050 352.85844  98.14855 398.00917 264.16294\nNyaungshwe  99.38590 216.52463 407.11649 138.12050 210.21337  95.66782\nHsihseng   131.49728 172.00796 342.91035 111.61846 381.20187 287.11074\nMongla     384.30076 549.42389 728.16301 372.59678 406.09124 260.26411\nHseni      189.37188 337.98982 534.44679 204.47572 213.61240  38.52842\nKunlong    224.12169 355.47066 531.63089 194.76257 396.61508 273.01375\nHopang     281.05362 443.26362 596.19312 265.96924 368.55167 185.14704\nNamhkan    386.02794 543.81859 714.43173 382.78835 379.56035 246.39577\nKengtung   246.45691 385.68322 573.23173 263.48638 219.47071  88.29335\nLangkho    164.26299 323.28133 507.78892 168.44228 253.84371  67.19580\nMonghsu    109.15790 198.35391 340.42789  80.86834 367.19820 237.34578\nTaunggyi   399.84278 503.75471 697.98323 429.54386 226.24011 252.26066\nPangwaun   381.51246 512.13162 580.13146 356.37963 523.44632 338.35194\nKyethi     202.92551 175.54012 287.29358 189.47065 442.07679 360.17247\nLoilen     145.48666 293.61143 469.51621  91.56527 375.06406 217.19877\nManton     430.64070 402.42888 306.16379 405.83081 674.01120 560.16577\nMongyang   309.51302 475.93982 630.71590 286.03834 411.88352 233.56349\nKunhing    173.50424 318.23811 449.67218 141.58836 375.82140 197.63683\nMongyawng  214.21738 332.92193 570.56521 235.55497 193.49994 173.43078\nTangyan    195.92520 208.43740 324.77002 169.50567 448.59948 348.06617\nNamhsan    237.78494 228.41073 286.16305 214.33352 488.33873 385.88676\n               Pekon  Lawksawk Nawnghkio   Kyaukme      Muse    Laihka\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk   157.51129                                                  \nNawnghkio  113.15370  90.82891                                        \nKyaukme    202.12206 186.29066 157.04230                              \nMuse       614.56144 510.13288 533.68806 434.75768                    \nLaihka     182.23667 246.74469 211.88187 128.24979 526.65211          \nMongnai    151.60031 241.71260 182.21245 142.45669 571.97975 100.53457\nMawkmai    416.00669 567.52693 495.15047 512.02846 926.93007 429.96554\nKutkai     114.98048 224.64646 147.44053 170.93318 592.90743 144.67198\nMongton    208.14888 311.07742 225.81118 229.28509 634.71074 212.07320\nMongyai    242.52301 391.26989 319.57938 339.27780 763.91399 264.13364\nMongkaing  480.23965 625.18712 546.69447 586.05094 995.66496 522.96309\nLashio     303.80011 220.75270 230.55346 129.95255 313.15288 238.64533\nMongpan    243.30037 228.54223 172.84425 110.37831 447.49969 210.76951\nMatman     368.25761 515.39711 444.05061 505.52285 929.11283 443.25453\nTachileik  573.39528 441.82621 470.45533 429.15493 221.19950 549.08985\nNarphan    416.84901 523.69580 435.59661 420.30003 770.40234 392.32592\nMongkhet   342.08722 487.41102 414.10280 409.03553 816.44931 324.97428\nHsipaw     145.37542 249.35081 176.09570 163.95741 591.03355 128.42987\nMonghsat   225.64279 352.31496 289.83220 253.25370 663.76026 158.93517\nMongmao    293.70625 314.64777 257.76465 146.09228 451.82530 185.99082\nNansang    160.37607 188.78869 151.13185  60.32773 489.35308  78.78999\nLaukkaing  624.82399 548.83928 552.65554 428.74978 149.26996 507.39700\nPangsang   321.81214 345.91486 287.10769 175.35273 460.24292 214.19291\nNamtu      165.02707 260.95300 257.52713 270.87277 659.16927 185.86794\nMonghpyak  190.93173 142.31691  93.03711 217.64419 539.43485 293.22640\nKonkyan    421.48797 520.31264 439.34272 393.79911 704.86973 351.75354\nMongping   259.68288 396.47081 316.14719 330.28984 744.44948 272.82761\nHopong     138.86577 274.91604 204.88286 218.84211 648.68011 157.48857\nNyaungshwe 139.31874 104.17830  43.26545 126.50414 505.88581 201.71653\nHsihseng   105.30573 257.11202 209.88026 250.27059 677.66886 175.89761\nMongla     441.20998 393.18472 381.40808 241.58966 256.80556 315.93218\nHseni      243.98001 171.50398 164.05304  81.20593 381.30567 204.49010\nKunlong    249.36301 318.30406 285.04608 215.63037 547.24297 122.68682\nHopang     336.38582 321.16462 279.84188 154.91633 377.44407 230.78652\nNamhkan    442.77120 379.41126 367.33575 247.81990 238.67060 342.43665\nKengtung   297.67761 209.38215 208.29647 136.23356 330.08211 258.23950\nLangkho    219.21623 190.30257 156.51662  51.67279 413.64173 160.94435\nMonghsu    113.84636 242.04063 170.09168 200.77712 633.21624 163.28926\nTaunggyi   440.66133 304.96838 344.79200 312.60547 250.81471 425.36916\nPangwaun   423.81347 453.02765 381.67478 308.31407 541.97887 351.78203\nKyethi     162.43575 317.74604 267.21607 328.14177 757.16745 255.83275\nLoilen     181.94596 265.29318 219.26405 146.92675 560.43400  59.69478\nManton     403.82131 551.13000 475.77296 522.86003 941.49778 458.30232\nMongyang   363.58788 363.37684 323.32123 188.59489 389.59919 229.71502\nKunhing    213.46379 278.68953 206.15773 145.00266 533.00162 142.03682\nMongyawng  248.43910 179.07229 220.61209 181.55295 422.37358 211.99976\nTangyan    167.79937 323.14701 269.07880 306.78359 736.93741 224.29176\nNamhsan    207.16559 362.84062 299.74967 347.85944 778.52971 273.79672\n             Mongnai   Mawkmai    Kutkai   Mongton   Mongyai Mongkaing\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai    374.50873                                                  \nKutkai      91.15307 364.95519                                        \nMongton    131.67061 313.35220 107.06341                              \nMongyai    203.23607 178.70499 188.94166 159.79790                    \nMongkaing  456.00842 133.29995 428.96133 365.50032 262.84016          \nLashio     270.86983 638.60773 289.82513 347.11584 466.36472 708.65819\nMongpan    178.09554 509.99632 185.18173 200.31803 346.39710 563.56780\nMatman     376.33870 147.83545 340.86349 303.04574 186.95158 135.51424\nTachileik  563.95232 919.38755 568.99109 608.76740 750.29555 967.14087\nNarphan    329.31700 273.75350 314.27683 215.97925 248.82845 285.65085\nMongkhet   275.76855 115.58388 273.91673 223.22828 104.98924 222.60577\nHsipaw      52.68195 351.34601  51.46282  90.69766 177.33790 423.77868\nMonghsat   125.25968 275.09705 154.32012 150.98053 127.35225 375.60376\nMongmao    188.29603 485.52853 204.69232 206.57001 335.61300 552.31959\nNansang     92.79567 462.41938 130.04549 199.58124 288.55962 542.16609\nLaukkaing  551.56800 882.51110 580.38112 604.66190 732.68347 954.11795\nPangsang   204.25746 484.14757 228.33583 210.77938 343.30638 548.40662\nNamtu      209.35473 427.95451 225.28268 308.71751 278.02761 525.04057\nMonghpyak  253.26470 536.71695 206.61627 258.04282 370.01575 568.21089\nKonkyan    328.82831 339.01411 310.60810 248.25265 287.87384 380.92091\nMongping   202.99615 194.31049 182.75266 119.86993  65.38727 257.18572\nHopong      91.53795 302.84362  73.45899 106.21031 124.62791 379.37916\nNyaungshwe 169.63695 502.99026 152.15482 219.72196 327.13541 557.32112\nHsihseng   142.36728 329.29477 128.21054 194.64317 162.27126 411.59788\nMongla     354.10985 686.88950 388.40984 411.06668 535.28615 761.48327\nHseni      216.81639 582.53670 229.37894 286.75945 408.23212 648.04408\nKunlong    202.92529 446.53763 204.54010 270.02165 299.36066 539.91284\nHopang     243.00945 561.24281 263.31986 273.50305 408.73288 626.17673\nNamhkan    370.05669 706.47792 392.48568 414.53594 550.62819 771.39688\nKengtung   272.28711 632.54638 279.19573 329.38387 460.39706 692.74693\nLangkho    174.67678 531.08019 180.51419 236.70878 358.95672 597.42714\nMonghsu     84.11238 332.07962  62.60859 107.04894 154.86049 400.71816\nTaunggyi   448.55282 810.74692 450.33382 508.40925 635.94105 866.21117\nPangwaun   312.13429 500.68857 321.80465 257.50434 394.07696 536.95736\nKyethi     210.50453 278.85535 184.23422 222.52947 137.79420 352.06533\nLoilen      58.41263 388.73386 131.56529 176.16001 224.79239 482.18190\nManton     391.54062 109.08779 361.82684 310.20581 195.59882  81.75337\nMongyang   260.39387 558.83162 285.33223 295.60023 414.31237 631.91325\nKunhing    110.55197 398.43973 108.84990 114.03609 238.99570 465.03971\nMongyawng  275.77546 620.04321 281.03383 375.22688 445.78964 700.98284\nTangyan    180.37471 262.66006 166.61820 198.88460 109.08506 348.56123\nNamhsan    218.10003 215.19289 191.32762 196.76188  77.35900 288.66231\n              Lashio   Mongpan    Matman Tachileik   Narphan  Mongkhet\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan    172.33279                                                  \nMatman     628.11049 494.81014                                        \nTachileik  311.95286 411.03849 890.12935                              \nNarphan    525.63854 371.13393 312.05193 760.29566                    \nMongkhet   534.44463 412.17123 203.02855 820.50164 217.28718          \nHsipaw     290.86435 179.52054 344.45451 576.18780 295.40170 253.80950\nMonghsat   377.86793 283.30992 313.59911 677.09508 278.21548 167.98445\nMongmao    214.23677 131.59966 501.59903 472.95568 331.42618 375.35820\nNansang    184.47950 144.77393 458.06573 486.77266 398.13308 360.99219\nLaukkaing  334.65738 435.58047 903.72094 325.06329 708.82887 769.06406\nPangsang   236.72516 140.23910 506.29940 481.31907 316.30314 375.58139\nNamtu      365.88437 352.91394 416.65397 659.56458 494.36143 355.99713\nMonghpyak  262.09281 187.85699 470.46845 444.04411 448.40651 462.63265\nKonkyan    485.51312 365.87588 392.40306 730.92980 158.82353 254.24424\nMongping   454.52548 318.47482 201.65224 727.08969 188.64567 113.80917\nHopong     345.31042 239.43845 291.84351 632.45718 294.40441 212.99485\nNyaungshwe 201.58191 137.29734 460.91883 445.81335 427.94086 417.08639\nHsihseng   369.00833 295.87811 304.02806 658.87060 377.52977 256.70338\nMongla     179.95877 253.20001 708.17595 347.33155 531.46949 574.40292\nHseni       79.41836 120.66550 564.64051 354.90063 474.12297 481.88406\nKunlong    295.23103 288.03320 468.27436 595.70536 413.07823 341.68641\nHopang     170.63913 135.62913 573.55355 403.82035 397.85908 451.51070\nNamhkan    173.27153 240.34131 715.42102 295.91660 536.85519 596.19944\nKengtung    59.85893 142.21554 613.01033 295.90429 505.40025 531.35998\nLangkho    115.18145  94.98486 518.86151 402.33622 420.65204 428.08061\nMonghsu    325.71557 216.25326 308.13805 605.02113 311.92379 247.73318\nTaunggyi   195.14541 319.81385 778.45810 150.84117 684.20905 712.80752\nPangwaun   362.45608 232.52209 523.43600 540.60474 264.64997 407.02947\nKyethi     447.10266 358.89620 233.83079 728.87329 374.90376 233.25039\nLoilen     268.92310 207.25000 406.56282 573.75476 354.79137 284.76895\nManton     646.66493 507.96808  59.52318 910.23039 280.26395 181.33894\nMongyang   209.33700 194.93467 585.61776 448.79027 401.39475 445.40621\nKunhing    255.10832 137.85278 403.66587 532.26397 281.62645 292.49814\nMongyawng  172.70139 275.15989 601.80824 432.10118 572.76394 522.91815\nTangyan    429.84475 340.39128 242.78233 719.84066 348.84991 201.49393\nNamhsan    472.04024 364.77086 180.09747 754.03913 316.54695 170.90848\n              Hsipaw  Monghsat   Mongmao   Nansang Laukkaing  Pangsang\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat   121.78922                                                  \nMongmao    185.99483 247.17708                                        \nNansang    120.24428 201.92690 164.99494                              \nLaukkaing  569.06099 626.44910 404.00848 480.60074                    \nPangsang   205.04337 256.37933  57.60801 193.36162 408.04016          \nNamtu      229.44658 231.78673 365.03882 217.61884 664.06286 392.97391\nMonghpyak  237.67919 356.84917 291.88846 227.52638 565.84279 315.11651\nKonkyan    296.74316 268.25060 281.87425 374.70456 635.92043 274.81900\nMongping   168.92101 140.95392 305.57166 287.36626 708.13447 308.33123\nHopong      62.86179 100.45714 244.16253 167.66291 628.48557 261.51075\nNyaungshwe 169.92664 286.37238 230.45003 131.18943 520.24345 257.77823\nHsihseng   136.54610 153.49551 311.98001 193.53779 670.74564 335.52974\nMongla     373.47509 429.00536 216.24705 289.45119 202.55831 217.88123\nHseni      231.48538 331.22632 184.67099 136.45492 391.74585 214.66375\nKunlong    205.10051 202.31862 224.43391 183.01388 521.88657 258.49342\nHopang     248.72536 317.64824  78.29342 196.47091 331.67199  92.57672\nNamhkan    382.79302 455.10875 223.32205 302.89487 196.46063 231.38484\nKengtung   284.08582 383.72138 207.58055 193.67980 351.48520 229.85484\nLangkho    183.05109 279.52329 134.50170  99.39859 410.41270 167.65920\nMonghsu     58.55724 137.24737 242.43599 153.59962 619.01766 260.52971\nTaunggyi   462.31183 562.88102 387.33906 365.04897 345.98041 405.59730\nPangwaun   298.12447 343.53898 187.40057 326.12960 470.63605 157.48757\nKyethi     195.17677 190.50609 377.89657 273.02385 749.99415 396.89963\nLoilen      98.04789 118.65144 190.26490  94.23028 535.57527 207.94433\nManton     359.60008 317.15603 503.79786 476.55544 907.38406 504.75214\nMongyang   267.10497 312.64797  91.06281 218.49285 326.19219 108.37735\nKunhing     90.77517 165.38834 103.91040 128.20940 500.41640 123.18870\nMongyawng  294.70967 364.40429 296.40789 191.11990 454.80044 336.16703\nTangyan    167.69794 144.59626 347.14183 249.70235 722.40954 364.76893\nNamhsan    194.47928 169.56962 371.71448 294.16284 760.45960 385.65526\n               Namtu Monghpyak   Konkyan  Mongping    Hopong Nyaungshwe\nPindaya                                                                \nYwangan                                                                \nPinlaung                                                               \nMabein                                                                 \nKalaw                                                                  \nPekon                                                                  \nLawksawk                                                               \nNawnghkio                                                              \nKyaukme                                                                \nMuse                                                                   \nLaihka                                                                 \nMongnai                                                                \nMawkmai                                                                \nKutkai                                                                 \nMongton                                                                \nMongyai                                                                \nMongkaing                                                              \nLashio                                                                 \nMongpan                                                                \nMatman                                                                 \nTachileik                                                              \nNarphan                                                                \nMongkhet                                                               \nHsipaw                                                                 \nMonghsat                                                               \nMongmao                                                                \nNansang                                                                \nLaukkaing                                                              \nPangsang                                                               \nNamtu                                                                  \nMonghpyak  346.57799                                                   \nKonkyan    478.37690 463.39594                                         \nMongping   321.66441 354.76537 242.02901                               \nHopong     206.82668 267.95563 304.49287 134.00139                     \nNyaungshwe 271.41464 103.97300 432.35040 319.32583 209.32532           \nHsihseng   131.89940 285.37627 383.49700 199.64389  91.65458  225.80242\nMongla     483.49434 408.03397 468.09747 512.61580 432.31105  347.60273\nHseni      327.41448 200.26876 448.84563 395.58453 286.41193  130.86310\nKunlong    233.60474 357.44661 329.11433 309.05385 219.06817  285.13095\nHopang     408.24516 304.26577 348.18522 379.27212 309.77356  247.19891\nNamhkan    506.32466 379.50202 481.59596 523.74815 444.13246  333.32428\nKengtung   385.33554 221.47613 474.82621 442.80821 340.47382  177.75714\nLangkho    305.03473 200.27496 386.95022 343.96455 239.63685  128.26577\nMonghsu    209.64684 232.17823 331.72187 158.90478  43.40665  173.82799\nTaunggyi   518.72748 334.17439 650.56905 621.53039 513.76415  325.09619\nPangwaun   517.03554 381.95144 263.97576 340.37881 346.00673  352.92324\nKyethi     186.90932 328.16234 400.10989 187.43974 136.49038  288.06872\nLoilen     194.24075 296.99681 334.19820 231.99959 124.74445  206.40432\nManton     448.58230 502.20840 366.66876 200.48082 310.58885  488.79874\nMongyang   413.26052 358.17599 329.39338 387.80686 323.35704  294.29500\nKunhing    296.43996 250.74435 253.74202 212.59619 145.15617  189.97131\nMongyawng  262.24331 285.56475 522.38580 455.59190 326.59925  218.12104\nTangyan    178.69483 335.26416 367.46064 161.67411 106.82328  284.14692\nNamhsan    240.95555 352.70492 352.20115 130.23777 132.70541  315.91750\n            Hsihseng    Mongla     Hseni   Kunlong    Hopang   Namhkan\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla     478.66210                                                  \nHseni      312.74375 226.82048                                        \nKunlong    231.85967 346.46200 276.19175                              \nHopang     370.01334 147.02444 162.80878 271.34451                    \nNamhkan    492.09476  77.21355 212.11323 375.73885 146.18632          \nKengtung   370.72441 202.45004  66.12817 317.14187 164.29921 175.63015\nLangkho    276.27441 229.01675  66.66133 224.52741 134.24847 224.40029\nMonghsu     97.82470 424.51868 262.28462 239.89665 301.84458 431.32637\nTaunggyi   528.14240 297.09863 238.19389 471.29032 329.95252 257.29147\nPangwaun   433.06326 319.18643 330.70182 392.45403 206.98364 310.44067\nKyethi      84.04049 556.02500 388.33498 298.55859 440.48114 567.86202\nLoilen     158.84853 338.67408 227.10984 166.53599 242.89326 364.90647\nManton     334.87758 712.51416 584.63341 479.76855 577.52046 721.86149\nMongyang   382.59743 146.66661 210.19929 247.22785  69.25859 167.72448\nKunhing    220.15490 306.47566 206.47448 193.77551 172.96164 314.92119\nMongyawng  309.51462 315.57550 173.86004 240.39800 290.51360 321.21112\nTangyan     70.27241 526.80849 373.07575 268.07983 412.22167 542.64078\nNamhsan    125.74240 564.02740 411.96125 310.40560 440.51555 576.42717\n            Kengtung   Langkho   Monghsu  Taunggyi  Pangwaun    Kyethi\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla                                                                \nHseni                                                                 \nKunlong                                                               \nHopang                                                                \nNamhkan                                                               \nKengtung                                                              \nLangkho    107.16213                                                  \nMonghsu    316.91914 221.84918                                        \nTaunggyi   186.28225 288.27478 486.91951                              \nPangwaun   337.48335 295.38434 343.38498 497.61245                    \nKyethi     444.26274 350.91512 146.61572 599.57407 476.62610          \nLoilen     282.22935 184.10672 131.55208 455.91617 331.69981 232.32965\nManton     631.99123 535.95620 330.76503 803.08034 510.79265 272.03299\nMongyang   217.08047 175.35413 323.95988 374.58247 225.25026 453.86726\nKunhing    245.95083 146.38284 146.78891 429.98509 229.09986 278.95182\nMongyawng  203.87199 186.11584 312.85089 287.73864 475.33116 387.71518\nTangyan    429.95076 332.02048 127.42203 592.65262 447.05580  47.79331\nNamhsan    466.20497 368.20978 153.22576 631.49232 448.58030  68.67929\n              Loilen    Manton  Mongyang   Kunhing Mongyawng   Tangyan\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla                                                                \nHseni                                                                 \nKunlong                                                               \nHopang                                                                \nNamhkan                                                               \nKengtung                                                              \nLangkho                                                               \nMonghsu                                                               \nTaunggyi                                                              \nPangwaun                                                              \nKyethi                                                                \nLoilen                                                                \nManton     419.06087                                                  \nMongyang   246.76592 585.70558                                        \nKunhing    130.39336 410.49230 188.89405                              \nMongyawng  261.75211 629.43339 304.21734 295.35984                    \nTangyan    196.60826 271.82672 421.06366 249.74161 377.52279          \nNamhsan    242.15271 210.48485 450.97869 270.79121 430.02019  63.67613"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#hierarchical-clustering",
    "href": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#hierarchical-clustering",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6.4 Hierarchical clustering",
    "text": "6.4 Hierarchical clustering\n\n6.4.1 Compute hierarchical clustering\nIn R, several packages provide hierarchical clustering functions. In this hands-on exercise, we will use hclust() from the Base R stats package.\nThe hclust() function uses an agglomerative method to compute clusters. It supports eight clustering algorithms: ward.D, ward.D2, single, complete, average (UPGMA), mcquitty (WPGMA), median (WPGMC), and centroid (UPGMC).\nThe code chunk below performs hierarchical cluster analysis using the ward.D method. The hierarchical clustering output is stored in an object of class hclust, which describes the tree produced by the clustering process.\n\nhclust_ward &lt;- hclust(proxmat, method = 'ward.D')\n\nWe can then plot the tree by using plot() of R Graphics as shown in the code chunk below.\n\nplot(hclust_ward, cex = 0.6)\n\n\n\n\n\n\n\n\n\n\n6.4.2 Selecting the optimal clustering algorithm\nOne of the challenges in performing hierarchical clustering is identifying stronger clustering structures. This issue can be addressed using the agnes() function from the cluster package. Similar to hclust(), the agnes() function computes hierarchical clusters, but it also provides the agglomerative coefficient, which measures the strength of the clustering structure (values closer to 1 indicate stronger clustering structures).\nThe code chunk below computes the agglomerative coefficients for all hierarchical clustering algorithms.\n\nm &lt;- c( \"average\", \"single\", \"complete\", \"ward\")\nnames(m) &lt;- c( \"average\", \"single\", \"complete\", \"ward\")\n\nac &lt;- function(x) {\n  agnes(shan_ict, method = x)$ac\n}\n\nmap_dbl(m, ac)\n\n  average    single  complete      ward \n0.8131144 0.6628705 0.8950702 0.9427730 \n\n\n\nBased on the output above, we can observe that Ward’s method provides the strongest clustering structure among the methods assessed. Therefore, in the subsequent analysis, only Ward’s method will be used.\n\n\n\n6.4.3 Determining Optimal Clusters\nAnother technical challenge face by data analyst in performing clustering analysis is to determine the optimal clusters to retain.\nThere are three commonly used methods to determine the optimal clusters, they are:\n\nElbow Method\nAverage Silhouette Method\nGap Statistic Method\n\n\n6.4.3.1 Gap Statistic Method\nThe gap statistic compares the total within-cluster variation for different values of k with the expected values under a null reference distribution. The estimate of the optimal number of clusters is the value of k that maximizes the gap statistic (i.e., the value that yields the largest gap statistic). This indicates that the clustering structure is far from a random uniform distribution of points.\nTo compute the gap statistic, we will use the clusGap() function from the cluster package.\n\nset.seed(12345)\ngap_stat &lt;- clusGap(shan_ict, \n                    FUN = hcut, \n                    nstart = 25, \n                    K.max = 10, \n                    B = 50)\n# Print the result\nprint(gap_stat, method = \"firstmax\")\n\nClustering Gap statistic [\"clusGap\"] from call:\nclusGap(x = shan_ict, FUNcluster = hcut, K.max = 10, B = 50, nstart = 25)\nB=50 simulated reference sets, k = 1..10; spaceH0=\"scaledPCA\"\n --&gt; Number of clusters (method 'firstmax'): 1\n          logW   E.logW       gap     SE.sim\n [1,] 8.407129 8.680794 0.2736651 0.04460994\n [2,] 8.130029 8.350712 0.2206824 0.03880130\n [3,] 7.992265 8.202550 0.2102844 0.03362652\n [4,] 7.862224 8.080655 0.2184311 0.03784781\n [5,] 7.756461 7.978022 0.2215615 0.03897071\n [6,] 7.665594 7.887777 0.2221833 0.03973087\n [7,] 7.590919 7.806333 0.2154145 0.04054939\n [8,] 7.526680 7.731619 0.2049390 0.04198644\n [9,] 7.458024 7.660795 0.2027705 0.04421874\n[10,] 7.377412 7.593858 0.2164465 0.04540947\n\n\nNext, we can visualise the plot by using fviz_gap_stat() of factoextra package.\n\nfviz_gap_stat(gap_stat)\n\n\n\n\n\n\n\n\nBased on the gap statistic graph above, the recommended number of clusters to retain is 1. However, retaining only one cluster is not logical. Upon further examination of the gap statistic graph, the 6-cluster solution gives the largest gap statistic after 1 and should be considered the next best choice for the optimal number of clusters.\n\n\n\n\n\n\nNote\n\n\n\nIn addition to these commonly used approaches, the NbClust package, published by Charrad et al., 2014, provides 30 indices for determining the relevant number of clusters and proposes to users the best clustering scheme from the different results obtained by varying all combinations of number of clusters, distance measures, and clustering methods.\n\n\n\n\n\n6.4.4 Interpreting the dendrograms\nIn the dendrogram displayed above, each leaf corresponds to an individual observation. As we move up the tree, observations that are similar to each other are combined into branches, which are then fused at higher heights.\nThe height of the fusion, indicated on the vertical axis, represents the dissimilarity between two observations. The higher the fusion, the less similar the observations are. Note that conclusions about the proximity of two observations should be based only on the height where the branches containing those two observations are first fused. The horizontal proximity of two observations in the dendrogram should not be used as a criterion for similarity.\nAdditionally, it is possible to highlight the selected clusters in the dendrogram by drawing a border around them using the rect.hclust() function from Base R. The argument border is used to specify the border colors for the rectangles.\n\nplot(hclust_ward, cex = 0.6)\nrect.hclust(hclust_ward, \n            k = 6, \n            border = 2:5)\n\n\n\n\n\n\n\n\n\n\n6.4.5 Visually-driven hierarchical clustering analysis\nIn this section, we will learn how to perform visually-driven hierarchical clustering analysis using the heatmaply package.\nWith heatmaply, we can create both highly interactive cluster heatmaps as well as static cluster heatmaps.\n\n6.4.5.1 Transforming the data frame into a matrix\nThe data has been loaded into a data frame, but it needs to be transformed into a data matrix to generate the heatmap.\nThe code chunk below will be used to convert the shan_ict data frame into a data matrix.\n\nshan_ict_mat &lt;- data.matrix(shan_ict)\n\n\n\n6.4.5.2 Plotting interactive cluster heatmap using heatmaply()\nIn the code chunk below, the heatmaply() function from the heatmaply package is used to build an interactive cluster heatmap.\n\nheatmaply(normalize(shan_ict_mat),\n          Colv=NA,\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\",\n          seriate = \"OLO\",\n          colors = Blues,\n          k_row = 6,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"Geographic Segmentation of Shan State by ICT indicators\",\n          xlab = \"ICT Indicators\",\n          ylab = \"Townships of Shan State\"\n          )\n\n\n\n\n\n\n\n\n6.4.6 Mapping the clusters formed\nAfter closely examining the dendrogram above, we have decided to retain six clusters.\nThe cutree() function from Base R will be used in the code chunk below to derive a 6-cluster model.\n\ngroups &lt;- as.factor(cutree(hclust_ward, k=6))\n\nTo visualize the clusters, the groups object needs to be appended to the shan_sf simple feature object.\nThe code chunk below performs this join in three steps:\n\nThe groups list object is converted into a matrix.\ncbind() is used to append the groups matrix to shan_sf, producing an output simple feature object called shan_sf_cluster.\nrename() from the dplyr package is used to rename the as.matrix.groups field as CLUSTER.\n\n\nshan_sf_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER`=`as.matrix.groups.`)\n\nNext, qtm() of tmap package is used to plot the choropleth map showing the cluster formed.\n\nqtm(shan_sf_cluster, \"CLUSTER\")\n\n\n\n\n\n\n\n\n\nThe choropleth map above reveals that the clusters are highly fragmented. This is one of the major limitations of using non-spatial clustering algorithms, such as hierarchical cluster analysis."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#converting-into-spatialpolygonsdataframe",
    "href": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#converting-into-spatialpolygonsdataframe",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "7.1 Converting into SpatialPolygonsDataFrame",
    "text": "7.1 Converting into SpatialPolygonsDataFrame\nFirst, we need to convert shan_sf into a SpatialPolygonsDataFrame, as the skater() function only supports sp objects, such as SpatialPolygonsDataFrame.\nThe code chunk below uses as_Spatial() from the sf package to convert shan_sf into a SpatialPolygonsDataFramecalled shan_sp.\n\nshan_sp &lt;- as_Spatial(shan_sf)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#computing-neighbour-list",
    "href": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#computing-neighbour-list",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "7.2 Computing Neighbour List",
    "text": "7.2 Computing Neighbour List\nNext, poly2nd() of spdep package will be used to compute the neighbours list from polygon list.\n\nshan.nb &lt;- poly2nb(shan_sp)\nsummary(shan.nb)\n\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\n\nWe can plot the neighbors list on shan_sp using the code chunk below. Since we can now plot the community area boundaries as well, this graph will be plotted on top of the map.\nThe first plot command draws the boundaries, followed by the plot of the neighbor list object. Coordinates are applied to the original SpatialPolygonsDataFrame (Shan State township boundaries) to extract the centroids of the polygons, which are used as the nodes in the graph representation. We set the color to blue and use add=TRUE to plot the network on top of the boundaries.\n\ncoords &lt;- st_coordinates(\n  st_centroid(st_geometry(shan_sf)))\nplot(st_geometry(shan_sf), \n     border=grey(.5))\nplot(shan.nb,\n     coords, \n     col=\"blue\", \n     add=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that if we plot the network first and then the boundaries, some areas may be clipped. This occurs because the plotting area is determined by the characteristics of the first plot. In this example, since the boundary map extends further than the graph, we plot the boundaries first."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#computing-minimum-spanning-tree",
    "href": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#computing-minimum-spanning-tree",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "7.3 Computing minimum spanning tree",
    "text": "7.3 Computing minimum spanning tree\n\n7.3.1 Calculating edge costs\nNext, the nbcosts() function from the spdep package is used to compute the cost of each edge, which represents the distance between its nodes. This function calculates the distance using a data frame with observation vectors for each node.\nThe code chunk below is used to compute the cost of each edge.\n\nlcosts &lt;- nbcosts(shan.nb, shan_ict)\n\nFor each observation, this computes the pairwise dissimilarity between its values on the five variables and those of the neighboring observation (based on the neighbor list). Essentially, this represents a generalized weight for a spatial weights matrix.\nNext, we will incorporate these costs into a weights object, similar to how we calculated inverse distance weights. In other words, we convert the neighbor list to a list weights object by specifying the previously computed lcosts as the weights.\nTo achieve this, we use the nb2listw() function from the spdep package, as shown in the code chunk below.\nNote that we specify the style as \"B\" to ensure that the cost values are not row-standardized.\n\nshan.w &lt;- nb2listw(shan.nb, \n                   lcosts, \n                   style=\"B\")\nsummary(shan.w)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\nWeights style: B \nWeights constants summary:\n   n   nn       S0       S1        S2\nB 55 3025 76267.65 58260785 522016004"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#computing-minimum-spanning-tree-1",
    "href": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#computing-minimum-spanning-tree-1",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "7.4 Computing minimum spanning tree",
    "text": "7.4 Computing minimum spanning tree\nThe minimum spanning tree is computed by mean of the mstree() of spdep package as shown in the code chunk below.\n\nshan.mst &lt;- mstree(shan.w)\n\nAfter computing the MST, we can check its class and dimension by using the code chunk below.\n\nclass(shan.mst)\n\n[1] \"mst\"    \"matrix\"\n\n\n\ndim(shan.mst)\n\n[1] 54  3\n\n\n\nNote that the dimension is 54 and not 55. This is because the minimum spanning tree consists of n-1 edges (links) to traverse all the nodes.\n\nWe can display the content of shan.mst by using head() as shown in the code chunk below.\n\nhead(shan.mst)\n\n     [,1] [,2]      [,3]\n[1,]   54   48  47.79331\n[2,]   54   17 109.08506\n[3,]   54   45 127.42203\n[4,]   45   52 146.78891\n[5,]   52   13 110.55197\n[6,]   13   28  92.79567\n\n\nThe plot method for the Minimum Spanning Tree (MST) includes an option to display the observation numbers of the nodes, in addition to the edges. As before, we will plot this together with the township boundaries. This allows us to observe how the initial neighbor list is simplified to just one edge connecting each node, while still passing through all the nodes.\n\nplot(st_geometry(shan_sf), \n                 border=gray(.5))\nplot.mst(shan.mst, \n         coords, \n         col=\"blue\", \n         cex.lab=0.7, \n         cex.circles=0.005, \n         add=TRUE)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#computing-spatially-constrained-clusters-using-skater-method",
    "href": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#computing-spatially-constrained-clusters-using-skater-method",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "7.5 Computing spatially constrained clusters using SKATER method",
    "text": "7.5 Computing spatially constrained clusters using SKATER method\nThe code chunk below compute the spatially constrained cluster using skater() of spdep package.\n\nclust6 &lt;- spdep::skater(edges = shan.mst[,1:2], \n                 data = shan_ict, \n                 method = \"euclidean\", \n                 ncuts = 5)\n\nThe skater() function takes three mandatory arguments:\n\nThe first two columns of the MST matrix (i.e., not the cost),\nThe data matrix (to update the costs as units are being grouped),\nThe number of cuts (set to one less than the number of clusters).\n\nNote: The value specified is not the number of clusters, but the number of cuts in the graph—one less than the desired number of clusters.\nThe result of skater() is an object of class skater. We can examine its contents using the code chunk below.\n\nstr(clust6)\n\nList of 8\n $ groups      : num [1:55] 3 3 6 3 3 3 3 3 3 3 ...\n $ edges.groups:List of 6\n  ..$ :List of 3\n  .. ..$ node: num [1:22] 13 48 54 55 45 37 34 16 25 52 ...\n  .. ..$ edge: num [1:21, 1:3] 48 55 54 37 34 16 45 25 13 13 ...\n  .. ..$ ssw : num 3423\n  ..$ :List of 3\n  .. ..$ node: num [1:18] 47 27 53 38 42 15 41 51 43 32 ...\n  .. ..$ edge: num [1:17, 1:3] 53 15 42 38 41 51 15 27 15 43 ...\n  .. ..$ ssw : num 3759\n  ..$ :List of 3\n  .. ..$ node: num [1:11] 2 6 8 1 36 4 10 9 46 5 ...\n  .. ..$ edge: num [1:10, 1:3] 6 1 8 36 4 6 8 10 10 9 ...\n  .. ..$ ssw : num 1458\n  ..$ :List of 3\n  .. ..$ node: num [1:2] 44 20\n  .. ..$ edge: num [1, 1:3] 44 20 95\n  .. ..$ ssw : num 95\n  ..$ :List of 3\n  .. ..$ node: num 23\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n  ..$ :List of 3\n  .. ..$ node: num 3\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n $ not.prune   : NULL\n $ candidates  : int [1:6] 1 2 3 4 5 6\n $ ssto        : num 12613\n $ ssw         : num [1:6] 12613 10977 9962 9540 9123 ...\n $ crit        : num [1:2] 1 Inf\n $ vec.crit    : num [1:55] 1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \"class\")= chr \"skater\"\n\n\nThe most interesting component of the resulting list structure is the groups vector, which contains the labels for the clusters to which each observation belongs (the labels themselves are arbitrary). This is followed by a detailed summary for each cluster in the edges.groups list. Sum of squares measures are provided as ssto (total sum of squares) and ssw(within-cluster sum of squares), which show the effect of each cut on the overall criterion.\nWe can check the cluster assignment using the code chunk below.\n\nccs6 &lt;- clust6$groups\nccs6\n\n [1] 3 3 6 3 3 3 3 3 3 3 2 1 1 1 2 1 1 1 2 4 1 2 5 1 1 1 2 1 2 2 1 2 2 1 1 3 1 2\n[39] 2 2 2 2 2 4 1 3 2 1 1 1 2 1 2 1 1\n\n\nWe can determine how many observations are in each cluster using the table command. Alternatively, we can find this information by examining the dimensions of each vector in the lists contained in edges.groups. For instance, the first list has a node with a dimension of 12, which corresponds to the number of observations in the first cluster.\n\ntable(ccs6)\n\nccs6\n 1  2  3  4  5  6 \n22 18 11  2  1  1 \n\n\nLastly, we can plot the pruned tree that displays the five clusters on top of the township area.\n\nplot(st_geometry(shan_sf), \n     border=gray(.5))\nplot(clust6, \n     coords, \n     cex.lab=.7,\n     groups.colors=c(\"red\",\"green\",\"blue\", \"brown\", \"pink\"),\n     cex.circles=0.005, \n     add=TRUE)\n\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1], coords[id2,\n: \"add\" is not a graphical parameter\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1], coords[id2,\n: \"add\" is not a graphical parameter\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1], coords[id2,\n: \"add\" is not a graphical parameter\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1], coords[id2,\n: \"add\" is not a graphical parameter"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#visualising-the-clusters-in-choropleth-map",
    "href": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#visualising-the-clusters-in-choropleth-map",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "7.6 Visualising the clusters in choropleth map",
    "text": "7.6 Visualising the clusters in choropleth map\nThe code chunk below is used to plot the newly derived clusters using the SKATER method.\n\ngroups_mat &lt;- as.matrix(clust6$groups)\nshan_sf_spatialcluster &lt;- cbind(shan_sf_cluster, as.factor(groups_mat)) %&gt;%\n  rename(`SP_CLUSTER`=`as.factor.groups_mat.`)\nqtm(shan_sf_spatialcluster, \"SP_CLUSTER\")\n\n\n\n\n\n\n\n\nFor easier comparison, it would be better to place both the hierarchical clustering map and the spatially constrained hierarchical clustering map side by side.\n\nhclust.map &lt;- qtm(shan_sf_cluster,\n                  \"CLUSTER\") + \n  tm_borders(alpha = 0.5) \n\nshclust.map &lt;- qtm(shan_sf_spatialcluster,\n                   \"SP_CLUSTER\") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(hclust.map, shclust.map,\n             asp=NA, ncol=2)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them)."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#ward-like-hierarchical-clustering-clustgeo",
    "href": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#ward-like-hierarchical-clustering-clustgeo",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "8.1 Ward-like hierarchical clustering: ClustGeo",
    "text": "8.1 Ward-like hierarchical clustering: ClustGeo\nThe ClustGeo package provides a function called hclustgeo() to perform Ward-like hierarchical clustering, similar to the hclust() function you learned about in the previous section.\nTo perform non-spatially constrained hierarchical clustering, we simply need to provide the function with a dissimilarity matrix, as shown in the code chunk below.\n\nnongeo_cluster &lt;- hclustgeo(proxmat)\nplot(nongeo_cluster, cex = 0.5)\nrect.hclust(nongeo_cluster, \n            k = 6, \n            border = 2:5)\n\n\n\n\n\n\n\n\n\nNote that the dissimilarity matrix must be an object of class dist, i.e. an object obtained with the function dist().\n\n\n8.1.1 Mapping the clusters formed\nWe can plot the clusters on a categorical area-shaded map to visualize the results.\n\ngroups &lt;- as.factor(cutree(nongeo_cluster, k=6))\n\n\nshan_sf_ngeo_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n\n\nqtm(shan_sf_ngeo_cluster, \"CLUSTER\")"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#spatially-constrained-hierarchical-clustering",
    "href": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#spatially-constrained-hierarchical-clustering",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "8.2 Spatially Constrained Hierarchical Clustering",
    "text": "8.2 Spatially Constrained Hierarchical Clustering\nBefore performing spatially constrained hierarchical clustering, a spatial distance matrix will be derived using the st_distance() function from the sf package.\n\ndist &lt;- st_distance(shan_sf, shan_sf)\ndistmat &lt;- as.dist(dist)\n\n\nNotice that as.dist() is used to convert the data frame into matrix.\n\nNext, the choicealpha() function will be used to determine a suitable value for the mixing parameter alpha, as shown in the code chunk below.\n\ncr &lt;- choicealpha(proxmat, distmat, range.alpha = seq(0, 1, 0.1), K=6, graph = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBased on the graphs above, alpha = 0.3 will be used, as shown in the code chunk below.\n\nclustG &lt;- hclustgeo(proxmat, distmat, alpha = 0.3)\n\nNext, cutree() is used to derive the cluster object.\n\ngroups &lt;- as.factor(cutree(clustG, k=6))\n\nNext, we will join the group list back to the shan_sf polygon feature data frame using the code chunk below.\n\nshan_sf_Gcluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n\nWe can now plot the map of the newly delineated spatially constrained clusters.\n\nqtm(shan_sf_Gcluster, \"CLUSTER\")"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#visualising-individual-clustering-variable",
    "href": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#visualising-individual-clustering-variable",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "9.1 Visualising individual clustering variable",
    "text": "9.1 Visualising individual clustering variable\nThe code chunk below is used to reveal the distribution of a clustering variable (e.g., RADIO_PR) by cluster.\n\nggplot(data = shan_sf_ngeo_cluster,\n       aes(x = CLUSTER, y = RADIO_PR)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\nThe boxplot reveals that Cluster 3 has the highest mean radio ownership per thousand households, followed by Clusters 2, 1, 4, 6, and 5."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#multivariate-visualisation",
    "href": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#multivariate-visualisation",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "9.2 Multivariate Visualisation",
    "text": "9.2 Multivariate Visualisation\nPast studies have shown that parallel coordinate plots can effectively reveal clustering variables by cluster. In the code chunk below, we use ggparcoord() from the GGally package.\n\nggparcoord(data = shan_sf_ngeo_cluster, \n           columns = c(17:21), \n           scale = \"globalminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of ICT Variables by Cluster\") +\n  facet_grid(~ CLUSTER) + \n  theme(axis.text.x = element_text(angle = 30))\n\n\n\n\n\n\n\n\n\nThe parallel coordinate plot above reveals that households in Cluster 4 townships tend to own the highest number of TVs and mobile phones. In contrast, households in Cluster 5 tend to own the lowest number of all five ICT devices.\n\nNote that the scale argument of ggparcoord() provides several methods to scale the clustering variables. They are:\n\nstd: Univariately subtracts the mean and divides by the standard deviation.\nrobust: Univariately subtracts the median and divides by the median absolute deviation.\nuniminmax: Univariately scales so that the minimum of the variable is zero and the maximum is one.\nglobalminmax: No scaling is applied; the range of the graphs is defined by the global minimum and maximum.\ncenter: Uses uniminmax to standardize vertical height, then centers each variable at a value specified by the scaleSummary parameter.\ncenterObs: Uses uniminmax to standardize vertical height, then centers each variable at the value of the observation specified by the centerObsID parameter.\n\nThere is no single best scaling method to use; we need to explore these options and select the one that best meets our analysis needs.\nLastly, we can also compute summary statistics such as mean, median, standard deviation, etc., to complement the visual interpretation.\nIn the code chunk below, group_by() and summarise() of dplyr are used to derive mean values of the clustering variables.\n\nshan_sf_ngeo_cluster %&gt;% \n  st_set_geometry(NULL) %&gt;%\n  group_by(CLUSTER) %&gt;%\n  summarise(mean_RADIO_PR = mean(RADIO_PR),\n            mean_TV_PR = mean(TV_PR),\n            mean_LLPHONE_PR = mean(LLPHONE_PR),\n            mean_MPHONE_PR = mean(MPHONE_PR),\n            mean_COMPUTER_PR = mean(COMPUTER_PR))\n\n# A tibble: 6 × 6\n  CLUSTER mean_RADIO_PR mean_TV_PR mean_LLPHONE_PR mean_MPHONE_PR\n  &lt;chr&gt;           &lt;dbl&gt;      &lt;dbl&gt;           &lt;dbl&gt;          &lt;dbl&gt;\n1 1               221.        521.            44.2           246.\n2 2               237.        402.            23.9           134.\n3 3               300.        611.            52.2           392.\n4 4               196.        744.            99.0           651.\n5 5               124.        224.            38.0           132.\n6 6                98.6       499.            74.5           468.\n# ℹ 1 more variable: mean_COMPUTER_PR &lt;dbl&gt;"
  },
  {
    "objectID": "take_home_ex/take_home_ex01/take_home_ex01.html#network-constrained-spatial-point-pattern-analysis",
    "href": "take_home_ex/take_home_ex01/take_home_ex01.html#network-constrained-spatial-point-pattern-analysis",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "4.2 Network Constrained Spatial Point Pattern Analysis",
    "text": "4.2 Network Constrained Spatial Point Pattern Analysis\nIn this section, we aim to analyze the spatial distribution of road accidents within the Bangkok Metropolitan Region (BMR) using Network Kernel Density Estimation (NKDE). Unlike traditional spatial point pattern analysis, NKDE considers the road network as a constraint, ensuring that density estimates are calculated along the network itself, rather than across a continuous surface. This method is particularly well-suited for transportation-related incidents, where events (such as accidents) are tied to specific roads.\n\n4.2.1 Preparing the lixels objects\nTo begin, the road network will be prepared by segmenting the road lines into smaller units, known as lixels (linear pixels), using the lixelize_lines() function of spNetwork package. Choosing the appropriate lixel length and minimum distance is crucial. Shorter lixels offer finer spatial resolution but may increase computational cost, while longer lixels capture broader patterns.\nWe can determine the optimal lixel length by analyzing the distribution of road segment length.\n\nsummary(st_length(roads_bmr))\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n    0.016    33.862   117.396   359.803   378.717 21708.848 \n\nquantile(st_length(roads_bmr), probs = seq(.1, .9, by = .1))\n\nUnits: [m]\n      10%       20%       30%       40%       50%       60%       70%       80% \n 15.30428  26.52962  43.49558  71.57635 117.39646 189.01541 301.66260 478.58565 \n      90% \n899.27046 \n\n\nSurprisingly, road lengths in the BMR vary significantly, with half of the roads being up to 118 meters long. However, since we know previously that the accidents concentrated on highway, we’ll set the length of lixel to 5,000 meters and minimum distance to 2,500 meters.\n\nlixels &lt;- lixelize_lines(lines = roads_bmr,\n                         lx_length = 5000,\n                         mindist = 2500)\n\n\n\n4.2.2 Generating line centre points\nNext, the lines_center() function from the spNetwork package will be used to generate a SpatialPointsDataFrame(i.e., samples) by extracting the center points of each line segment. The following code chunk demonstrates this process.\n\nsamples &lt;- lines_center(lixels)\n\n\n\n4.2.3 Bandwidth selection\nBefore computing NKDE, it is essential to define the appropriate bandwidth, as described in the NKDE documentation. According to the documentation, bandwidth is the most critical parameter when performing kernel density estimation, as it controls the smoothing of the density estimation. In this analysis, we will use the bw_cv_likelihood_calc() function, which applies likelihood cross-validation through a leave-one-out approach. The idea is to find a bandwidth that produces the most accurate results by minimizing the difference when an event is removed from the dataset.\n\nbws_selection_cv &lt;- bw_cv_likelihood_calc(\n  bws = seq(200,3000,100),\n  lines = mtl_network, events = bike_accidents,\n  w = rep(1,nrow(bike_accidents)),\n  kernel_name = \"quartic\", method = \"continuous\",\n  diggle_correction = FALSE, study_area = NULL,\n  max_depth = 8,\n  digits=2, tol=1, agg=50,\n  sparse=TRUE, grid_shape=c(10,10),\n  verbose=FALSE, check=TRUE)\n\nwrite_rds(bws_selection_cv, \"data/rds/bws_selection_cv.rds\")\n\n\ncv_values &lt;- data.frame(\n  \"bw\" = bws_selection_cv$bw,\n  \"cv_likelihood_adpt_cont\" = bws_selection_cv$cv_scores\n)\ncv_values\n\n     bw cv_likelihood_adpt_cont\n1   200               -99.98859\n2   300               -44.39478\n3   400               -24.62782\n4   500               -16.85588\n5   600               -15.03705\n6   700               -15.17730\n7   800               -15.31530\n8   900               -15.45111\n9  1000               -15.58165\n10 1100               -15.70630\n11 1200               -15.82792\n12 1300               -17.93564\n13 1400               -18.04830\n14 1500               -18.15752\n15 1600               -18.26293\n16 1700               -16.38082\n17 1800               -16.47389\n18 1900               -16.56562\n19 2000               -16.65462\n20 2100               -16.74066\n21 2200               -16.82379\n22 2300               -16.90409\n23 2400               -16.98168\n24 2500               -17.05668\n25 2600               -17.12923\n26 2700               -17.19946\n27 2800               -17.26749\n28 2900               -17.33346\n29 3000               -17.39746\n\n\n\n\nAlthough the bandwidth range of 600-800 yields the lowest cross-validation likelihood scores, we have chosen a bandwidth of 1700 to produce smoother results.\nThis larger bandwidth captures broader trends across the road network, offering a more generalized view of accident density.\nIt is appropriate for our focus on overall patterns over BMR region rather than detailed, localized hotspots.\n\n\n\n\n4.2.4 Performing NKDE\nWe are now ready to compute the Network Kernel Density Estimation (NKDE) using the bandwidth that we selected, as demonstrated in the code chunk below.\n\ndensities &lt;- nkde(roads_bmr, \n                  events = accidents_bmr,\n                  w = rep(1, nrow(accidents_bmr)),\n                  samples = samples,\n                  kernel_name = \"quartic\",\n                  bw = 1700, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(10,10), \n                  max_depth = 8,\n                  agg = 50,\n                  sparse = TRUE,\n                  verbose = FALSE)\nwrite_rds(densities, \"data/rds/densities_1700.rds\")\n\nWe can rescale the density values from number of accidents per meter to number of accidents per kilometer using the following code:\n\ndensities = read_rds(\"data/rds/densities_1700.rds\")\nlixels$density &lt;- densities*1000\nlixels$density_lwd &lt;- densities*1000*10\n\n\n\n4.2.5 Visualise using tmap package\nNext, we will use the tmap package to visualize the Network Kernel Density Estimation (NKDE) results. To enhance the visibility of accident hotspots, we will represent network density through line widths. The line widths will be adjusted using the density_lwd column, which is calculated by multiplying the density by 10 to make the hotspots stand out more clearly on the map.\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\ntm_shape(admin_boundary_bmr) +\n  tm_polygons(col = \"white\", border.col = \"black\", alpha = 0.5) +\ntm_shape(lixels) +\n  tm_lines(col = \"density\",\n           palette = \"YlOrRd\",\n           lwd = \"density_lwd\",\n           title.col = \"Accident Density\",\n           legend.lwd.show = F) +\n  tm_layout(main.title = \"Network KDE of Road Accidents in the Bangkok Metropolitan Region\",\n            main.title.position = \"center\",\n            frame = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nRoad segments with a higher density of accidents are highlighted in darker colors, while those with lower density are shown in lighter colors.\nAs expected, the concentration is mostly along highways, consistent with the earlier KDE map.\nHowever, this interactive map allows us to identify specific road segments with particularly high accident concentrations in greater detail.\n\nFor example, we can see the hot-spot on this part of the highway intersection on Bangkok−Ban Chang Motorway, located less than 11 km from Suvarnabhumi Airport.\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nDue to computational limitations, we are unable to run CSR test of road accidents on the network.\nHowever, based on the current density results from NKDE, it suggests that the accident points are not forming regular patterns along the road network."
  },
  {
    "objectID": "take_home_ex/take_home_ex01/take_home_ex01.html#temporal-visualisation-of-road-accidents",
    "href": "take_home_ex/take_home_ex01/take_home_ex01.html#temporal-visualisation-of-road-accidents",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "5.1 Temporal Visualisation of Road Accidents",
    "text": "5.1 Temporal Visualisation of Road Accidents\nIn this sub-section, we will visualize the geographic distribution of road accidents across different temporal categories using point symbol map.\n\nBy seasonBy monthBy day of the weekBy hourDuring Songkran\n\n\n\ntm_shape(admin_boundary_bmr)+\n  tm_polygons() +\ntm_shape(accidents_bmr) +\n  tm_dots(size = 0.01) +\ntm_facets(by=\"season\", \n            free.coords=FALSE, \n            drop.units = TRUE)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(admin_boundary_bmr)+\n  tm_polygons() +\ntm_shape(accidents_bmr) +\n  tm_dots(size = 0.01) +\ntm_facets(by=\"Month_lab\", \n            free.coords=FALSE, \n            drop.units = TRUE)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(admin_boundary_bmr)+\n  tm_polygons() +\ntm_shape(accidents_bmr) +\n  tm_dots(size = 0.01) +\ntm_facets(by=\"Day_of_Week_lab\", \n            free.coords=FALSE, \n            drop.units = TRUE)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(admin_boundary_bmr)+\n  tm_polygons() +\ntm_shape(accidents_bmr) +\n  tm_dots(size = 0.01) +\ntm_facets(by=\"Hour\", \n            free.coords=FALSE, \n            drop.units = TRUE)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(admin_boundary_bmr)+\n  tm_polygons() +\ntm_shape(accidents_bmr) +\n  tm_dots(size = 0.01) +\ntm_facets(by=\"is_songkran\", \n            free.coords=FALSE, \n            drop.units = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote"
  },
  {
    "objectID": "take_home_ex/take_home_ex01/take_home_ex01.html#spatio-temporal-bandwidth-selection",
    "href": "take_home_ex/take_home_ex01/take_home_ex01.html#spatio-temporal-bandwidth-selection",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "5.1 Spatio-Temporal bandwidth selection",
    "text": "5.1 Spatio-Temporal bandwidth selection\nWe will calculate the kernel density values over time using several different bandwidths to explore how varying the bandwidth affects the temporal distribution of accidents. To find the optimal bandwidth, we will use bw_tnkde_cv_likelihood_calc() function which employs cross-validation likelihood over lines length and time window.\n\ncv_scores &lt;- bw_tnkde_cv_likelihood_calc(\n  bws_net = seq(100,3000,100),\n  bws_time = seq(10,90,10),\n  lines = roads_bmr,\n  events = accidents_bmr,\n  time_field = \"Day_of_year\",\n  w = rep(1, nrow(accidents_bmr)),\n  kernel_name = \"quartic\",\n  method = \"discontinuous\",\n  diggle_correction = FALSE,\n  study_area = NULL,\n  max_depth = 10,\n  digits = 2,\n  tol = 1,\n  agg = 50,\n  sparse=TRUE,\n  grid_shape=c(10,10),\n  sub_sample=1,\n  verbose = FALSE,\n  check = TRUE)\n\nwrite_rds(cv_scores, 'data/rds/cv_scores.rds')\n\n\nknitr::kable(cv_scores)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n10\n20\n30\n40\n50\n60\n70\n80\n90\n\n\n\n\n100\n-503.1470\n-411.56024\n-359.13252\n-319.70043\n-296.28244\n-273.46883\n-256.57819\n-245.45838\n-233.50709\n\n\n200\n-451.8656\n-349.25712\n-297.12981\n-259.80706\n-238.57315\n-219.25308\n-204.94545\n-193.87420\n-184.33171\n\n\n300\n-411.7409\n-308.21627\n-258.28398\n-224.93362\n-203.85115\n-186.89160\n-174.35886\n-164.05281\n-156.10756\n\n\n400\n-382.4193\n-281.44792\n-233.43310\n-201.49690\n-180.97676\n-165.88205\n-154.89507\n-145.70645\n-138.14710\n\n\n500\n-356.7807\n-259.70366\n-212.53396\n-182.31666\n-162.97646\n-149.53098\n-138.56529\n-130.38578\n-123.41433\n\n\n600\n-333.7798\n-241.27209\n-196.56845\n-168.32959\n-151.46738\n-138.62101\n-128.08409\n-120.07269\n-113.31804\n\n\n700\n-315.4986\n-225.84796\n-183.22485\n-155.80094\n-140.01447\n-128.17854\n-118.59510\n-111.11699\n-104.47427\n\n\n800\n-300.3759\n-214.05495\n-172.46246\n-145.79880\n-131.01733\n-119.61561\n-110.45929\n-103.87991\n-97.66436\n\n\n900\n-286.0675\n-201.01334\n-160.71178\n-135.42729\n-121.65593\n-110.78660\n-102.42547\n-96.63766\n-91.21185\n\n\n1000\n-275.2791\n-192.21778\n-153.09315\n-128.56451\n-115.49001\n-105.14884\n-96.84836\n-90.70122\n-85.74936\n\n\n1100\n-263.8679\n-183.16971\n-145.58847\n-122.27583\n-110.15384\n-100.23870\n-92.26160\n-85.96417\n-81.22520\n\n\n1200\n-253.0554\n-174.49833\n-138.35342\n-116.62406\n-104.25656\n-95.28539\n-87.46922\n-81.02047\n-76.44000\n\n\n1300\n-242.5470\n-165.76288\n-131.89500\n-109.97811\n-97.61630\n-88.55010\n-81.10195\n-74.70785\n-70.33985\n\n\n1400\n-234.2463\n-158.49539\n-125.17606\n-104.15641\n-92.58619\n-84.05052\n-76.92149\n-70.84351\n-66.84340\n\n\n1500\n-225.2628\n-151.64531\n-118.92226\n-99.37900\n-88.60009\n-80.53976\n-73.83456\n-68.33277\n-64.38924\n\n\n1600\n-217.2265\n-145.42937\n-113.19715\n-94.39875\n-84.15044\n-76.25414\n-70.12543\n-64.78711\n-61.26364\n\n\n1700\n-209.5104\n-139.57852\n-108.30288\n-90.55891\n-80.57820\n-72.68777\n-66.98060\n-62.01027\n-58.59556\n\n\n1800\n-202.8955\n-134.14565\n-103.82617\n-87.14138\n-77.37781\n-69.69971\n-64.25748\n-59.60120\n-56.76175\n\n\n1900\n-197.8099\n-130.39546\n-100.60941\n-84.19633\n-74.33447\n-66.86946\n-61.89645\n-57.14168\n-54.35724\n\n\n2000\n-191.2115\n-126.22755\n-97.75892\n-81.35705\n-72.22746\n-64.50579\n-59.95342\n-55.46089\n-52.62840\n\n\n2100\n-183.8220\n-121.17288\n-93.60826\n-78.67117\n-70.17067\n-62.35075\n-57.95792\n-53.93573\n-51.20826\n\n\n2200\n-178.2100\n-117.52620\n-90.70301\n-76.29805\n-68.06560\n-60.71304\n-56.27251\n-52.56467\n-49.89440\n\n\n2300\n-173.2338\n-113.78064\n-87.59311\n-73.56317\n-65.85420\n-59.18160\n-55.05630\n-51.40431\n-49.09845\n\n\n2400\n-167.6774\n-109.35022\n-84.48444\n-70.92985\n-63.74787\n-57.44583\n-53.58383\n-50.13942\n-47.78359\n\n\n2500\n-163.6985\n-105.81237\n-82.10487\n-68.97492\n-61.79712\n-55.70652\n-51.74596\n-48.51130\n-46.62338\n\n\n2600\n-157.9985\n-102.11856\n-79.56787\n-67.06982\n-59.89830\n-54.07061\n-50.57911\n-47.45140\n-45.61844\n\n\n2700\n-153.5967\n-99.77410\n-77.76029\n-65.63215\n-58.72508\n-53.10908\n-49.77726\n-46.60018\n-44.76963\n\n\n2800\n-149.5649\n-97.33060\n-76.26542\n-64.24820\n-57.86415\n-52.45969\n-49.13222\n-46.00723\n-44.28095\n\n\n2900\n-146.3715\n-94.31745\n-73.99179\n-62.55229\n-56.22724\n-50.87926\n-47.86623\n-44.89889\n-43.38140\n\n\n3000\n-142.2466\n-92.50544\n-72.44896\n-61.27443\n-55.16108\n-50.12642\n-47.27126\n-44.66811\n-43.25534\n\n\n\n\n\n\nWe have obtained the cross-validation results for the bandwidth options in our spatio-temporal analysis.\nUsing the “leave one out cross-validation” method, the optimal bandwidths are 3000 meters for space and 90 days for time."
  },
  {
    "objectID": "take_home_ex/take_home_ex01/take_home_ex01.html#compute-temporal-network-kernel-density-estimate-tnkde",
    "href": "take_home_ex/take_home_ex01/take_home_ex01.html#compute-temporal-network-kernel-density-estimate-tnkde",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "5.2 Compute Temporal Network Kernel Density Estimate (TNKDE)",
    "text": "5.2 Compute Temporal Network Kernel Density Estimate (TNKDE)\nNow, we will compute the Temporal Network Kernel Density Estimation (TNKDE) using the tnkde() function of spNetwork package with the selected bandwidth.\n\nsample_time &lt;- seq(0, max(accidents_bmr$Day_of_year), 90)\n\n# calculating densities\ntnkde_densities_adapt &lt;- tnkde(lines = roads_bmr,\n                   events = accidents_bmr,\n                   time_field = \"Day_of_year\",\n                   w = rep(1, nrow(accidents_bmr)), \n                   samples_loc = samples,\n                   samples_time = sample_time, \n                   kernel_name = \"quartic\",\n                   bw_net = 3000,\n                   bw_time = 90,\n                   adaptive = T,\n                   trim_bw_net = 3100,\n                   trim_bw_time = 100,\n                   method = \"discontinuous\",\n                   div = \"bw\",\n                   max_depth = 10,\n                   digits = 2,\n                   tol = 1,\n                   agg = 50,\n                   grid_shape = c(10,10), \n                   verbose  = FALSE)\nwrite_rds(tnkde_densities_adapt, \"data/rds/tnkde_densities_adapt.rds\")\n\n\n\n\n\n\n\nReflection\n\n\n\nThis code chunk is adapted from spNetwork documentations example on tnkde(). Below is a breakdown of key arguments used in this code:\n\nbw_net = 3000, bw_time = 90: These parameters define the bandwidths for the network and time dimensions, set to 3000 meters and 90 days, respectively. These values were selected based on the results of the “leave one out cross-validation” discussed in the previous section.\ntrim_bw_net = 3100, trim_bw_time = 100: These parameters set the maximum values for the adaptive bandwidth in the network and time dimensions. In this case, we used simple rule-of-thumb values for 3100 meters and 100 days."
  },
  {
    "objectID": "take_home_ex/take_home_ex01/take_home_ex01.html#visualize-tnkde-map",
    "href": "take_home_ex/take_home_ex01/take_home_ex01.html#visualize-tnkde-map",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "5.3 Visualize TNKDE map",
    "text": "5.3 Visualize TNKDE map\nUpon completing the TNKDE density calculations, we will visualize the results as an animated GIF.\nFirst, we will use the classInt package to create color breaks for the density values. The class intervals will be determined using the k-means algorithm to group the densities into meaningful ranges.\n\nall_densities &lt;- c(tnkde_densities_adapt$k)\ncolor_breaks &lt;- classIntervals(all_densities, n = 10, style = \"kmeans\")\n\nNext, we will generate individual maps for each sample time and compile them into all_maps using the lapply() function. Each map will visualize the TNKDE densities for a specific time point, with dots representing the density values. The colors of the dots will correspond to the density values, using the color breaks and palette defined earlier.\nWe will create an animated GIF from the series of maps stored in the all_maps object using the tmap_animation() function from the tmap package. After generating the GIF, we will display it using the include_graphics() function from the knitr package.\n\nall_maps &lt;- lapply(1:ncol(tnkde_densities_adapt$k), function(i){\n  time &lt;- sample_time[[i]]\n  \n  samples$density &lt;- tnkde_densities_adapt$k[,i]\n  map1 &lt;- tm_shape(samples) + \n  tm_dots(col = \"density\", size = 0.01,\n          breaks = color_breaks$brks, \n           palette = \"YlOrRd\",) + \n    tm_layout(legend.show=FALSE, main.title = as.character(time), main.title.size = 0.5)\n  return(map1)\n})\n\n# creating a gif with all the maps\ntmap_animation(all_maps, filename = \"images/animated_map2.gif\", \n               width = 1000, height = 1000, dpi = 300, delay = 50)\n\n\nknitr::include_graphics(\"images/animated_map2.gif\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFrom the animated GIF, we can observe that while there are some minor temporal shifts in accident density across certain areas of the BMR, the primary hotspots remain largely unchanged.\nThese consistent hotspots, as identified in the KDE analysis, suggest that certain locations consistently experience high accident rates over time.\nAlthough there is some density movement in less concentrated areas, the major hotspots appear to be long-standing, emphasizing the need for focused road safety measures in these critical zones."
  },
  {
    "objectID": "take_home_ex/take_home_ex01/take_home_ex01.html#key-findings",
    "href": "take_home_ex/take_home_ex01/take_home_ex01.html#key-findings",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "6.1 Key findings",
    "text": "6.1 Key findings\n\nConsistent Accident Hotspots\nThe Network Kernel Density Estimation (NKDE) and Temporal NKDE (TNKDE) analyses identified consistent accident hotspots across the BMR, particularly on major highways in Bangkok and Samut Prakan provinces. These areas show persistent high-density accident zones, suggesting that these locations face ongoing road safety challenges.\nMinimal Temporal Shifts\nThe major hotspots remained largely stable over time, with only minor temporal shifts observed in less concentrated areas. This indicates that the high-risk areas are consistently prone to accidents throughout the year, likely due to factors like traffic congestion or complex road layouts.\nAccidents During Clear Weather\nInterestingly, most accidents occurred during clear weather conditions, despite the increased accident rates typically associated with the rainy season. This suggests that other factors, such as driver behavior, may have a greater influence on accident occurrence than weather alone.\nHigh-Risk Time Periods\nRush hours (both morning and evening) were identified as periods with a higher distribution of accidents, reflecting the increased traffic volumes during commuting times."
  },
  {
    "objectID": "take_home_ex/take_home_ex01/take_home_ex01.html#limitation",
    "href": "take_home_ex/take_home_ex01/take_home_ex01.html#limitation",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "6.2 Limitation",
    "text": "6.2 Limitation\nOne challenge I encountered was the difficulty in finding appropriate references on spatial point analysis. Some library documentation lacked clarity or contained outdated code, making it harder to fully understand the functions provided by certain packages. Additionally, limited computational resources restricted my ability to perform more extensive bandwidth tests and experiment with adaptive estimation techniques from spNetwork in the analysis."
  },
  {
    "objectID": "take_home_ex/take_home_ex01/take_home_ex01.html#future-works",
    "href": "take_home_ex/take_home_ex01/take_home_ex01.html#future-works",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "6.3 Future works",
    "text": "6.3 Future works\nThere are several ideas that can be explored for future work on this topic. These improvements could provide more depth to the analysis of road accidents in BMR.\n\nFocusing on High-Risk Provinces\nGiven that accidents are most concentrated in Bangkok, Samut Prakan, and Pathum Thani, future analysis could prioritize these provinces. A more granular study might help identify specific local risk factors contributing to the high accident rates in these provinces.\nExploring Different Temporal Aspects\nSo far, my spatio-temporal point analysis has focused on day of the year. Future work could explore density patterns by hour or month to reveal more detailed trends and temporal shifts.\nIncorporating Additional Data\nIncorporating data like traffic volumes and road maintenance locations could add more depth to the analysis. Since the accidents are mainly concentrated on major highways in the BMR, these factors could help our analysis."
  },
  {
    "objectID": "index.html#take-home-exercise",
    "href": "index.html#take-home-exercise",
    "title": "Welcome to ISSS626 Geospatial Analytics and Applications",
    "section": "Take-home Exercise",
    "text": "Take-home Exercise\n\n\n\n\n\n\n\n\nTake-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics\n\n\n54 min\n\n\n\nOct 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nTake-home Exercise 1: Geospatial Analytics for Social Good\n\n\n53 min\n\n\n\nSep 11, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "in_class_ex/in_class_ex05/in_class_ex05.html#loading-the-data",
    "href": "in_class_ex/in_class_ex05/in_class_ex05.html#loading-the-data",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Association: sfdep methods",
    "section": "4.1 Loading the data",
    "text": "4.1 Loading the data\nIn this section, we will learn how to bring a geospatial data and its associated attribute table into R environment. The geospatial data is in ESRI shapefile format and the attribute table is in csv fomat.\n\nImport geospatial dataImport aspatial dataPerform relational join\n\n\nWe use st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be simple features Object of sf.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/Users/cham/project/Geospatial-Analytics/chrismanafe/ISSS626-GAA/in_class_ex/in_class_ex05/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\nRows: 88\nColumns: 8\n$ NAME_2     &lt;chr&gt; \"Changde\", \"Changde\", \"Changde\", \"Changde\", \"Changde\", \"Cha…\n$ ID_3       &lt;int&gt; 21098, 21100, 21101, 21102, 21103, 21104, 21109, 21110, 211…\n$ NAME_3     &lt;chr&gt; \"Anxiang\", \"Hanshou\", \"Jinshi\", \"Li\", \"Linli\", \"Shimen\", \"L…\n$ ENGTYPE_3  &lt;chr&gt; \"County\", \"County\", \"County City\", \"County\", \"County\", \"Cou…\n$ Shape_Leng &lt;dbl&gt; 1.869074, 2.360691, 1.425620, 3.474325, 2.289506, 4.171918,…\n$ Shape_Area &lt;dbl&gt; 0.10056190, 0.19978745, 0.05302413, 0.18908121, 0.11450357,…\n$ County     &lt;chr&gt; \"Anxiang\", \"Hanshou\", \"Jinshi\", \"Li\", \"Linli\", \"Shimen\", \"L…\n$ geometry   &lt;POLYGON [°]&gt; POLYGON ((112.0625 29.75523..., POLYGON ((112.2288 …\n\n\n\n\nThen we will import Hunan_2012.csv into R by using read_csv() of readr package. The output is R dataframe class.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nRows: 88\nColumns: 29\n$ County      &lt;chr&gt; \"Anhua\", \"Anren\", \"Anxiang\", \"Baojing\", \"Chaling\", \"Changn…\n$ City        &lt;chr&gt; \"Yiyang\", \"Chenzhou\", \"Changde\", \"Hunan West\", \"Zhuzhou\", …\n$ avg_wage    &lt;dbl&gt; 30544, 28058, 31935, 30843, 31251, 28518, 54540, 28597, 33…\n$ deposite    &lt;dbl&gt; 10967.0, 4598.9, 5517.2, 2250.0, 8241.4, 10860.0, 24332.0,…\n$ FAI         &lt;dbl&gt; 6831.7, 6386.1, 3541.0, 1005.4, 6508.4, 7920.0, 33624.0, 1…\n$ Gov_Rev     &lt;dbl&gt; 456.72, 220.57, 243.64, 192.59, 620.19, 769.86, 5350.00, 1…\n$ Gov_Exp     &lt;dbl&gt; 2703.0, 1454.7, 1779.5, 1379.1, 1947.0, 2631.6, 7885.5, 11…\n$ GDP         &lt;dbl&gt; 13225.0, 4941.2, 12482.0, 4087.9, 11585.0, 19886.0, 88009.…\n$ GDPPC       &lt;dbl&gt; 14567, 12761, 23667, 14563, 20078, 24418, 88656, 10132, 17…\n$ GIO         &lt;dbl&gt; 9276.90, 4189.20, 5108.90, 3623.50, 9157.70, 37392.00, 513…\n$ Loan        &lt;dbl&gt; 3954.90, 2555.30, 2806.90, 1253.70, 4287.40, 4242.80, 4053…\n$ NIPCR       &lt;dbl&gt; 3528.3, 3271.8, 7693.7, 4191.3, 3887.7, 9528.0, 17070.0, 3…\n$ Bed         &lt;dbl&gt; 2718, 970, 1931, 927, 1449, 3605, 3310, 582, 2170, 2179, 1…\n$ Emp         &lt;dbl&gt; 494.310, 290.820, 336.390, 195.170, 330.290, 548.610, 670.…\n$ EmpR        &lt;dbl&gt; 441.4, 255.4, 270.5, 145.6, 299.0, 415.1, 452.0, 127.6, 21…\n$ EmpRT       &lt;dbl&gt; 338.0, 99.4, 205.9, 116.4, 154.0, 273.7, 219.4, 94.4, 174.…\n$ Pri_Stu     &lt;dbl&gt; 54.175, 33.171, 19.584, 19.249, 33.906, 81.831, 59.151, 18…\n$ Sec_Stu     &lt;dbl&gt; 32.830, 17.505, 17.819, 11.831, 20.548, 44.485, 39.685, 7.…\n$ Household   &lt;dbl&gt; 290.4, 104.6, 148.1, 73.2, 148.7, 211.2, 300.3, 76.1, 139.…\n$ Household_R &lt;dbl&gt; 234.5, 121.9, 135.4, 69.9, 139.4, 211.7, 248.4, 59.6, 110.…\n$ NOIP        &lt;dbl&gt; 101, 34, 53, 18, 106, 115, 214, 17, 55, 70, 44, 84, 74, 17…\n$ Pop_R       &lt;dbl&gt; 670.3, 243.2, 346.0, 184.1, 301.6, 448.2, 475.1, 189.6, 31…\n$ RSCG        &lt;dbl&gt; 5760.60, 2386.40, 3957.90, 768.04, 4009.50, 5220.40, 22604…\n$ Pop_T       &lt;dbl&gt; 910.8, 388.7, 528.3, 281.3, 578.4, 816.3, 998.6, 256.7, 45…\n$ Agri        &lt;dbl&gt; 4942.253, 2357.764, 4524.410, 1118.561, 3793.550, 6430.782…\n$ Service     &lt;dbl&gt; 5414.5, 3814.1, 14100.0, 541.8, 5444.0, 13074.6, 17726.6, …\n$ Disp_Inc    &lt;dbl&gt; 12373, 16072, 16610, 13455, 20461, 20868, 183252, 12379, 1…\n$ RORP        &lt;dbl&gt; 0.7359464, 0.6256753, 0.6549309, 0.6544614, 0.5214385, 0.5…\n$ ROREmp      &lt;dbl&gt; 0.8929619, 0.8782065, 0.8041262, 0.7460163, 0.9052651, 0.7…\n\n\n\n\nWe will also update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe. This is performed by using left_join() of dplyr package.\n\ncolnames(hunan)\n\n[1] \"NAME_2\"     \"ID_3\"       \"NAME_3\"     \"ENGTYPE_3\"  \"Shape_Leng\"\n[6] \"Shape_Area\" \"County\"     \"geometry\"  \n\n\n\ncolnames(hunan2012)\n\n [1] \"County\"      \"City\"        \"avg_wage\"    \"deposite\"    \"FAI\"        \n [6] \"Gov_Rev\"     \"Gov_Exp\"     \"GDP\"         \"GDPPC\"       \"GIO\"        \n[11] \"Loan\"        \"NIPCR\"       \"Bed\"         \"Emp\"         \"EmpR\"       \n[16] \"EmpRT\"       \"Pri_Stu\"     \"Sec_Stu\"     \"Household\"   \"Household_R\"\n[21] \"NOIP\"        \"Pop_R\"       \"RSCG\"        \"Pop_T\"       \"Agri\"       \n[26] \"Service\"     \"Disp_Inc\"    \"RORP\"        \"ROREmp\"     \n\n\n\nhunan &lt;- left_join(hunan,hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`\n\n\n\n\nRows: 88\nColumns: 7\n$ NAME_2    &lt;chr&gt; \"Changde\", \"Changde\", \"Changde\", \"Changde\", \"Changde\", \"Chan…\n$ ID_3      &lt;int&gt; 21098, 21100, 21101, 21102, 21103, 21104, 21109, 21110, 2111…\n$ NAME_3    &lt;chr&gt; \"Anxiang\", \"Hanshou\", \"Jinshi\", \"Li\", \"Linli\", \"Shimen\", \"Li…\n$ ENGTYPE_3 &lt;chr&gt; \"County\", \"County\", \"County City\", \"County\", \"County\", \"Coun…\n$ County    &lt;chr&gt; \"Anxiang\", \"Hanshou\", \"Jinshi\", \"Li\", \"Linli\", \"Shimen\", \"Li…\n$ GDPPC     &lt;dbl&gt; 23667, 20981, 34592, 24473, 25554, 27137, 63118, 62202, 7066…\n$ geometry  &lt;POLYGON [°]&gt; POLYGON ((112.0625 29.75523..., POLYGON ((112.2288 2…"
  },
  {
    "objectID": "in_class_ex/in_class_ex05/in_class_ex05.html#visualising-choropleth-map-of-gdppc-of-hunan-province",
    "href": "in_class_ex/in_class_ex05/in_class_ex05.html#visualising-choropleth-map-of-gdppc-of-hunan-province",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Association: sfdep methods",
    "section": "4.2 Visualising Choropleth Map of GDPPC of Hunan province",
    "text": "4.2 Visualising Choropleth Map of GDPPC of Hunan province\nNow, we are going to prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 of Hunan Province.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(hunan) +\n  tm_fill(\"GDPPC\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"GDPPC\") +\n  tm_layout(main.title = \"Distribution of GDP per capita by county, Hunan Province\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)"
  },
  {
    "objectID": "in_class_ex/in_class_ex05/in_class_ex05.html#derive-queens-contiguity-weights-sfdep-methods",
    "href": "in_class_ex/in_class_ex05/in_class_ex05.html#derive-queens-contiguity-weights-sfdep-methods",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Association: sfdep methods",
    "section": "5.1 Derive Queen’s contiguity weights: sfdep methods",
    "text": "5.1 Derive Queen’s contiguity weights: sfdep methods\n\nwm_q &lt;- hunan %&gt;%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb,\n                         style = \"W\"),\n         .before = 1)\n\n\nNotice that st_weights() provides tree arguments, they are:\n\nnb: A neighbour list object as created by st_neighbors()\nstyle: Default “W” for row standardized weights. The other accepted values are “B”, “C”, “U”, “minmax”, and “S”.\nallow_zero: if TRUE, assigns zero as lagged value to zone without neighbors."
  },
  {
    "objectID": "in_class_ex/in_class_ex05/in_class_ex05.html#compute-global-morans-i",
    "href": "in_class_ex/in_class_ex05/in_class_ex05.html#compute-global-morans-i",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Association: sfdep methods",
    "section": "5.2 Compute Global Moran’s I",
    "text": "5.2 Compute Global Moran’s I\nWe will use global_moran() function to compute the Moran’s I value.\n\nmoranI &lt;- global_moran(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt)\nglimpse(moranI)\n\nList of 2\n $ I: num 0.301\n $ K: num 7.64\n\n\n\nDifferent from spdep package, the output of this function is a tibble data.frame."
  },
  {
    "objectID": "in_class_ex/in_class_ex05/in_class_ex05.html#performing-global-morans-i-test",
    "href": "in_class_ex/in_class_ex05/in_class_ex05.html#performing-global-morans-i-test",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Association: sfdep methods",
    "section": "5.3 Performing Global Moran’s I test",
    "text": "5.3 Performing Global Moran’s I test\nIn general, a Moran’s I test will be conducted rather than merely calculating the Moran’s I statistic. Using the sfdep package, the Moran’s I test can be performed with the global_moran_test() function, as demonstrated in the code chunk below.\n\nglobal_moran_test(wm_q$GDPPC,\n                  wm_q$nb,\n                  wm_q$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\nThere is sign of positive autocorrelation (derived from Moran I statistic)."
  },
  {
    "objectID": "in_class_ex/in_class_ex05/in_class_ex05.html#perfoming-global-morans-i-permutation-test",
    "href": "in_class_ex/in_class_ex05/in_class_ex05.html#perfoming-global-morans-i-permutation-test",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Association: sfdep methods",
    "section": "5.4 Perfoming Global Moran’s I permutation test",
    "text": "5.4 Perfoming Global Moran’s I permutation test\nIn practice, a Monte Carlo simulation should be used to perform the statistical test. In the sfdep package, this is supported by the global_moran_perm() function.\nLet us use set.seed() before performing simulation. This is to ensure that the computation is reproducible.\n\nset.seed(1234)\n\nNow we will perform Monte Carlo simulation using global_moran_perm().\n\nglobal_moran_perm(wm_q$GDPPC,\n                  wm_q$nb,\n                  wm_q$wt,\n                  nsim = 99) # means running this 100 times because it started from 0\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\nThe statistical report indicates that the p-value is smaller than the alpha value of 0.05. Therefore, we have sufficient statistical evidence to reject the null hypothesis that the spatial distribution of GDP per capita resembles a random distribution (i.e., is spatially independent). Since the Moran’s I statistic is greater than 0, we can infer that the spatial distribution exhibits signs of clustering."
  },
  {
    "objectID": "in_class_ex/in_class_ex05/in_class_ex05.html#lisa-map",
    "href": "in_class_ex/in_class_ex05/in_class_ex05.html#lisa-map",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Association: sfdep methods",
    "section": "6.1 LISA map",
    "text": "6.1 LISA map\nLISA map is a categorical map that illustrates spatial clusters and outliers. The map identifies two types of outliers: High-Low and Low-High, and two types of clusters: High-High and Low-Low. Essentially, a LISA map is an interpreted visualization that combines the local Moran’s I values of geographical areas with their respective p-values to show statistically significant spatial patterns."
  },
  {
    "objectID": "in_class_ex/in_class_ex05/in_class_ex05.html#computing-local-morans-i",
    "href": "in_class_ex/in_class_ex05/in_class_ex05.html#computing-local-morans-i",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Association: sfdep methods",
    "section": "6.2 Computing local Moran’s I",
    "text": "6.2 Computing local Moran’s I\nNow, we will compute Local Moran’s I of GDPPC at county level by using local_moran() of sfdep package.\n\nlisa &lt;- wm_q %&gt;% \n  mutate(local_moran = local_moran(\n    GDPPC, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\n\n\n\n\n\n\nNote\n\n\n\nThe output of local_moran() is a sf data.frame containing the columns ii, eii, var_ii, z_ii, p_ii, p_ii_sim, and p_folded_sim.\n\nii: local moran statistic\neii: expectation of local moran statistic; for localmoran_permthe permutation sample means\nvar_ii: variance of local moran statistic; for localmoran_permthe permutation sample standard deviations\nz_ii: standard deviate of local moran statistic; for localmoran_perm based on permutation sample means and standard deviations p_ii: p-value of local moran statistic using pnorm(); for localmoran_perm using standard deviatse based on permutation sample means and standard deviations p_ii_sim: For localmoran_perm(), rank() and punif() of observed statistic rank for [0, 1] p-values using alternative= -p_folded_sim: the simulation folded [0, 0.5] range ranked p-value (based on https://github.com/pysal/esda/blob/4a63e0b5df1e754b17b5f1205b cadcbecc5e061/esda/crand.py#L211-L213)\nskewness: For localmoran_perm, the output of e1071::skewness() for the permutation samples underlying the standard deviates\nkurtosis: For localmoran_perm, the output of e1071::kurtosis() for the permutation samples underlying the standard deviates."
  },
  {
    "objectID": "in_class_ex/in_class_ex05/in_class_ex05.html#visualising-local-morans-i",
    "href": "in_class_ex/in_class_ex05/in_class_ex05.html#visualising-local-morans-i",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Association: sfdep methods",
    "section": "6.3 Visualising local Moran’s I",
    "text": "6.3 Visualising local Moran’s I\nWe will use tmap package to prepare choropleth map using value in the ii field.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(\n    main.title = \"local Moran's I of GDPPC\",\n    main.title.size = 2)\n\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "in_class_ex/in_class_ex05/in_class_ex05.html#visualising-p-value-of-local-morans-i",
    "href": "in_class_ex/in_class_ex05/in_class_ex05.html#visualising-p-value-of-local-morans-i",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Association: sfdep methods",
    "section": "6.4 Visualising p-value of local Moran’s I",
    "text": "6.4 Visualising p-value of local Moran’s I\nWe will use tmap package to prepare choropleth map using value in the p_ii_sim field.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(lisa) +\n  tm_fill(\"p_ii_sim\") +\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(\n    main.title = \"p-value of Local Moran's I\",\n    main.title.size = 2\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor p-values, the appropriate classification should be 0.001, 0.01, 0.05 and not significant instead of using default classification scheme."
  },
  {
    "objectID": "in_class_ex/in_class_ex05/in_class_ex05.html#visualising-local-morans-i-and-p-value",
    "href": "in_class_ex/in_class_ex05/in_class_ex05.html#visualising-local-morans-i-and-p-value",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Association: sfdep methods",
    "section": "6.5 Visualising local Moran’s I and p-value",
    "text": "6.5 Visualising local Moran’s I and p-value\nFor effective comparison, we will plot both maps next to each other\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nmap1 &lt;- tm_shape(lisa) +\n  tm_fill(\"ii\") +\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(\n    main.title = \"Local Moran's I of GDPPC\",\n    main.title.size = 0.8\n  )\n\nmap2 &lt;- tm_shape(lisa) +\n  tm_fill(\"p_ii\") +\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(\n    main.title = \"p-value of Local Moran's I\",\n    main.title.size = 0.8\n  )\n\ntmap_arrange(map1, map2, ncol = 2)\n\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "in_class_ex/in_class_ex05/in_class_ex05.html#lisa-map-1",
    "href": "in_class_ex/in_class_ex05/in_class_ex05.html#lisa-map-1",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Association: sfdep methods",
    "section": "6.6 LISA map",
    "text": "6.6 LISA map\nLISA map is a categorical map showing outliers and clusters. There are two types of outliers namely: High-Low and Low-High outliers.\nLikewise, there are two type of clusters namely: High-High and Low-Low clusters. In fact, LISA map is an interpreted map by combining local Moran’s I of geographical areas and their respective p-values."
  },
  {
    "objectID": "in_class_ex/in_class_ex05/in_class_ex05.html#visualising-lisa-map",
    "href": "in_class_ex/in_class_ex05/in_class_ex05.html#visualising-lisa-map",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Association: sfdep methods",
    "section": "6.7 Visualising LISA map",
    "text": "6.7 Visualising LISA map\nIn the lisa sf data frame, there are three fields that contain the LISA categories: mean, median, and pysal. Typically, classification based on the mean field is used, as demonstrated in the code chunk below.\n\nlisa_sig &lt;- lisa  %&gt;%\n  filter(p_ii_sim &lt; 0.05)\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(lisa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them)."
  },
  {
    "objectID": "in_class_ex/in_class_ex05/in_class_ex05.html#computing-local-gi-statistics",
    "href": "in_class_ex/in_class_ex05/in_class_ex05.html#computing-local-gi-statistics",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Association: sfdep methods",
    "section": "7.1 Computing local Gi* statistics",
    "text": "7.1 Computing local Gi* statistics\n\n7.1.1 Derive spatial weight matrix\nAs with most spatial analyses, we first need to derive a spatial weight matrix before computing the local Gi* statistics. The code chunk below demonstrates how to derive a spatial weight matrix using functions from the sfdep package, combined with the tidyverse approach.\n\nwm_idw &lt;- hunan %&gt;%\n  mutate(nb = include_self(\n    st_contiguity(geometry)),\n    wts = st_inverse_distance(nb, \n                              geometry, \n                              scale = 1,\n                              alpha = 1),\n         .before = 1)\n\n! Polygon provided. Using point on surface.\n\n\nWarning: There was 1 warning in `stopifnot()`.\nℹ In argument: `wts = st_inverse_distance(nb, geometry, scale = 1, alpha = 1)`.\nCaused by warning in `st_point_on_surface.sfc()`:\n! st_point_on_surface may not give correct results for longitude/latitude data\n\n\n\n\n\n\n\n\n\nGi* and local Gi* are distance-based spatial statistics, so distance-based methods, rather than contiguity methods, should be used to derive the spatial weight matrix.\nSince we will be computing Gi* statistics, the include_self() function is applied to ensure that each location is considered in its own neighborhood.\n\n\n\n\n\n\n7.1.2 Compute local Gi* statistics\nNow, we will compute the local Gi* by using the code chunk below.\n\nHCSA &lt;- wm_idw %&gt;% \n  mutate(local_Gi = local_gstar_perm(\n    GDPPC, nb, wts, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi)\nHCSA\n\nSimple feature collection with 88 features and 18 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n# A tibble: 88 × 19\n    gi_star cluster     e_gi  var_gi std_dev p_value p_sim p_folded_sim skewness\n      &lt;dbl&gt; &lt;fct&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1  0.261   Low     0.00126  1.07e-7  0.283  7.78e-1  0.66         0.33    0.783\n 2 -0.276   Low     0.000969 4.76e-8 -0.123  9.02e-1  0.98         0.49    0.713\n 3  0.00573 High    0.00156  2.53e-7 -0.0571 9.54e-1  0.78         0.39    0.972\n 4  0.528   High    0.00155  2.97e-7  0.321  7.48e-1  0.56         0.28    0.942\n 5  0.466   High    0.00137  2.76e-7  0.386  7.00e-1  0.52         0.26    1.32 \n 6 -0.445   High    0.000992 7.08e-8 -0.588  5.57e-1  0.68         0.34    0.692\n 7  2.99    High    0.000700 4.05e-8  3.13   1.74e-3  0.04         0.02    0.975\n 8  2.04    High    0.00152  1.58e-7  1.77   7.59e-2  0.16         0.08    1.26 \n 9  4.42    High    0.00130  1.18e-7  4.22   2.39e-5  0.02         0.01    1.20 \n10  1.21    Low     0.00175  1.25e-7  1.49   1.36e-1  0.18         0.09    0.408\n# ℹ 78 more rows\n# ℹ 10 more variables: kurtosis &lt;dbl&gt;, nb &lt;nb&gt;, wts &lt;list&gt;, NAME_2 &lt;chr&gt;,\n#   ID_3 &lt;int&gt;, NAME_3 &lt;chr&gt;, ENGTYPE_3 &lt;chr&gt;, County &lt;chr&gt;, GDPPC &lt;dbl&gt;,\n#   geometry &lt;POLYGON [°]&gt;"
  },
  {
    "objectID": "in_class_ex/in_class_ex05/in_class_ex05.html#visualising-gi",
    "href": "in_class_ex/in_class_ex05/in_class_ex05.html#visualising-gi",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Association: sfdep methods",
    "section": "7.2 Visualising Gi*",
    "text": "7.2 Visualising Gi*\nIn the code chunk below, tmap functions are used to plot the local Gi* (i.e. gi_star) at the province level.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(HCSA) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8))\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "in_class_ex/in_class_ex05/in_class_ex05.html#visualising-p-value-of-hcsa",
    "href": "in_class_ex/in_class_ex05/in_class_ex05.html#visualising-p-value-of-hcsa",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Association: sfdep methods",
    "section": "7.3 Visualising p-value of HCSA",
    "text": "7.3 Visualising p-value of HCSA\nIn the code chunk below, tmap functions are used to plot the p-values of local Gi* (i.e. p_sim) at the province level.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(HCSA) +\n  tm_fill(\"p_sim\") + \n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "in_class_ex/in_class_ex05/in_class_ex05.html#visualising-local-hot-spot-and-cold-spot-areas",
    "href": "in_class_ex/in_class_ex05/in_class_ex05.html#visualising-local-hot-spot-and-cold-spot-areas",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Association: sfdep methods",
    "section": "7.4 Visualising local hot spot and cold spot areas",
    "text": "7.4 Visualising local hot spot and cold spot areas\nNow, we will plot the significant (i.e. p-values less than 0.05) hot spot and cold spot areas by using appropriate tmap functions as shown below.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nmap1 &lt;- tm_shape(HCSA) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of GDPPC\",\n            main.title.size = 0.8)\n\nmap2 &lt;- tm_shape(HCSA) +\n  tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi*\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex07/hands_on_ex07.html",
    "href": "hands_on_ex/hands_on_ex07/hands_on_ex07.html",
    "title": "Hands-on Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "",
    "text": "Geographically Weighted Regression (GWR) is a spatial statistical technique that accounts for non-stationary variables (e.g., climate, demographic factors, physical environment characteristics) to model the local relationships between these independent variables and a dependent variable, or outcome of interest.\nIn this hands-on exercise, we will learn to build hedonic pricing models using GWR methods. The dependent variable in this exercise is the resale prices of condominiums in 2015, while the independent variables are categorized as either structural or locational factors."
  },
  {
    "objectID": "take_home_ex/index.html",
    "href": "take_home_ex/index.html",
    "title": "Take-home Exercise",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\nTake-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics\n\n\n\nOct 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nTake-home Exercise 1: Geospatial Analytics for Social Good\n\n\n\nSep 11, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex07/hands_on_ex07.html#aspatial-data-wrangling",
    "href": "hands_on_ex/hands_on_ex07/hands_on_ex07.html#aspatial-data-wrangling",
    "title": "Hands-on Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "4.1 Aspatial data wrangling",
    "text": "4.1 Aspatial data wrangling\n\ncondo_resale.sf &lt;- st_as_sf(condo_resale,\n                            coords = c(\"LONGITUDE\", \"LATITUDE\"),\n                            crs=4326) %&gt;%\n  st_transform(crs=3414)\n\n\nNotice that the st_transform() function from the sf package is used to convert the coordinates from WGS84 (i.e., CRS: 4326) to SVY21 (i.e., CRS: 3414).\n\nLet’s list the contents of the condo_resale.sf object.\n\nhead(condo_resale.sf)\n\nSimple feature collection with 6 features and 21 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 22085.12 ymin: 29951.54 xmax: 41042.56 ymax: 34546.2\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 6 × 22\n  POSTCODE SELLING_PRICE AREA_SQM   AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE\n     &lt;dbl&gt;         &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt;\n1   118635       3000000      309    30     7.94          0.166            2.52 \n2   288420       3880000      290    32     6.61          0.280            1.93 \n3   267833       3325000      248    33     6.90          0.429            0.502\n4   258380       4250000      127     7     4.04          0.395            1.99 \n5   467169       1400000      145    28    11.8           0.119            1.12 \n6   466472       1320000      139    22    10.3           0.125            0.789\n# ℹ 15 more variables: PROX_URA_GROWTH_AREA &lt;dbl&gt;, PROX_HAWKER_MARKET &lt;dbl&gt;,\n#   PROX_KINDERGARTEN &lt;dbl&gt;, PROX_MRT &lt;dbl&gt;, PROX_PARK &lt;dbl&gt;,\n#   PROX_PRIMARY_SCH &lt;dbl&gt;, PROX_TOP_PRIMARY_SCH &lt;dbl&gt;,\n#   PROX_SHOPPING_MALL &lt;dbl&gt;, PROX_SUPERMARKET &lt;dbl&gt;, PROX_BUS_STOP &lt;dbl&gt;,\n#   NO_Of_UNITS &lt;dbl&gt;, FAMILY_FRIENDLY &lt;dbl&gt;, FREEHOLD &lt;dbl&gt;,\n#   LEASEHOLD_99YR &lt;dbl&gt;, geometry &lt;POINT [m]&gt;\n\n\n\nNotice that the output is in point feature data frame."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex07/hands_on_ex07.html#eda-using-statistical-graphics",
    "href": "hands_on_ex/hands_on_ex07/hands_on_ex07.html#eda-using-statistical-graphics",
    "title": "Hands-on Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "5.1 EDA using statistical graphics",
    "text": "5.1 EDA using statistical graphics\n\n5.1.1 Plot distribution\nWe can plot the distribution of SELLING_PRICE using appropriate Exploratory Data Analysis (EDA) techniques, as shown in the code chunk below.\n\nggplot(data=condo_resale.sf, aes(x=`SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\n\nThe distribution is right-skewed.\nThis indicates that more condominium units were transacted at relatively lower prices.\nStatistically, the skewed distribution can be normalized using a log transformation.\n\n\n\n\n\n5.1.2 Normalise using Log Transformation\nThe code chunk below derives a new variable called LOG_SELLING_PRICE by applying a log transformation to the SELLING_PRICE variable. This is done using the mutate() function from the dplyr package.\n\ncondo_resale.sf &lt;- condo_resale.sf %&gt;%\n  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))\n\n\n\n5.1.3 Plot of normalised selling price\n\nggplot(data=condo_resale.sf, aes(x=`LOG_SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n\n\n\n\n\n\n\n\nNotice that the distribution is relatively less skewed after the log transformation.\n\n\n\n5.1.4 Multiple Histogram Plots: Distribution of Variables\nIn this section, we will create small multiple histograms (also known as a trellis plot) using the ggarrange() function from the ggpubr package.\nThe code chunk below generates 12 histograms, which are then organized into a 3-column by 4-row small multiple plot using ggarrange().\n\nAREA_SQM &lt;- ggplot(data=condo_resale.sf, aes(x= `AREA_SQM`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nAGE &lt;- ggplot(data=condo_resale.sf, aes(x= `AGE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CBD &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_CBD`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CHILDCARE &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_CHILDCARE`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_ELDERLYCARE &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_ELDERLYCARE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_URA_GROWTH_AREA &lt;- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_URA_GROWTH_AREA`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_HAWKER_MARKET &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_HAWKER_MARKET`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_KINDERGARTEN &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_KINDERGARTEN`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_MRT &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_MRT`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PARK &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_PARK`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PRIMARY_SCH &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_TOP_PRIMARY_SCH &lt;- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_TOP_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, \n          PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,\n          PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  \n          ncol = 3, nrow = 4)\n\n\n\n\n\n\n\n\n\n\n5.1.5 Drawing Statistical Point Map\nLastly, we will visualize the geospatial distribution of condominium resale prices in Singapore. The map will be created using the tmap package.\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntmap_options(check.and.fix = TRUE)\ntm_shape(mpsz_svy21)+\n  tm_polygons() +\ntm_shape(condo_resale.sf) +  \n  tm_dots(col = \"SELLING_PRICE\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\nWarning: The shape mpsz_svy21 is invalid (after reprojection). See\nsf::st_is_valid\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\n\nThe set.zoom.limits argument of tm_view() sets the minimum and maximum zoom levels to 11 and 14, respectively."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex07/hands_on_ex07.html#simple-linear-regression-method",
    "href": "hands_on_ex/hands_on_ex07/hands_on_ex07.html#simple-linear-regression-method",
    "title": "Hands-on Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "6.1 Simple Linear Regression Method",
    "text": "6.1 Simple Linear Regression Method\n\n6.1.1 Build Simple Linear Regression model\nWe will build a simple linear regression model using SELLING_PRICE as the dependent variable and AREA_SQM as the independent variable.\nWe will use the lm() function from base R. The lm() function returns an object of class “lm” or, for multiple responses, of class c(\"mlm\", \"lm\").\nThe functions summary() and anova() can be used to obtain and print a summary and an analysis of variance table for the results. Additionally, generic accessor functions like coefficients(), effects(), fitted.values(), and residuals()can be used to extract various useful features from the object returned by lm().\n\ncondo.slr &lt;- lm(formula=SELLING_PRICE ~ AREA_SQM, \n                data = condo_resale.sf)\n\nsummary(condo.slr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3695815  -391764   -87517   258900 13503875 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -258121.1    63517.2  -4.064 5.09e-05 ***\nAREA_SQM      14719.0      428.1  34.381  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 942700 on 1434 degrees of freedom\nMultiple R-squared:  0.4518,    Adjusted R-squared:  0.4515 \nF-statistic:  1182 on 1 and 1434 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe output report reveals that SELLING_PRICE can be explained by the following formula:\n\\[ y = -258,121.1 + 14,719 \\times x_1 \\]\nwhere ( \\(x_1\\) ) represents AREA_SQM.\n\nThe R-squared value of 0.4518 indicates that this simple regression model explains approximately 45% of the variation in resale prices.\nSince the p-value is significantly smaller than 0.0001, we reject the null hypothesis that the mean is a good estimator of SELLING_PRICE. This suggests that the simple linear regression model is a better estimator for SELLING_PRICE.\nThe Coefficients section of the report shows that the p-values for both the intercept and AREA_SQM estimates are smaller than 0.001. Given this, we can reject the null hypothesis that B0 and B1 are equal to 0. As a result, we infer that B0 and B1 are reliable parameter estimates for this model.\n\n\n\n\n\n6.1.2 Visualise best fit curve\nNext, we will visualize the best fit curve on a scatterplot by using lm() as the method function in ggplot’s geometry.\n\nggplot(data=condo_resale.sf,  \n       aes(x=`AREA_SQM`, y=`SELLING_PRICE`)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nFigure above reveals that there are a few statistical outliers with relatively high selling prices."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex07/hands_on_ex07.html#multiple-linear-regression-method",
    "href": "hands_on_ex/hands_on_ex07/hands_on_ex07.html#multiple-linear-regression-method",
    "title": "Hands-on Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "6.2 Multiple Linear Regression Method",
    "text": "6.2 Multiple Linear Regression Method\n\n6.2.1 Visualising the relationships of the independent variables\nBefore building a multiple regression model, it is essential to ensure that the independent variables are not highly correlated with each other. Using highly correlated variables in a regression model can compromise its quality, a statistical phenomenon known as multicollinearity.\nA correlation matrix is commonly used to visualize the relationships between independent variables. Besides the pairs()function in base R, there are many packages that support the display of a correlation matrix. In this section, we will use the corrplot package.\nReordering the matrix is crucial for uncovering hidden structures and patterns within the data. The corrplot package provides four methods for reordering the matrix (via the order parameter): “AOE”, “FPC”, “hclust”, and “alphabet”. In the code chunk below, the AOE order is used, which arranges the variables based on the angular order of eigenvectors, as suggested by Michael Friendly.\n\ncorrplot(cor(condo_resale[, 5:23]), diag = FALSE, order = \"AOE\",\n         tl.pos = \"td\", tl.cex = 0.5, method = \"number\", type = \"upper\")\n\n\n\n\n\n\n\n\n\n\nFrom the scatterplot matrix, it is clear that Freehold is highly correlated with LEASE_99YEAR.\nGiven this, it is more prudent to include only one of these variables in the subsequent model building.\nAs a result, LEASE_99YEAR is excluded from the subsequent model."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex07/hands_on_ex07.html#building-a-hedonic-pricing-model-using-multiple-linear-regression-method",
    "href": "hands_on_ex/hands_on_ex07/hands_on_ex07.html#building-a-hedonic-pricing-model-using-multiple-linear-regression-method",
    "title": "Hands-on Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "6.3 Building a hedonic pricing model using multiple linear regression method",
    "text": "6.3 Building a hedonic pricing model using multiple linear regression method\n\n6.3.1 Calibrate the multiple linear regression model\nWe will use the lm() function to calibrate the multiple linear regression model, incorporating the selected independent variables to predict the dependent variable.\n\ncondo.mlr &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE    + \n                  PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                  PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + \n                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + \n                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n                  PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                data=condo_resale.sf)\nsummary(condo.mlr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3475964  -293923   -23069   241043 12260381 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           481728.40  121441.01   3.967 7.65e-05 ***\nAREA_SQM               12708.32     369.59  34.385  &lt; 2e-16 ***\nAGE                   -24440.82    2763.16  -8.845  &lt; 2e-16 ***\nPROX_CBD              -78669.78    6768.97 -11.622  &lt; 2e-16 ***\nPROX_CHILDCARE       -351617.91  109467.25  -3.212  0.00135 ** \nPROX_ELDERLYCARE      171029.42   42110.51   4.061 5.14e-05 ***\nPROX_URA_GROWTH_AREA   38474.53   12523.57   3.072  0.00217 ** \nPROX_HAWKER_MARKET     23746.10   29299.76   0.810  0.41782    \nPROX_KINDERGARTEN     147468.99   82668.87   1.784  0.07466 .  \nPROX_MRT             -314599.68   57947.44  -5.429 6.66e-08 ***\nPROX_PARK             563280.50   66551.68   8.464  &lt; 2e-16 ***\nPROX_PRIMARY_SCH      180186.08   65237.95   2.762  0.00582 ** \nPROX_TOP_PRIMARY_SCH    2280.04   20410.43   0.112  0.91107    \nPROX_SHOPPING_MALL   -206604.06   42840.60  -4.823 1.57e-06 ***\nPROX_SUPERMARKET      -44991.80   77082.64  -0.584  0.55953    \nPROX_BUS_STOP         683121.35  138353.28   4.938 8.85e-07 ***\nNO_Of_UNITS             -231.18      89.03  -2.597  0.00951 ** \nFAMILY_FRIENDLY       140340.77   47020.55   2.985  0.00289 ** \nFREEHOLD              359913.01   49220.22   7.312 4.38e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 755800 on 1417 degrees of freedom\nMultiple R-squared:  0.6518,    Adjusted R-squared:  0.6474 \nF-statistic: 147.4 on 18 and 1417 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n\nObservations:\n\n\n\n\nSignificant Variables:\n\nAREA_SQM has a positive and significant effect on SELLING_PRICE (Estimate = 12,708.32, p &lt; 2e-16).\nAGE negatively impacts SELLING_PRICE (Estimate = -24,440.82, p &lt; 2e-16).\nProximity to CBD, Childcare, and MRT have significant negative effects, while proximity to Parks, Primary Schools, and Bus Stops positively affect SELLING_PRICE.\nFREEHOLD status significantly increases the selling price (Estimate = 359,913.01, p &lt; 4.38e-13).\n\nInsignificant Variables:\n\nSome variables, such as PROX_HAWKER_MARKET, PROX_TOP_PRIMARY_SCH, and PROX_SUPERMARKET, do not show significant influence on SELLING_PRICE (p-values &gt; 0.05).\n\nModel Fit:\n\nThe Multiple R-squared value is 0.6518, indicating that approximately 65% of the variability in SELLING_PRICE is explained by this model.\nThe Adjusted R-squared is 0.6474, slightly lower, accounting for the number of predictors.\nThe F-statistic of 147.4 and p-value &lt; 2.2e-16 show that the model overall is highly significant.\n\n\n\n\n\n\n6.3.2 Calibrate the revised model\nWith reference to the report above, it is clear that not all the independent variables are statistically significant. We will revise the model by removing those variables that are not statistically significant.\n\ncondo.mlr1 &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                   PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                   PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK + \n                   PROX_PRIMARY_SCH + PROX_SHOPPING_MALL    + PROX_BUS_STOP + \n                   NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,\n                 data=condo_resale.sf)\nols_regress(condo.mlr1)\n\n                                Model Summary                                 \n-----------------------------------------------------------------------------\nR                            0.807       RMSE                     751998.679 \nR-Squared                    0.651       MSE                571471422208.592 \nAdj. R-Squared               0.647       Coef. Var                    43.168 \nPred R-Squared               0.638       AIC                       42966.758 \nMAE                     414819.628       SBC                       43051.072 \n-----------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.512586e+15          14        1.080418e+14    189.059    0.0000 \nResidual      8.120609e+14        1421    571471422208.592                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     527633.222    108183.223                   4.877    0.000     315417.244     739849.200 \n            AREA_SQM      12777.523       367.479        0.584     34.771    0.000      12056.663      13498.382 \n                 AGE     -24687.739      2754.845       -0.167     -8.962    0.000     -30091.739     -19283.740 \n            PROX_CBD     -77131.323      5763.125       -0.263    -13.384    0.000     -88436.469     -65826.176 \n      PROX_CHILDCARE    -318472.751    107959.512       -0.084     -2.950    0.003    -530249.889    -106695.613 \n    PROX_ELDERLYCARE     185575.623     39901.864        0.090      4.651    0.000     107302.737     263848.510 \nPROX_URA_GROWTH_AREA      39163.254     11754.829        0.060      3.332    0.001      16104.571      62221.936 \n            PROX_MRT    -294745.107     56916.367       -0.112     -5.179    0.000    -406394.234    -183095.980 \n           PROX_PARK     570504.807     65507.029        0.150      8.709    0.000     442003.938     699005.677 \n    PROX_PRIMARY_SCH     159856.136     60234.599        0.062      2.654    0.008      41697.849     278014.424 \n  PROX_SHOPPING_MALL    -220947.251     36561.832       -0.115     -6.043    0.000    -292668.213    -149226.288 \n       PROX_BUS_STOP     682482.221    134513.243        0.134      5.074    0.000     418616.359     946348.082 \n         NO_Of_UNITS       -245.480        87.947       -0.053     -2.791    0.005       -418.000        -72.961 \n     FAMILY_FRIENDLY     146307.576     46893.021        0.057      3.120    0.002      54320.593     238294.560 \n            FREEHOLD     350599.812     48506.485        0.136      7.228    0.000     255447.802     445751.821 \n-----------------------------------------------------------------------------------------------------------------\n\n\n\nIn this step, our condo.mlr1 object will contain the coefficients, residuals, effects, and fitted values. We will later extract the residuals as a dataframe to examine them closely.\n\n\n\n6.3.3 Preparing Publication Quality Table: gtsummary method\nThe gtsummary package provides an elegant and flexible way to create publication-ready summary tables in R.\nIn the code chunk below, tbl_regression() is used to create a well formatted regression report.\n\ntbl_regression(condo.mlr1, intercept = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI\n1\np-value\n\n\n\n\n(Intercept)\n527,633\n315,417, 739,849\n&lt;0.001\n\n\nAREA_SQM\n12,778\n12,057, 13,498\n&lt;0.001\n\n\nAGE\n-24,688\n-30,092, -19,284\n&lt;0.001\n\n\nPROX_CBD\n-77,131\n-88,436, -65,826\n&lt;0.001\n\n\nPROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n\n\nPROX_ELDERLYCARE\n185,576\n107,303, 263,849\n&lt;0.001\n\n\nPROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n&lt;0.001\n\n\nPROX_MRT\n-294,745\n-406,394, -183,096\n&lt;0.001\n\n\nPROX_PARK\n570,505\n442,004, 699,006\n&lt;0.001\n\n\nPROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n\n\nPROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n&lt;0.001\n\n\nPROX_BUS_STOP\n682,482\n418,616, 946,348\n&lt;0.001\n\n\nNO_Of_UNITS\n-245\n-418, -73\n0.005\n\n\nFAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n\n\nFREEHOLD\n350,600\n255,448, 445,752\n&lt;0.001\n\n\n\n1\nCI = Confidence Interval\n\n\n\n\n\n\n\n\nUsing the gtsummary package, model statistics can be included in the report by either appending them to the report table with add_glance_table(), or adding them as a table source note with add_glance_source_note().\n\ntbl_regression(condo.mlr1, \n               intercept = TRUE) %&gt;% \n  add_glance_source_note(\n    label = list(sigma ~ \"\\U03C3\"),\n    include = c(r.squared, adj.r.squared, \n                AIC, statistic,\n                p.value, sigma))\n\n\n\n\n  \n    \n      Characteristic\n\n      Beta\n\n      95% CI\n1\n      p-value\n\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n&lt;0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n&lt;0.001\n    AGE\n-24,688\n-30,092, -19,284\n&lt;0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n&lt;0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n&lt;0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n&lt;0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n&lt;0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n&lt;0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n&lt;0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n&lt;0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n&lt;0.001\n  \n  \n    \n      R² = 0.651; Adjusted R² = 0.647; AIC = 42,967; Statistic = 189; p-value = &lt;0.001; σ = 755,957\n\n    \n  \n  \n    \n      1 CI = Confidence Interval\n\n    \n  \n\n\n\n\n\n\n6.3.4 Checking for multicolinearity\nWhen performing OLS regression, we can use the olsrr package, which provides a collection of useful methods for building better multiple linear regression models, including:\n\nComprehensive regression output\nResidual diagnostics\nMeasures of influence\nHeteroskedasticity tests\nCollinearity diagnostics\nModel fit assessment\nVariable contribution assessment\nVariable selection procedures\n\nAdditionally, the ols_vif_tol() function from the olsrr package is used to check for strong signs of multicollinearity.\n\nols_vif_tol(condo.mlr1)\n\n              Variables Tolerance      VIF\n1              AREA_SQM 0.8728554 1.145665\n2                   AGE 0.7071275 1.414172\n3              PROX_CBD 0.6356147 1.573280\n4        PROX_CHILDCARE 0.3066019 3.261559\n5      PROX_ELDERLYCARE 0.6598479 1.515501\n6  PROX_URA_GROWTH_AREA 0.7510311 1.331503\n7              PROX_MRT 0.5236090 1.909822\n8             PROX_PARK 0.8279261 1.207837\n9      PROX_PRIMARY_SCH 0.4524628 2.210126\n10   PROX_SHOPPING_MALL 0.6738795 1.483945\n11        PROX_BUS_STOP 0.3514118 2.845664\n12          NO_Of_UNITS 0.6901036 1.449058\n13      FAMILY_FRIENDLY 0.7244157 1.380423\n14             FREEHOLD 0.6931163 1.442759\n\n\n\nSince the VIF values of the independent variables are all less than 10, we can safely conclude that there are no signs of multicollinearity among the independent variables.\n\n\n\n6.3.5 Test for Non-Linearity\nIn multiple linear regression, it is important to test the assumption of linearity and additivity in the relationship between the dependent and independent variables. To test the linearity assumption, we use the ols_plot_resid_fit() function from the olsrr package.\n\nols_plot_resid_fit(condo.mlr1)\n\n\n\n\n\n\n\n\n\nThe figure above shows that most of the data points are scattered around the zero line, allowing us to conclude that the relationships between the dependent variable and the independent variables are linear.\n\n\n\n6.3.6 Test for Normality Assumption\nWe can use ols_plot_resid_hist() of olsrr package to perform normality assumption test.\n\nols_plot_resid_hist(condo.mlr1)\n\n\n\n\n\n\n\n\n\nThe figure reveals that the residual of the multiple linear regression model (i.e. condo.mlr1) is resemble normal distribution.\n\nFor formal statistical test methods, the ols_test_normality() of olsrr package can be used as well.\n\nols_test_normality(condo.mlr1)\n\nWarning in ks.test.default(y, \"pnorm\", mean(y), sd(y)): ties should not be\npresent for the one-sample Kolmogorov-Smirnov test\n\n\n-----------------------------------------------\n       Test             Statistic       pvalue  \n-----------------------------------------------\nShapiro-Wilk              0.6856         0.0000 \nKolmogorov-Smirnov        0.1366         0.0000 \nCramer-von Mises         121.0768        0.0000 \nAnderson-Darling         67.9551         0.0000 \n-----------------------------------------------\n\n\n\nThe summary table above shows that the p-values for all four tests are much smaller than the alpha value of 0.05. Therefore, we reject the null hypothesis and conclude that there is statistical evidence that the residuals are not normally distributed.\n\n\n\n6.3.7 Testing for Spatial Autocorrelation\nThe hedonic model we are building uses geographically referenced attributes, so it is important to visualize the residuals of the hedonic pricing model.\nTo perform a spatial autocorrelation test, we first need to convert the condo_resale.sf object from an sf data frame into a SpatialPointsDataFrame.\n\n6.3.7.1 Export the residual of hedonic pricing model\nExport the residual of the hedonic pricing model and save it as a data frame.\n\nmlr.output &lt;- as.data.frame(condo.mlr1$residuals)\n\n\n\n6.3.7.2 Join with condo_resale.sf object\nJoin the newly created data frame with condo_resale.sf object.\n\ncondo_resale.res.sf &lt;- cbind(condo_resale.sf, \n                        condo.mlr1$residuals) %&gt;%\nrename(`MLR_RES` = `condo.mlr1.residuals`)\n\n\n\n6.3.7.3 Convert to SpatialPointsDataFrame\nConvert condo_resale.res.sf simple feature object into a SpatialPointsDataFrame because spdep package can only process sp conformed spatial data objects\n\ncondo_resale.sp &lt;- as_Spatial(condo_resale.res.sf)\ncondo_resale.sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1436 \nextent      : 14940.85, 43352.45, 24765.67, 48382.81  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 23\nnames       : POSTCODE, SELLING_PRICE, AREA_SQM, AGE,    PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN,    PROX_MRT,   PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH, PROX_SHOPPING_MALL, ... \nmin values  :    18965,        540000,       34,   0, 0.386916393,    0.004927023,      0.054508623,          0.214539508,        0.051817113,       0.004927023, 0.052779424, 0.029064164,      0.077106132,          0.077106132,                  0, ... \nmax values  :   828833,       1.8e+07,      619,  37, 19.18042832,     3.46572633,      3.949157205,           9.15540001,        5.374348075,       2.229045366,  3.48037319,  2.16104919,      3.928989144,          6.748192062,        3.477433767, ... \n\n\n\n\n6.3.7.4 Plot interactive point symbol map\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(mpsz_svy21)+\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(alpha = 0.4) +\ntm_shape(condo_resale.res.sf) +  \n  tm_dots(col = \"MLR_RES\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\nWarning: The shape mpsz_svy21 is invalid (after reprojection). See\nsf::st_is_valid\n\n\nVariable(s) \"MLR_RES\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\n\nThe figure above reveal that there is sign of spatial autocorrelation.\nTo proof that our observation is indeed true, the Moran’s I test will be performed\n\n\n\n6.3.7.5 Moran’s I test\nTo perform Moran’s I test, we will compute the distance-based weight matrix by using dnearneigh() function of spdep.\n\nnb &lt;- dnearneigh(coordinates(condo_resale.sp), 0, 1500, longlat = FALSE)\nsummary(nb)\n\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \n10 disjoint connected subgraphs\nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\n\nNext, nb2listw() of spdep packge will be used to convert the output neighbours lists (i.e. nb) into a spatial weights.\n\nnb_lw &lt;- nb2listw(nb, style = 'W')\nsummary(nb_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \n10 disjoint connected subgraphs\nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\nWeights style: W \nWeights constants summary:\n     n      nn   S0       S1       S2\nW 1436 2062096 1436 94.81916 5798.341\n\n\nNext, lm.morantest() of spdep package will be used to perform Moran’s I test for residual spatial autocorrelation\n\nlm.morantest(condo.mlr1, nb_lw)\n\n\n    Global Moran I for regression residuals\n\ndata:  \nmodel: lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD +\nPROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_MRT +\nPROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP +\nNO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data = condo_resale.sf)\nweights: nb_lw\n\nMoran I statistic standard deviate = 24.366, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nObserved Moran I      Expectation         Variance \n    1.438876e-01    -5.487594e-03     3.758259e-05 \n\n\n\nThe Global Moran’s I test for residual spatial autocorrelation indicates that its p-value is less than 0.00000000000000022, which is below the alpha level of 0.05. Hence, we reject the null hypothesis that the residuals are randomly distributed.\nSince the observed Global Moran’s I value is 0.1424418, which is greater than zero, we can infer that the residuals exhibit a clustered spatial distribution."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex07/hands_on_ex07.html#building-fixed-bandwidth-gwr-model",
    "href": "hands_on_ex/hands_on_ex07/hands_on_ex07.html#building-fixed-bandwidth-gwr-model",
    "title": "Hands-on Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "7.1 Building Fixed Bandwidth GWR model",
    "text": "7.1 Building Fixed Bandwidth GWR model\n\n7.1.1 Compute fixed bandwidth\nIn the code chunk below, the bw.gwr() function from the GWmodel package is used to determine the optimal fixed bandwidth for the model. Notice that the argument adaptive is set to FALSE, indicating that we are interested in computing a fixed bandwidth.\nThere are two possible approaches that can be used to determine the stopping rule: the cross-validation (CV) approach and the corrected Akaike Information Criterion (AICc) approach. We define the stopping rule using an agreement between these approaches.\n\nbw.fixed &lt;- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                     PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                     PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                     PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                     FAMILY_FRIENDLY + FREEHOLD, \n                   data=condo_resale.sp, \n                   approach=\"CV\", \n                   kernel=\"gaussian\", \n                   adaptive=FALSE, \n                   longlat=FALSE)\n\nFixed bandwidth: 17660.96 CV score: 8.259118e+14 \nFixed bandwidth: 10917.26 CV score: 7.970454e+14 \nFixed bandwidth: 6749.419 CV score: 7.273273e+14 \nFixed bandwidth: 4173.553 CV score: 6.300006e+14 \nFixed bandwidth: 2581.58 CV score: 5.404958e+14 \nFixed bandwidth: 1597.687 CV score: 4.857515e+14 \nFixed bandwidth: 989.6077 CV score: 4.722431e+14 \nFixed bandwidth: 613.7939 CV score: 1.379526e+16 \nFixed bandwidth: 1221.873 CV score: 4.778717e+14 \nFixed bandwidth: 846.0596 CV score: 4.791629e+14 \nFixed bandwidth: 1078.325 CV score: 4.751406e+14 \nFixed bandwidth: 934.7772 CV score: 4.72518e+14 \nFixed bandwidth: 1023.495 CV score: 4.730305e+14 \nFixed bandwidth: 968.6643 CV score: 4.721317e+14 \nFixed bandwidth: 955.7206 CV score: 4.722072e+14 \nFixed bandwidth: 976.6639 CV score: 4.721387e+14 \nFixed bandwidth: 963.7202 CV score: 4.721484e+14 \nFixed bandwidth: 971.7199 CV score: 4.721293e+14 \nFixed bandwidth: 973.6083 CV score: 4.721309e+14 \nFixed bandwidth: 970.5527 CV score: 4.721295e+14 \nFixed bandwidth: 972.4412 CV score: 4.721296e+14 \nFixed bandwidth: 971.2741 CV score: 4.721292e+14 \nFixed bandwidth: 970.9985 CV score: 4.721293e+14 \nFixed bandwidth: 971.4443 CV score: 4.721292e+14 \nFixed bandwidth: 971.5496 CV score: 4.721293e+14 \nFixed bandwidth: 971.3793 CV score: 4.721292e+14 \nFixed bandwidth: 971.3391 CV score: 4.721292e+14 \nFixed bandwidth: 971.3143 CV score: 4.721292e+14 \nFixed bandwidth: 971.3545 CV score: 4.721292e+14 \nFixed bandwidth: 971.3296 CV score: 4.721292e+14 \nFixed bandwidth: 971.345 CV score: 4.721292e+14 \nFixed bandwidth: 971.3355 CV score: 4.721292e+14 \nFixed bandwidth: 971.3413 CV score: 4.721292e+14 \nFixed bandwidth: 971.3377 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3396 CV score: 4.721292e+14 \nFixed bandwidth: 971.3402 CV score: 4.721292e+14 \nFixed bandwidth: 971.3398 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3399 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \n\n\n\nThe results indicate that the recommended bandwidth is 971.34 meters.\nThe projection coordinate system used is SVY21, which operates in meters. This explains why the results are presented in meters.\n\n\n\n7.1.2 Construct the fixed bandwidth gwr model\nWe will calibrate the GWR (Geographically Weighted Regression) model using a fixed bandwidth and a Gaussian kernel. The output is saved as a list of class gwrm.\n\ngwr.fixed &lt;- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                         PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                         PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                         PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                         FAMILY_FRIENDLY + FREEHOLD, \n                       data=condo_resale.sp, \n                       bw=bw.fixed, \n                       kernel = 'gaussian', \n                       longlat = FALSE)\ngwr.fixed\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-09-27 21:08:54.577932 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.fixed, kernel = \"gaussian\", \n    longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Fixed bandwidth: 971.34 \n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -3.5988e+07 -5.1998e+05  7.6780e+05  1.7412e+06\n   AREA_SQM              1.0003e+03  5.2758e+03  7.4740e+03  1.2301e+04\n   AGE                  -1.3475e+05 -2.0813e+04 -8.6260e+03 -3.7784e+03\n   PROX_CBD             -7.7047e+07 -2.3608e+05 -8.3599e+04  3.4646e+04\n   PROX_CHILDCARE       -6.0097e+06 -3.3667e+05 -9.7426e+04  2.9007e+05\n   PROX_ELDERLYCARE     -3.5001e+06 -1.5970e+05  3.1970e+04  1.9577e+05\n   PROX_URA_GROWTH_AREA -3.0170e+06 -8.2013e+04  7.0749e+04  2.2612e+05\n   PROX_MRT             -3.5282e+06 -6.5836e+05 -1.8833e+05  3.6922e+04\n   PROX_PARK            -1.2062e+06 -2.1732e+05  3.5383e+04  4.1335e+05\n   PROX_PRIMARY_SCH     -2.2695e+07 -1.7066e+05  4.8472e+04  5.1555e+05\n   PROX_SHOPPING_MALL   -7.2585e+06 -1.6684e+05 -1.0517e+04  1.5923e+05\n   PROX_BUS_STOP        -1.4676e+06 -4.5207e+04  3.7601e+05  1.1664e+06\n   NO_Of_UNITS          -1.3170e+03 -2.4822e+02 -3.0846e+01  2.5496e+02\n   FAMILY_FRIENDLY      -2.2749e+06 -1.1140e+05  7.6214e+03  1.6107e+05\n   FREEHOLD             -9.2067e+06  3.8074e+04  1.5169e+05  3.7528e+05\n                             Max.\n   Intercept            112794435\n   AREA_SQM                 21575\n   AGE                     434203\n   PROX_CBD               2704604\n   PROX_CHILDCARE         1654086\n   PROX_ELDERLYCARE      38867861\n   PROX_URA_GROWTH_AREA  78515805\n   PROX_MRT               3124325\n   PROX_PARK             18122439\n   PROX_PRIMARY_SCH       4637517\n   PROX_SHOPPING_MALL     1529953\n   PROX_BUS_STOP         11342209\n   NO_Of_UNITS              12907\n   FAMILY_FRIENDLY        1720745\n   FREEHOLD               6073642\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 438.3807 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 997.6193 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 42263.61 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41632.36 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 42515.71 \n   Residual sum of squares: 2.534069e+14 \n   R-square value:  0.8909912 \n   Adjusted R-square value:  0.8430418 \n\n   ***********************************************************************\n   Program stops at: 2024-09-27 21:08:55.512363 \n\n\n\nThe report shows that the AICc of the gwr is 42263.61 which is significantly smaller than the globel multiple linear regression model of 42967.14."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex07/hands_on_ex07.html#building-adaptive-bandwidth-gwr-model",
    "href": "hands_on_ex/hands_on_ex07/hands_on_ex07.html#building-adaptive-bandwidth-gwr-model",
    "title": "Hands-on Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "7.2 Building Adaptive Bandwidth GWR Model",
    "text": "7.2 Building Adaptive Bandwidth GWR Model\nIn this section, we will calibrate the gwr-based hedonic pricing model by using adaptive bandwidth approach.\n\n7.2.1 Compute adaptive bandwidth\n\nSimilar to the earlier section, we will first use bw.gwr() to determine the recommended data point to use.\nNote: adaptive argument set to TRUE.\n\n\nbw.adaptive &lt;- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE  + \n                        PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE    + \n                        PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                        PROX_PRIMARY_SCH + PROX_SHOPPING_MALL   + PROX_BUS_STOP + \n                        NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                      data=condo_resale.sp, \n                      approach=\"CV\", \n                      kernel=\"gaussian\", \n                      adaptive=TRUE, \n                      longlat=FALSE)\n\nAdaptive bandwidth: 895 CV score: 7.952401e+14 \nAdaptive bandwidth: 561 CV score: 7.667364e+14 \nAdaptive bandwidth: 354 CV score: 6.953454e+14 \nAdaptive bandwidth: 226 CV score: 6.15223e+14 \nAdaptive bandwidth: 147 CV score: 5.674373e+14 \nAdaptive bandwidth: 98 CV score: 5.426745e+14 \nAdaptive bandwidth: 68 CV score: 5.168117e+14 \nAdaptive bandwidth: 49 CV score: 4.859631e+14 \nAdaptive bandwidth: 37 CV score: 4.646518e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \nAdaptive bandwidth: 25 CV score: 4.430816e+14 \nAdaptive bandwidth: 32 CV score: 4.505602e+14 \nAdaptive bandwidth: 27 CV score: 4.462172e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \n\n\n\nThe result shows that the 30 is the recommended data points to be used.\n\n\n\n7.2.2 Construct the adaptive bandwidth gwr model\nWe will now calibrate the GWR-based hedonic pricing model using an adaptive bandwidth and a Gaussian kernel.\n\ngwr.adaptive &lt;- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                            PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + \n                            PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                            PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + \n                            NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                          data=condo_resale.sp, bw=bw.adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE, \n                          longlat = FALSE)\ngwr.adaptive\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-09-27 21:09:03.214476 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 30 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -1.3487e+08 -2.4669e+05  7.7928e+05  1.6194e+06\n   AREA_SQM              3.3188e+03  5.6285e+03  7.7825e+03  1.2738e+04\n   AGE                  -9.6746e+04 -2.9288e+04 -1.4043e+04 -5.6119e+03\n   PROX_CBD             -2.5330e+06 -1.6256e+05 -7.7242e+04  2.6624e+03\n   PROX_CHILDCARE       -1.2790e+06 -2.0175e+05  8.7158e+03  3.7778e+05\n   PROX_ELDERLYCARE     -1.6212e+06 -9.2050e+04  6.1029e+04  2.8184e+05\n   PROX_URA_GROWTH_AREA -7.2686e+06 -3.0350e+04  4.5869e+04  2.4613e+05\n   PROX_MRT             -4.3781e+07 -6.7282e+05 -2.2115e+05 -7.4593e+04\n   PROX_PARK            -2.9020e+06 -1.6782e+05  1.1601e+05  4.6572e+05\n   PROX_PRIMARY_SCH     -8.6418e+05 -1.6627e+05 -7.7853e+03  4.3222e+05\n   PROX_SHOPPING_MALL   -1.8272e+06 -1.3175e+05 -1.4049e+04  1.3799e+05\n   PROX_BUS_STOP        -2.0579e+06 -7.1461e+04  4.1104e+05  1.2071e+06\n   NO_Of_UNITS          -2.1993e+03 -2.3685e+02 -3.4699e+01  1.1657e+02\n   FAMILY_FRIENDLY      -5.9879e+05 -5.0927e+04  2.6173e+04  2.2481e+05\n   FREEHOLD             -1.6340e+05  4.0765e+04  1.9023e+05  3.7960e+05\n                            Max.\n   Intercept            18758355\n   AREA_SQM                23064\n   AGE                     13303\n   PROX_CBD             11346650\n   PROX_CHILDCARE        2892127\n   PROX_ELDERLYCARE      2465671\n   PROX_URA_GROWTH_AREA  7384059\n   PROX_MRT              1186242\n   PROX_PARK             2588497\n   PROX_PRIMARY_SCH      3381462\n   PROX_SHOPPING_MALL   38038564\n   PROX_BUS_STOP        12081592\n   NO_Of_UNITS              1010\n   FAMILY_FRIENDLY       2072414\n   FREEHOLD              1813995\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 350.3088 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 1085.691 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 41982.22 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41546.74 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 41914.08 \n   Residual sum of squares: 2.528227e+14 \n   R-square value:  0.8912425 \n   Adjusted R-square value:  0.8561185 \n\n   ***********************************************************************\n   Program stops at: 2024-09-27 21:09:04.347509 \n\n\n\nThe report shows that the AICc for the adaptive bandwidth GWR is 41982.22, which is smaller than the AICc of the fixed bandwidth GWR at 42263.61."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex07/hands_on_ex07.html#visualising-gwr-output",
    "href": "hands_on_ex/hands_on_ex07/hands_on_ex07.html#visualising-gwr-output",
    "title": "Hands-on Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "7.3 Visualising GWR Output",
    "text": "7.3 Visualising GWR Output\nIn addition to regression residuals, the output feature class table includes fields for observed and predicted y values, condition number (cond), Local R2, residuals, and explanatory variable coefficients and standard errors:\n\nCondition Number: evaluates local collinearity. In the presence of strong local collinearity, results become unstable. Results associated with condition numbers larger than 30, may be unreliable\nLocal R2: these values range between 0.0 and 1.0 and indicate how well the local regression model fits observed y values.\n\nVery low values indicate the local model is performing poorly.\nMapping the Local R2 values to see where GWR predicts well and where it predicts poorly may provide clues about important variables that may be missing from the regression model.\n\nPredicted: estimated (or fitted) y values computed by GWR.\nResiduals: to obtain the residual values, the fitted y values are subtracted from the observed y values.\n\nStandardized residuals have a mean of zero and a standard deviation of 1.\nA cold-to-hot rendered map of standardized residuals can be produce by using these values.\n\nCoefficient Standard Error: these values measure the reliability of each coefficient estimate.\n\nConfidence in those estimates are higher when standard errors are small in relation to the actual coefficient values.\nLarge standard errors may indicate problems with local collinearity.\n\n\nThey are all stored in a SpatialPointsDataFrame or SpatialPolygonsDataFrame object integrated with fit.points, GWR coefficient estimates, y value, predicted values, coefficient standard errors and t-values in its “data” slot in an object called SDF of the output list.\n\n7.3.1 Converting SDF into sf data.frame\nTo visualise the fields in SDF, we need to first convert it into sf data.frame.\n\ncondo_resale.sf.adaptive &lt;- st_as_sf(gwr.adaptive$SDF) %&gt;%\n  st_transform(crs=3414)\n\n\ncondo_resale.sf.adaptive.svy21 &lt;- st_transform(condo_resale.sf.adaptive, 3414)\ncondo_resale.sf.adaptive.svy21  \n\nSimple feature collection with 1436 features and 51 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14940.85 ymin: 24765.67 xmax: 43352.45 ymax: 48382.81\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n    Intercept  AREA_SQM        AGE  PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE\n1   2050011.7  9561.892  -9514.634 -120681.9      319266.92       -393417.79\n2   1633128.2 16576.853 -58185.479 -149434.2      441102.18        325188.74\n3   3433608.2 13091.861 -26707.386 -259397.8     -120116.82        535855.81\n4    234358.9 20730.601 -93308.988 2426853.7      480825.28        314783.72\n5   2285804.9  6722.836 -17608.018 -316835.5       90764.78       -137384.61\n6  -3568877.4  6039.581 -26535.592  327306.1     -152531.19       -700392.85\n7  -2874842.4 16843.575 -59166.727 -983577.2     -177810.50       -122384.02\n8   2038086.0  6905.135 -17681.897 -285076.6       70259.40        -96012.78\n9   1718478.4  9580.703 -14401.128  105803.4     -657698.02       -123276.00\n10  3457054.0 14072.011 -31579.884 -234895.4       79961.45        548581.04\n   PROX_URA_GROWTH_AREA    PROX_MRT  PROX_PARK PROX_PRIMARY_SCH\n1            -159980.20  -299742.96 -172104.47        242668.03\n2            -142290.39 -2510522.23  523379.72       1106830.66\n3            -253621.21  -936853.28  209099.85        571462.33\n4           -2679297.89 -2039479.50 -759153.26       3127477.21\n5             303714.81   -44567.05  -10284.62         30413.56\n6             -28051.25   733566.47 1511488.92        320878.23\n7            1397676.38 -2745430.34  710114.74       1786570.95\n8             269368.71   -14552.99   73533.34         53359.73\n9            -361974.72  -476785.32 -132067.59        -40128.92\n10           -150024.38 -1503835.53  574155.47        108996.67\n   PROX_SHOPPING_MALL PROX_BUS_STOP  NO_Of_UNITS FAMILY_FRIENDLY  FREEHOLD\n1          300881.390     1210615.4  104.8290640       -9075.370  303955.6\n2          -87693.378     1843587.2 -288.3441183      310074.664  396221.3\n3         -126732.712     1411924.9   -9.5532945        5949.746  168821.7\n4          -29593.342     7225577.5 -161.3551620     1556178.531 1212515.6\n5           -7490.586      677577.0   42.2659674       58986.951  328175.2\n6          258583.881     1086012.6 -214.3671271      201992.641  471873.1\n7         -384251.210     5094060.5   -0.9212521      359659.512  408871.9\n8          -39634.902      735767.1   30.1741069       55602.506  347075.0\n9          276718.757     2815772.4  675.1615559      -30453.297  503872.8\n10        -454726.822     2123557.0  -21.3044311     -100935.586  213324.6\n         y    yhat    residual CV_Score Stud_residual Intercept_SE AREA_SQM_SE\n1  3000000 2886532   113468.16        0    0.38207013     516105.5    823.2860\n2  3880000 3466801   413198.52        0    1.01433140     488083.5    825.2380\n3  3325000 3616527  -291527.20        0   -0.83780678     963711.4    988.2240\n4  4250000 5435482 -1185481.63        0   -2.84614670     444185.5    617.4007\n5  1400000 1388166    11834.26        0    0.03404453    2119620.6   1376.2778\n6  1320000 1516702  -196701.95        0   -0.72065801   28572883.7   2348.0091\n7  3410000 3266881   143118.77        0    0.41291992     679546.6    893.5893\n8  1420000 1431955   -11955.27        0   -0.03033109    2217773.1   1415.2604\n9  2025000 1832799   192200.83        0    0.52018109     814281.8    943.8434\n10 2550000 2223364   326635.53        0    1.10559735    2410252.0   1271.4073\n      AGE_SE PROX_CBD_SE PROX_CHILDCARE_SE PROX_ELDERLYCARE_SE\n1   5889.782    37411.22          319111.1           120633.34\n2   6226.916    23615.06          299705.3            84546.69\n3   6510.236    56103.77          349128.5           129687.07\n4   6010.511   469337.41          304965.2           127150.69\n5   8180.361   410644.47          698720.6           327371.55\n6  14601.909  5272846.47         1141599.8          1653002.19\n7   8970.629   346164.20          530101.1           148598.71\n8   8661.309   438035.69          742532.8           399221.05\n9  11791.208    89148.35          704630.7           329683.30\n10  9941.980   173532.77          500976.2           281876.74\n   PROX_URA_GROWTH_AREA_SE PROX_MRT_SE PROX_PARK_SE PROX_PRIMARY_SCH_SE\n1                 56207.39    185181.3     205499.6            152400.7\n2                 76956.50    281133.9     229358.7            165150.7\n3                 95774.60    275483.7     314124.3            196662.6\n4                470762.12    279877.1     227249.4            240878.9\n5                474339.56    363830.0     364580.9            249087.7\n6               5496627.21    730453.2    1741712.0            683265.5\n7                371692.97    375511.9     297400.9            344602.8\n8                517977.91    423155.4     440984.4            261251.2\n9                153436.22    285325.4     304998.4            278258.5\n10               239182.57    571355.7     599131.8            331284.8\n   PROX_SHOPPING_MALL_SE PROX_BUS_STOP_SE NO_Of_UNITS_SE FAMILY_FRIENDLY_SE\n1               109268.8         600668.6       218.1258           131474.7\n2                98906.8         410222.1       208.9410           114989.1\n3               119913.3         464156.7       210.9828           146607.2\n4               177104.1         562810.8       361.7767           108726.6\n5               301032.9         740922.4       299.5034           160663.7\n6              2931208.6        1418333.3       602.5571           331727.0\n7               249969.5         821236.4       532.1978           129241.2\n8               351634.0         775038.4       338.6777           171895.1\n9               289872.7         850095.5       439.9037           220223.4\n10              265529.7         631399.2       259.0169           189125.5\n   FREEHOLD_SE Intercept_TV AREA_SQM_TV     AGE_TV PROX_CBD_TV\n1     115954.0    3.9720784   11.614302  -1.615447 -3.22582173\n2     130110.0    3.3460017   20.087361  -9.344188 -6.32792021\n3     141031.5    3.5629010   13.247868  -4.102368 -4.62353528\n4     138239.1    0.5276150   33.577223 -15.524302  5.17080808\n5     210641.1    1.0784029    4.884795  -2.152474 -0.77155660\n6     374347.3   -0.1249043    2.572214  -1.817269  0.06207388\n7     182216.9   -4.2305303   18.849348  -6.595605 -2.84136028\n8     216649.4    0.9189786    4.879056  -2.041481 -0.65080678\n9     220473.7    2.1104224   10.150733  -1.221345  1.18682383\n10    206346.2    1.4343123   11.068059  -3.176418 -1.35360852\n   PROX_CHILDCARE_TV PROX_ELDERLYCARE_TV PROX_URA_GROWTH_AREA_TV PROX_MRT_TV\n1         1.00048819          -3.2612693            -2.846248368 -1.61864578\n2         1.47178634           3.8462625            -1.848971738 -8.92998600\n3        -0.34404755           4.1319138            -2.648105057 -3.40075727\n4         1.57665606           2.4756745            -5.691404992 -7.28705261\n5         0.12990138          -0.4196596             0.640289855 -0.12249416\n6        -0.13361179          -0.4237096            -0.005103357  1.00426206\n7        -0.33542751          -0.8235874             3.760298131 -7.31116712\n8         0.09462126          -0.2405003             0.520038994 -0.03439159\n9        -0.93339393          -0.3739225            -2.359121712 -1.67102293\n10        0.15961128           1.9461735            -0.627237944 -2.63204802\n   PROX_PARK_TV PROX_PRIMARY_SCH_TV PROX_SHOPPING_MALL_TV PROX_BUS_STOP_TV\n1   -0.83749312           1.5923022            2.75358842        2.0154464\n2    2.28192684           6.7019454           -0.88662640        4.4941192\n3    0.66565951           2.9058009           -1.05686949        3.0419145\n4   -3.34061770          12.9836105           -0.16709578       12.8383775\n5   -0.02820944           0.1220998           -0.02488294        0.9145046\n6    0.86781794           0.4696245            0.08821750        0.7656963\n7    2.38773567           5.1844351           -1.53719231        6.2029165\n8    0.16674816           0.2042469           -0.11271635        0.9493299\n9   -0.43301073          -0.1442145            0.95462153        3.3123012\n10   0.95831249           0.3290120           -1.71252687        3.3632555\n   NO_Of_UNITS_TV FAMILY_FRIENDLY_TV FREEHOLD_TV  Local_R2\n1     0.480589953        -0.06902748    2.621347 0.8846744\n2    -1.380026395         2.69655779    3.045280 0.8899773\n3    -0.045279967         0.04058290    1.197050 0.8947007\n4    -0.446007570        14.31276425    8.771149 0.9073605\n5     0.141120178         0.36714544    1.557983 0.9510057\n6    -0.355762335         0.60891234    1.260522 0.9247586\n7    -0.001731033         2.78285441    2.243875 0.8310458\n8     0.089093858         0.32346758    1.602012 0.9463936\n9     1.534793921        -0.13828365    2.285410 0.8380365\n10   -0.082251138        -0.53369623    1.033819 0.9080753\n                    geometry\n1  POINT (22085.12 29951.54)\n2   POINT (25656.84 34546.2)\n3   POINT (23963.99 32890.8)\n4  POINT (27044.28 32319.77)\n5  POINT (41042.56 33743.64)\n6   POINT (39717.04 32943.1)\n7   POINT (28419.1 33513.37)\n8  POINT (40763.57 33879.61)\n9  POINT (23595.63 28884.78)\n10 POINT (24586.56 33194.31)\n\n\n\ngwr.adaptive.output &lt;- as.data.frame(gwr.adaptive$SDF)\ncondo_resale.sf.adaptive &lt;- cbind(condo_resale.res.sf, as.matrix(gwr.adaptive.output))\n\n\nglimpse(condo_resale.sf.adaptive)\n\nRows: 1,436\nColumns: 77\n$ POSTCODE                &lt;dbl&gt; 118635, 288420, 267833, 258380, 467169, 466472…\n$ SELLING_PRICE           &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ AREA_SQM                &lt;dbl&gt; 309, 290, 248, 127, 145, 139, 218, 141, 165, 1…\n$ AGE                     &lt;dbl&gt; 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22,…\n$ PROX_CBD                &lt;dbl&gt; 7.941259, 6.609797, 6.898000, 4.038861, 11.783…\n$ PROX_CHILDCARE          &lt;dbl&gt; 0.16597932, 0.28027246, 0.42922669, 0.39473543…\n$ PROX_ELDERLYCARE        &lt;dbl&gt; 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.…\n$ PROX_URA_GROWTH_AREA    &lt;dbl&gt; 6.618741, 7.505109, 6.463887, 4.906512, 6.4106…\n$ PROX_HAWKER_MARKET      &lt;dbl&gt; 1.76542207, 0.54507614, 0.37789301, 1.68259969…\n$ PROX_KINDERGARTEN       &lt;dbl&gt; 0.05835552, 0.61592412, 0.14120309, 0.38200076…\n$ PROX_MRT                &lt;dbl&gt; 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.…\n$ PROX_PARK               &lt;dbl&gt; 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.…\n$ PROX_PRIMARY_SCH        &lt;dbl&gt; 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.…\n$ PROX_TOP_PRIMARY_SCH    &lt;dbl&gt; 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.…\n$ PROX_SHOPPING_MALL      &lt;dbl&gt; 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.…\n$ PROX_SUPERMARKET        &lt;dbl&gt; 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.…\n$ PROX_BUS_STOP           &lt;dbl&gt; 0.10336166, 0.28673408, 0.28504777, 0.29872340…\n$ NO_Of_UNITS             &lt;dbl&gt; 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34…\n$ FAMILY_FRIENDLY         &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD                &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR          &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ LOG_SELLING_PRICE       &lt;dbl&gt; 14.91412, 15.17135, 15.01698, 15.26243, 14.151…\n$ MLR_RES                 &lt;dbl&gt; -1489099.55, 415494.57, 194129.69, 1088992.71,…\n$ Intercept               &lt;dbl&gt; 2050011.67, 1633128.24, 3433608.17, 234358.91,…\n$ AREA_SQM.1              &lt;dbl&gt; 9561.892, 16576.853, 13091.861, 20730.601, 672…\n$ AGE.1                   &lt;dbl&gt; -9514.634, -58185.479, -26707.386, -93308.988,…\n$ PROX_CBD.1              &lt;dbl&gt; -120681.94, -149434.22, -259397.77, 2426853.66…\n$ PROX_CHILDCARE.1        &lt;dbl&gt; 319266.925, 441102.177, -120116.816, 480825.28…\n$ PROX_ELDERLYCARE.1      &lt;dbl&gt; -393417.795, 325188.741, 535855.806, 314783.72…\n$ PROX_URA_GROWTH_AREA.1  &lt;dbl&gt; -159980.203, -142290.389, -253621.206, -267929…\n$ PROX_MRT.1              &lt;dbl&gt; -299742.96, -2510522.23, -936853.28, -2039479.…\n$ PROX_PARK.1             &lt;dbl&gt; -172104.47, 523379.72, 209099.85, -759153.26, …\n$ PROX_PRIMARY_SCH.1      &lt;dbl&gt; 242668.03, 1106830.66, 571462.33, 3127477.21, …\n$ PROX_SHOPPING_MALL.1    &lt;dbl&gt; 300881.390, -87693.378, -126732.712, -29593.34…\n$ PROX_BUS_STOP.1         &lt;dbl&gt; 1210615.44, 1843587.22, 1411924.90, 7225577.51…\n$ NO_Of_UNITS.1           &lt;dbl&gt; 104.8290640, -288.3441183, -9.5532945, -161.35…\n$ FAMILY_FRIENDLY.1       &lt;dbl&gt; -9075.370, 310074.664, 5949.746, 1556178.531, …\n$ FREEHOLD.1              &lt;dbl&gt; 303955.61, 396221.27, 168821.75, 1212515.58, 3…\n$ y                       &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ yhat                    &lt;dbl&gt; 2886531.8, 3466801.5, 3616527.2, 5435481.6, 13…\n$ residual                &lt;dbl&gt; 113468.16, 413198.52, -291527.20, -1185481.63,…\n$ CV_Score                &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Stud_residual           &lt;dbl&gt; 0.38207013, 1.01433140, -0.83780678, -2.846146…\n$ Intercept_SE            &lt;dbl&gt; 516105.5, 488083.5, 963711.4, 444185.5, 211962…\n$ AREA_SQM_SE             &lt;dbl&gt; 823.2860, 825.2380, 988.2240, 617.4007, 1376.2…\n$ AGE_SE                  &lt;dbl&gt; 5889.782, 6226.916, 6510.236, 6010.511, 8180.3…\n$ PROX_CBD_SE             &lt;dbl&gt; 37411.22, 23615.06, 56103.77, 469337.41, 41064…\n$ PROX_CHILDCARE_SE       &lt;dbl&gt; 319111.1, 299705.3, 349128.5, 304965.2, 698720…\n$ PROX_ELDERLYCARE_SE     &lt;dbl&gt; 120633.34, 84546.69, 129687.07, 127150.69, 327…\n$ PROX_URA_GROWTH_AREA_SE &lt;dbl&gt; 56207.39, 76956.50, 95774.60, 470762.12, 47433…\n$ PROX_MRT_SE             &lt;dbl&gt; 185181.3, 281133.9, 275483.7, 279877.1, 363830…\n$ PROX_PARK_SE            &lt;dbl&gt; 205499.6, 229358.7, 314124.3, 227249.4, 364580…\n$ PROX_PRIMARY_SCH_SE     &lt;dbl&gt; 152400.7, 165150.7, 196662.6, 240878.9, 249087…\n$ PROX_SHOPPING_MALL_SE   &lt;dbl&gt; 109268.8, 98906.8, 119913.3, 177104.1, 301032.…\n$ PROX_BUS_STOP_SE        &lt;dbl&gt; 600668.6, 410222.1, 464156.7, 562810.8, 740922…\n$ NO_Of_UNITS_SE          &lt;dbl&gt; 218.1258, 208.9410, 210.9828, 361.7767, 299.50…\n$ FAMILY_FRIENDLY_SE      &lt;dbl&gt; 131474.73, 114989.07, 146607.22, 108726.62, 16…\n$ FREEHOLD_SE             &lt;dbl&gt; 115954.0, 130110.0, 141031.5, 138239.1, 210641…\n$ Intercept_TV            &lt;dbl&gt; 3.9720784, 3.3460017, 3.5629010, 0.5276150, 1.…\n$ AREA_SQM_TV             &lt;dbl&gt; 11.614302, 20.087361, 13.247868, 33.577223, 4.…\n$ AGE_TV                  &lt;dbl&gt; -1.6154474, -9.3441881, -4.1023685, -15.524301…\n$ PROX_CBD_TV             &lt;dbl&gt; -3.22582173, -6.32792021, -4.62353528, 5.17080…\n$ PROX_CHILDCARE_TV       &lt;dbl&gt; 1.000488185, 1.471786337, -0.344047555, 1.5766…\n$ PROX_ELDERLYCARE_TV     &lt;dbl&gt; -3.26126929, 3.84626245, 4.13191383, 2.4756745…\n$ PROX_URA_GROWTH_AREA_TV &lt;dbl&gt; -2.846248368, -1.848971738, -2.648105057, -5.6…\n$ PROX_MRT_TV             &lt;dbl&gt; -1.61864578, -8.92998600, -3.40075727, -7.2870…\n$ PROX_PARK_TV            &lt;dbl&gt; -0.83749312, 2.28192684, 0.66565951, -3.340617…\n$ PROX_PRIMARY_SCH_TV     &lt;dbl&gt; 1.59230221, 6.70194543, 2.90580089, 12.9836104…\n$ PROX_SHOPPING_MALL_TV   &lt;dbl&gt; 2.753588422, -0.886626400, -1.056869486, -0.16…\n$ PROX_BUS_STOP_TV        &lt;dbl&gt; 2.0154464, 4.4941192, 3.0419145, 12.8383775, 0…\n$ NO_Of_UNITS_TV          &lt;dbl&gt; 0.480589953, -1.380026395, -0.045279967, -0.44…\n$ FAMILY_FRIENDLY_TV      &lt;dbl&gt; -0.06902748, 2.69655779, 0.04058290, 14.312764…\n$ FREEHOLD_TV             &lt;dbl&gt; 2.6213469, 3.0452799, 1.1970499, 8.7711485, 1.…\n$ Local_R2                &lt;dbl&gt; 0.8846744, 0.8899773, 0.8947007, 0.9073605, 0.…\n$ coords.x1               &lt;dbl&gt; 22085.12, 25656.84, 23963.99, 27044.28, 41042.…\n$ coords.x2               &lt;dbl&gt; 29951.54, 34546.20, 32890.80, 32319.77, 33743.…\n$ geometry                &lt;POINT [m]&gt; POINT (22085.12 29951.54), POINT (25656.…\n\n\n\nsummary(gwr.adaptive$SDF$yhat)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n  171347  1102001  1385528  1751842  1982307 13887901"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex07/hands_on_ex07.html#visualising-local-r2",
    "href": "hands_on_ex/hands_on_ex07/hands_on_ex07.html#visualising-local-r2",
    "title": "Hands-on Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "7.4 Visualising local R2",
    "text": "7.4 Visualising local R2\nNow we will create an interactive point symbol map.\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"Local_R2\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\nWarning: The shape mpsz_svy21 is invalid (after reprojection). See\nsf::st_is_valid\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex07/hands_on_ex07.html#visualising-coefficient-estimates",
    "href": "hands_on_ex/hands_on_ex07/hands_on_ex07.html#visualising-coefficient-estimates",
    "title": "Hands-on Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "7.5 Visualising coefficient estimates",
    "text": "7.5 Visualising coefficient estimates\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\nAREA_SQM_SE &lt;- tm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"AREA_SQM_SE\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\nAREA_SQM_TV &lt;- tm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"AREA_SQM_TV\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\ntmap_arrange(AREA_SQM_SE, AREA_SQM_TV, \n             asp=1, ncol=2,\n             sync = TRUE)\n\nWarning: The shape mpsz_svy21 is invalid (after reprojection). See\nsf::st_is_valid\nWarning: The shape mpsz_svy21 is invalid (after reprojection). See\nsf::st_is_valid\n\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting"
  },
  {
    "objectID": "in_class_ex/in_class_ex06/in_class_ex06.html",
    "href": "in_class_ex/in_class_ex06/in_class_ex06.html",
    "title": "In-class Exercise 6: Emerging Hot Spot Analysis",
    "section": "",
    "text": "Emerging Hot Spot Analysis (EHSA) is a spatio-temporal analysis method for revealing and describing how hot spot and cold spot areas evolve over time. The analysis consist of four main steps:\n\nBuilding a space-time cube,\nCalculating Getis-Ord local Gi* statistic for each bin by using an FDR correction,\nEvaluating these hot and cold spot trends by using Mann-Kendall trend test,\nCategorising each study area location by referring to the resultant trend z-score and p-value for each location with data, and with the hot spot z-score and p-value for each bin."
  },
  {
    "objectID": "in_class_ex/in_class_ex06/in_class_ex06.html#loading-the-data",
    "href": "in_class_ex/in_class_ex06/in_class_ex06.html#loading-the-data",
    "title": "In-class Exercise 6: Emerging Hot Spot Analysis",
    "section": "4.1 Loading the data",
    "text": "4.1 Loading the data\nIn this section, we will learn how to bring a geospatial data and its associated attribute table into R environment. The geospatial data is in ESRI shapefile format and the attribute table is in csv fomat.\n\nImport geospatial dataImport aspatial dataCreating a Time Series Cube\n\n\nWe use st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be simple features Object of sf.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/Users/cham/project/Geospatial-Analytics/chrismanafe/ISSS626-GAA/in_class_ex/in_class_ex06/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\nRows: 88\nColumns: 8\n$ NAME_2     &lt;chr&gt; \"Changde\", \"Changde\", \"Changde\", \"Changde\", \"Changde\", \"Cha…\n$ ID_3       &lt;int&gt; 21098, 21100, 21101, 21102, 21103, 21104, 21109, 21110, 211…\n$ NAME_3     &lt;chr&gt; \"Anxiang\", \"Hanshou\", \"Jinshi\", \"Li\", \"Linli\", \"Shimen\", \"L…\n$ ENGTYPE_3  &lt;chr&gt; \"County\", \"County\", \"County City\", \"County\", \"County\", \"Cou…\n$ Shape_Leng &lt;dbl&gt; 1.869074, 2.360691, 1.425620, 3.474325, 2.289506, 4.171918,…\n$ Shape_Area &lt;dbl&gt; 0.10056190, 0.19978745, 0.05302413, 0.18908121, 0.11450357,…\n$ County     &lt;chr&gt; \"Anxiang\", \"Hanshou\", \"Jinshi\", \"Li\", \"Linli\", \"Shimen\", \"L…\n$ geometry   &lt;POLYGON [°]&gt; POLYGON ((112.0625 29.75523..., POLYGON ((112.2288 …\n\n\n\n\nThen we will import Hunan_2012.csv into R by using read_csv() of readr package. The output is R dataframe class.\n\nGDPPC &lt;- read_csv(\"data/aspatial/Hunan_GDPPC.csv\")\n\nRows: 1496 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): County\ndbl (2): Year, GDPPC\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nRows: 1,496\nColumns: 3\n$ Year   &lt;dbl&gt; 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 200…\n$ County &lt;chr&gt; \"Longshan\", \"Changsha\", \"Wangcheng\", \"Ningxiang\", \"Liuyang\", \"Z…\n$ GDPPC  &lt;dbl&gt; 3469, 24612, 14659, 11687, 13406, 8546, 10944, 8040, 7383, 1168…\n\n\n\n\nIn the code chunk below, spacetime() of sfdep is used to create an spatio-temporal cube.\n\nGDPPC_st &lt;- spacetime(GDPPC, hunan,\n                      .loc_col = \"County\",\n                      .time_col = \"Year\")\n\nNext, we will use is_spacetime_cube() of sfdep package to verify if GDPPC_st is indeed an space-time cube object.\n\nis_spacetime_cube(GDPPC_st)\n\n[1] TRUE\n\n\n\nThe result confirms that GDPPC_st object is indeed an time-space cube."
  },
  {
    "objectID": "in_class_ex/in_class_ex06/in_class_ex06.html#computing-local-gi-statistics",
    "href": "in_class_ex/in_class_ex06/in_class_ex06.html#computing-local-gi-statistics",
    "title": "In-class Exercise 6: Emerging Hot Spot Analysis",
    "section": "5.1 Computing local Gi* statistics",
    "text": "5.1 Computing local Gi* statistics\nNext, we will compute the local Gi* statistics.\n\n5.1.1 Deriving the spatial weights\nAs with most spatial analyses, we first need to derive a spatial weight matrix before computing the local Gi* statistics. The code chunk below demonstrates how to derive a spatial weight matrix using functions from the sfdep package, combined with the tidyverse approach.\n\nGDPPC_nb &lt;- GDPPC_st %&gt;%\n  activate(\"geometry\") %&gt;%\n  mutate(nb = include_self(st_contiguity(geometry)),\n         wt = st_inverse_distance(nb, geometry,\n                                  scale = 1,\n                                  alpha = 1),\n         .before = 1) %&gt;%\n  set_nbs(\"nb\") %&gt;%\n  set_wts(\"wt\")\n\n! Polygon provided. Using point on surface.\n\n\nWarning: There was 1 warning in `stopifnot()`.\nℹ In argument: `wt = st_inverse_distance(nb, geometry, scale = 1, alpha = 1)`.\nCaused by warning in `st_point_on_surface.sfc()`:\n! st_point_on_surface may not give correct results for longitude/latitude data\n\n\n\n\nactivate() of dplyr package is used to activate the geometry context\nmutate() of dplyr package is used to create two new columns nb and wt.\nThen we will activate the data context again and copy over the nb and wt columns to each time-slice using set_nbs() and set_wts()\n\nrow order is very important so do not rearrange the observations after using set_nbs() or set_wts().\n\n\n\n\n\n5.1.2 Compute Gi*\nWe can manually calculate the local Gi* for each location using the new columns. This is done by grouping the data by Year and applying the local_gstar_perm() function from the sfdep package. Afterward, we can use unnest() to unnest the gi_star column from the newly created gi_stars data frame.\n\ngi_stars &lt;- GDPPC_nb %&gt;% \n  group_by(Year) %&gt;% \n  mutate(gi_star = local_gstar_perm(\n    GDPPC, nb, wt)) %&gt;% \n  tidyr::unnest(gi_star)"
  },
  {
    "objectID": "in_class_ex/in_class_ex06/in_class_ex06.html#mann-kendall-test",
    "href": "in_class_ex/in_class_ex06/in_class_ex06.html#mann-kendall-test",
    "title": "In-class Exercise 6: Emerging Hot Spot Analysis",
    "section": "5.2 Mann-Kendall Test",
    "text": "5.2 Mann-Kendall Test\nA monotonic series or function is one that only increases or decreases and never changes direction. As long as the function either stays flat or continues to increase (or decrease), it is considered monotonic.\n\nH₀ (Null Hypothesis): There is no monotonic trend.\nH₁ (Alternative Hypothesis): A monotonic trend is present.\n\nInterpretation:\n\nReject the null hypothesis (H₀) if the p-value is smaller than the alpha level (i.e., 1 - confidence level).\nTau (τ) ranges between -1 and 1, where:\n\n-1 represents a perfectly decreasing series.\n1 represents a perfectly increasing series.\n\n\n\n5.2.1 Mann-Kendall Test on Gi\nWith these Gi* measures we can then evaluate each location for a trend using the Mann-Kendal test. Let’s use it on Changsha county.\n\ncbg &lt;- gi_stars %&gt;% \n  ungroup() %&gt;% \n  filter(County == \"Changsha\") |&gt; \n  select(County, Year, gi_star)\n\n\n\n5.2.2 Visualize Mann-Kendall Test Result\nNext, we plot the result by using ggplot2 functions.\n\nggplot(data = cbg, \n       aes(x = Year, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\n\n\n\n\n\n\n\nWe can also create an interactive plot by using ggplotly() of plotly package.\n\np &lt;- ggplot(data = cbg, \n       aes(x = Year, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\nggplotly(p)\n\n\n\n\n\n\n\n5.2.3 Print Mann-Kendall test report\n\ncbg %&gt;%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %&gt;%\n  tidyr::unnest_wider(mk)\n\n# A tibble: 1 × 5\n    tau      sl     S     D  varS\n  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 0.485 0.00742    66  136.  589.\n\n\n\nIn the above result, sl is the p-value. With reference to the results, we will reject the null hypothesis and infer there’s a slight upward trend.\n\n\n\n5.2.4 Mann-Kendall test data.frame\nWe can replicate this for each location by using group_by() of dplyr package.\n\nehsa &lt;- gi_stars %&gt;%\n  group_by(County) %&gt;%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %&gt;%\n  tidyr::unnest_wider(mk)\nhead(ehsa)\n\n# A tibble: 6 × 6\n  County        tau        sl     S     D  varS\n  &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Anhua      0.191  0.303        26  136.  589.\n2 Anren     -0.294  0.108       -40  136.  589.\n3 Anxiang    0      1             0  136.  589.\n4 Baojing   -0.691  0.000128    -94  136.  589.\n5 Chaling   -0.0882 0.650       -12  136.  589.\n6 Changning -0.750  0.0000318  -102  136.  589.\n\n\n\n5.2.4.1 Arrange significant emerging hot/cold spots\nWe can also sort to show significant hot spots using following code chunk.\n\nemerging &lt;- ehsa %&gt;% \n  arrange(sl, abs(tau)) %&gt;% \n  slice(1:10)\nemerging\n\n# A tibble: 10 × 6\n   County        tau         sl     S     D  varS\n   &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Shuangfeng  0.868 0.00000143   118  136.  589.\n 2 Xiangtan    0.868 0.00000143   118  136.  589.\n 3 Xiangxiang  0.868 0.00000143   118  136.  589.\n 4 Chengbu    -0.824 0.00000482  -112  136.  589.\n 5 Dongan     -0.824 0.00000482  -112  136.  589.\n 6 Wugang     -0.809 0.00000712  -110  136.  589.\n 7 Huayuan    -0.794 0.0000105   -108  136.  589.\n 8 Shaoshan    0.794 0.0000105    108  136.  589.\n 9 Liuyang     0.779 0.0000153    106  136.  589.\n10 Zhuzhou     0.765 0.0000221    104  136.  589.\n\n\n\n\n\n5.2.5 Performing Emerging Hotspot Analysis\nLastly, we will perform EHSA analysis by using emerging_hotspot_analysis() of sfdep package. It takes a spacetime object x (i.e. GDPPC_st), and the quoted name of the variable of interest (i.e. GDPPC) for .var argument. The k argument is used to specify the number of time lags which is set to 1 by default. Lastly, nsim map numbers of simulation to be performed.\n\nehsa &lt;- emerging_hotspot_analysis(\n  x = GDPPC_st, \n  .var = \"GDPPC\", \n  k = 1, \n  nsim = 99\n)\n\n\n\n5.2.6 Visualising the distribution of EHSA classes\nWe’ll visualise the distribution of EHSA classes using ggplot2 functions.\n\nggplot(data = ehsa,\n       aes(x = classification)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\nThe figure above shows that sporadic cold spots class has the high numbers of county.\n\n\n\n5.2.7 Visualising EHSA\nIn this section, we will visualise the geographic distribution EHSA classes. However, before we can do so, we need to join both hunan and ehsa together by using the code chunk below.\n\nhunan_ehsa &lt;- hunan %&gt;%\n  left_join(ehsa,\n            by = join_by(County == location))\n\nNext, tmap functions will be used to plot a categorical choropleth map by using the code chunk below.\n\nehsa_sig &lt;- hunan_ehsa  %&gt;%\n  filter(p_value &lt; 0.05)\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(hunan_ehsa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(ehsa_sig) +\n  tm_fill(\"classification\") + \n  tm_borders(alpha = 0.4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them)."
  },
  {
    "objectID": "take_home_ex/take_home_ex02/take_home_ex02.html",
    "href": "take_home_ex/take_home_ex02/take_home_ex02.html",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "",
    "text": "Tourism is one of Thailand’s largest industries, contributing approximately 20% to the country’s gross domestic product (GDP). In 2019, Thailand generated 90 billion US dollars from both domestic and international tourism, but this figure plummeted to 24 billion US dollars in 2020 due to the COVID-19 pandemic.\nSince September 2021, the tourism sector has been steadily recovering. However, it’s important to note that the tourism economy in Thailand is not evenly distributed across the country, with much of the activity concentrated in key provinces such as Bangkok, Phuket, and Chiang Mai."
  },
  {
    "objectID": "take_home_ex/take_home_ex02/take_home_ex02.html#the-packages",
    "href": "take_home_ex/take_home_ex02/take_home_ex02.html#the-packages",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "3.1 The Packages",
    "text": "3.1 The Packages\nIn this exercise, we will use following packages:\n\n\n\n\n\n\n\nPackage\nDescription\n\n\n\n\nsf\nProvides functions to manage, processing, and manipulate Simple Features, a formal geospatial data standard that specifies a storage and access model of spatial geometries such as points, lines, and polygons.\n\n\nsfdep\nProvides collection of functions to create spatial weights matrix objects from polygon ‘contiguities’, from point patterns by distance and tessellations.\n\n\ntidyverse\nProvides collection of functions for performing data science task such as importing, tidying, wrangling data and visualising data.\n\n\ntmap\nProvides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API\n\n\ncorrplot\nProvides functions for visualizing correlation matrices.\n\n\nheatmaply\nProvides an easy-to-use interface for creating interactive heatmaps.\n\n\n\n\npacman::p_load(sf, sfdep, tmap, tidyverse, corrplot, heatmaply)"
  },
  {
    "objectID": "take_home_ex/take_home_ex02/take_home_ex02.html#the-data",
    "href": "take_home_ex/take_home_ex02/take_home_ex02.html#the-data",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "3.2 The Data",
    "text": "3.2 The Data\n\n\n\nDataset Name\nDescription\nFormat\nSource\n\n\n\n\nThailand Domestic Tourism Statistics\n[2019-2023]\nMonthly Provincial Data on Tourist Numbers, Occupancy, and Revenue in Thailand\nCSV\nKaggle\n\n\nThailand - Subnational Administrative Boundaries\nAdministrative boundary data for Thailand’s subnational divisions\nESRI Shapefile\nHumanitarian Data Exchange (HDX)"
  },
  {
    "objectID": "take_home_ex/take_home_ex02/take_home_ex02.html#loading-the-data",
    "href": "take_home_ex/take_home_ex02/take_home_ex02.html#loading-the-data",
    "title": "Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "3.3 Loading the Data",
    "text": "3.3 Loading the Data\n\n3.3.1 Thailand Domestic Tourism Statistics\nWe will load Thailand Domestic Tourism Statistics data using read_csv() function of readr package.\n\ntourism &lt;- read_csv(\"data/aspatial/thailand_domestic_tourism_2019_2023_ver2.csv\")\n\nRows: 30800 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (5): province_thai, province_eng, region_thai, region_eng, variable\ndbl  (1): value\ndate (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nglimpse(tourism)\n\nRows: 30,800\nColumns: 7\n$ date          &lt;date&gt; 2019-01-01, 2019-01-01, 2019-01-01, 2019-01-01, 2019-01…\n$ province_thai &lt;chr&gt; \"กรุงเทพมหานคร\", \"ลพบุรี\", \"พระนครศรีอยุธยา\", \"สระบุรี\", \"ชัยนาท…\n$ province_eng  &lt;chr&gt; \"Bangkok\", \"Lopburi\", \"Phra Nakhon Si Ayutthaya\", \"Sarab…\n$ region_thai   &lt;chr&gt; \"ภาคกลาง\", \"ภาคกลาง\", \"ภาคกลาง\", \"ภาคกลาง\", \"ภาคกลาง\", \"…\n$ region_eng    &lt;chr&gt; \"central\", \"central\", \"central\", \"central\", \"central\", \"…\n$ variable      &lt;chr&gt; \"ratio_tourist_stay\", \"ratio_tourist_stay\", \"ratio_touri…\n$ value         &lt;dbl&gt; 93.37, 61.32, 73.37, 67.33, 79.31, 71.70, 64.65, 71.21, …\n\n\nThe dataset consists of 30,800 rows and 7 columns. Below is a detailed description of each column, as provided from dataset source:\n\n\n\n\n\n\n\nColumn\nDescription\n\n\n\n\ndate\nThe month and year in which the statistics were recorded. The dataset covers the years 2019-2023.\n\n\nprovince_thai\nThe name of the province in Thailand, in the Thai language.\n\n\nprovince_eng\nThe name of the province in Thailand, in English.\n\n\nregion_thai\nThe name of the region in Thailand to which the province belongs, in the Thai language.\n\n\nregion_eng\nThe name of the region in Thailand to which the province belongs, in English.\n\n\nvariable\nEight type of data to tourism activity in each province. Below are the descriptions of each type of data:\n\nno_tourist_all: The total number of domestic tourists who visited the province.\nno_tourist_foreign: The number of foreign tourists who visited the province.\nno_tourist_occupied: The total number of occupied hotel rooms in the province.\nno_tourist_thai: The number of Thai tourists who visited the province.\noccupancy_rate: The percentage of occupied travel accommodations in the province.\nrevenue_all: The total revenue generated by the tourism industry in the province (in Thai Baht).\nrevenue_foreign: The revenue generated specifically by foreign tourists (in Thai Baht).\nrevenue_thai: The revenue generated specifically by Thai tourists (in Thai Baht).\n\n\n\nvalue\nThe value of the data being recorded.\n\n\n\n\n\n3.3.2 Thailand’s Province Administrative Boundaries\nThe Thailand subnational administrative boundaries dataset is available at four levels: administrative level 0 (country), level 1 (province), level 2 (district), and level 3 (sub-district or tambon). For this analysis, we will use administrative level 1 (province).\nWe will load the province-level boundaries using the st_read() function. The boundaries will then be transformed into EPSG:32647, which uses meters as units and is based on the UTM Zone 47N projection.\n\nadmin_boundary &lt;- st_read(dsn = \"data/geospatial/\",\n                          layer = \"tha_admbnda_adm1_rtsd_20220121\") %&gt;%\n  st_transform(crs = 32647)\n\nReading layer `tha_admbnda_adm1_rtsd_20220121' from data source \n  `/Users/cham/project/Geospatial-Analytics/chrismanafe/ISSS626-GAA/take_home_ex/take_home_ex02/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 77 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n\n\nLet’s verify the coordinate reference system of admin_boundary using st_crs function.\n\nst_crs(admin_boundary)\n\nCoordinate Reference System:\n  User input: EPSG:32647 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 47N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 47N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",99,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Engineering survey, topographic mapping.\"],\n        AREA[\"Between 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\"],\n        BBOX[0,96,84,102]],\n    ID[\"EPSG\",32647]]\n\n\n\n# Extract unique values from both columns\nadmin_provinces &lt;- unique(admin_boundary$ADM1_EN)\ntourism_provinces &lt;- unique(tourism$province_eng)\n\n# Check for mismatches\nadmin_not_in_tourism &lt;- setdiff(admin_provinces, tourism_provinces)  # In admin but not in tourism\ntourism_not_in_admin &lt;- setdiff(tourism_provinces, admin_provinces)  # In tourism but not in admin\n\n# Print mismatches\ncat(\"Provinces in admin_boundary but not in tourism:\\n\")\n\nProvinces in admin_boundary but not in tourism:\n\nprint(admin_not_in_tourism)\n\n[1] \"Lop Buri\"         \"Chai Nat\"         \"Chon Buri\"        \"Prachin Buri\"    \n[5] \"Buri Ram\"         \"Si Sa Ket\"        \"Nong Bua Lam Phu\" \"Phangnga\"        \n\ncat(\"Provinces in tourism but not in admin_boundary:\\n\")\n\nProvinces in tourism but not in admin_boundary:\n\nprint(tourism_not_in_admin)\n\n[1] \"Lopburi\"         \"Chainat\"         \"Chonburi\"        \"Prachinburi\"    \n[5] \"Phang Nga\"       \"Buriram\"         \"Sisaket\"         \"Nong Bua Lamphu\"\n\n\n\nunique_values &lt;- unique(tourism$variable)\nprint(unique_values)\n\n[1] \"ratio_tourist_stay\" \"no_tourist_stay\"    \"no_tourist_all\"    \n[4] \"no_tourist_thai\"    \"no_tourist_foreign\" \"revenue_all\"       \n[7] \"revenue_thai\"       \"revenue_foreign\""
  },
  {
    "objectID": "take_home_ex/take_home_ex02/take_home_ex02.html#importing-datasets-to-r-environment",
    "href": "take_home_ex/take_home_ex02/take_home_ex02.html#importing-datasets-to-r-environment",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "3.3 Importing Datasets to R environment",
    "text": "3.3 Importing Datasets to R environment\n\n3.3.1 Thailand Domestic Tourism Statistics\nWe will load Thailand Domestic Tourism Statistics data using read_csv() function of readr package.\n\ntourism &lt;- read_csv(\"data/aspatial/thailand_domestic_tourism_2019_2023_ver2.csv\") %&gt;%\n  pivot_wider(names_from = variable, values_from = value) %&gt;%\n  select(1,3,5:13)\n\nRows: 30800 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (5): province_thai, province_eng, region_thai, region_eng, variable\ndbl  (1): value\ndate (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nglimpse(tourism)\n\nRows: 3,850\nColumns: 11\n$ date               &lt;date&gt; 2019-01-01, 2019-01-01, 2019-01-01, 2019-01-01, 20…\n$ province_eng       &lt;chr&gt; \"Bangkok\", \"Lopburi\", \"Phra Nakhon Si Ayutthaya\", \"…\n$ region_eng         &lt;chr&gt; \"central\", \"central\", \"central\", \"central\", \"centra…\n$ ratio_tourist_stay &lt;dbl&gt; 93.37, 61.32, 73.37, 67.33, 79.31, 71.70, 64.65, 71…\n$ no_tourist_stay    &lt;dbl&gt; 3334971, 51858, 117052, 89850, 27141, 118629, 18147…\n$ no_tourist_all     &lt;dbl&gt; 5959075, 268664, 730329, 207236, 79073, 296107, 494…\n$ no_tourist_thai    &lt;dbl&gt; 3534061, 266301, 561553, 201400, 78514, 284408, 491…\n$ no_tourist_foreign &lt;dbl&gt; 2425014, 2363, 168776, 5836, 559, 11699, 248, 5281,…\n$ revenue_all        &lt;dbl&gt; 81926490000, 457240000, 1438730000, 347790000, 1017…\n$ revenue_thai       &lt;dbl&gt; 29742580000, 451830000, 1054250000, 336190000, 1009…\n$ revenue_foreign    &lt;dbl&gt; 52183910000, 5410000, 384480000, 11600000, 890000, …\n\n\n\n\n\n\n\n\nThe original dataset consists of 30,800 rows and 7 column in “long-format”, where each row represents a combination of a variable and its corresponding value for a specific province and time period.\nThis format can make analysis more difficult since the different metrics are stored in rows instead of separate columns. Therefore we used pivot_wider() function from the tidyr package in R to transform the long format into a wider format. We also dropped province_thai and region_thai column as the information is already available in the English columns.\nThe resulting dataset has 3,850 rows and 11 columns. The columns are described as follows:\n\n\n\n\n\n\n\nColumn\nDescription\n\n\n\n\ndate\nThe month and year in which the statistics were recorded. The dataset covers the years 2019-2023.\n\n\nprovince_eng\nThe name of the province in Thailand, in English.\n\n\nregion_eng\nThe name of the region in Thailand to which the province belongs, in English.\n\n\nno_tourist_all\nThe total number of domestic tourists who visited the province.\n\n\nno_tourist_foreign\nThe number of foreign tourists who visited the province.\n\n\nno_tourist_stay\nThe number of tourists who stay over-night in the province.\n\n\nno_tourist_thai\nThe number of Thai tourists who visited the province.\n\n\nratio_tourist_stay\nThe percentage of occupied travel accommodations in the province.\n\n\nrevenue_all\nThe total revenue generated by the tourism industry in the province (in Thai Baht).\n\n\nrevenue_foreign\nThe revenue generated specifically by foreign tourists (in Thai Baht).\n\n\nrevenue_thai\nThe revenue generated specifically by Thai tourists (in Thai Baht).\n\n\n\n\n\n\n\n\n3.3.2 Thailand’s Province Administrative Boundaries\nThe Thailand subnational administrative boundaries dataset is available at four levels: administrative level 0 (country), level 1 (province), level 2 (district), and level 3 (sub-district or tambon). For this analysis, we will use administrative level 1 (province).\nWe will load the province-level boundaries using the st_read() function. The boundaries will then be transformed into EPSG:32647, which uses meters as units and is based on the UTM Zone 47N projection. Additionally, we will remove any unnecessary columns to streamline the dataset for analysis.\n\nadmin_boundary &lt;- st_read(dsn = \"data/geospatial/\",\n                          layer = \"tha_admbnda_adm1_rtsd_20220121\") %&gt;%\n  st_transform(crs = 32647) %&gt;%\n  rename(province_eng = ADM1_EN, pcode = ADM1_PCODE) %&gt;%\n  select(1:3,5)\n\nReading layer `tha_admbnda_adm1_rtsd_20220121' from data source \n  `/Users/cham/project/Geospatial-Analytics/chrismanafe/ISSS626-GAA/take_home_ex/take_home_ex02/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 77 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n\n\nLet’s verify the coordinate reference system of admin_boundary using st_crs function.\n\nst_crs(admin_boundary)\n\nCoordinate Reference System:\n  User input: EPSG:32647 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 47N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 47N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",99,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Engineering survey, topographic mapping.\"],\n        AREA[\"Between 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\"],\n        BBOX[0,96,84,102]],\n    ID[\"EPSG\",32647]]\n\n\nNext, we will visualize admin_boundary using tmap.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(admin_boundary)+\n  tm_fill(col=\"white\") +\n  tm_borders(col = \"black\", lwd=0.3, alpha=0.6)+\n  tm_layout(\n    main.title = \"Thailand Administrative Boundaries by Province\",\n    main.title.size = 1,\n    main.title.position = \"center\",\n    legend.show = FALSE,\n     frame = FALSE)"
  },
  {
    "objectID": "take_home_ex/take_home_ex02/take_home_ex02.html#province-name-alignment",
    "href": "take_home_ex/take_home_ex02/take_home_ex02.html#province-name-alignment",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "5.2 Province name alignment",
    "text": "5.2 Province name alignment\nWe will resolve discrepancies in province names between the boundary and tourism datasets to ensure consistency, enabling accurate analysis and spatial joins. First, we will extract unique province names from both datasets and checks for mismatches by identifying provinces present in one dataset but not the other.\n\n# Extract unique values from both columns\nadmin_provinces &lt;- unique(admin_boundary$province_eng)\ntourism_provinces &lt;- unique(tourism$province_eng)\n\n# Check for mismatches\nadmin_not_in_tourism &lt;- setdiff(admin_provinces, tourism_provinces)\ntourism_not_in_admin &lt;- setdiff(tourism_provinces, admin_provinces)\n\n# Print mismatches\nprint(admin_not_in_tourism)\n\n[1] \"Lop Buri\"         \"Chai Nat\"         \"Chon Buri\"        \"Prachin Buri\"    \n[5] \"Buri Ram\"         \"Si Sa Ket\"        \"Nong Bua Lam Phu\" \"Phangnga\"        \n\nprint(tourism_not_in_admin)\n\n[1] \"Lopburi\"         \"Chainat\"         \"Chonburi\"        \"Prachinburi\"    \n[5] \"Phang Nga\"       \"Buriram\"         \"Sisaket\"         \"Nong Bua Lamphu\"\n\n\n\nWe identified 8 provinces with different English names between the two datasets, so we will use mutate() to align the province names in the tourism dataset to match those in the admin_boundary dataset.\n\n\ntourism &lt;- tourism %&gt;%\n  mutate(province_eng = case_when(\n    province_eng == \"Lopburi\" ~ \"Lop Buri\",\n    province_eng == \"Chainat\" ~ \"Chai Nat\",\n    province_eng == \"Chonburi\" ~ \"Chon Buri\",\n    province_eng == \"Prachinburi\" ~ \"Prachin Buri\",\n    province_eng == \"Phang Nga\" ~ \"Phangnga\",\n    province_eng == \"Buriram\" ~ \"Buri Ram\",\n    province_eng == \"Sisaket\" ~ \"Si Sa Ket\",\n    province_eng == \"Nong Bua Lamphu\" ~ \"Nong Bua Lam Phu\",\n    TRUE ~ province_eng  # Keep the original name if no match\n  ))\n\nLet’s verify the result.\n\n# Extract unique values from both columns\nadmin_provinces &lt;- unique(admin_boundary$province_eng)\ntourism_provinces &lt;- unique(tourism$province_eng)\n\n# Check for mismatches\nadmin_not_in_tourism &lt;- setdiff(admin_provinces, tourism_provinces)\ntourism_not_in_admin &lt;- setdiff(tourism_provinces, admin_provinces)\n\n# Print mismatches\nprint(admin_not_in_tourism)\n\ncharacter(0)\n\nprint(tourism_not_in_admin)\n\ncharacter(0)"
  },
  {
    "objectID": "take_home_ex/take_home_ex02/take_home_ex02.html#perform-relational-join",
    "href": "take_home_ex/take_home_ex02/take_home_ex02.html#perform-relational-join",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "5.3 Perform relational join",
    "text": "5.3 Perform relational join\nSince the tourism dataset does not contain any geospatial properties, we will perform a relational join with the admin_boundary dataset, which includes the necessary spatial information. This will allow us to incorporate geospatial data into the tourism dataset. We will use the left_join() function from the dplyr package to merge the two datasets based on the province names.\n\ntourism_geo &lt;- left_join(admin_boundary, tourism)\n\nJoining with `by = join_by(province_eng)`\n\nglimpse(tourism_geo)\n\nRows: 3,850\nColumns: 17\n$ Shape_Leng              &lt;dbl&gt; 2.417227, 2.417227, 2.417227, 2.417227, 2.4172…\n$ Shape_Area              &lt;dbl&gt; 0.1313387, 0.1313387, 0.1313387, 0.1313387, 0.…\n$ province_eng            &lt;chr&gt; \"Bangkok\", \"Bangkok\", \"Bangkok\", \"Bangkok\", \"B…\n$ pcode                   &lt;chr&gt; \"TH10\", \"TH10\", \"TH10\", \"TH10\", \"TH10\", \"TH10\"…\n$ date                    &lt;date&gt; 2019-01-01, 2020-01-01, 2021-01-01, 2022-01-0…\n$ region_eng              &lt;chr&gt; \"central\", \"central\", \"central\", \"central\", \"c…\n$ ratio_tourist_stay      &lt;dbl&gt; 93.37, 89.36, 7.54, 26.34, 75.02, 89.19, 68.37…\n$ no_tourist_stay         &lt;dbl&gt; 3334971, 3213765, 354676, 1009583, 2440463, 30…\n$ no_tourist_all          &lt;dbl&gt; 5959075, 6046765, 1681847, 2437497, 4872078, 5…\n$ no_tourist_thai         &lt;dbl&gt; 3534061, 3573040, 1632693, 2299906, 2749877, 2…\n$ no_tourist_foreign      &lt;dbl&gt; 2425014, 2473725, 49154, 137591, 2122201, 2291…\n$ revenue_all             &lt;dbl&gt; 81926490000, 88202890000, 9539730000, 11823610…\n$ revenue_thai            &lt;dbl&gt; 29742580000, 31137650000, 8447450000, 96426000…\n$ revenue_foreign         &lt;dbl&gt; 52183910000, 57065240000, 1092280000, 21810100…\n$ tourist_stay_rate       &lt;dbl&gt; 55.96458, 53.14850, 21.08848, 41.41884, 50.090…\n$ revenue_per_tourist_all &lt;dbl&gt; 13748.189, 14586.790, 5672.175, 4850.718, 1237…\n$ geometry                &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((674339.8 15..., M…\n\n\n\nwrite_rds(tourism_geo, \"data/rds/tourism_geo.rds\")"
  },
  {
    "objectID": "take_home_ex/take_home_ex02/take_home_ex02.html#determining-key-indicators-of-thailands-tourism-economy",
    "href": "take_home_ex/take_home_ex02/take_home_ex02.html#determining-key-indicators-of-thailands-tourism-economy",
    "title": "Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "5.5 Determining Key Indicators of Thailand’s Tourism Economy",
    "text": "5.5 Determining Key Indicators of Thailand’s Tourism Economy\nTo determine key indicators of Thailand’s tourism economy, we performed a Pearson correlation analysis on selected variables, including ratio_tourist_stay, no_tourist_stay, no_tourist_all, no_tourist_thai, no_tourist_foreign, revenue_all, revenue_foreign, and revenue_thai. The results were visualized using a mixed correlation plot, with ellipses in the lower section representing the strength and direction of correlations, and the exact correlation values displayed in the upper section. This helped us identify the most important relationships between tourism indicators.\nAs the variables represent different units (e.g., number of tourists vs revenue in Thai Baht), we will standardize the variables using normalize() function of heatmaply package. This function is using the Min-Max method.\n\nindicators &lt;- province_summary %&gt;%\n  st_drop_geometry() %&gt;%\n  select(\n    total_tourists_all,\n    total_foreign_tourists,\n    total_thai_tourists,\n    total_stay_tourists,\n    avg_occupancy_rate,\n    total_revenue_all,\n    total_revenue_foreign,\n    total_revenue_thai,\n    avg_tourist_stay_rate,\n    avg_revenue_per_tourist\n  )\nindicators.std &lt;- normalize(indicators)\nsummary(indicators.std)\n\n total_tourists_all total_foreign_tourists total_thai_tourists\n Min.   :0.00000    Min.   :0.0000000      Min.   :0.00000    \n 1st Qu.:0.01583    1st Qu.:0.0007648      1st Qu.:0.02066    \n Median :0.03123    Median :0.0027815      Median :0.03611    \n Mean   :0.06338    Mean   :0.0363234      Mean   :0.07487    \n 3rd Qu.:0.06672    3rd Qu.:0.0146183      3rd Qu.:0.08351    \n Max.   :1.00000    Max.   :1.0000000      Max.   :1.00000    \n total_stay_tourists avg_occupancy_rate total_revenue_all \n Min.   :0.00000     Min.   :0.0000     Min.   :0.000000  \n 1st Qu.:0.01305     1st Qu.:0.2823     1st Qu.:0.002449  \n Median :0.03008     Median :0.4382     Median :0.006718  \n Mean   :0.06649     Mean   :0.4454     Mean   :0.035913  \n 3rd Qu.:0.05748     3rd Qu.:0.6060     3rd Qu.:0.012005  \n Max.   :1.00000     Max.   :1.0000     Max.   :1.000000  \n total_revenue_foreign total_revenue_thai avg_tourist_stay_rate\n Min.   :0.0000000     Min.   :0.000000   Min.   :0.0000       \n 1st Qu.:0.0000636     1st Qu.:0.005364   1st Qu.:0.3132       \n Median :0.0003447     Median :0.014735   Median :0.4940       \n Mean   :0.0307419     Mean   :0.043644   Mean   :0.5190       \n 3rd Qu.:0.0020230     3rd Qu.:0.028364   3rd Qu.:0.6873       \n Max.   :1.0000000     Max.   :1.000000   Max.   :1.0000       \n avg_revenue_per_tourist\n Min.   :0.00000        \n 1st Qu.:0.02341        \n Median :0.04284        \n Mean   :0.10471        \n 3rd Qu.:0.11320        \n Max.   :1.00000        \n\n\n\ncluster_vars.cor = cor(indicators.std, method = \"pearson\")\ncorrplot.mixed(cluster_vars.cor,\n         lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\nThe matrix reveals strong positive correlations between total_tourists_all, total_foreign_tourists, and total_revenue_all, suggesting that higher tourist numbers, particularly foreign tourists, are closely linked with increased tourism revenue. total_foreign_tourists is especially well-correlated with both total_revenue_all and total_revenue_foreign, underscoring the significant contribution of foreign tourists to the overall tourism economy.\nIn contrast, avg_occupancy_rate and avg_tourist_stay_rate show weak correlations with other variables, indicating less alignment with overall tourist numbers and revenue.\nGiven the strong similarities and high correlations among the variables, I have selected the following three key indicators for the next stage of analysis:\n\ntotal_tourists_all: This variable captures the total number of tourists, representing both domestic and foreign visitors, and is highly correlated with other important metrics such as revenue and overnight stays.\ntotal_foreign_tourists: This indicator highlights the contribution of international visitors, who are closely tied to revenue generation and are particularly important for high-value tourism.\nrevenue_per_tourist: This indicator focuses on the average revenue generated per tourist, providing insights into the economic quality of tourism in different provinces."
  },
  {
    "objectID": "take_home_ex/take_home_ex02/take_home_ex02.html#visualize-economy-indicators-of-thailands-tourism",
    "href": "take_home_ex/take_home_ex02/take_home_ex02.html#visualize-economy-indicators-of-thailands-tourism",
    "title": "Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "4.4 Visualize Economy Indicators of Thailand’s Tourism",
    "text": "4.4 Visualize Economy Indicators of Thailand’s Tourism\n\ntourist &lt;- tm_shape(tourism_geo) +\n  tm_fill(\"no_tourist_all\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Total tourist classification\")\n\nrevenue &lt;- tm_shape(tourism_geo) +\n  tm_fill(\"revenue_all\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Total revenue classification\")\n\ntmap_arrange(tourist,\n             revenue,\n             asp=1,\n             ncol=2)"
  },
  {
    "objectID": "take_home_ex/take_home_ex02/take_home_ex02.html#province-level-summary-of-tourism-economy-indicators",
    "href": "take_home_ex/take_home_ex02/take_home_ex02.html#province-level-summary-of-tourism-economy-indicators",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "5.4 Province-level Summary of Tourism Economy Indicators",
    "text": "5.4 Province-level Summary of Tourism Economy Indicators\nWe will prepare a province-level summary of key tourism indicators, including both original metrics such as total tourists, foreign tourists, and total revenue, as well as newly engineered indicators like the tourist stay rate and revenue per tourist. This summary will provide a overall view of tourism patterns and economic contributions across each province.\n\nprovince_summary &lt;- tourism_geo %&gt;%\n  group_by(province_eng) %&gt;%\n  summarise(\n    # Summarize original data\n    total_tourists_all = sum(no_tourist_all, na.rm = TRUE),\n    total_foreign_tourists = sum(no_tourist_foreign, na.rm = TRUE),\n    total_thai_tourists = sum(no_tourist_thai, na.rm = TRUE),\n    total_stay_tourists = sum(no_tourist_stay, na.rm = TRUE),\n    avg_occupancy_rate = mean(ratio_tourist_stay, na.rm = TRUE),\n    total_revenue_all = sum(revenue_all, na.rm = TRUE),\n    total_revenue_foreign = sum(revenue_foreign, na.rm = TRUE),\n    total_revenue_thai = sum(revenue_thai, na.rm = TRUE),\n    \n    # Summarize engineered data\n    avg_tourist_stay_rate = mean(tourist_stay_rate, na.rm = TRUE),\n    avg_revenue_per_tourist = mean(revenue_per_tourist_all, na.rm = TRUE)\n  )\nwrite_rds(province_summary, \"data/rds/province_summary.rds\")\n\n\nWe will use following indicators for our analysis:\n\nTotal Tourists (total_tourists_all), because it helps us understand how tourist numbers are distributed across provinces.\nTourist Stay Rate (avg_tourist_stay_rate), because it could reveal regional patterns in how provinces retain visitors to stay over-night.\nRevenue Per Tourist (avg_revenue_per_tourist), because it helps identify areas where tourism generates the most economic benefit, potentially showing clusters of higher revenue generation."
  },
  {
    "objectID": "take_home_ex/take_home_ex02/take_home_ex02.html#choropleth-visualization-of-thailands-tourism-distribution",
    "href": "take_home_ex/take_home_ex02/take_home_ex02.html#choropleth-visualization-of-thailands-tourism-distribution",
    "title": "Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "4.5 Choropleth Visualization of Thailand’s Tourism Distribution",
    "text": "4.5 Choropleth Visualization of Thailand’s Tourism Distribution\nUsing the `tourism_summary` data frame, we will create choropleth maps to visualize the geographical distribution of tourism activity across Thailand.\n\ntourist &lt;- tm_shape(tourism_summary) +\n  tm_fill(\"no_tourist_all\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Total tourist classification\")\n\nrevenue &lt;- tm_shape(tourism_summary) +\n  tm_fill(\"revenue_all\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Total revenue classification\")\n\ntmap_arrange(tourist,\n             revenue,\n             asp=1,\n             ncol=2)"
  },
  {
    "objectID": "take_home_ex/take_home_ex02/take_home_ex02.html#summary-statistics",
    "href": "take_home_ex/take_home_ex02/take_home_ex02.html#summary-statistics",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "4.1 Summary statistics",
    "text": "4.1 Summary statistics\nLet’s find out the summary statistics of tourism data using summary() function.\n\nsummary(tourism)\n\n      date            province_eng        region_eng        ratio_tourist_stay\n Min.   :2019-01-01   Length:3850        Length:3850        Min.   : 0.00     \n 1st Qu.:2020-01-01   Class :character   Class :character   1st Qu.:20.18     \n Median :2021-01-16   Mode  :character   Mode  :character   Median :41.81     \n Mean   :2021-01-15                                         Mean   :38.93     \n 3rd Qu.:2022-02-01                                         3rd Qu.:56.20     \n Max.   :2023-02-01                                         Max.   :95.86     \n no_tourist_stay   no_tourist_all    no_tourist_thai   no_tourist_foreign \n Min.   :      0   Min.   :      0   Min.   :      0   Min.   :      0.0  \n 1st Qu.:  16271   1st Qu.:  39092   1st Qu.:  37169   1st Qu.:     49.2  \n Median :  44579   Median :  92122   Median :  88782   Median :    553.0  \n Mean   : 105161   Mean   : 206328   Mean   : 173962   Mean   :  32366.1  \n 3rd Qu.:  90902   3rd Qu.: 203646   3rd Qu.: 184256   3rd Qu.:   5189.5  \n Max.   :3335728   Max.   :6131044   Max.   :4087756   Max.   :2473725.0  \n  revenue_all         revenue_thai       revenue_foreign     \n Min.   :0.000e+00   Min.   :0.000e+00   Min.   :-4.250e+03  \n 1st Qu.:6.332e+07   1st Qu.:5.925e+07   1st Qu.: 1.100e+05  \n Median :1.955e+08   Median :1.773e+08   Median : 1.540e+06  \n Mean   :1.344e+09   Mean   :6.636e+08   Mean   : 6.802e+08  \n 3rd Qu.:5.060e+08   3rd Qu.:4.600e+08   3rd Qu.: 1.742e+07  \n Max.   :1.103e+11   Max.   :4.506e+10   Max.   : 8.503e+10  \n\n\nWe observed there’s negative value on revenue_foreign variables. Since the revenue represents earnings from tourism, let’s assume that this is likely data entry error. So let’s fix this.\n\ntourism &lt;- tourism %&gt;%\n  mutate(\n    revenue_foreign = ifelse(revenue_foreign &lt; 0, 0, revenue_foreign),\n    revenue_all = ifelse(revenue_foreign == 0, revenue_thai, revenue_all)\n  )\nsummary(tourism)\n\n      date            province_eng        region_eng        ratio_tourist_stay\n Min.   :2019-01-01   Length:3850        Length:3850        Min.   : 0.00     \n 1st Qu.:2020-01-01   Class :character   Class :character   1st Qu.:20.18     \n Median :2021-01-16   Mode  :character   Mode  :character   Median :41.81     \n Mean   :2021-01-15                                         Mean   :38.93     \n 3rd Qu.:2022-02-01                                         3rd Qu.:56.20     \n Max.   :2023-02-01                                         Max.   :95.86     \n no_tourist_stay   no_tourist_all    no_tourist_thai   no_tourist_foreign \n Min.   :      0   Min.   :      0   Min.   :      0   Min.   :      0.0  \n 1st Qu.:  16271   1st Qu.:  39092   1st Qu.:  37169   1st Qu.:     49.2  \n Median :  44579   Median :  92122   Median :  88782   Median :    553.0  \n Mean   : 105161   Mean   : 206328   Mean   : 173962   Mean   :  32366.1  \n 3rd Qu.:  90902   3rd Qu.: 203646   3rd Qu.: 184256   3rd Qu.:   5189.5  \n Max.   :3335728   Max.   :6131044   Max.   :4087756   Max.   :2473725.0  \n  revenue_all         revenue_thai       revenue_foreign    \n Min.   :0.000e+00   Min.   :0.000e+00   Min.   :0.000e+00  \n 1st Qu.:6.332e+07   1st Qu.:5.925e+07   1st Qu.:1.100e+05  \n Median :1.955e+08   Median :1.773e+08   Median :1.540e+06  \n Mean   :1.344e+09   Mean   :6.636e+08   Mean   :6.802e+08  \n 3rd Qu.:5.060e+08   3rd Qu.:4.600e+08   3rd Qu.:1.742e+07  \n Max.   :1.103e+11   Max.   :4.506e+10   Max.   :8.503e+10"
  },
  {
    "objectID": "take_home_ex/take_home_ex02/take_home_ex02.html#check-missing-values",
    "href": "take_home_ex/take_home_ex02/take_home_ex02.html#check-missing-values",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "4.2 Check Missing Values",
    "text": "4.2 Check Missing Values\nLet’s check of any missing values in the dataset.\n\ncolSums(is.na(tourism))\n\n              date       province_eng         region_eng ratio_tourist_stay \n                 0                  0                  0                  0 \n   no_tourist_stay     no_tourist_all    no_tourist_thai no_tourist_foreign \n                 0                  0                  0                  0 \n       revenue_all       revenue_thai    revenue_foreign \n                 0                  0                  0"
  },
  {
    "objectID": "take_home_ex/take_home_ex02/take_home_ex02.html#distribution-plots-for-numerical-variables",
    "href": "take_home_ex/take_home_ex02/take_home_ex02.html#distribution-plots-for-numerical-variables",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "4.3 Distribution Plots for Numerical Variables",
    "text": "4.3 Distribution Plots for Numerical Variables\nLet’s visualize the numerical variables by province. We will apply a log transformation since some provinces have significantly larger numbers of tourists, which could make the boxplot difficult to analyze without scaling.\n\nNumber of TouristRevenueOvernight-Staying Tourists\n\n\n\nggplot(tourism, aes(x = reorder(province_eng, no_tourist_all, FUN = median), y = no_tourist_all)) +\n  geom_boxplot(fill = \"lightblue\", color = \"black\") +\n  theme_minimal() +\n  scale_y_log10() +  # Log transformation for better scaling\n  labs(title = \"Boxplot of Tourists by Province (Log-Scale)\", \n       x = \"Province\", \n       y = \"Number of Tourists (Log Scale)\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\nWarning in scale_y_log10(): log-10 transformation introduced infinite values.\n\n\nWarning: Removed 25 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(tourism, aes(x = reorder(province_eng, revenue_all, FUN = median), y = revenue_all)) +\n  geom_boxplot(fill = \"lightblue\", color = \"black\") +\n  theme_minimal() +\n  scale_y_log10() +  # Log transformation for better scaling\n  labs(title = \"Boxplot of Revenue by Province (Log Scale)\", x = \"Province\", y = \"Total Revenue (Log Scale)\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\nWarning in scale_y_log10(): log-10 transformation introduced infinite values.\n\n\nWarning: Removed 24 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(tourism, aes(x = reorder(province_eng, no_tourist_stay, FUN = median), y = no_tourist_stay)) +\n  geom_boxplot(fill = \"lightblue\", color = \"black\") +\n  theme_minimal() +\n  scale_y_log10() +  # Log transformation for better scaling\n  labs(title = \"Boxplot of Overnight-Staying Tourists (Log Scale) by Province\", \n       x = \"Province\", \n       y = \"Number of Overnight-Staying Tourists (Log Scale)\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\nWarning in scale_y_log10(): log-10 transformation introduced infinite values.\n\n\nWarning: Removed 25 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\nThe three boxplots above provide insights into tourism activity across Thai provinces, focusing on total tourists, overnight-staying tourists, and total tourism revenue.\n\nTourist Concentration: Provinces like Bangkok, Chiang Mai, and Phuket consistently show the highest median values across all three metrics, highlighting their dominance as key tourist hubs. These provinces also exhibit greater variability, indicating fluctuating tourism activity possibly due to factors like seasonality or COVID-19 pandemics.\nSmaller Provinces: Provinces such as Amnat Charoen and Nong Bua Lamphu consistently display much lower median values and narrower interquartile ranges (IQR), suggesting smaller tourist volumes and revenues.\nOutliers: Many provinces show significant lower-end outliers across all metrics, likely reflecting periods of reduced tourist activity due to external factors like travel restrictions during COVID-19 pandemics.\n\nOverall, Thailand’s tourism revenue and tourist distribution are concentrated in a few key provinces, with the majority of smaller provinces experiencing lower and more stable activity."
  },
  {
    "objectID": "take_home_ex/take_home_ex02/take_home_ex02.html#feature-engineering",
    "href": "take_home_ex/take_home_ex02/take_home_ex02.html#feature-engineering",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "5.1 Feature engineering",
    "text": "5.1 Feature engineering\nWe wanted to introduce new indicators to enhance our analysis of tourist behavior and economic impact. We’ll create two key indicators:\n\nTourist Stay Rate: The percentage of tourists staying overnight in each province.\nRevenue Per Tourist (Overall): The average revenue generated per tourist.\n\n\ntourism &lt;- tourism %&gt;%\n  mutate(\n    tourist_stay_rate = ifelse(no_tourist_all &gt; 0, (no_tourist_stay / no_tourist_all) * 100, 0),\n    revenue_per_tourist_all = ifelse(no_tourist_all &gt; 0, revenue_all / no_tourist_all, 0)\n  )"
  },
  {
    "objectID": "take_home_ex/take_home_ex02/take_home_ex02.html#visualization-of-thailands-tourism-distribution",
    "href": "take_home_ex/take_home_ex02/take_home_ex02.html#visualization-of-thailands-tourism-distribution",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "5.6 Visualization of Thailand’s Tourism Distribution",
    "text": "5.6 Visualization of Thailand’s Tourism Distribution\nUsing the province_summary data frame, we will create choropleth maps to visualize the geographical distribution of the 3 tourism economy indicators across Thailand.\n\ntourist &lt;- tm_shape(province_summary) +\n  tm_fill(\"total_tourists_all\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Total Tourist\", main.title.size = 1)\n\nforeign_tourists &lt;- tm_shape(province_summary) +\n  tm_fill(\"avg_tourist_stay_rate\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Tourist Stay Rate\", main.title.size = 1)\n\nrevenue_per_tourist &lt;- tm_shape(province_summary) +\n  tm_fill(\"avg_revenue_per_tourist\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Revenue per Tourist\", main.title.size = 1)\n\ntmap_arrange(tourist,\n             foreign_tourists,\n             revenue_per_tourist,\n             asp=1,\n             ncol=3)"
  },
  {
    "objectID": "take_home_ex/take_home_ex02/take_home_ex02.html#computing-contiguity-neighbours",
    "href": "take_home_ex/take_home_ex02/take_home_ex02.html#computing-contiguity-neighbours",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "6.1 Computing Contiguity Neighbours",
    "text": "6.1 Computing Contiguity Neighbours\nTypically, we use the st_contiguity() function from the sfdep package to compute contiguity weight matrices, which build neighbor relationships based on shared boundaries between regions. However, because our dataset includes province located on separate island (i.e. Phuket), contiguity-based methods would leave some region without neighbors. To overcome this issue, we will use the K-Nearest Neighbors (KNN) approach to compute spatial weights. This method ensures that every province has neighbors, even for those on isolated islands, by assigning each region a fixed number of nearest neighbors based on distance rather than shared boundaries.\nFirst, we need to ensure that the centroids used for each province are correctly placed within the province boundaries and not in the sea or outside of the boundary.\n\nprovince_centroids &lt;- province_summary %&gt;%\n      st_centroid() %&gt;%\n      select(province_eng, geometry)\n\nWarning: st_centroid assumes attributes are constant over geometries\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\ntm_shape(province_summary) +\n  tm_borders() +\n  tm_shape(province_centroids) +\n  tm_dots(col = \"red\", size = 0.1) +\n  tm_layout(main.title = \"Centroids of Thailand Provinces\",\n            main.title.position = \"center\",\n            frame = FALSE)\n\n\n\n\n\n\n\n\n\nWe verified that the centroids are correctly placed within the province boundaries, ensuring that none are positioned in the sea or outside their respective boundaries.\n\nWith the centroids correctly positioned, we will proceed with two approaches for computing spatial weights:\n\nK-Nearest Neighbors (KNN): Using the st_knn() function from the sfdep package, we will compute KNN-based spatial weights. This ensures that all provinces, including those on isolated islands, have neighbors based on geographic proximity rather than shared boundaries.\nDistance Band Weights: We will also use the st_dist_band() function from sfdep to create a distance-based spatial weights matrix. This method defines neighbors for provinces based on a maximum distance threshold, ensuring that regions within a certain distance of each other are considered neighbors.\n\nBoth methods will help account for geographic proximity while ensuring that all regions, including isolated provinces, are part of the spatial analysis.\n\nst_knn()st_dist_band()\n\n\n\nwm_knn &lt;- province_summary %&gt;%\n  mutate(nb = st_knn(geometry, k = 8),\n         wt = st_inverse_distance(nb, geometry, scale = 1, alpha = 1),\n         wt = map(wt, ~ .x / sum(.x)),\n         .before = 1)\n\n! Polygon provided. Using point on surface.\n! Polygon provided. Using point on surface.\n\n\n\n\n\nwm_fd &lt;- province_summary %&gt;%\n  mutate(nb = st_dist_band(province_summary$geometry),\n         wt = st_inverse_distance(nb, geometry, scale = 1, alpha = 1),\n         wt = map(wt, ~ .x / sum(.x)),\n         .before = 1)\n\n! Polygon provided. Using point on surface.\n! Polygon provided. Using point on surface.\n\n\n\n\n\n\nWe normalize the inverse distance weights to ensure that each province’s spatial influence is comparable and sum up to 1."
  },
  {
    "objectID": "take_home_ex/take_home_ex02/take_home_ex02.html#global-morans-i-test",
    "href": "take_home_ex/take_home_ex02/take_home_ex02.html#global-morans-i-test",
    "title": "Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "6.2 Global Moran’s I Test",
    "text": "6.2 Global Moran’s I Test\nWith the spatial weights prepared, we can now perform Global Moran’s I test to determine if there is spatial dependence in the tourism economy indicators.\nIf the indicators are independent of space, Moran’s I should show no significant spatial autocorrelation. The following hypotheses will be tested:\n\nNull Hypothesis (H₀): The tourism economy indicators are spatially independent (randomly distributed in space).\nAlternative Hypothesis (H₁): There is spatial dependence, indicating that similar values are clustered or dispersed.\n\nA 95% confidence interval (significance level of 0.05) will be used for the analysis. We will use the global_moran() function from the sfdep package to compute the Global Moran’s I value for our selected tourism economy indicators: no_tourist_all and revenue_all.\n\n6.2.1 Test on Total number of tourists\n\n6.2.1.1 KNN Weights\n\nset.seed(2024)\nglobal_moran_test(wm_knn$total_tourists_all,\n           wm_knn$nb,\n           wm_knn$wt,\n           zero.policy = TRUE,\n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 1.4903, p-value = 0.06807\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.034783238      -0.013157895       0.001034825 \n\n\n\n\n6.2.1.2 Distance Band Weights\n\nglobal_moran_test(wm_fd$total_tourists_all,\n           wm_fd$nb,\n           wm_fd$wt,\n           zero.policy = TRUE,\n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 1.3221, p-value = 0.09307\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.051235364      -0.013157895       0.002372201 \n\n\n\n\n\n\n\n\nObservations:\nK-Nearest Neighbors (KNN):\n\nMoran’s I statistic: 0.0348\np-value: 0.06807\n\nAt the 95% confidence level, we do not reject the null hypothesis of no spatial autocorrelation, as the p-value is above 0.05. This indicates that there is no strong evidence of spatial clustering for the total number of tourists at this confidence level.\nHowever, at the 90% confidence level (p &lt; 0.10), we reject the null hypothesis, indicating weak evidence of spatial autocorrelation. This suggests that there may be mild clustering of similar tourist numbers, though the strength of the evidence is limited.\n\nDistance Band Weights:\n\nMoran’s I statistic: 0.0512\np-value: 0.09307\n\nAt the 95% confidence level, we do not reject the null hypothesis of no spatial autocorrelation, as the p-value is above 0.05. This indicates there is no strong evidence of spatial clustering at this higher confidence level.\nHowever, at the 90% confidence level (p &lt; 0.10), we reject the null hypothesis, suggesting weak evidence of spatial autocorrelation. This implies there may be mild clustering of total tourists, though the evidence is not strong enough for higher confidence levels.\n\nFor both KNN and distance band methods, we do not reject the null hypothesis, indicating that there is no significant spatial clustering of total tourists at the 95% confidence level. While the KNN method suggests weak spatial autocorrelation at the 90% confidence level, the overall spatial dependence remains weak.\n\n\n\n\n\n\n6.2.2 Test on Total Foreign Tourists\n\n6.2.2.1 KNN Weights\n\nglobal_moran_test(wm_knn$total_foreign_tourists,\n           wm_knn$nb,\n           wm_knn$wt,\n           zero.policy = TRUE,\n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 0.75616, p-value = 0.2248\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.011924374      -0.013157895       0.001100285 \n\n\n\n\n6.2.2.2 Distance Band Weights\n\nglobal_moran_test(wm_fd$total_foreign_tourists,\n           wm_fd$nb,\n           wm_fd$wt,\n           zero.policy = TRUE,\n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 1.5524, p-value = 0.06028\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.064835644      -0.013157895       0.002524157 \n\n\n\n\n\n\n\n\nObservations:\nK-Nearest Neighbors (KNN):\n\nMoran’s I statistic: 0.0119\np-value: 0.2248\n\nBased on the p-value, we do not reject the null hypothesis of no spatial autocorrelation for foreign tourists. The Moran’s I statistic is close to zero, and the p-value suggests there is no significant evidence of spatial clustering using KNN weights.\n\nDistance Band Weights:\n\nMoran’s I statistic: 0.0512\np-value: 0.09307\n\nFor the distance band method, we do not reject the null hypothesis at the 95% confidence level, as the p-value is slightly above 0.05. However, there is weak evidence of spatial autocorrelation at the 90% confidence level.\n\nIn both cases, we do not reject the null hypothesis, indicating that the distribution of foreign tourists does not exhibit significant spatial clustering at the 95% confidence level.\n\n\n\n\n\n\n6.2.3 Test on Average Revenue per Tourists\n\n6.2.3.1 KNN Weights\n\nglobal_moran_test(wm_knn$avg_revenue_per_tourist,\n           wm_knn$nb,\n           wm_knn$wt,\n           zero.policy = TRUE,\n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 7.1831, p-value = 3.408e-13\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.308643681      -0.013157895       0.002007037 \n\n\n\n\n6.2.3.2 Distance Band Weights\n\nglobal_moran_test(wm_fd$avg_revenue_per_tourist,\n           wm_fd$nb,\n           wm_fd$wt,\n           zero.policy = TRUE,\n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 6.5495, p-value = 2.887e-11\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.432451531      -0.013157895       0.004629059 \n\n\n\n\n\n\n\n\nObservations:\nK-Nearest Neighbors (KNN):\n\nMoran’s I statistic: 0.3086\np-value: 3.408e-13 (very close to zero)\n\nThe Moran’s I value of 0.3086 indicates moderate positive spatial autocorrelation. This suggests that provinces with similar values of average revenue per tourist (either high or low) are moderately clustered together. The extremely low p-value (essentially zero) confirms that this clustering is highly statistically significant.\nAt the 95% confidence level, we reject the null hypothesis of no spatial autocorrelation, meaning there is strong evidence that spatial clustering exists in the average revenue per tourist values across provinces when using KNN weights.\n\nDistance Band Weights:\n\nMoran’s I statistic: 0.4325\np-value: 2.887e-11\n\nUsing distance band weights, the Moran’s I value is even higher at 0.4325, suggesting strong positive spatial autocorrelation. This means that provinces with similar values of average revenue per tourist are more strongly clustered together when proximity is based on geographic distance. The extremely low p-value shows that this result is highly statistically significant.\nAt the 95% confidence level, we reject the null hypothesis of no spatial autocorrelation, indicating strong spatial clustering of provinces with similar average revenue per tourist values when using distance-based weights.\n\nFor both KNN and distance band methods, we reject the null hypothesis at the 95% confidence level, indicating strong evidence of spatial clustering. The distance band method reveals even stronger spatial autocorrelation (with a Moran’s I of 0.4325) compared to KNN, suggesting that geographically close provinces tend to exhibit similar patterns in the average revenue per tourist indicator."
  },
  {
    "objectID": "take_home_ex/take_home_ex02/take_home_ex02.html#interpreting-results",
    "href": "take_home_ex/take_home_ex02/take_home_ex02.html#interpreting-results",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "6.3 Interpreting Results",
    "text": "6.3 Interpreting Results\nThe results from the Global Moran’s I test and the Monte Carlo simulation tell us that:\n\nTotal tourist numbers show weak spatial autocorrelation, indicating that while some provinces attract more tourists, there is no strong regional clustering. The distribution of tourists seems random, with individual provinces standing out rather than forming distinct regional patterns.\nIn contrast, both average tourist stay rate and average revenue per tourist display moderate to strong and statistically significant spatial autocorrelation. Provinces that are geographically close tend to have similar tourist retention rates and revenue generated per tourist. This suggests that these tourism economy indicators are regionally concentrated, likely due to shared tourism infrastructure, similar attractions, or collaborative regional policies."
  },
  {
    "objectID": "take_home_ex/take_home_ex02/take_home_ex02.html#local-morans-i",
    "href": "take_home_ex/take_home_ex02/take_home_ex02.html#local-morans-i",
    "title": "Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "7.1 Local Moran’s I",
    "text": "7.1 Local Moran’s I\nWe will compute Local Moran’s I of selected indicators at county level by using local_moran() function of sfdep package.\n\n7.1.1 Local Moran’s I on Total Number of Tourists\n\nlisa_total_tourists_all &lt;- wm_knn %&gt;% \n  mutate(local_moran = local_moran(\n    total_tourists_all, nb, wt),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\n\n\n7.1.2 Local Moran’s I on Total Number of Foreign Tourists\n\nlisa_total_foreign_tourists &lt;- wm_knn %&gt;% \n  mutate(local_moran = local_moran(\n    total_foreign_tourists, nb, wt),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\n\n\n\n\n\n\nNote\n\n\n\nThe output of local_moran() is a sf data.frame containing the columns ii, eii, var_ii, z_ii, p_ii, p_ii_sim, and p_folded_sim.\n\nii: local moran statistic\neii: expectation of local moran statistic; for localmoran_permthe permutation sample means\nvar_ii: variance of local moran statistic; for localmoran_permthe permutation sample standard deviations\nz_ii: standard deviate of local moran statistic; for localmoran_perm based on permutation sample means and standard deviations\np_ii: p-value of local moran statistic using pnorm(); for localmoran_perm using standard deviate based on permutation sample means and standard deviations\np_ii_sim: For localmoran_perm(), rank() and punif() of observed statistic rank for [0, 1] p-values using alternative= -p_folded_sim: the simulation folded [0, 0.5] range ranked p-value (based on https://github.com/pysal/esda/blob/4a63e0b5df1e754b17b5f1205b cadcbecc5e061/esda/crand.py#L211-L213)\nskewness: For localmoran_perm, the output of e1071::skewness() for the permutation samples underlying the standard deviates\nkurtosis: For localmoran_perm, the output of e1071::kurtosis() for the permutation samples underlying the standard deviates."
  },
  {
    "objectID": "take_home_ex/take_home_ex02/take_home_ex02.html#visualising-local-morans-i-and-p-value",
    "href": "take_home_ex/take_home_ex02/take_home_ex02.html#visualising-local-morans-i-and-p-value",
    "title": "Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "7.2 Visualising Local Moran’s I and p-value",
    "text": "7.2 Visualising Local Moran’s I and p-value\nWe will use tmap package to prepare choropleth map using value in the ii field.\n\n7.2.1 Local Moran’s I on Total Number of Tourists\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nmap1 &lt;- tm_shape(lisa_total_tourists_all) +\n  tm_fill(\"ii\") +\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(\n    main.title = \"Local Moran's I of Total Number of Tourists\",\n    main.title.size = 0.8\n  )\n\nmap2 &lt;- tm_shape(lisa_total_foreign_tourists) +\n  tm_fill(\"p_ii\") +\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(\n    main.title = \"p-value of Local Moran's I - Total Number of Tourists\",\n    main.title.size = 0.8\n  )\n\ntmap_arrange(map1, map2, ncol = 2)\n\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n7.2.2 Local Moran’s I of Total Revenue"
  },
  {
    "objectID": "take_home_ex/take_home_ex02/take_home_ex02.html#global-morans-i-test-and-permutation-test",
    "href": "take_home_ex/take_home_ex02/take_home_ex02.html#global-morans-i-test-and-permutation-test",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "6.2 Global Moran’s I Test and Permutation Test",
    "text": "6.2 Global Moran’s I Test and Permutation Test\nIn this section, we will assess the spatial dependence of three key tourism indicators across provinces in Thailand using the Global Moran’s I test. If the indicators are independent of space, Moran’s I should show no significant spatial autocorrelation.\n\nNull Hypothesis (H₀): The tourism economy indicators are spatially independent (randomly distributed in space).\nAlternative Hypothesis (H₁): There is spatial dependence, indicating that similar values are clustered or dispersed.\n\nWe will conduct the analysis at a 95% confidence interval (significance level of 0.05) using the global_moran_test function from the sfdep package. Additionally, we will run a permutation test with 1,000 simulations to validate the results using global_moran_perm function.\nWe will evaluate the following tourism economy indicators:\n\nTotal Tourists\nAverage of Tourist Stay Rate\nRevenue per Tourist\n\nFor each indicator, we will apply both the K-Nearest Neighbors (KNN) and Distance Band weight matrices to observe the spatial patterns.\n\n6.2.1 Total Tourists: Global Moran’s I Test and Permutation Test\n\n6.2.1.1 KNN Weights\n\nglobal_moran_test(wm_knn$total_tourists_all,\n           wm_knn$nb,\n           wm_knn$wt,\n           zero.policy = TRUE,\n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 1.1069, p-value = 0.1342\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.026678128      -0.013157895       0.001295218 \n\n\n\nset.seed(2024)\nglobal_moran_perm(wm_knn$total_tourists_all,\n                  wm_knn$nb,\n                  wm_knn$wt,\n                  nsim = 999)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.026678, observed rank = 879, p-value = 0.242\nalternative hypothesis: two.sided\n\n\n\n\n6.2.1.2 Distance Band Weights\n\nglobal_moran_test(wm_fd$total_tourists_all,\n           wm_fd$nb,\n           wm_fd$wt,\n           zero.policy = TRUE,\n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 1.0694, p-value = 0.1424\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.040849188      -0.013157895       0.002550464 \n\n\n\nset.seed(2024)\nglobal_moran_perm(wm_fd$total_tourists_all,\n                  wm_fd$nb,\n                  wm_fd$wt,\n                  nsim = 999)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.040849, observed rank = 881, p-value = 0.238\nalternative hypothesis: two.sided\n\n\n\n\n\n\n\n\nObservations:\nK-Nearest Neighbors (KNN):\n\nMoran’s I statistic: 0.0267\np-value (Moran’s I test): 0.1342\np-value (Monte Carlo permutation test): 0.242\n\nThe Moran’s I statistic of 0.0267 shows very weak positive spatial autocorrelation, suggesting almost no spatial clustering of total tourists. Both the Moran’s I test and the Monte Carlo permutation test yield high p-values (above 0.05), indicating that we fail to reject the null hypothesis. This implies that the distribution of total tourists remains random, with no significant spatial clustering when using normalized KNN weights.\n\nDistance Band Weights:\n\nMoran’s I statistic: 0.0408\np-value (Moran’s I test): 0.1424\np-value (Monte Carlo permutation test): 0.238\n\nThe Moran’s I statistic of 0.0408 also shows weak positive spatial autocorrelation, indicating no substantial clustering of total tourists across provinces. The high p-values from both the Moran’s I test and Monte Carlo permutation test further confirm that we fail to reject the null hypothesis. The total tourist distribution remains random, with no significant spatial dependence when using normalized distance-based weights.\n\nFor total tourists, both the KNN and distance band methods show no significant spatial autocorrelation. The p-values from both tests indicate that we fail to reject the null hypothesis.\n\n\n\n\n\n\n6.2.2 Average of Tourist Stay Rate: Global Moran’s I Test and Permutation Test\n\n6.2.2.1 KNN Weights\n\nglobal_moran_test(wm_knn$avg_tourist_stay_rate,\n           wm_knn$nb,\n           wm_knn$wt,\n           zero.policy = TRUE,\n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 7.4571, p-value = 4.422e-14\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.409217712      -0.013157895       0.003208175 \n\n\n\nset.seed(2024)\nglobal_moran_perm(wm_knn$avg_tourist_stay_rate,\n                  wm_knn$nb,\n                  wm_knn$wt,\n                  nsim = 999)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.40922, observed rank = 1000, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\n6.2.2.2 Distance Band Weights\n\nglobal_moran_test(wm_fd$avg_tourist_stay_rate,\n           wm_fd$nb,\n           wm_fd$wt,\n           zero.policy = TRUE,\n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 5.9277, p-value = 1.536e-09\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.458854837      -0.013157895       0.006340634 \n\n\n\nset.seed(2024)\nglobal_moran_perm(wm_fd$avg_tourist_stay_rate,\n                  wm_fd$nb,\n                  wm_fd$wt,\n                  nsim = 999)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.45885, observed rank = 1000, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\n\n\n\n\nObservations:\nK-Nearest Neighbors (KNN):\n\nMoran’s I statistic: 0.4092\np-value (Moran’s I test): 4.422e-14\np-value (Monte Carlo permutation test): &lt; 2.2e-16\n\nThe Moran’s I statistic of 0.4092 indicates strong positive spatial autocorrelation, suggesting that provinces with similar tourist stay rates tend to be clustered together. Both the Moran’s I test and the Monte Carlo permutation test return extremely low p-values, confirming that this clustering is highly statistically significant. Thus, we reject the null hypothesis, as there is strong evidence of spatial dependence in tourist stay rates when using normalized KNN weights.\n\nDistance Band Weights:\n\nMoran’s I statistic: 0.4586\np-value (Moran’s I test): 1.536e-09\np-value (Monte Carlo permutation test): &lt; 2.2e-16\n\nThe Moran’s I statistic of 0.4586 shows strong positive spatial autocorrelation, indicating that provinces with similar tourist stay rates are geographically clustered. Both the Moran’s I test and the Monte Carlo permutation test yield very low p-values, confirming that this spatial clustering is highly statistically significant. Therefore, we reject the null hypothesis, as there is strong evidence of spatial dependence using normalized distance-based weights.\n\nFor average tourist stay rate, both the KNN and distance band methods show strong spatial autocorrelation, and the results are highly statistically significant. In both cases, we reject the null hypothesis, indicating that provinces with similar tourist stay rates are spatially clustered.\n\n\n\n\n\n\n6.2.3 Average Revenue per Tourists: Global Moran’s I Test and Permutation Test\n\n6.2.3.1 KNN Weights\n\nglobal_moran_test(wm_knn$avg_revenue_per_tourist,\n           wm_knn$nb,\n           wm_knn$wt,\n           zero.policy = TRUE,\n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 7.125, p-value = 5.204e-13\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.344633674      -0.013157895       0.002521688 \n\n\n\nset.seed(2024)\nglobal_moran_perm(wm_knn$avg_revenue_per_tourist,\n                  wm_knn$nb,\n                  wm_knn$wt,\n                  nsim = 999)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.34463, observed rank = 1000, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\n6.2.3.2 Distance Band Weights\n\nglobal_moran_test(wm_fd$avg_revenue_per_tourist,\n           wm_fd$nb,\n           wm_fd$wt,\n           zero.policy = TRUE,\n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 6.3368, p-value = 1.173e-10\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.434043125      -0.013157895       0.004980487 \n\n\n\nset.seed(2024)\nglobal_moran_perm(wm_fd$avg_revenue_per_tourist,\n                  wm_fd$nb,\n                  wm_fd$wt,\n                  nsim = 999)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.43404, observed rank = 1000, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\n\n\n\n\nObservations:\nK-Nearest Neighbors (KNN):\n\nMoran’s I statistic: 0.3446\np-value (Moran’s I test): 5.204e-13\np-value (Monte Carlo permutation test): &lt; 2.2e-16\n\nThe Moran’s I statistic of 0.3446 indicates moderate positive spatial autocorrelation, suggesting that provinces with similar revenue per tourist tend to be clustered. Both the Moran’s I test and the Monte Carlo permutation test return very low p-values, confirming that this clustering is highly statistically significant. Therefore, we reject the null hypothesis, as there is strong evidence of spatial dependence in revenue per tourist when using normalized KNN weights.\n\nDistance Band Weights:\n\nMoran’s I statistic: 0.4340\np-value (Moran’s I test): 1.173e-10\np-value (Monte Carlo permutation test): &lt; 2.2e-16\n\nThe Moran’s I statistic of 0.4340 indicates strong positive spatial autocorrelation, showing that provinces with similar revenue per tourist are geographically clustered. Both the Moran’s I test and the Monte Carlo permutation test yield extremely low p-values, confirming that this spatial clustering is highly statistically significant. Therefore, we reject the null hypothesis, as there is clear evidence of spatial dependence using normalized distance-based weights.\n\nFor average revenue per tourist, both the KNN and distance band methods with inverse distance weights show moderate spatial autocorrelation, and the results are statistically significant. In both cases, we reject the null hypothesis, indicating that provinces with similar revenue per tourist are spatially clustered."
  },
  {
    "objectID": "take_home_ex/take_home_ex02/take_home_ex02.html#cluster-and-outlier-analysis",
    "href": "take_home_ex/take_home_ex02/take_home_ex02.html#cluster-and-outlier-analysis",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "7.1 Cluster and Outlier Analysis",
    "text": "7.1 Cluster and Outlier Analysis\n\n7.1.1 Computing Local Moran’s I\nWe will compute Local Moran’s I of three selected indicators at province level by using local_moran() function of sfdep package.\n\nset.seed(2024)\nlisa_total_tourists_knn &lt;- wm_knn %&gt;% \n  mutate(local_moran = local_moran(\n    total_tourists_all, nb, wt),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\n\nset.seed(2024)\nlisa_tourist_stay_rate_knn &lt;- wm_knn %&gt;% \n  mutate(local_moran = local_moran(\n    avg_tourist_stay_rate, nb, wt),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\n\nset.seed(2024)\nlisa_revenue_per_tourist_knn &lt;- wm_knn %&gt;% \n  mutate(local_moran = local_moran(\n    avg_revenue_per_tourist, nb, wt),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\n\n\n7.1.2 Plotting LISA map\nWe will use the tmap package to visualize the results of the Local Moran’s I computation, specifically using the values from the ii and mean fields. To enable effective comparison, we will plot both maps side by side—one showing the local spatial autocorrelation (ii values) and the other highlighting the clusters or outliers of total tourists. Specifically, we will highlight clusters where the p-values from the Local Moran’s I are below 0.05, indicating potential spatial clusters or outliers.\nFirst, let’s define the label and palette for each cluster.\n\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"Insignificant\", \"Low-Low\", \"Low-High\", \"High-Low\", \"High-High\")\n\n\n7.1.2.1 Total Number of Tourists\n\nlisa_total_tourists_knn$quadrant &lt;- case_when(\n  lisa_total_tourists_knn$p_ii_sim &gt;= 0.05 ~ 0,  # Set quadrant to 0 if p_ii_sim is greater than or equal to 0.05\n  lisa_total_tourists_knn$mean == \"Low-Low\" ~ 1,  # Assign quadrant values for significant clusters\n  lisa_total_tourists_knn$mean == \"Low-High\" ~ 2,\n  lisa_total_tourists_knn$mean == \"High-Low\" ~ 3,\n  lisa_total_tourists_knn$mean == \"High-High\" ~ 4\n)\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nmap1 &lt;- tm_shape(lisa_total_tourists_knn) +\n  tm_fill(\"ii\") +\n  tm_borders(alpha = 0.5) +\n  tm_view() +\n  tm_layout(\n    main.title = \"Local Moran's I of Total Tourists\",\n    main.title.size = 0.8\n  )\n\nmap2 &lt;- tm_shape(lisa_total_tourists_knn) +\n  tm_fill(\"quadrant\",\n          breaks = c(-0.5, 0.5, 1.5, 2.5, 3.5, 4.5),\n          palette = colors,\n          labels = clusters)+\n  tm_borders(alpha = 0.5) +\n  tm_view() +\n  tm_layout(\n    main.title = \"LISA Map of Total Tourists\",\n    main.title.size = 0.8\n  )\n\ntmap_arrange(map1, map2, ncol = 2)\n\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n7.1.2.2 Average of Tourist Stay Rate\n\nlisa_tourist_stay_rate_knn$quadrant &lt;- case_when(\n  lisa_tourist_stay_rate_knn$p_ii_sim &gt;= 0.05 ~ 0,  # Set quadrant to 0 if p_ii_sim is greater than or equal to 0.05\n  lisa_tourist_stay_rate_knn$mean == \"Low-Low\" ~ 1,  # Assign quadrant values for significant clusters\n  lisa_tourist_stay_rate_knn$mean == \"Low-High\" ~ 2,\n  lisa_tourist_stay_rate_knn$mean == \"High-Low\" ~ 3,\n  lisa_tourist_stay_rate_knn$mean == \"High-High\" ~ 4\n)\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nmap1 &lt;- tm_shape(lisa_tourist_stay_rate_knn) +\n  tm_fill(\"ii\") +\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(\n    main.title = \"Local Moran's I of Tourists Stay Rate\",\n    main.title.size = 0.8\n  )\n\nmap2 &lt;- tm_shape(lisa_tourist_stay_rate_knn) +\n  tm_fill(\"quadrant\",\n          breaks = c(-0.5, 0.5, 1.5, 2.5, 3.5, 4.5),\n          palette = colors,\n          labels = clusters) +\n  tm_borders(alpha = 0.5) +\n  tm_view() +\n  tm_layout(\n    main.title = \"LISA Map of Tourists Stay Rate\",\n    main.title.size = 0.8\n  )\n\ntmap_arrange(map1, map2, ncol = 2)\n\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\n\n\n7.1.2.3 Average Revenue Per Tourists\n\nlisa_revenue_per_tourist_knn$quadrant &lt;- case_when(\n  lisa_revenue_per_tourist_knn$p_ii_sim &gt;= 0.05 ~ 0,  # Set quadrant to 0 if p_ii_sim is greater than or equal to 0.05\n  lisa_revenue_per_tourist_knn$mean == \"Low-Low\" ~ 1,  # Assign quadrant values for significant clusters\n  lisa_revenue_per_tourist_knn$mean == \"Low-High\" ~ 2,\n  lisa_revenue_per_tourist_knn$mean == \"High-Low\" ~ 3,\n  lisa_revenue_per_tourist_knn$mean == \"High-High\" ~ 4\n)\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nmap1 &lt;- tm_shape(lisa_revenue_per_tourist_knn) +\n  tm_fill(\"ii\") +\n  tm_borders(alpha = 0.5) +\n  tm_view() +\n  tm_layout(\n    main.title = \"Local Moran's I of Revenue per Tourist\",\n    main.title.size = 0.8\n  )\n\nmap2 &lt;- tm_shape(lisa_revenue_per_tourist_knn) +\n  tm_fill(\"quadrant\",\n          breaks = c(-0.5, 0.5, 1.5, 2.5, 3.5, 4.5),\n          palette = colors,\n          labels = clusters) +\n  tm_borders(alpha = 0.5) +\n  tm_view() +\n  tm_layout(\n    main.title = \"LISA Map of Revenue per Tourist\",\n    main.title.size = 0.8\n  )\n\ntmap_arrange(map1, map2, ncol = 2)\n\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\nIn the analysis of total tourists, Samut Prakan emerges as a Low-High outlier. This province has 8 million tourists in contrast to its neighboring province, Bangkok, which sees 151 million tourists. For tourist stay rates, several Low-High outliers are observed in provinces surrounding Bangkok, likely due to the prevalence of day trips where tourists visit nearby locations but return to Bangkok by the end of the day. Additionally, High-High clusters are identified in Krabi and adjacent southern provinces, with a Low-High outlier in Phang Nga, which is in close proximity to the popular tourist destinations such as Phuket and Krabi.\nIn terms of revenue per tourist, Bangkok is classified as a High-Low outlier, which aligns with its status as Thailand’s primary tourism hub, attracting the largest number of tourists. Furthermore, a High-High cluster is evident in Phuket, Krabi, and Phang Nga, which are well-known major tourism areas. However, neighboring provinces such as Nakhon Si Thammarat and Phatthalung are identified as Low-High outliers, despite their proximity to these popular destinations."
  },
  {
    "objectID": "take_home_ex/take_home_ex02/take_home_ex02.html#hot-and-cold-spot-analysis-with-local-gi",
    "href": "take_home_ex/take_home_ex02/take_home_ex02.html#hot-and-cold-spot-analysis-with-local-gi",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "7.2 Hot and Cold Spot Analysis with Local Gi*",
    "text": "7.2 Hot and Cold Spot Analysis with Local Gi*\nBesides detecting clusters and outliers, localized spatial statistics can also be used to identify hot spots and/or cold spots.\nThe High/Low Clustering (General G) tool measures the spatial concentration of high or low values within a given study area. The null hypothesis for this statistic states that there is no spatial clustering of feature values. When the p-value is small and statistically significant, the null hypothesis can be rejected, and the sign of the Gi value becomes crucial for interpretation.\n\nIf the Gi value is positive and statistically significant, it indicates that the location is associated with high values in the surrounding area (i.e., hot spots).\nIf the Gi value is negative and statistically significant, it indicates that the location is surrounded by low values (i.e., cold spots).\n\nThe Getis-Ord General G tool is most effective when values are evenly distributed across the area, as it helps identify unexpected clusters of high values (hot spots). However, it has a limitation: when both high and low values are clustered within the same region, they tend to cancel each other out, reducing the tool’s effectiveness in such cases.\nIn this study, we will compute the Local Gi statistic in R. First, we will use the st_dist_band() function to create a neighbor list, and then apply the include_self() function to ensure that the focal observation is included in its own neighbor list. Afterward, we will use this neighbor list to create a weight list by applying the st_inverse_distance() function. To ensure comparability and balanced influence across locations, we will normalize the weights, which helps prevent bias and stabilizes the effect of distance on the results.\n\nwm_idw &lt;- province_summary %&gt;%\n  mutate(nb = include_self(st_dist_band(geometry)),\n         wt = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1),\n         wt = map(wt, ~ .x / sum(.x)),\n         .before = 1)\n\n! Polygon provided. Using point on surface.\n! Polygon provided. Using point on surface.\n\n\nNow, we will calculate the Local Gi statistic using the local_gstar_perm() function from the sfdep package. This function takes a neighbor list (nb) and a weight list (wt) as inputs and generates the Gi statistics* through a Monte Carlo permutation with a specified number of simulations (nsim). The results will then be stored in a new object called HCSA.\nAfter we run the Montewe replace any p-values (p_sim) greater than 0.05 with NA to filter out non-significant results. Then, we update the Gi statistic (gi_star) by setting it to NA for any non-significant values, ensuring that only statistically significant hot spots and cold spots are retained in the final output.\n\n7.2.1 Compute Local Gi statistic\nTotal Number of Tourists\n\nHCSA_total_tourist &lt;- wm_idw %&gt;% \n  mutate(local_Gi = local_gstar_perm(\n    total_tourists_all, nb, wt, nsim = 999),\n         .before = 1) %&gt;%\n  unnest(local_Gi) %&gt;%\n  mutate(\"p_sim\" = replace(`p_sim`, `p_sim` &gt; 0.05, NA),\n         \"gi_star\" = ifelse(is.na(`p_sim`), NA, `gi_star`))\n\nAverage of Tourist Stay Rate\n\nHCSA_tourist_stay_rate &lt;- wm_idw %&gt;% \n  mutate(local_Gi = local_gstar_perm(\n    avg_tourist_stay_rate, nb, wt, nsim = 999),\n         .before = 1) %&gt;%\n  unnest(local_Gi) %&gt;%\n  mutate(\"p_sim\" = replace(`p_sim`, `p_sim` &gt; 0.05, NA),\n         \"gi_star\" = ifelse(is.na(`p_sim`), NA, `gi_star`))\n\nAverage Revenue per Tourist\n\nHCSA_revenue_per_tourist &lt;- wm_idw %&gt;% \n  mutate(local_Gi = local_gstar_perm(\n    avg_revenue_per_tourist, nb, wt, nsim = 999),\n         .before = 1) %&gt;%\n  unnest(local_Gi) %&gt;%\n  mutate(\"p_sim\" = replace(`p_sim`, `p_sim` &gt; 0.05, NA),\n         \"gi_star\" = ifelse(is.na(`p_sim`), NA, `gi_star`))\n\n\n\n7.2.2 Visualize local hot spot and cold spot areas\nNext, we will visualize the locations of hot spot and cold spot areas. The choropleth mapping functions from the tmap package will be used to map the Gi values for each selected indicator.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nmap1 &lt;- tm_shape(HCSA_total_tourist) +\n  tm_fill(\"gi_star\", palette=\"-RdBu\", midpoint=0, title=\"Gi*\") + \n  tm_borders(alpha = 0.5) +\n  tm_layout(\n    main.title = \"HCSA: Total Tourists\",\n    main.title.size = 0.8\n  )\n\nmap2 &lt;- tm_shape(HCSA_tourist_stay_rate) +\n  tm_fill(\"gi_star\", palette=\"-RdBu\", midpoint=0, title=\"Gi*\") + \n  tm_borders(alpha = 0.5) +\n  tm_layout(\n    main.title = \"HCSA: Tourist Stay Rate\",\n    main.title.size = 0.8\n  )\n\nmap3 &lt;- tm_shape(HCSA_revenue_per_tourist) +\n  tm_fill(\"gi_star\", palette=\"-RdBu\", midpoint=0, title=\"Gi*\") + \n  tm_borders(alpha = 0.5) +\n  tm_layout(\n    main.title = \"HCSA: Revenue per Tourist\",\n    main.title.size = 0.8\n  )\n\ntmap_arrange(map1, map2, map3, ncol = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe Local Gi maps* highlight distinct patterns of hot spots and cold spots across Thailand, consistent with the earlier LISA analysis. In the total tourists map, a cold spot is visible in the north-eastern provinces, reflecting a lower concentration of tourists, while a small hot spot is visible in Bangkok Province. The tourist stay rate map shows cold spots in provinces surrounding Bangkok, likely due to day-trip tourists, while hot spots are observed in southern provinces like Krabi and Phang Nga, where tourists tend to stay longer. Finally, the revenue per tourist map identifies strong hot spots in the southern provinces of Phuket, Krabi, and Phang Nga, known for their tourism appeal, with cold spots in the north-eastern provinces, where fewer tourists visit and generate less revenue."
  },
  {
    "objectID": "take_home_ex/take_home_ex02/take_home_ex02.html#spacetime-cube",
    "href": "take_home_ex/take_home_ex02/take_home_ex02.html#spacetime-cube",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "5.5 Spacetime Cube",
    "text": "5.5 Spacetime Cube\nThe sfdep package introduces an S3 class called spacetime, developed by Edzer Pebesma (2012), to represent spatio-temporal data. The spacetime class links a flat dataset containing both spatial and temporal information with the corresponding geometry. By encapsulating both spatial and temporal aspects, it is ideal for conducting spatio-temporal analysis. We will utilize this spacetime cube for our spatio-temporal analysis in the Emerging Hot Spot Analysis section.\nWe will use the spacetime() function from the sfdep package to create a spatio-temporal cube of the data. The year and month will serve as our temporal factors for structuring the analysis.\nFirst, we will add period column to our tourism data by combining the year and month using the format() function, and then converting it to an integer with as.integer().\n\ntourism &lt;- tourism %&gt;%\n  mutate(period = as.integer(format(date, \"%Y%m\")))\n\nNext, we will create a spatio-temporal cube using the spacetime() function from the sfdep package. We will use the period as the time_col and province_eng as the loc_col to represent the temporal and spatial dimensions. We’ll also set NA values in revenue_per_tourist_all and tourist_stay_rate to 0, as this will help us identify potential cold spots in the analysis later.\n\ntourism$tourist_stay_rate[is.na(tourism$tourist_stay_rate)] &lt;- 0\ntourism$revenue_per_tourist_all[is.na(tourism$revenue_per_tourist_all)] &lt;- 0\ntourism_st &lt;- spacetime(tourism, admin_boundary,\n                        .loc_col = \"province_eng\",\n                        .time_col = \"period\")\n\nNext, we will use is_spacetime_cube() of sfdep package to verify if tourism_st is indeed an space-time cube object.\n\nis_spacetime_cube(tourism_st)\n\n[1] TRUE\n\n\n\n tourism_st &lt;- tourism_st %&gt;%\n  activate(\"geometry\") %&gt;%\n  mutate(nb = st_knn(geometry, k = 8),\n         wt = st_inverse_distance(nb, geometry, scale = 1, alpha = 1),\n         wt = map(wt, ~ .x / sum(.x)),\n         .before = 1) %&gt;%\n  set_nbs(\"nb\") %&gt;%\n  set_wts(\"wt\")\n\n! Polygon provided. Using point on surface.\n! Polygon provided. Using point on surface."
  },
  {
    "objectID": "take_home_ex/take_home_ex02/take_home_ex02.html#time-horizons",
    "href": "take_home_ex/take_home_ex02/take_home_ex02.html#time-horizons",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "8.1 Time Horizons",
    "text": "8.1 Time Horizons\nAs hot spots and cold spots may shift over time, we aim to perform the Emerging Hot Spot Analysis (EHSA) across different time horizons to capture these changes. The analysis will be conducted in four distinct periods:\n\nAcross All Time: This phase includes all available data within the dataset, providing a comprehensive view of hot and cold spot evolution over the entire time span.\nPre-COVID-19 Pandemic: This period covers tourism trends before the pandemic began affecting Thailand, specifically before January 13, 2020, when Thailand confirmed its first COVID-19 case.\nCOVID-19 Pandemic Period: This period starts in January 2020, when Thailand reported its first COVID-19 case, and extends until the country began reopening its borders in June 2022.\nPost-COVID-19 Pandemic: This period begins in June 2022, when Thailand started to lift pandemic-related restrictions and resumed international travel, this phase reflects the gradual recovery of the tourism industry."
  },
  {
    "objectID": "take_home_ex/take_home_ex02/take_home_ex02.html#performing-emerging-hotspot-analysis",
    "href": "take_home_ex/take_home_ex02/take_home_ex02.html#performing-emerging-hotspot-analysis",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "8.2 Performing Emerging Hotspot Analysis",
    "text": "8.2 Performing Emerging Hotspot Analysis\nWe’ll use the following function to ensure consistent coloring for each kind of hot/cold spot, making it easier to compare across maps. This function is originally found from Matthew Ho’s IS415 Geospatial Analytics & Applications, with a slight adaptation in the color map to enhance contrast and clarity between categories.\n\ncreate_color_mapping &lt;- function(all_breaks, all_colors, map_breaks) {\n  color_mapping &lt;- rep(NA, length(map_breaks))\n  for (i in seq_along(map_breaks)) {\n    match_index &lt;- match(map_breaks[i], all_breaks)\n    if (!is.na(match_index)) {\n      color_mapping[i] &lt;- all_colors[match_index]\n    }\n  }\n  return(color_mapping)\n}\n\nall_breaks &lt;- c(\"consecutive coldspot\", \"consecutive hotspot\", \"new coldspot\", \"new hotspot\", \"no pattern detected\", \"intensifying coldspot\", \"intensifying hotspot\", \"oscilating coldspot\", \"oscilating hotspot\", \"persistent coldspot\", \"persistent hotspot\", \"sporadic coldspot\", \"sporadic hotspot\")\n\nall_colors &lt;- c(\n  \"#1E90FF\",  # Consecutive coldspot - bright blue (strong cool)\n  \"#FF4500\",  # Consecutive hotspot - strong orange-red (strong heat)\n  \"#87CEEB\",  # New coldspot - sky blue (mild cool)\n  \"#FFA07A\",  # New hotspot - light salmon (mild heat)\n  \"#A9A9A9\",  # No pattern detected - neutral grey\n  \"#00008B\",  # Intensifying coldspot - dark blue (intensifying cool)\n  \"#FF8C00\",  # Intensifying hotspot - dark orange (intensifying heat)\n  \"#5F9EA0\",  # Oscillating coldspot - cadet blue (moderate cool)\n  \"#FF6347\",  # Oscillating hotspot - tomato (moderate heat)\n  \"#4682B4\",  # Persistent coldspot - steel blue (long-term cool)\n  \"#FF0000\",  # Persistent hotspot - red (long-term heat)\n  \"#00CED1\",  # Sporadic coldspot - dark turquoise (irregular cool)\n  \"#FFD700\"   # Sporadic hotspot - gold (irregular heat)\n)\n\nAs we plan to run the analysis over multiple time horizons and across multiple tourism economy indicators, we will use the following function. This function will accept a space-time object, the indicator name, and the start and end periods to perform a series of computations and visualizations of the Emerging Hotspot Analysis results.\n\nperform_ehsa_analysis &lt;- function(space_time_object, indicator, admin_boundary, start_period = NULL, end_period = NULL) {\n  \n  # Step 1: Filter the space-time object based on the period if provided\n  filtered_data &lt;- tourism_st %&gt;%\n    filter(\n      if (!is.null(start_period)) period &gt;= start_period else TRUE,\n      if (!is.null(end_period)) period &lt;= end_period else TRUE\n    )\n  \n  set.seed(2024)\n  # Step 2: Perform the Emerging Hotspot Analysis\n  ehsa &lt;- emerging_hotspot_analysis(\n    x = filtered_data,\n    .var = indicator, \n    k = 1, \n    nsim = 499,\n    nb_col = 'nb',\n    wt_col = 'wt'\n  )\n  \n  # Step 3: Visualize the classification distribution as a bar plot\n  gghist &lt;- ggplot(data = ehsa, aes(x = classification)) +\n    geom_bar(fill=\"light blue\") + \n    coord_flip()\n  \n  plot(gghist)\n\n  # Step 4: Join EHSA results with the admin boundary data\n  result_ehsa &lt;- admin_boundary %&gt;%\n    left_join(ehsa, by = join_by(province_eng == location))\n  \n  # Step 5: Filter the significant results with p-value &lt; 0.05\n  ehsa_sig &lt;- result_ehsa %&gt;%\n    filter(p_value &lt; 0.05)\n  \n  # Step 6: Create color mapping for the significant classifications\n  color_mapping &lt;- create_color_mapping(all_breaks, all_colors, sort(unique(ehsa_sig$classification)))\n\n  # Step 7: Visualize the results using tmap\n  tmap_mode(\"plot\")\n  tm_shape(result_ehsa) +\n    tm_borders(alpha = 0.2) +\n    tm_shape(ehsa_sig) +\n    tm_fill(\"classification\", title = \"Classification\", palette = color_mapping) + \n    tm_borders(alpha = 0.2)\n}\n\n\n8.2.1 Number of All Tourists\n\nAll timePre-pandemicPandemic periodPost-pandemic\n\n\n\nperform_ehsa_analysis(\n  space_time_object = tourism_st,\n  indicator = \"no_tourist_all\",\n  admin_boundary = admin_boundary\n)\n\ntmap mode set to plotting\n\n\n\n\n\n\n\n\n\nLegend labels were too wide. The labels have been resized to 0.51, 0.59. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\n\n\n\n\n\n\n\n\n\n\n\n\nperform_ehsa_analysis(\n  space_time_object = tourism_st,\n  indicator = \"no_tourist_all\",\n  admin_boundary = admin_boundary,\n  end_period = 201912\n)\n\ntmap mode set to plotting\n\n\n\n\n\n\n\n\n\nLegend labels were too wide. The labels have been resized to 0.51, 0.56. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\n\n\n\n\n\n\n\n\n\n\n\n\nperform_ehsa_analysis(\n  space_time_object = tourism_st,\n  indicator = \"no_tourist_all\",\n  admin_boundary = admin_boundary,\n  start_period = 202001,\n  end_period = 202205\n)\n\ntmap mode set to plotting\n\n\n\n\n\n\n\n\n\nLegend labels were too wide. The labels have been resized to 0.51, 0.56. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\n\n\n\n\n\n\n\n\n\n\n\n\nperform_ehsa_analysis(\n  space_time_object = tourism_st,\n  indicator = \"no_tourist_all\",\n  admin_boundary = admin_boundary,\n  start_period = 202206\n)\n\ntmap mode set to plotting\n\n\n\n\n\n\n\n\n\nLegend labels were too wide. The labels have been resized to 0.49, 0.49, 0.51, 0.52, 0.56. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe analysis of the Number of All Tourists across various time periods reveals distinct patterns of hot and cold spots in different provinces. All time data shows Sukhothai and Rayong as sporadic hotspots, indicating occasional high tourist activity in these provinces. Before the pandemic, Nakhon Si Thammarat and Chachoengsao were identified as sporadic cold spots, reflecting lower tourist numbers. During the pandemic, Phuket, a major tourist destination, experienced a sporadic cold spot, likely due to the severe impact of travel restrictions. In the post-pandemic period, several patterns emerged: Trang remained a sporadic cold spot, while Ang Thong and Phitsanulok became consecutive hotspots, showing sustained increases in tourist numbers. Meanwhile, Phichit is experiencing an intensifying cold spot, and Nong Bua Lamphu is classified as a persistent cold spot, indicating a continuous lack of tourist activity.\n\n\n\n\n8.2.2 Tourist Stay Rate\n\nAll timePre-pandemicPandemic periodPost-pandemic\n\n\n\nperform_ehsa_analysis(\n  space_time_object = tourism_st,\n  indicator = \"tourist_stay_rate\",\n  admin_boundary = admin_boundary\n)\n\ntmap mode set to plotting\n\n\n\n\n\n\n\n\n\nLegend labels were too wide. The labels have been resized to 0.49, 0.51, 0.53, 0.56, 0.59. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\n\n\n\n\n\n\n\n\n\n\n\n\nperform_ehsa_analysis(\n  space_time_object = tourism_st,\n  indicator = \"tourist_stay_rate\",\n  admin_boundary = admin_boundary,\n  end_period = 201912\n)\n\ntmap mode set to plotting\n\n\n\n\n\n\n\n\n\nSome legend labels were too wide. These labels have been resized to 0.47, 0.49, 0.49, 0.51, 0.52, 0.55, 0.56, 0.59. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\n\n\n\n\n\n\n\n\n\n\n\n\nperform_ehsa_analysis(\n  space_time_object = tourism_st,\n  indicator = \"tourist_stay_rate\",\n  admin_boundary = admin_boundary,\n  start_period = 202001,\n  end_period = 202205\n)\n\ntmap mode set to plotting\n\n\n\n\n\n\n\n\n\nLegend labels were too wide. The labels have been resized to 0.49, 0.51, 0.53, 0.56, 0.59. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\n\n\n\n\n\n\n\n\n\n\n\n\nperform_ehsa_analysis(\n  space_time_object = tourism_st,\n  indicator = \"tourist_stay_rate\",\n  admin_boundary = admin_boundary,\n  start_period = 202206\n)\n\ntmap mode set to plotting\n\n\n\n\n\n\n\n\n\nLegend labels were too wide. The labels have been resized to 0.47, 0.49, 0.51, 0.52, 0.55, 0.59. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe analysis of Tourist Stay Rate reveals varying patterns of hot and cold spots across different time periods. Across all time, Phang Nga, Prachuap Khiri Khan, Samut Prakan, and Prachin Buri show intensifying cold spots, indicating a decline in tourist stay rates. Several provinces, including Phuket, Chumphon, Yala, Songkhla, and Ayutthaya, experienced sporadic hotspots, reflecting occasional spikes in overnight stays, while others, like Bangkok and Kanchanaburi, displayed sporadic cold spots. Additionally, provinces like Sisaket, Pathum Thani, and Udon Thani showed oscillating cold spots, meaning fluctuating tourist stay rate.\nBefore the pandemic, Samut Prakan was a persistent cold spot, while Mukdahan was a persistent hotspot. Lamphun and Samut Songkhram saw consecutive hotspots, with steady increases in tourist stays. Sporadic cold spots were observed in Khon Kaen, while Pathum Thani and Sukhothai exhibited consecutive cold spots. Trat emerged as a new cold spot during this period.\nDuring the pandemic, Phuket, Chumphon, and other provinces like Tak and Chainat became sporadic hotspots, while Samut Prakan, Phang Nga, and Prachin Buri showed intensifying cold spots. Sporadic cold spots were present in Pathum Thani, Sukhothai, and Sisaket, and Udon Thani displayed oscillating cold spot behavior.\nIn the post-pandemic phase, Chiang Rai, Phang Nga, and Samut Sakhon became persistent cold spots, indicating a continuous decline in tourist stay rates. Nakhon Pathom and Nonthaburi exhibited consecutive cold spots, while Samut Prakan and Sukhothai saw intensifying cold spots. On the other hand, Tak maintained a persistent hotspot, and Yala and Mukdahan experienced sporadic hotspots.\n\n\n\n\n8.2.3 Revenue Per Tourist\n\nAll timePre-pandemicPandemic periodPost-pandemic\n\n\n\nperform_ehsa_analysis(\n  space_time_object = tourism_st,\n  indicator = \"revenue_per_tourist_all\",\n  admin_boundary = admin_boundary\n)\n\ntmap mode set to plotting\n\n\n\n\n\n\n\n\n\nLegend labels were too wide. The labels have been resized to 0.47, 0.51, 0.51, 0.53, 0.56, 0.59. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\n\n\n\n\n\n\n\n\n\n\n\n\nperform_ehsa_analysis(\n  space_time_object = tourism_st,\n  indicator = \"revenue_per_tourist_all\",\n  admin_boundary = admin_boundary,\n  end_period = 201912\n)\n\ntmap mode set to plotting\n\n\n\n\n\n\n\n\n\nLegend labels were too wide. The labels have been resized to 0.51, 0.52. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\n\n\n\n\n\n\n\n\n\n\n\n\nperform_ehsa_analysis(\n  space_time_object = tourism_st,\n  indicator = \"revenue_per_tourist_all\",\n  admin_boundary = admin_boundary,\n  start_period = 202001,\n  end_period = 202205\n)\n\ntmap mode set to plotting\n\n\n\n\n\n\n\n\n\nLegend labels were too wide. The labels have been resized to 0.47, 0.51, 0.53, 0.52, 0.56, 0.59. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\n\n\n\n\n\n\n\n\n\n\n\n\nperform_ehsa_analysis(\n  space_time_object = tourism_st,\n  indicator = \"revenue_per_tourist_all\",\n  admin_boundary = admin_boundary,\n  start_period = 202206\n)\n\ntmap mode set to plotting\n\n\n\n\n\n\n\n\n\nLegend labels were too wide. The labels have been resized to 0.47, 0.49, 0.51, 0.52, 0.56. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe analysis of Revenue per Tourist shows notable patterns across various time horizons. Across all time, many provinces, including Bangkok and Ratchaburi, experienced sporadic cold spots, indicating occasional drops in revenue generated per tourist. In contrast, Phang Nga and Satun saw intensifying hotspots, suggesting consistent growth in tourist spending. Other provinces like Phuket, Kanchanaburi, and Chiang Mai were identified as sporadic hotspots, while Trang and Trat faced consecutive cold spots, showing a steady decline in revenue.\nBefore the pandemic, Chaiyaphum was a persistent cold spot, maintaining low tourist revenue throughout this period.\nDuring the pandemic, several patterns emerged: Phang Nga became a persistent cold spot, while Satun faced consecutive cold spots. Udon Thani displayed oscillating cold spot behavior, showing fluctuations in revenue. Sporadic cold spots appeared in several provinces, including Krabi, Surat Thani, and Nonthaburi, while Phuket, Nakhon Si Thammarat, and Yala emerged as sporadic hotspots, reflecting occasional spikes in revenue despite the challenging pandemic environment.\nIn the post-pandemic phase, Phang Nga and Prachuap Khiri Khan became persistent cold spots, indicating prolonged declines in revenue. Several other provinces, such as Surat Thani and Nonthaburi, exhibited consecutive cold spots. Meanwhile, intensifying cold spots appeared in Bangkok, Samut Prakan, and Phichit, showing a worsening trend in revenue per tourist. On the other hand, Ratchaburi and Phatthalung experienced sporadic cold spots, signaling occasional dips in tourist revenue."
  },
  {
    "objectID": "in_class_ex/in_class_ex07/in_class_ex07.html",
    "href": "in_class_ex/in_class_ex07/in_class_ex07.html",
    "title": "In-class Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "",
    "text": "Geographically Weighted Regression (GWR) is a spatial statistical technique that accounts for non-stationary variables (e.g., climate, demographic factors, physical environment characteristics) to model the local relationships between these independent variables and a dependent variable, or outcome of interest.\nIn this hands-on exercise, we will learn to build hedonic pricing models using GWR methods. The dependent variable in this exercise is the resale prices of condominiums in 2015, while the independent variables are categorized as either structural or locational factors."
  },
  {
    "objectID": "in_class_ex/in_class_ex07/in_class_ex07.html#correlation-analysis---ggstatsplot-methods",
    "href": "in_class_ex/in_class_ex07/in_class_ex07.html#correlation-analysis---ggstatsplot-methods",
    "title": "In-class Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "4.1 Correlation Analysis - ggstatsplot methods",
    "text": "4.1 Correlation Analysis - ggstatsplot methods\nInstead of using corrplot, we’ll use ggcorrmat() function of ggstatplot package to perform correlation analysis.\n\nggcorrmat(condo_resale[, 5:23])"
  },
  {
    "objectID": "in_class_ex/in_class_ex07/in_class_ex07.html#model-assessment-olsrr-method",
    "href": "in_class_ex/in_class_ex07/in_class_ex07.html#model-assessment-olsrr-method",
    "title": "In-class Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "5.1 Model Assessment: olsrr method",
    "text": "5.1 Model Assessment: olsrr method\nIn this section, we will use a package named olsrr that specially programmed for performing OLS regression. It provides a collection of useful methods for building better multiple linear regression models:\n\ncomprehensive regression output\nresidual diagnostics\nmeasures of influence\nheteroskedasticity tests\nmodel fit assessment\nvariable contribution assessment\nvariable selection procedures\n\n\n5.1.1 Generating tidy linear regression report\n\nols_regress(condo_mlr)\n\n                                Model Summary                                 \n-----------------------------------------------------------------------------\nR                            0.807       RMSE                     750537.537 \nR-Squared                    0.652       MSE                571262902261.220 \nAdj. R-Squared               0.647       Coef. Var                    43.160 \nPred R-Squared               0.637       AIC                       42971.173 \nMAE                     412117.987       SBC                       43081.835 \n-----------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.515738e+15          19        7.977571e+13    139.648    0.0000 \nResidual      8.089083e+14        1416    571262902261.220                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     543071.420    136210.918                   3.987    0.000     275874.535     810268.305 \n            AREA_SQM      12688.669       370.119        0.579     34.283    0.000      11962.627      13414.710 \n                 AGE     -24566.001      2766.041       -0.166     -8.881    0.000     -29991.980     -19140.022 \n            PROX_CBD     -78121.985      6791.377       -0.267    -11.503    0.000     -91444.227     -64799.744 \n      PROX_CHILDCARE    -333219.036    111020.303       -0.087     -3.001    0.003    -551000.984    -115437.089 \n    PROX_ELDERLYCARE     170949.961     42110.748        0.083      4.060    0.000      88343.803     253556.120 \nPROX_URA_GROWTH_AREA      38507.622     12523.661        0.059      3.075    0.002      13940.700      63074.545 \n  PROX_HAWKER_MARKET      23801.197     29299.923        0.019      0.812    0.417     -33674.725      81277.120 \n   PROX_KINDERGARTEN     144097.972     82738.669        0.030      1.742    0.082     -18205.570     306401.514 \n            PROX_MRT    -322775.874     58528.079       -0.123     -5.515    0.000    -437586.937    -207964.811 \n           PROX_PARK     564487.876     66563.011        0.148      8.481    0.000     433915.162     695060.590 \n    PROX_PRIMARY_SCH     186170.524     65515.193        0.072      2.842    0.005      57653.253     314687.795 \nPROX_TOP_PRIMARY_SCH       -477.073     20597.972       -0.001     -0.023    0.982     -40882.894      39928.747 \n  PROX_SHOPPING_MALL    -207721.520     42855.500       -0.109     -4.847    0.000    -291788.613    -123654.427 \n    PROX_SUPERMARKET     -48074.679     77145.257       -0.012     -0.623    0.533    -199405.956     103256.599 \n       PROX_BUS_STOP     675755.044    138551.991        0.133      4.877    0.000     403965.817     947544.272 \n         NO_Of_UNITS       -216.180        90.302       -0.046     -2.394    0.017       -393.320        -39.040 \n     FAMILY_FRIENDLY     142128.272     47055.082        0.056      3.020    0.003      49823.107     234433.438 \n            FREEHOLD     300646.543     77296.529        0.117      3.890    0.000     149018.525     452274.561 \n      LEASEHOLD_99YR     -77137.375     77570.869       -0.030     -0.994    0.320    -229303.551      75028.801 \n-----------------------------------------------------------------------------------------------------------------\n\n\n\n\n5.1.2 Multicollinearity\n\nols_vif_tol(condo_mlr)\n\n              Variables Tolerance      VIF\n1              AREA_SQM 0.8601326 1.162611\n2                   AGE 0.7011585 1.426211\n3              PROX_CBD 0.4575471 2.185567\n4        PROX_CHILDCARE 0.2898233 3.450378\n5      PROX_ELDERLYCARE 0.5922238 1.688551\n6  PROX_URA_GROWTH_AREA 0.6614081 1.511926\n7    PROX_HAWKER_MARKET 0.4373874 2.286303\n8     PROX_KINDERGARTEN 0.8356793 1.196631\n9              PROX_MRT 0.4949877 2.020252\n10            PROX_PARK 0.8015728 1.247547\n11     PROX_PRIMARY_SCH 0.3823248 2.615577\n12 PROX_TOP_PRIMARY_SCH 0.4878620 2.049760\n13   PROX_SHOPPING_MALL 0.4903052 2.039546\n14     PROX_SUPERMARKET 0.6142127 1.628100\n15        PROX_BUS_STOP 0.3311024 3.020213\n16          NO_Of_UNITS 0.6543336 1.528272\n17      FAMILY_FRIENDLY 0.7191719 1.390488\n18             FREEHOLD 0.2728521 3.664990\n19       LEASEHOLD_99YR 0.2645988 3.779307\n\n\n\n\n5.1.3 Variable selection\n\ncondo_fw_mlr &lt;- ols_step_forward_p(\n  condo_mlr,\n  p_val = 0.05,\n  details = FALSE)\n\n\nplot(condo_fw_mlr)"
  },
  {
    "objectID": "in_class_ex/in_class_ex07/in_class_ex07.html#visualize-model-parameters",
    "href": "in_class_ex/in_class_ex07/in_class_ex07.html#visualize-model-parameters",
    "title": "In-class Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "5.2 Visualize model parameters",
    "text": "5.2 Visualize model parameters\n\nggcoefstats(condo_mlr,\n            sort = \"ascending\")\n\nNumber of labels is greater than default palette color count.\n• Select another color `palette` (and/or `package`)."
  },
  {
    "objectID": "in_class_ex/in_class_ex07/in_class_ex07.html#test-for-non-linearity",
    "href": "in_class_ex/in_class_ex07/in_class_ex07.html#test-for-non-linearity",
    "title": "In-class Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "5.3 Test for Non-Linearity",
    "text": "5.3 Test for Non-Linearity\nIn multiple linear regression, it is important for us to test the assumption that linearity and additivity of the relationship between dependent and independent variables.\nIn the code chunk below, the ols_plot_resid_fit() of olsrr package is used to perform linearity assumption test.\n\nols_plot_resid_fit(condo_fw_mlr$model)\n\n\n\n\n\n\n\n\n\nThe figure above reveals that most of the data poitns are scattered around the 0 line, hence we can safely conclude that the relationships between the dependent variable and independent variables are linear."
  },
  {
    "objectID": "in_class_ex/in_class_ex07/in_class_ex07.html#test-for-normality-assumption",
    "href": "in_class_ex/in_class_ex07/in_class_ex07.html#test-for-normality-assumption",
    "title": "In-class Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "5.4 Test for Normality Assumption",
    "text": "5.4 Test for Normality Assumption\nLastly, the code chunk below uses ols_plot_resid_hist() of olsrr package to perform normality assumption test.\n\nols_plot_resid_hist(condo_fw_mlr$model)\n\n\n\n\n\n\n\n\n\nThe figure reveals that the residual of the multiple linear regression model (i.e. condo.mlr1) is resemble normal distribution.\n\nWhen formal statistical test methods is preferred, we can use ols_test_normality() of olsrr package as shown in the code chunk below.\n\nols_test_normality(condo_fw_mlr$model)\n\nWarning in ks.test.default(y, \"pnorm\", mean(y), sd(y)): ties should not be\npresent for the one-sample Kolmogorov-Smirnov test\n\n\n-----------------------------------------------\n       Test             Statistic       pvalue  \n-----------------------------------------------\nShapiro-Wilk              0.6856         0.0000 \nKolmogorov-Smirnov        0.1366         0.0000 \nCramer-von Mises         121.0768        0.0000 \nAnderson-Darling         67.9551         0.0000 \n-----------------------------------------------\n\n\n\nThe summary table above reveals that the p-values of the four tests are way smaller than the alpha value of 0.05. Hence we will reject the null hypothesis and infer that there is statistical evidence that the residual are not normally distributed."
  },
  {
    "objectID": "in_class_ex/in_class_ex07/in_class_ex07.html#test-for-spatial-autocorrelation",
    "href": "in_class_ex/in_class_ex07/in_class_ex07.html#test-for-spatial-autocorrelation",
    "title": "In-class Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "5.5 Test for Spatial Autocorrelation",
    "text": "5.5 Test for Spatial Autocorrelation\nThe hedonic model we try to build are using geographically referenced attributes, hence it is also important for us to visual the residual of the hedonic pricing model.\nFirst, we will export the residual of the hedonic pricing model and save it as a data frame.\n\nmlr_output &lt;- as.data.frame(condo_fw_mlr$model$residuals) %&gt;%\n  rename(`FW_MLR_RES` = `condo_fw_mlr$model$residuals`)\n\nNext, we will join the newly created data frame with condo_resale_sf object.\n\ncondo_resale_sf &lt;- cbind(condo_resale_sf, \n                        mlr_output$FW_MLR_RES) %&gt;%\n  rename(`MLR_RES` = `mlr_output.FW_MLR_RES`)\n\nNext, we will use tmap package to display the distribution of the residuals on an interactive map.\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(mpsz)+\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(alpha = 0.4) +\ntm_shape(condo_resale_sf) +  \n  tm_dots(col = \"MLR_RES\",\n          alpha = 0.6,\n          style=\"quantile\")\n\nWarning: The shape mpsz is invalid (after reprojection). See sf::st_is_valid\n\n\nVariable(s) \"MLR_RES\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\n\nThe figure above reveal that there is sign of spatial autocorrelation.\n\n\n5.5.1 Spatial stationary test\nTo proof that our observation is indeed true, the Moran’s I test will be performed\nHo: The residuals are randomly distributed (also known as spatial stationary) H1: The residuals are spatially non-stationary\nFirst, we will compute the weight matrix by using st_knn() function of sfdep.\n\ncondo_resale_sf &lt;- condo_resale_sf %&gt;%\n  mutate(nb = st_knn(geometry, k=6,\n                     longlat = FALSE),\n         wt = st_weights(nb,\n                         style = \"W\"),\n         .before = 1)\n\nNext, global_moran_perm() of sfdep is used to perform global Moran permutation test.\n\nglobal_moran_perm(condo_resale_sf$MLR_RES, \n                  condo_resale_sf$nb, \n                  condo_resale_sf$wt, \n                  alternative = \"two.sided\", \n                  nsim = 99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.32254, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\nThe Global Moran’s I test for residual spatial autocorrelation shows that it’s p-value is less than 2.2e-16 which is less than the alpha value of 0.05. Hence, we will reject the null hypothesis that the residuals are randomly distributed.\nSince the Observed Global Moran I = 0.25586 which is greater than 0, we can infer than the residuals resemble cluster distribution."
  },
  {
    "objectID": "in_class_ex/in_class_ex07/in_class_ex07.html#building-fixed-bandwidth-gwr-model",
    "href": "in_class_ex/in_class_ex07/in_class_ex07.html#building-fixed-bandwidth-gwr-model",
    "title": "In-class Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "6.1 Building Fixed Bandwidth GWR Model",
    "text": "6.1 Building Fixed Bandwidth GWR Model\n\n6.1.1 Computing fixed bandwidth\nIn the code chunk below bw.gwr() of GWModel package is used to determine the optimal fixed bandwidth to use in the model. Notice that the argument adaptive is set to FALSE indicates that we are interested to compute the fixed bandwidth.\nThere are two possible approaches can be uused to determine the stopping rule, they are: CV cross-validation approach and AIC corrected (AICc) approach. We define the stopping rule using approach agreement.\n\nbw_fixed &lt;- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                     PROX_CBD + PROX_CHILDCARE + \n                     PROX_ELDERLYCARE   + PROX_URA_GROWTH_AREA + \n                     PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                     PROX_SHOPPING_MALL + PROX_BUS_STOP + \n                     NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                   data=condo_resale_sf, \n                   approach=\"CV\", \n                   kernel=\"gaussian\", \n                   adaptive=FALSE, \n                   longlat=FALSE)\n\nFixed bandwidth: 17660.96 CV score: 8.259118e+14 \nFixed bandwidth: 10917.26 CV score: 7.970454e+14 \nFixed bandwidth: 6749.419 CV score: 7.273273e+14 \nFixed bandwidth: 4173.553 CV score: 6.300006e+14 \nFixed bandwidth: 2581.58 CV score: 5.404958e+14 \nFixed bandwidth: 1597.687 CV score: 4.857515e+14 \nFixed bandwidth: 989.6077 CV score: 4.722431e+14 \nFixed bandwidth: 613.7939 CV score: 1.379526e+16 \nFixed bandwidth: 1221.873 CV score: 4.778717e+14 \nFixed bandwidth: 846.0596 CV score: 4.791629e+14 \nFixed bandwidth: 1078.325 CV score: 4.751406e+14 \nFixed bandwidth: 934.7772 CV score: 4.72518e+14 \nFixed bandwidth: 1023.495 CV score: 4.730305e+14 \nFixed bandwidth: 968.6643 CV score: 4.721317e+14 \nFixed bandwidth: 955.7206 CV score: 4.722072e+14 \nFixed bandwidth: 976.6639 CV score: 4.721387e+14 \nFixed bandwidth: 963.7202 CV score: 4.721484e+14 \nFixed bandwidth: 971.7199 CV score: 4.721293e+14 \nFixed bandwidth: 973.6083 CV score: 4.721309e+14 \nFixed bandwidth: 970.5527 CV score: 4.721295e+14 \nFixed bandwidth: 972.4412 CV score: 4.721296e+14 \nFixed bandwidth: 971.2741 CV score: 4.721292e+14 \nFixed bandwidth: 970.9985 CV score: 4.721293e+14 \nFixed bandwidth: 971.4443 CV score: 4.721292e+14 \nFixed bandwidth: 971.5496 CV score: 4.721293e+14 \nFixed bandwidth: 971.3793 CV score: 4.721292e+14 \nFixed bandwidth: 971.3391 CV score: 4.721292e+14 \nFixed bandwidth: 971.3143 CV score: 4.721292e+14 \nFixed bandwidth: 971.3545 CV score: 4.721292e+14 \nFixed bandwidth: 971.3296 CV score: 4.721292e+14 \nFixed bandwidth: 971.345 CV score: 4.721292e+14 \nFixed bandwidth: 971.3355 CV score: 4.721292e+14 \nFixed bandwidth: 971.3413 CV score: 4.721292e+14 \nFixed bandwidth: 971.3377 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3396 CV score: 4.721292e+14 \nFixed bandwidth: 971.3402 CV score: 4.721292e+14 \nFixed bandwidth: 971.3398 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3399 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \n\n\n\nThe result shows that the recommended bandwidth is 971.3405 metres. The unit is in meter because we’re using CRS 3414 which use meter as unit.\n\n\n\n6.1.2 GWModel method - fixed bandwidth\nNow we can use the code chunk below to calibrate the gwr model using fixed bandwidth and gaussian kernel.\n\ngwr_fixed &lt;- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + \n                         AGE    + PROX_CBD + PROX_CHILDCARE + \n                         PROX_ELDERLYCARE   +PROX_URA_GROWTH_AREA + \n                         PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH +\n                         PROX_SHOPPING_MALL + PROX_BUS_STOP + \n                         NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                       data=condo_resale_sf, \n                       bw=bw_fixed, \n                       kernel = 'gaussian', \n                       longlat = FALSE)\n\nThe output is saved in a list of class “gwrm”. The code below can be used to display the model output.\n\ngwr_fixed\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-10-15 13:41:02.342276 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale_sf, bw = bw_fixed, kernel = \"gaussian\", \n    longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Fixed bandwidth: 971.34 \n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -3.5988e+07 -5.1998e+05  7.6780e+05  1.7412e+06\n   AREA_SQM              1.0003e+03  5.2758e+03  7.4740e+03  1.2301e+04\n   AGE                  -1.3475e+05 -2.0813e+04 -8.6260e+03 -3.7784e+03\n   PROX_CBD             -7.7047e+07 -2.3608e+05 -8.3599e+04  3.4646e+04\n   PROX_CHILDCARE       -6.0097e+06 -3.3667e+05 -9.7426e+04  2.9007e+05\n   PROX_ELDERLYCARE     -3.5001e+06 -1.5970e+05  3.1970e+04  1.9577e+05\n   PROX_URA_GROWTH_AREA -3.0170e+06 -8.2013e+04  7.0749e+04  2.2612e+05\n   PROX_MRT             -3.5282e+06 -6.5836e+05 -1.8833e+05  3.6922e+04\n   PROX_PARK            -1.2062e+06 -2.1732e+05  3.5383e+04  4.1335e+05\n   PROX_PRIMARY_SCH     -2.2695e+07 -1.7066e+05  4.8472e+04  5.1555e+05\n   PROX_SHOPPING_MALL   -7.2585e+06 -1.6684e+05 -1.0517e+04  1.5923e+05\n   PROX_BUS_STOP        -1.4676e+06 -4.5207e+04  3.7601e+05  1.1664e+06\n   NO_Of_UNITS          -1.3170e+03 -2.4822e+02 -3.0846e+01  2.5496e+02\n   FAMILY_FRIENDLY      -2.2749e+06 -1.1140e+05  7.6214e+03  1.6107e+05\n   FREEHOLD             -9.2067e+06  3.8074e+04  1.5169e+05  3.7528e+05\n                             Max.\n   Intercept            112794435\n   AREA_SQM                 21575\n   AGE                     434203\n   PROX_CBD               2704604\n   PROX_CHILDCARE         1654086\n   PROX_ELDERLYCARE      38867861\n   PROX_URA_GROWTH_AREA  78515805\n   PROX_MRT               3124325\n   PROX_PARK             18122439\n   PROX_PRIMARY_SCH       4637517\n   PROX_SHOPPING_MALL     1529953\n   PROX_BUS_STOP         11342209\n   NO_Of_UNITS              12907\n   FAMILY_FRIENDLY        1720745\n   FREEHOLD               6073642\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 438.3807 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 997.6193 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 42263.61 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41632.36 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 42515.71 \n   Residual sum of squares: 2.534069e+14 \n   R-square value:  0.8909912 \n   Adjusted R-square value:  0.8430418 \n\n   ***********************************************************************\n   Program stops at: 2024-10-15 13:41:03.437483 \n\n\n\nThe report shows that the AICc of the gwr is 42263.61 which is significantly smaller than the globel multiple linear regression model of 42967.1."
  },
  {
    "objectID": "in_class_ex/in_class_ex07/in_class_ex07.html#building-adaptive-bandwidth-gwr-model",
    "href": "in_class_ex/in_class_ex07/in_class_ex07.html#building-adaptive-bandwidth-gwr-model",
    "title": "In-class Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "6.2 Building Adaptive Bandwidth GWR Model",
    "text": "6.2 Building Adaptive Bandwidth GWR Model\nIn this section, we will calibrate the gwr-based hedonic pricing model by using adaptive bandwidth approach.\n\n6.2.1 Computing the adaptive bandwidth\nSimilar to the earlier section, we will first use bw.gwr() to determine the recommended data point to use.\nThe code chunk used look very similar to the one used to compute the fixed bandwidth except the adaptive argument has changed to TRUE.\n\nbw_adaptive &lt;- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE  + \n                        PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE    + \n                        PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                        PROX_PRIMARY_SCH + PROX_SHOPPING_MALL   + PROX_BUS_STOP + \n                        NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                      data=condo_resale_sf, \n                      approach=\"CV\", \n                      kernel=\"gaussian\", \n                      adaptive=TRUE, \n                      longlat=FALSE)\n\nAdaptive bandwidth: 895 CV score: 7.952401e+14 \nAdaptive bandwidth: 561 CV score: 7.667364e+14 \nAdaptive bandwidth: 354 CV score: 6.953454e+14 \nAdaptive bandwidth: 226 CV score: 6.15223e+14 \nAdaptive bandwidth: 147 CV score: 5.674373e+14 \nAdaptive bandwidth: 98 CV score: 5.426745e+14 \nAdaptive bandwidth: 68 CV score: 5.168117e+14 \nAdaptive bandwidth: 49 CV score: 4.859631e+14 \nAdaptive bandwidth: 37 CV score: 4.646518e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \nAdaptive bandwidth: 25 CV score: 4.430816e+14 \nAdaptive bandwidth: 32 CV score: 4.505602e+14 \nAdaptive bandwidth: 27 CV score: 4.462172e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \n\n\n\nThe result shows that the 30 is the recommended data points to be used.\n\n\n\n6.2.2 Constructing the adaptive bandwidth gwr model\nNow, we can go ahead to calibrate the gwr-based hedonic pricing model by using adaptive bandwidth and gaussian kernel as shown in the code chunk below.\n\ngwr_adaptive &lt;- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                            PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + \n                            PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                            PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + \n                            NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                          data=condo_resale_sf, \n                          bw=bw_adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE, \n                          longlat = FALSE)\n\nLet’s display the model output.\n\ngwr_adaptive\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-10-15 13:41:10.377288 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale_sf, bw = bw_adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 30 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -1.3487e+08 -2.4669e+05  7.7928e+05  1.6194e+06\n   AREA_SQM              3.3188e+03  5.6285e+03  7.7825e+03  1.2738e+04\n   AGE                  -9.6746e+04 -2.9288e+04 -1.4043e+04 -5.6119e+03\n   PROX_CBD             -2.5330e+06 -1.6256e+05 -7.7242e+04  2.6624e+03\n   PROX_CHILDCARE       -1.2790e+06 -2.0175e+05  8.7158e+03  3.7778e+05\n   PROX_ELDERLYCARE     -1.6212e+06 -9.2050e+04  6.1029e+04  2.8184e+05\n   PROX_URA_GROWTH_AREA -7.2686e+06 -3.0350e+04  4.5869e+04  2.4613e+05\n   PROX_MRT             -4.3781e+07 -6.7282e+05 -2.2115e+05 -7.4593e+04\n   PROX_PARK            -2.9020e+06 -1.6782e+05  1.1601e+05  4.6572e+05\n   PROX_PRIMARY_SCH     -8.6418e+05 -1.6627e+05 -7.7853e+03  4.3222e+05\n   PROX_SHOPPING_MALL   -1.8272e+06 -1.3175e+05 -1.4049e+04  1.3799e+05\n   PROX_BUS_STOP        -2.0579e+06 -7.1461e+04  4.1104e+05  1.2071e+06\n   NO_Of_UNITS          -2.1993e+03 -2.3685e+02 -3.4699e+01  1.1657e+02\n   FAMILY_FRIENDLY      -5.9879e+05 -5.0927e+04  2.6173e+04  2.2481e+05\n   FREEHOLD             -1.6340e+05  4.0765e+04  1.9023e+05  3.7960e+05\n                            Max.\n   Intercept            18758355\n   AREA_SQM                23064\n   AGE                     13303\n   PROX_CBD             11346650\n   PROX_CHILDCARE        2892127\n   PROX_ELDERLYCARE      2465671\n   PROX_URA_GROWTH_AREA  7384059\n   PROX_MRT              1186242\n   PROX_PARK             2588497\n   PROX_PRIMARY_SCH      3381462\n   PROX_SHOPPING_MALL   38038564\n   PROX_BUS_STOP        12081592\n   NO_Of_UNITS              1010\n   FAMILY_FRIENDLY       2072414\n   FREEHOLD              1813995\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 350.3088 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 1085.691 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 41982.22 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41546.74 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 41914.08 \n   Residual sum of squares: 2.528227e+14 \n   R-square value:  0.8912425 \n   Adjusted R-square value:  0.8561185 \n\n   ***********************************************************************\n   Program stops at: 2024-10-15 13:41:11.440144 \n\n\n\nThe report shows that the AICc the adaptive distance gwr is 41982.22 which is even smaller than the AICc of the fixed distance gwr of 42263.61.\n\n\n\n\n\n\n\nNote\n\n\n\nIn addition to regression residuals, the output feature class table includes fields for observed and predicted y values, condition number (cond), Local R2, residuals, and explanatory variable coefficients and standard errors:\n\nCondition Number: this diagnostic evaluates local collinearity. In the presence of strong local collinearity, results become unstable. Results associated with condition numbers larger than 30, may be unreliable.\nLocal R2: these values range between 0.0 and 1.0 and indicate how well the local regression model fits observed y values. Very low values indicate the local model is performing poorly. Mapping the Local R2 values to see where GWR predicts well and where it predicts poorly may provide clues about important variables that may be missing from the regression model.\nPredicted: these are the estimated (or fitted) y values 3. computed by GWR.\nResiduals: to obtain the residual values, the fitted y values are subtracted from the observed y values. Standardized residuals have a mean of zero and a standard deviation of 1. A cold-to-hot rendered map of standardized residuals can be produce by using these values.\nCoefficient Standard Error: these values measure the reliability of each coefficient estimate. Confidence in those estimates are higher when standard errors are small in relation to the actual coefficient values. Large standard errors may indicate problems with local collinearity.\n\nThey are all stored in a SpatialPointsDataFrame or SpatialPolygonsDataFrame object integrated with fit.points, GWR coefficient estimates, y value, predicted values, coefficient standard errors and t-values in its “data” slot in an object called SDF of the output list.\n\n\n\n\n6.2.3 Converting SDF into sf data.frame\nTo visualise the fields in SDF, we need to first convert it into sf data.frame by using the code chunk below.\n\ngwr_adaptive_output &lt;- as.data.frame(\n  gwr_adaptive$SDF) %&gt;%\n  select(-c(2:15))\ngwr_sf_adaptive &lt;- cbind(condo_resale_sf,\n                         gwr_adaptive_output)\n\nNext, glimpse() is used to display the content of condo_resale_sf.adaptive sf data frame.\n\nglimpse(gwr_sf_adaptive)\n\nRows: 1,436\nColumns: 63\n$ nb                      &lt;nb&gt; &lt;66, 77, 123, 238, 239, 343&gt;, &lt;21, 162, 163, 19…\n$ wt                      &lt;list&gt; &lt;0.1666667, 0.1666667, 0.1666667, 0.1666667, …\n$ POSTCODE                &lt;dbl&gt; 118635, 288420, 267833, 258380, 467169, 466472…\n$ SELLING_PRICE           &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ AREA_SQM                &lt;dbl&gt; 309, 290, 248, 127, 145, 139, 218, 141, 165, 1…\n$ AGE                     &lt;dbl&gt; 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22,…\n$ PROX_CBD                &lt;dbl&gt; 7.941259, 6.609797, 6.898000, 4.038861, 11.783…\n$ PROX_CHILDCARE          &lt;dbl&gt; 0.16597932, 0.28027246, 0.42922669, 0.39473543…\n$ PROX_ELDERLYCARE        &lt;dbl&gt; 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.…\n$ PROX_URA_GROWTH_AREA    &lt;dbl&gt; 6.618741, 7.505109, 6.463887, 4.906512, 6.4106…\n$ PROX_HAWKER_MARKET      &lt;dbl&gt; 1.76542207, 0.54507614, 0.37789301, 1.68259969…\n$ PROX_KINDERGARTEN       &lt;dbl&gt; 0.05835552, 0.61592412, 0.14120309, 0.38200076…\n$ PROX_MRT                &lt;dbl&gt; 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.…\n$ PROX_PARK               &lt;dbl&gt; 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.…\n$ PROX_PRIMARY_SCH        &lt;dbl&gt; 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.…\n$ PROX_TOP_PRIMARY_SCH    &lt;dbl&gt; 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.…\n$ PROX_SHOPPING_MALL      &lt;dbl&gt; 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.…\n$ PROX_SUPERMARKET        &lt;dbl&gt; 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.…\n$ PROX_BUS_STOP           &lt;dbl&gt; 0.10336166, 0.28673408, 0.28504777, 0.29872340…\n$ NO_Of_UNITS             &lt;dbl&gt; 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34…\n$ FAMILY_FRIENDLY         &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD                &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR          &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ MLR_RES                 &lt;dbl&gt; -1489099.55, 415494.57, 194129.69, 1088992.71,…\n$ Intercept               &lt;dbl&gt; 2050011.67, 1633128.24, 3433608.17, 234358.91,…\n$ y                       &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ yhat                    &lt;dbl&gt; 2886531.8, 3466801.5, 3616527.2, 5435481.6, 13…\n$ residual                &lt;dbl&gt; 113468.16, 413198.52, -291527.20, -1185481.63,…\n$ CV_Score                &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Stud_residual           &lt;dbl&gt; 0.38207013, 1.01433140, -0.83780678, -2.846146…\n$ Intercept_SE            &lt;dbl&gt; 516105.5, 488083.5, 963711.4, 444185.5, 211962…\n$ AREA_SQM_SE             &lt;dbl&gt; 823.2860, 825.2380, 988.2240, 617.4007, 1376.2…\n$ AGE_SE                  &lt;dbl&gt; 5889.782, 6226.916, 6510.236, 6010.511, 8180.3…\n$ PROX_CBD_SE             &lt;dbl&gt; 37411.22, 23615.06, 56103.77, 469337.41, 41064…\n$ PROX_CHILDCARE_SE       &lt;dbl&gt; 319111.1, 299705.3, 349128.5, 304965.2, 698720…\n$ PROX_ELDERLYCARE_SE     &lt;dbl&gt; 120633.34, 84546.69, 129687.07, 127150.69, 327…\n$ PROX_URA_GROWTH_AREA_SE &lt;dbl&gt; 56207.39, 76956.50, 95774.60, 470762.12, 47433…\n$ PROX_MRT_SE             &lt;dbl&gt; 185181.3, 281133.9, 275483.7, 279877.1, 363830…\n$ PROX_PARK_SE            &lt;dbl&gt; 205499.6, 229358.7, 314124.3, 227249.4, 364580…\n$ PROX_PRIMARY_SCH_SE     &lt;dbl&gt; 152400.7, 165150.7, 196662.6, 240878.9, 249087…\n$ PROX_SHOPPING_MALL_SE   &lt;dbl&gt; 109268.8, 98906.8, 119913.3, 177104.1, 301032.…\n$ PROX_BUS_STOP_SE        &lt;dbl&gt; 600668.6, 410222.1, 464156.7, 562810.8, 740922…\n$ NO_Of_UNITS_SE          &lt;dbl&gt; 218.1258, 208.9410, 210.9828, 361.7767, 299.50…\n$ FAMILY_FRIENDLY_SE      &lt;dbl&gt; 131474.73, 114989.07, 146607.22, 108726.62, 16…\n$ FREEHOLD_SE             &lt;dbl&gt; 115954.0, 130110.0, 141031.5, 138239.1, 210641…\n$ Intercept_TV            &lt;dbl&gt; 3.9720784, 3.3460017, 3.5629010, 0.5276150, 1.…\n$ AREA_SQM_TV             &lt;dbl&gt; 11.614302, 20.087361, 13.247868, 33.577223, 4.…\n$ AGE_TV                  &lt;dbl&gt; -1.6154474, -9.3441881, -4.1023685, -15.524301…\n$ PROX_CBD_TV             &lt;dbl&gt; -3.22582173, -6.32792021, -4.62353528, 5.17080…\n$ PROX_CHILDCARE_TV       &lt;dbl&gt; 1.000488185, 1.471786337, -0.344047555, 1.5766…\n$ PROX_ELDERLYCARE_TV     &lt;dbl&gt; -3.26126929, 3.84626245, 4.13191383, 2.4756745…\n$ PROX_URA_GROWTH_AREA_TV &lt;dbl&gt; -2.846248368, -1.848971738, -2.648105057, -5.6…\n$ PROX_MRT_TV             &lt;dbl&gt; -1.61864578, -8.92998600, -3.40075727, -7.2870…\n$ PROX_PARK_TV            &lt;dbl&gt; -0.83749312, 2.28192684, 0.66565951, -3.340617…\n$ PROX_PRIMARY_SCH_TV     &lt;dbl&gt; 1.59230221, 6.70194543, 2.90580089, 12.9836104…\n$ PROX_SHOPPING_MALL_TV   &lt;dbl&gt; 2.753588422, -0.886626400, -1.056869486, -0.16…\n$ PROX_BUS_STOP_TV        &lt;dbl&gt; 2.0154464, 4.4941192, 3.0419145, 12.8383775, 0…\n$ NO_Of_UNITS_TV          &lt;dbl&gt; 0.480589953, -1.380026395, -0.045279967, -0.44…\n$ FAMILY_FRIENDLY_TV      &lt;dbl&gt; -0.06902748, 2.69655779, 0.04058290, 14.312764…\n$ FREEHOLD_TV             &lt;dbl&gt; 2.6213469, 3.0452799, 1.1970499, 8.7711485, 1.…\n$ Local_R2                &lt;dbl&gt; 0.8846744, 0.8899773, 0.8947007, 0.9073605, 0.…\n$ geometry                &lt;POINT [m]&gt; POINT (22085.12 29951.54), POINT (25656.…\n$ geometry.1              &lt;POINT [m]&gt; POINT (22085.12 29951.54), POINT (25656.…\n\n\n\nsummary(gwr_adaptive$SDF$yhat)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n  171347  1102001  1385528  1751842  1982307 13887901 \n\n\n\n\n6.2.4 Visualising local R2\nThe code chunks below is used to create an interactive point symbol map.\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntmap_options(check.and.fix = TRUE)\ntm_shape(mpsz)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(gwr_sf_adaptive) +  \n  tm_dots(col = \"Local_R2\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\nWarning: The shape mpsz is invalid (after reprojection). See sf::st_is_valid\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\n\n\n6.2.5 Visualising coefficient estimates\nThe code chunks below is used to create an interactive point symbol map.\n\ntmap_options(check.and.fix = TRUE)\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\nAREA_SQM_SE &lt;- tm_shape(mpsz)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(gwr_sf_adaptive) +  \n  tm_dots(col = \"AREA_SQM_SE\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\nAREA_SQM_TV &lt;- tm_shape(mpsz)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(gwr_sf_adaptive) +  \n  tm_dots(col = \"AREA_SQM_TV\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\ntmap_arrange(AREA_SQM_SE, AREA_SQM_TV, \n             asp=1, ncol=2,\n             sync = TRUE)\n\nWarning: The shape mpsz is invalid (after reprojection). See sf::st_is_valid\nWarning: The shape mpsz is invalid (after reprojection). See sf::st_is_valid\n\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\n\n6.2.5.1 By URA Planning Region\n\ntm_shape(mpsz[mpsz$REGION_N==\"CENTRAL REGION\", ])+\n  tm_polygons()+\ntm_shape(gwr_sf_adaptive) + \n  tm_bubbles(col = \"Local_R2\",\n           size = 0.15,\n           border.col = \"gray60\",\n           border.lwd = 1)\n\nWarning: The shape mpsz[mpsz$REGION_N == \"CENTRAL REGION\", ] is invalid. See\nsf::st_is_valid"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex08/hands_on_ex08.html",
    "href": "hands_on_ex/hands_on_ex08/hands_on_ex08.html",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "",
    "text": "Predictive modeling uses statistical learning or machine learning techniques to forecast outcomes. Typically, the event being predicted occurs in the future. However, a set of known outcomes and predictors (also referred to as variables) is used to calibrate the predictive models.\nThis exercise aims to build predictive models using geographical random forest. Along the way, the intended acquired skills are:\n\nPreparing training and test data sets using sampling methods\nCalibrating predictive models using both geospatial statistical learning and machine learning methods\nComparing and selecting the best model for predicting the future outcome and,\nPredicting future outcomes using the best calibrated model"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex08/hands_on_ex08.html#import-the-data",
    "href": "hands_on_ex/hands_on_ex08/hands_on_ex08.html#import-the-data",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "4.1 Import the data",
    "text": "4.1 Import the data\nWe already have processed data on above datasets in .rds format. Let’s load it using read_rds() function.\n\nmdata &lt;- read_rds(\"data/mdata.rds\")\nglimpse(mdata)\n\nRows: 15,901\nColumns: 18\n$ resale_price             &lt;dbl&gt; 330000, 360000, 370000, 375000, 380000, 38000…\n$ floor_area_sqm           &lt;dbl&gt; 92, 91, 92, 99, 92, 92, 92, 92, 93, 91, 91, 9…\n$ storey_order             &lt;int&gt; 1, 3, 1, 2, 2, 4, 3, 2, 4, 3, 3, 3, 4, 3, 2, …\n$ remaining_lease_mths     &lt;dbl&gt; 684, 738, 733, 700, 715, 732, 706, 745, 731, …\n$ PROX_CBD                 &lt;dbl&gt; 8.824749, 9.841309, 9.560780, 9.609731, 8.351…\n$ PROX_ELDERLYCARE         &lt;dbl&gt; 0.2514065, 0.6318448, 1.0824168, 0.3473195, 0…\n$ PROX_HAWKER              &lt;dbl&gt; 0.44182653, 0.26972560, 0.25829513, 0.4364751…\n$ PROX_MRT                 &lt;dbl&gt; 0.6885144, 1.0969096, 0.8862859, 1.4093169, 0…\n$ PROX_PARK                &lt;dbl&gt; 0.7450859, 0.4294870, 0.7800777, 0.1776163, 0…\n$ PROX_GOOD_PRISCH         &lt;dbl&gt; 1.2703931, 0.4045792, 2.0942375, 0.1375070, 1…\n$ PROX_MALL                &lt;dbl&gt; 0.5534331, 1.0677012, 0.9751113, 1.1752392, 1…\n$ PROX_CHAS                &lt;dbl&gt; 1.364596e-01, 2.569863e-01, 1.906189e-01, 2.9…\n$ PROX_SUPERMARKET         &lt;dbl&gt; 0.2708222, 0.3101889, 0.3187560, 0.4586748, 0…\n$ WITHIN_350M_KINDERGARTEN &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, …\n$ WITHIN_350M_CHILDCARE    &lt;int&gt; 6, 5, 2, 3, 3, 2, 3, 4, 3, 2, 4, 4, 4, 5, 2, …\n$ WITHIN_350M_BUS          &lt;int&gt; 8, 8, 8, 7, 6, 9, 6, 6, 5, 4, 10, 5, 6, 9, 8,…\n$ WITHIN_1KM_PRISCH        &lt;int&gt; 2, 2, 1, 2, 2, 1, 3, 2, 2, 2, 2, 2, 3, 2, 2, …\n$ geometry                 &lt;POINT [m]&gt; POINT (29179.92 38822.08), POINT (28423…"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex08/hands_on_ex08.html#data-sampling",
    "href": "hands_on_ex/hands_on_ex08/hands_on_ex08.html#data-sampling",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "4.2 Data Sampling",
    "text": "4.2 Data Sampling\nThe entire dataset is split into training and test sets, with 65% allocated to the training set and 35% to the test set, using the initial_split() function from rsample package.\n\nset.seed(1234)\nresale_split &lt;- initial_split(mdata, \n                              prop = 6.5/10,)\ntrain_data &lt;- training(resale_split)\ntest_data &lt;- testing(resale_split)\n\n\nwrite_rds(train_data, \"data/model/train_data.rds\")\nwrite_rds(test_data, \"data/model/test_data.rds\")"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex08/hands_on_ex08.html#convert-sf-data-frame-to-spatialpointdataframe",
    "href": "hands_on_ex/hands_on_ex08/hands_on_ex08.html#convert-sf-data-frame-to-spatialpointdataframe",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "7.1 Convert sf data frame to SpatialPointDataFrame",
    "text": "7.1 Convert sf data frame to SpatialPointDataFrame\nFirst, we need to convert our sf data frame to a SpatialPointsDataFrame, as the functions in the GWmodel package require data in this format. We can perform this conversion using the as_Spatial() function from the sf package.\n\ntrain_data_sp &lt;- as_Spatial(train_data)\ntrain_data_sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 10335 \nextent      : 11597.31, 42623.63, 28217.39, 48741.06  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 17\nnames       : resale_price, floor_area_sqm, storey_order, remaining_lease_mths,          PROX_CBD,     PROX_ELDERLYCARE,        PROX_HAWKER,           PROX_MRT,          PROX_PARK,   PROX_GOOD_PRISCH,        PROX_MALL,            PROX_CHAS,     PROX_SUPERMARKET, WITHIN_350M_KINDERGARTEN, WITHIN_350M_CHILDCARE, ... \nmin values  :       218000,             74,            1,                  555, 0.999393538715878, 1.98943787433087e-08, 0.0333358643817954, 0.0220407324774434, 0.0441643212802781, 0.0652540365486641,                0, 6.20621206270077e-09, 1.21715176356525e-07,                        0,                     0, ... \nmax values  :      1186888,            133,           17,                 1164,  19.6500691667807,     3.30163731686804,   2.86763031236184,   2.13060636038504,   2.41313695915468,   10.6223726149914, 2.27100643784442,    0.808332738794272,     1.57131703651196,                        7,                    20, ..."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex08/hands_on_ex08.html#compute-adaptive-bandwidth",
    "href": "hands_on_ex/hands_on_ex08/hands_on_ex08.html#compute-adaptive-bandwidth",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "7.2 Compute adaptive bandwidth",
    "text": "7.2 Compute adaptive bandwidth\nNext, the bw.gwr() function from the GWmodel package will be used to determine the optimal bandwidth for the GWR model.\n\nbw_adaptive &lt;- bw.gwr(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL + \n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                  data=train_data_sp,\n                  approach=\"CV\",\n                  kernel=\"gaussian\",\n                  adaptive=TRUE,\n                  longlat=FALSE)\nwrite_rds(bw_adaptive, \"data/aspatial/bw_adaptive.rds\")\n\n\nIn the adaptive approach, the bandwidth is not a fixed distance but is determined by the number of nearest neighbor points. This approach is particularly useful in areas where the density of data points varies.\nThe result from the bw.gwr() function indicates that the optimal bandwidth for this dataset is 40 neighbor points. This means that when estimating the parameters for a given location, the model will consider the 40 nearest neighbors."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex08/hands_on_ex08.html#construct-adaptive-bandwidth-gwr-model",
    "href": "hands_on_ex/hands_on_ex08/hands_on_ex08.html#construct-adaptive-bandwidth-gwr-model",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "7.3 Construct adaptive bandwidth GWR model",
    "text": "7.3 Construct adaptive bandwidth GWR model\nNext, let us call the saved bandwidth by using the code chunk below.\n\nbw_adaptive &lt;- read_rds(\"data/aspatial/bw_adaptive.rds\")\nbw_adaptive\n\n[1] 40\n\n\nNow, we can proceed to calibrate the GWR-based hedonic pricing model using an adaptive bandwidth and a Gaussian kernel, as shown in the code chunk below.\n\ngwr_adaptive &lt;- gwr.basic(formula = resale_price ~\n                            floor_area_sqm + storey_order +\n                            remaining_lease_mths + PROX_CBD + \n                            PROX_ELDERLYCARE + PROX_HAWKER +\n                            PROX_MRT + PROX_PARK + PROX_MALL + \n                            PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                            WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                            WITHIN_1KM_PRISCH,\n                          data=train_data_sp,\n                          bw=bw_adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE,\n                          longlat = FALSE)\nwrite_rds(gwr_adaptive, \"data/aspatial/gwr_adaptive.rds\")"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex08/hands_on_ex08.html#retrieve-gwr-output-object",
    "href": "hands_on_ex/hands_on_ex08/hands_on_ex08.html#retrieve-gwr-output-object",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "7.4 Retrieve GWR output object",
    "text": "7.4 Retrieve GWR output object\nThe code chunk below will be used to retrieve the saved GWR model object.\n\ngwr_adaptive &lt;- read_rds(\"data/aspatial/gwr_adaptive.rds\")\ngwr_adaptive\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-10-16 23:08:34.710299 \n   Call:\n   gwr.basic(formula = resale_price ~ floor_area_sqm + storey_order + \n    remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + \n    PROX_MRT + PROX_PARK + PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN + \n    WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH, \n    data = train_data_sp, bw = bw_adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  resale_price\n   Independent variables:  floor_area_sqm storey_order remaining_lease_mths PROX_CBD PROX_ELDERLYCARE PROX_HAWKER PROX_MRT PROX_PARK PROX_MALL PROX_SUPERMARKET WITHIN_350M_KINDERGARTEN WITHIN_350M_CHILDCARE WITHIN_350M_BUS WITHIN_1KM_PRISCH\n   Number of data points: 10335\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n    Min      1Q  Median      3Q     Max \n-205193  -39120   -1930   36545  472355 \n\n   Coefficients:\n                              Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)              107601.073  10601.261  10.150  &lt; 2e-16 ***\n   floor_area_sqm             2780.698     90.579  30.699  &lt; 2e-16 ***\n   storey_order              14299.298    339.115  42.167  &lt; 2e-16 ***\n   remaining_lease_mths        344.490      4.592  75.027  &lt; 2e-16 ***\n   PROX_CBD                 -16930.196    201.254 -84.124  &lt; 2e-16 ***\n   PROX_ELDERLYCARE         -14441.025    994.867 -14.516  &lt; 2e-16 ***\n   PROX_HAWKER              -19265.648   1273.597 -15.127  &lt; 2e-16 ***\n   PROX_MRT                 -32564.272   1744.232 -18.670  &lt; 2e-16 ***\n   PROX_PARK                 -5712.625   1483.885  -3.850 0.000119 ***\n   PROX_MALL                -14717.388   2007.818  -7.330 2.47e-13 ***\n   PROX_SUPERMARKET         -26881.938   4189.624  -6.416 1.46e-10 ***\n   WITHIN_350M_KINDERGARTEN   8520.472    632.812  13.464  &lt; 2e-16 ***\n   WITHIN_350M_CHILDCARE     -4510.650    354.015 -12.741  &lt; 2e-16 ***\n   WITHIN_350M_BUS             813.493    222.574   3.655 0.000259 ***\n   WITHIN_1KM_PRISCH         -8010.834    491.512 -16.298  &lt; 2e-16 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 61650 on 10320 degrees of freedom\n   Multiple R-squared: 0.7373\n   Adjusted R-squared: 0.737 \n   F-statistic:  2069 on 14 and 10320 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 3.922202e+13\n   Sigma(hat): 61610.08\n   AIC:  257320.2\n   AICc:  257320.3\n   BIC:  247249\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 40 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                                   Min.     1st Qu.      Median     3rd Qu.\n   Intercept                -3.2594e+08 -4.7727e+05 -8.3004e+03  5.5025e+05\n   floor_area_sqm           -2.8714e+04  1.4475e+03  2.3011e+03  3.3900e+03\n   storey_order              3.3186e+03  8.5899e+03  1.0826e+04  1.3397e+04\n   remaining_lease_mths     -1.4431e+03  2.6063e+02  3.9048e+02  5.2865e+02\n   PROX_CBD                 -1.0837e+07 -5.7697e+04 -1.3787e+04  2.6552e+04\n   PROX_ELDERLYCARE         -3.2291e+07 -4.0643e+04  1.0562e+04  6.1054e+04\n   PROX_HAWKER              -2.3985e+08 -5.1365e+04  3.0026e+03  6.4287e+04\n   PROX_MRT                 -1.1660e+07 -1.0488e+05 -4.9373e+04  5.1037e+03\n   PROX_PARK                -6.5961e+06 -4.8671e+04 -8.8128e+02  5.3498e+04\n   PROX_MALL                -1.8112e+07 -7.4238e+04 -1.3982e+04  4.9779e+04\n   PROX_SUPERMARKET         -4.5761e+06 -6.3461e+04 -1.7429e+04  3.5616e+04\n   WITHIN_350M_KINDERGARTEN -4.1881e+05 -6.0040e+03  9.0209e+01  4.7127e+03\n   WITHIN_350M_CHILDCARE    -1.0273e+05 -2.2375e+03  2.6668e+02  2.6388e+03\n   WITHIN_350M_BUS          -1.1757e+05 -1.4719e+03  1.1626e+02  1.7584e+03\n   WITHIN_1KM_PRISCH        -6.6465e+05 -5.5959e+03  2.6916e+02  5.7500e+03\n                                  Max.\n   Intercept                1.6493e+08\n   floor_area_sqm           5.0907e+04\n   storey_order             2.9537e+04\n   remaining_lease_mths     1.8119e+03\n   PROX_CBD                 2.2489e+07\n   PROX_ELDERLYCARE         8.2444e+07\n   PROX_HAWKER              5.9654e+06\n   PROX_MRT                 2.0189e+08\n   PROX_PARK                1.5224e+07\n   PROX_MALL                1.0443e+07\n   PROX_SUPERMARKET         3.8330e+06\n   WITHIN_350M_KINDERGARTEN 6.6799e+05\n   WITHIN_350M_CHILDCARE    1.0802e+05\n   WITHIN_350M_BUS          3.7313e+04\n   WITHIN_1KM_PRISCH        5.0262e+05\n   ************************Diagnostic information*************************\n   Number of data points: 10335 \n   Effective number of parameters (2trace(S) - trace(S'S)): 1730.101 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 8604.899 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 238871.8 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 237036.9 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 238209 \n   Residual sum of squares: 4.829177e+12 \n   R-square value:  0.9676571 \n   Adjusted R-square value:  0.9611535 \n\n   ***********************************************************************\n   Program stops at: 2024-10-16 23:09:34.919185"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex08/hands_on_ex08.html#convert-test-data-from-sf-data-frame-to-spatialpointdataframe",
    "href": "hands_on_ex/hands_on_ex08/hands_on_ex08.html#convert-test-data-from-sf-data-frame-to-spatialpointdataframe",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "7.5 Convert test data from sf data frame to SpatialPointDataFrame",
    "text": "7.5 Convert test data from sf data frame to SpatialPointDataFrame\nWe need to convert our test data from an sf data frame to a SpatialPointsDataFrame, as the functions in the GWmodel package require data in this format. We will use the as_Spatial() function from the sf package to perform this conversion.\n\ntest_data_sp &lt;- test_data %&gt;%\n  as_Spatial()\n\ntest_data_sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 5566 \nextent      : 11597.31, 42623.63, 28287.8, 48669.59  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 17\nnames       : resale_price, floor_area_sqm, storey_order, remaining_lease_mths,         PROX_CBD,     PROX_ELDERLYCARE,        PROX_HAWKER,           PROX_MRT,          PROX_PARK,   PROX_GOOD_PRISCH,        PROX_MALL,            PROX_CHAS,     PROX_SUPERMARKET, WITHIN_350M_KINDERGARTEN, WITHIN_350M_CHILDCARE, ... \nmin values  :       230888,             74,            1,                  546, 1.00583660772922, 3.34897933104965e-07, 0.0474019664161957, 0.0414043955932523, 0.0502664084494264, 0.0907500295577619,                0, 4.55547870890763e-09, 1.21715176356525e-07,                        0,                     0, ... \nmax values  :      1050000,            138,           14,                 1151,  19.632402730488,     3.30163731686804,   2.83106651960209,   2.13060636038504,   2.41313695915468,   10.6169590126272, 2.26056404492346,     0.79249074802552,     1.53786629004208,                        7,                    16, ..."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex08/hands_on_ex08.html#compute-adaptive-bandwidth-for-test-data",
    "href": "hands_on_ex/hands_on_ex08/hands_on_ex08.html#compute-adaptive-bandwidth-for-test-data",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "7.6 Compute adaptive bandwidth for test data",
    "text": "7.6 Compute adaptive bandwidth for test data\nNext, similar to the process used for the training data, we will use the bw.gwr() function from the GWmodel package to determine the optimal bandwidth for the GWR model on the test data.\n\ngwr_bw_test_adaptive &lt;- bw.gwr(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL + \n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                  data=test_data_sp,\n                  approach=\"CV\",\n                  kernel=\"gaussian\",\n                  adaptive=TRUE,\n                  longlat=FALSE)\nwrite_rds(gwr_bw_test_adaptive, \"data/aspatial/gwr_bw_test_adaptive.rds\")"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex08/hands_on_ex08.html#compute-predicted-values-of-test-data",
    "href": "hands_on_ex/hands_on_ex08/hands_on_ex08.html#compute-predicted-values-of-test-data",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "7.7 Compute predicted values of test data",
    "text": "7.7 Compute predicted values of test data\nFinally, we use the gwr.predict() function from the GWmodel package to compute the predicted values for the test data based on our GWR model.\n\ngwr_pred &lt;- gwr.predict(formula = resale_price ~\n                          floor_area_sqm + storey_order +\n                          remaining_lease_mths + PROX_CBD + \n                          PROX_ELDERLYCARE + PROX_HAWKER + \n                          PROX_MRT + PROX_PARK + PROX_MALL + \n                          PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                          WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + \n                          WITHIN_1KM_PRISCH, \n                        data=train_data_sp, \n                        predictdata = test_data_sp, \n                        bw=40, \n                        kernel = 'gaussian', \n                        adaptive=TRUE, \n                        longlat = FALSE)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex08/hands_on_ex08.html#extracting-coordinates-data",
    "href": "hands_on_ex/hands_on_ex08/hands_on_ex08.html#extracting-coordinates-data",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "8.1 Extracting coordinates data",
    "text": "8.1 Extracting coordinates data\nThe code chunk below extract the x, y coordinates of the full, training and test data sets using st_coordinates() function from the sf package.\n\ncoords &lt;- st_coordinates(mdata)\ncoords_train &lt;- st_coordinates(train_data)\ncoords_test &lt;- st_coordinates(test_data)\n\nSave the output into rds for future use.\n\ncoords_train &lt;- write_rds(coords_train, \"data/geospatial/coords_train.rds\" )\ncoords_test &lt;- write_rds(coords_test, \"data/geospatial/coords_test.rds\" )"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex08/hands_on_ex08.html#dropping-geometry-field",
    "href": "hands_on_ex/hands_on_ex08/hands_on_ex08.html#dropping-geometry-field",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "8.2 Dropping geometry field",
    "text": "8.2 Dropping geometry field\nNext, we drop the geometry column from the sf data frame, as it is not needed for our upcoming analysis. We will use the st_drop_geometry() function from the sf package to perform this operation.\n\ntrain_data &lt;- train_data %&gt;% \n  st_drop_geometry()"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex08/hands_on_ex08.html#calibrating-using-training-data",
    "href": "hands_on_ex/hands_on_ex08/hands_on_ex08.html#calibrating-using-training-data",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "10.1 Calibrating using training data",
    "text": "10.1 Calibrating using training data\nLet’s calibrate a geographic random forest model then save the model.\n\nset.seed(1234)\ngwRF_adaptive &lt;- grf(formula = resale_price ~ floor_area_sqm + storey_order +\n                       remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE +\n                       PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL +\n                       PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                       WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                       WITHIN_1KM_PRISCH,\n                     dframe=train_data, \n                     bw=55,\n                     kernel=\"adaptive\",\n                     coords=coords_train)\nwrite_rds(gwRF_adaptive, \"data/model/gwRF_adaptive.rds\")"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex08/hands_on_ex08.html#predicting-using-test-data",
    "href": "hands_on_ex/hands_on_ex08/hands_on_ex08.html#predicting-using-test-data",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "10.2 Predicting using test data",
    "text": "10.2 Predicting using test data\n\n10.2.1 Preparing test data\nFirst, combine the test data with the corresponding coordinates. Since none of the rows in our datasets were sorted, using cbind() is sufficient. The st_drop_geometry() function is used to remove the geometry column.\n\ntest_data &lt;- cbind(test_data, coords_test) %&gt;%\n  st_drop_geometry()\n\n\n\n10.2.2 Predicting with test data\nNext, the predict.grf() function from the SpatialML package will be used to predict the resale value using the test data and the previously calibrated gwRF_adaptive model.\n\nGRF_pred &lt;- predict.grf(gwRF_adaptive, \n                           test_data, \n                           x.var.name=\"X\",\n                           y.var.name=\"Y\", \n                           local.w=1,\n                           global.w=0)\nwrite_rds(GRF_pred, \"data/model/GRF_pred.rds\")\n\n\n\n10.2.3 Converting prediction output into a data frame\nThe output of predict.grf() is a vector of predicted values. It is advisable to convert this into a data frame for easier visualization and analysis.\n\nGRF_pred &lt;- read_rds(\"data/model/GRF_pred.rds\")\nGRF_pred_df &lt;- as.data.frame(GRF_pred)\n\nThen, we’ll use cbind() to append the predicted values to the test data.\n\ntest_data_p &lt;- cbind(test_data, GRF_pred_df)\nwrite_rds(test_data_p, \"data/model/test_data_p.rds\")"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex08/hands_on_ex08.html#calculate-root-mean-square-error-rmse",
    "href": "hands_on_ex/hands_on_ex08/hands_on_ex08.html#calculate-root-mean-square-error-rmse",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "10.3 Calculate Root Mean Square Error (RMSE)",
    "text": "10.3 Calculate Root Mean Square Error (RMSE)\nThe root mean square error (RMSE) allows us to measure how far the predicted values are from the observed values in a regression analysis. In the code chunk below, the rmse() function from the Metrics package is used to compute the RMSE.\n\nrmse(test_data_p$resale_price,\n     test_data_p$GRF_pred)\n\n[1] 27302.9"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex08/hands_on_ex08.html#visualize-predicted-value",
    "href": "hands_on_ex/hands_on_ex08/hands_on_ex08.html#visualize-predicted-value",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "10.4 Visualize Predicted Value",
    "text": "10.4 Visualize Predicted Value\nA scatterplot can be used to visualize the actual resale prices versus the predicted resale prices, as shown in the code chunk below.\n\nggplot(data = test_data_p,\n       aes(x = GRF_pred,\n           y = resale_price)) +\n  geom_point() +\n  geom_abline(slope = 1, intercept = 0, color = \"red\", linetype = \"solid\")"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex09/hands_on_ex09.html",
    "href": "hands_on_ex/hands_on_ex09/hands_on_ex09.html",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to model geographical accessibility by using R’s geospatial analysis packages."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex09/hands_on_ex09.html#importing-geospatial-data",
    "href": "hands_on_ex/hands_on_ex09/hands_on_ex09.html#importing-geospatial-data",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "4.1 Importing Geospatial Data",
    "text": "4.1 Importing Geospatial Data\nThree geospatial datasets will be imported from the data/geospatial sub-folder: MP14_SUBZONE_NO_SEA_PL, hexagons, and ELDERCARE.\nWe will use the st_read() function from the sf package to import these datasets.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_NO_SEA_PL\")\n\nReading layer `MP14_SUBZONE_NO_SEA_PL' from data source \n  `/Users/cham/project/Geospatial-Analytics/chrismanafe/ISSS626-GAA/hands_on_ex/hands_on_ex09/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\nhexagons &lt;- st_read(dsn = \"data/geospatial\", layer = \"hexagons\")\n\nReading layer `hexagons' from data source \n  `/Users/cham/project/Geospatial-Analytics/chrismanafe/ISSS626-GAA/hands_on_ex/hands_on_ex09/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3125 features and 6 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 21506.33 xmax: 50010.26 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\n\neldercare &lt;- st_read(dsn = \"data/geospatial\", layer = \"ELDERCARE\") \n\nReading layer `ELDERCARE' from data source \n  `/Users/cham/project/Geospatial-Analytics/chrismanafe/ISSS626-GAA/hands_on_ex/hands_on_ex09/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 120 features and 19 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14481.92 ymin: 28218.43 xmax: 41665.14 ymax: 46804.9\nProjected CRS: SVY21 / Singapore TM\n\n\n\nThe report above shows that the R object containing the imported MP14_SUBZONE_WEB_PL shapefile is called mpsz, and it is a simple feature (sf) object. The geometry type is multipolygon. It’s also important to note that the mpsz simple feature object does not have EPSG information.\n\nThe code chunk below updates the newly imported mpsz object with the correct EPSG code (i.e., 3414):\n\nmpsz &lt;- st_transform(mpsz, 3414)\neldercare &lt;- st_transform(eldercare, 3414)\nhexagons &lt;- st_transform(hexagons, 3414)\n\nAfter transforming the projection metadata, we can verify the projection of the newly transformed mpsz object by using the st_crs() function from the sf package.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\nNotice that the EPSG code is now indicated as 3414."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex09/hands_on_ex09.html#cleaning-and-updating-attribute-fields-of-the-geospatial-data",
    "href": "hands_on_ex/hands_on_ex09/hands_on_ex09.html#cleaning-and-updating-attribute-fields-of-the-geospatial-data",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "4.2 Cleaning and updating attribute fields of the geospatial data",
    "text": "4.2 Cleaning and updating attribute fields of the geospatial data\nThere are several redundant fields in the data tables of both the eldercare and hexagons datasets. The code chunks below will be used to exclude those redundant fields. Additionally, a new field called demand will be added to the hexagons data table, and a new field called capacity will be added to the eldercare data table. Both fields will be derived using the mutate() function from the dplyr package.\n\neldercare &lt;- eldercare %&gt;%\n  select(fid, ADDRESSPOS) %&gt;%\n  mutate(capacity = 100)\n\n\nhexagons &lt;- hexagons %&gt;%\n  select(fid) %&gt;%\n  mutate(demand = 100)\n\n\nNote that for the purpose of this hands-on exercise, a constant value of 100 is used. In practice, the actual demand for each hexagon and the capacity of each eldercare center should be used."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex09/hands_on_ex09.html#importing-distance-matrix",
    "href": "hands_on_ex/hands_on_ex09/hands_on_ex09.html#importing-distance-matrix",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "5.1 Importing Distance Matrix",
    "text": "5.1 Importing Distance Matrix\nThe code chunk below uses the read_csv() function from the readr package to import OD_Matrix.csv into RStudio. The imported object is a tibble data frame called ODMatrix.\n\nODMatrix &lt;- read_csv(\"data/aspatial/OD_Matrix.csv\", skip = 0)\n\nRows: 375000 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (6): origin_id, destination_id, entry_cost, network_cost, exit_cost, tot...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex09/hands_on_ex09.html#tidying-distance-matrix",
    "href": "hands_on_ex/hands_on_ex09/hands_on_ex09.html#tidying-distance-matrix",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "5.2 Tidying distance matrix",
    "text": "5.2 Tidying distance matrix\nThe imported ODMatrix organizes the distance matrix in a column-wise format.\nHowever, most modeling packages in R expect a matrix structure where the rows represent origins (also known as the from field) and the columns represent destinations (also known as the to field).\nThe code chunk below uses the spread() function from the tidyr package to transform the O-D matrix from a “thin” format to a “wide” format.\n\ndistmat &lt;- ODMatrix %&gt;%\n  select(origin_id, destination_id, total_cost) %&gt;%\n  spread(destination_id, total_cost)%&gt;%\n  select(c(-c('origin_id')))\n\nCurrently, the distances are measured in meters because the SVY21 projected coordinate system is used. The code chunk below will be used to convert the unit of measurement from meters to kilometers.\n\ndistmat_km &lt;- as.matrix(distmat/1000)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex09/hands_on_ex09.html#computing-hansens-accessibility",
    "href": "hands_on_ex/hands_on_ex09/hands_on_ex09.html#computing-hansens-accessibility",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "6.1 Computing Hansen’s accessibility",
    "text": "6.1 Computing Hansen’s accessibility\nWe are now ready to compute Hansen’s accessibility using the ac() function from the SpatialAcc package. Before getting started, it is encouraged to review the function’s arguments to ensure all required inputs are available.\nThe code chunk below calculates Hansen’s accessibility using ac() from SpatialAcc, and data.frame() is used to save the output in a data frame called acc_Hansen.\n\nacc_Hansen &lt;- data.frame(ac(hexagons$demand,\n                            eldercare$capacity,\n                            distmat_km, \n                            #d0 = 50,\n                            power = 2, \n                            family = \"Hansen\"))\nhead(acc_Hansen)\n\n  ac.hexagons.demand..eldercare.capacity..distmat_km..power...2..\n1                                                    1.648313e-14\n2                                                    1.096143e-16\n3                                                    3.865857e-17\n4                                                    1.482856e-17\n5                                                    1.051348e-17\n6                                                    5.076391e-18\n\n\nThe default field names are quite messy, so we will rename them to accHansen using the code chunk below.\n\ncolnames(acc_Hansen) &lt;- \"accHansen\"\nhead(acc_Hansen)\n\n     accHansen\n1 1.648313e-14\n2 1.096143e-16\n3 3.865857e-17\n4 1.482856e-17\n5 1.051348e-17\n6 5.076391e-18\n\n\nNext, we will convert the data table into a tibble format using the code chunk below.\n\nacc_Hansen &lt;- as_tibble(acc_Hansen)\n\nLastly, the bind_cols() function from dplyr will be used to join the acc_Hansen tibble with the hexagons simple feature data frame. The output will be called hexagon_Hansen.\n\nhexagon_Hansen &lt;- bind_cols(hexagons, acc_Hansen)\n\nhead(hexagon_Hansen)\n\nSimple feature collection with 6 features and 3 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 22756.33 xmax: 3244.888 ymax: 27756.33\nProjected CRS: SVY21 / Singapore TM\n  fid demand    accHansen                       geometry\n1   1    100 1.648313e-14 POLYGON ((2667.538 27506.33...\n2   2    100 1.096143e-16 POLYGON ((2667.538 25006.33...\n3   3    100 3.865857e-17 POLYGON ((2667.538 24506.33...\n4   4    100 1.482856e-17 POLYGON ((2667.538 24006.33...\n5   5    100 1.051348e-17 POLYGON ((2667.538 23506.33...\n6   6    100 5.076391e-18 POLYGON ((2667.538 23006.33..."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex09/hands_on_ex09.html#visualising-hansens-accessibility",
    "href": "hands_on_ex/hands_on_ex09/hands_on_ex09.html#visualising-hansens-accessibility",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "6.2 Visualising Hansen’s accessibility",
    "text": "6.2 Visualising Hansen’s accessibility\n\n6.2.1 Extracting map extend\nFirst, we will extract the extent of the hexagons simple feature data frame using the st_bbox() function from the sf package.\n\nmapex &lt;- st_bbox(hexagons)\n\nThe code chunk below uses a collection of mapping functions from the tmap package to create a high-quality cartographic map showing accessibility to eldercare centers in Singapore.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(hexagon_Hansen,\n         bbox = mapex) + \n  tm_fill(col = \"accHansen\",\n          n = 10,\n          style = \"quantile\",\n          border.col = \"black\",\n          border.lwd = 1) +\ntm_shape(eldercare) +\n  tm_symbols(size = 0.1) +\n  tm_layout(main.title = \"Accessibility to eldercare: Hansen method\",\n            main.title.position = \"center\",\n            main.title.size = 2,\n            legend.outside = FALSE,\n            legend.height = 0.45, \n            legend.width = 3.0,\n            legend.format = list(digits = 6),\n            legend.position = c(\"right\", \"top\"),\n            frame = TRUE) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.5)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex09/hands_on_ex09.html#statistical-graphic-visualisation",
    "href": "hands_on_ex/hands_on_ex09/hands_on_ex09.html#statistical-graphic-visualisation",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "6.3 Statistical graphic visualisation",
    "text": "6.3 Statistical graphic visualisation\nIn this section, we will compare the distribution of Hansen’s accessibility values by URA Planning Region.\nFirst, we need to add the planning region field to the hexagon_Hansen simple feature data frame using the code chunk below.\n\nhexagon_Hansen &lt;- st_join(hexagon_Hansen, mpsz, \n                          join = st_intersects)\n\nNext, we will use ggplot() to plot the distribution of Hansen’s accessibility values using the boxplot graphical method.\n\nggplot(data=hexagon_Hansen, \n       aes(y = log(accHansen), \n           x= REGION_N)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\", \n             fun.y=\"mean\", \n             colour =\"red\", \n             size=2)\n\nWarning in geom_point(stat = \"summary\", fun.y = \"mean\", colour = \"red\", :\nIgnoring unknown parameters: `fun.y`\n\n\nNo summary function supplied, defaulting to `mean_se()`"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex09/hands_on_ex09.html#computing-kd2sfcas-accessibility",
    "href": "hands_on_ex/hands_on_ex09/hands_on_ex09.html#computing-kd2sfcas-accessibility",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "7.1 Computing KD2SFCA’s accessibility",
    "text": "7.1 Computing KD2SFCA’s accessibility\nNow, we will calculate Hansen’s accessibility using the ac() function from the SpatialAcc package, and the output will be saved in a data frame called acc_KD2SFCA. Note that KD2SFCA is used for the family argument.\n\nacc_KD2SFCA &lt;- data.frame(ac(hexagons$demand,\n                            eldercare$capacity,\n                            distmat_km, \n                            d0 = 50,\n                            power = 2, \n                            family = \"KD2SFCA\"))\n\ncolnames(acc_KD2SFCA) &lt;- \"accKD2SFCA\"\nacc_KD2SFCA &lt;- tbl_df(acc_KD2SFCA)\n\nWarning: `tbl_df()` was deprecated in dplyr 1.0.0.\nℹ Please use `tibble::as_tibble()` instead.\n\nhexagon_KD2SFCA &lt;- bind_cols(hexagons, acc_KD2SFCA)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex09/hands_on_ex09.html#visualising-kd2sfcas-accessibility",
    "href": "hands_on_ex/hands_on_ex09/hands_on_ex09.html#visualising-kd2sfcas-accessibility",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "7.2 Visualising KD2SFCA’s accessibility",
    "text": "7.2 Visualising KD2SFCA’s accessibility\nThe code chunk below uses a collection of mapping functions from the tmap package to create a high-quality cartographic map showing accessibility to eldercare centers in Singapore. Note that mapex is reused for the bbox argument.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(hexagon_KD2SFCA,\n         bbox = mapex) + \n  tm_fill(col = \"accKD2SFCA\",\n          n = 10,\n          style = \"quantile\",\n          border.col = \"black\",\n          border.lwd = 1) +\ntm_shape(eldercare) +\n  tm_symbols(size = 0.1) +\n  tm_layout(main.title = \"Accessibility to eldercare: KD2SFCA method\",\n            main.title.position = \"center\",\n            main.title.size = 2,\n            legend.outside = FALSE,\n            legend.height = 0.45, \n            legend.width = 3.0,\n            legend.format = list(digits = 6),\n            legend.position = c(\"right\", \"top\"),\n            frame = TRUE) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.5)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex09/hands_on_ex09.html#statistical-graphic-visualisation-1",
    "href": "hands_on_ex/hands_on_ex09/hands_on_ex09.html#statistical-graphic-visualisation-1",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "7.3 Statistical graphic visualisation",
    "text": "7.3 Statistical graphic visualisation\nNow, we will compare the distribution of KD2SFCA accessibility values by URA Planning Region.\nFirst, we need to add the planning region field to the hexagon_KD2SFCA simple feature data frame using the code chunk below.\n\nhexagon_KD2SFCA &lt;- st_join(hexagon_KD2SFCA, mpsz, \n                          join = st_intersects)\n\nNext, we will use ggplot() to plot the distribution of KD2SFCA accessibility values using the boxplot graphical method.\n\nggplot(data=hexagon_KD2SFCA, \n       aes(y = accKD2SFCA, \n           x= REGION_N)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\", \n             fun.y=\"mean\", \n             colour =\"red\", \n             size=2)\n\nWarning in geom_point(stat = \"summary\", fun.y = \"mean\", colour = \"red\", :\nIgnoring unknown parameters: `fun.y`\n\n\nNo summary function supplied, defaulting to `mean_se()`"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex09/hands_on_ex09.html#computing-sam-accessibility",
    "href": "hands_on_ex/hands_on_ex09/hands_on_ex09.html#computing-sam-accessibility",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "8.1 Computing SAM accessibility",
    "text": "8.1 Computing SAM accessibility\nIn this section, we will repeat most of the steps learned in the previous section to perform the analysis. However, some of the code will be combined into a single code chunk.\nThe code chunk below calculates Hansen’s accessibility using the ac() function from the SpatialAcc package, and the output is saved in a data frame called acc_SAM. Note that SAM is used for the family argument.\n\nacc_SAM &lt;- data.frame(ac(hexagons$demand,\n                         eldercare$capacity,\n                         distmat_km, \n                         d0 = 50,\n                         power = 2, \n                         family = \"SAM\"))\n\ncolnames(acc_SAM) &lt;- \"accSAM\"\nacc_SAM &lt;- tbl_df(acc_SAM)\n\nWarning: `tbl_df()` was deprecated in dplyr 1.0.0.\nℹ Please use `tibble::as_tibble()` instead.\n\nhexagon_SAM &lt;- bind_cols(hexagons, acc_SAM)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex09/hands_on_ex09.html#visualising-sams-accessibility",
    "href": "hands_on_ex/hands_on_ex09/hands_on_ex09.html#visualising-sams-accessibility",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "8.2 Visualising SAM’s accessibility",
    "text": "8.2 Visualising SAM’s accessibility\nThe code chunk below uses a collection of mapping functions from the tmap package to create a high-quality cartographic map showing accessibility to eldercare centers in Singapore. Note that mapex is reused for the bbox argument.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(hexagon_SAM,\n         bbox = mapex) + \n  tm_fill(col = \"accSAM\",\n          n = 10,\n          style = \"quantile\",\n          border.col = \"black\",\n          border.lwd = 1) +\ntm_shape(eldercare) +\n  tm_symbols(size = 0.1) +\n  tm_layout(main.title = \"Accessibility to eldercare: SAM method\",\n            main.title.position = \"center\",\n            main.title.size = 2,\n            legend.outside = FALSE,\n            legend.height = 0.45, \n            legend.width = 3.0,\n            legend.format = list(digits = 3),\n            legend.position = c(\"right\", \"top\"),\n            frame = TRUE) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.5)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex09/hands_on_ex09.html#statistical-graphic-visualisation-2",
    "href": "hands_on_ex/hands_on_ex09/hands_on_ex09.html#statistical-graphic-visualisation-2",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "8.3 Statistical graphic visualisation",
    "text": "8.3 Statistical graphic visualisation\nNow, we will compare the distribution of SAM accessibility values by URA Planning Region.\nFirst, we need to add the planning region field to the hexagon_SAM simple feature data frame using the code chunk below.\n\nhexagon_SAM &lt;- st_join(hexagon_SAM, mpsz, \n                       join = st_intersects)\n\nNext, ggplot() will be used to plot the distribution by using boxplot graphical method.\n\nggplot(data=hexagon_SAM, \n       aes(y = accSAM, \n           x= REGION_N)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\", \n             fun.y=\"mean\", \n             colour =\"red\", \n             size=2)\n\nWarning in geom_point(stat = \"summary\", fun.y = \"mean\", colour = \"red\", :\nIgnoring unknown parameters: `fun.y`\n\n\nNo summary function supplied, defaulting to `mean_se()`"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex09/data/geospatial/hexagons.html",
    "href": "hands_on_ex/hands_on_ex09/data/geospatial/hexagons.html",
    "title": "ISSS626-GAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n                 0 0     false"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex10/hands_on_ex10a.html",
    "href": "hands_on_ex/hands_on_ex10/hands_on_ex10a.html",
    "title": "Hands-on Exercise 9a: Processing and Visualising Flow Data",
    "section": "",
    "text": "1 Overview\nIn this hands-on exercise, we will learn how to compute spatial weights using R.\n\n\n2 Reference\nKam, T. S. Processing and Visualising Flow Data. R for Geospatial Data Science and Analytics. https://r4gdsa.netlify.app/chap15.html"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex10/hands_on_ex10b.html",
    "href": "hands_on_ex/hands_on_ex10/hands_on_ex10b.html",
    "title": "Hands-on Exercise 9b: Calibrating Spatial Interaction Models with R",
    "section": "",
    "text": "1 Overview\nIn this hands-on exercise, we will learn how to compute spatial weights using R.\n\n\n2 Reference\nKam, T. S. Calibrating Spatial Interaction Models with R. R for Geospatial Data Science and Analytics. https://r4gdsa.netlify.app/chap16"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex09/data/geospatial/ELDERCARE.html",
    "href": "hands_on_ex/hands_on_ex09/data/geospatial/ELDERCARE.html",
    "title": "ISSS626-GAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;  ELDERCARE  ENG dataset\n\nELDERCARE\n\n                 0 0     false"
  }
]