---
title: "In-class Exercise 10: Spatial Interaction Models"
author: "Christover Manafe"
date: "2024-11-04"
date-modified: "last-modified"
execute: 
  eval: true
  echo: true
  message: false
  freeze: true
format: 
  html:
    code-fold: false
    code-summary: "code chunk"
    number-sections: true
    number-depth: 4
---

# Overview

In this in-class exercise, we mainly review what we did in hands-on exercise 10A and 10B.

# Hands-on Exercise 10A

## The Packages

We will use following packages in this exercise

::: panel-tabset
## Packages

We will use following packages in this exercise:

+-----------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| **Package**                                               | **Description**                                                                                                                                                                                                   |
+===========================================================+===================================================================================================================================================================================================================+
| [**sf**](https://r-spatial.github.io/sf/)                 | Provides functions to manage, process, and manipulate **Simple Features**, a formal geospatial data standard that specifies a storage and access model of spatial geometries such as points, lines, and polygons. |
+-----------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| [**tidyverse**](https://www.tidyverse.org/)               | A collection of R packages for data science tasks such as importing, tidying, wrangling, and visualizing data.                                                                                                    |
+-----------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| [**tmap**](https://cran.r-project.org/web/packages/tmap/) | Provides functions for creating cartographic-quality static maps or interactive maps using the [leaflet](https://leafletjs.com/) API.                                                                             |
+-----------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| [**DT**](https://rstudio.github.io/DT/)                   | Provides an R interface to the JavaScript library DataTables.                                                                                                                                                     |
+-----------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| [**stplanr**](https://docs.ropensci.org/stplanr/)         | Provides functions for solving common problems in transport planning and modelling.                                                                                                                               |
+-----------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

: {tbl-colwidths="\[15,85\]"}

## Code

To install and launch all R packages.

```{r}
pacman::p_load(tmap, sf, DT, stplanr, tidyverse)
```
:::

## Preparing the Flow Data

### Downloading the OD data

First, we would need to download the OD data from LTA DataMall. We can follow these steps to do so.

+---------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Step    | Description                                                                                                                                                                                                                                        |
+=========+====================================================================================================================================================================================================================================================+
| 1       | Request API Access from [LTA DataMall website](https://datamall.lta.gov.sg/content/datamall/en/dynamic-data.html) and complete the request form.                                                                                                   |
+---------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| 2       | Install [Postman](https://www.postman.com/downloads/) and follow instructions from [API User Guide](https://datamall.lta.gov.sg/content/dam/datamall/datasets/LTA_DataMall_API_User_Guide.pdf).                                                    |
+---------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| 3       | Search for `Passenger Volume by Origin Destination Bus Stops` in [API User Guide](https://datamall.lta.gov.sg/content/dam/datamall/datasets/LTA_DataMall_API_User_Guide.pdf), then use the URL from the documentation into Postman                 |
+---------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| 4       | Set Http request in Postman to `GET`, then add following parameters:                                                                                                                                                                               |
|         |                                                                                                                                                                                                                                                    |
|         | -   Under `Params` tab:                                                                                                                                                                                                                            |
|         |                                                                                                                                                                                                                                                    |
|         |     -   Key: `Date`                                                                                                                                                                                                                                |
|         |                                                                                                                                                                                                                                                    |
|         |     -   Value: `202407`                                                                                                                                                                                                                            |
|         |                                                                                                                                                                                                                                                    |
|         |         The data is updated monthly by the 10th, with passenger volumes for the previous month. Since it's currently October, the most recent available data covers July, August, and September. For this analysis, I am using the data from July. |
|         |                                                                                                                                                                                                                                                    |
|         | -   Under `Headers` tab:                                                                                                                                                                                                                           |
|         |                                                                                                                                                                                                                                                    |
|         |     -   Key: `AccountKey`                                                                                                                                                                                                                          |
|         |                                                                                                                                                                                                                                                    |
|         |     -   Value: Use the API Account Key that is sent to our email.                                                                                                                                                                                  |
+---------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| 5       | Click `Send` button on the postman, and the API will return a URL in the response that can be used to download the file.                                                                                                                           |
|         |                                                                                                                                                                                                                                                    |
|         | The URL will remain active for 5 minutes.                                                                                                                                                                                                          |
+---------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

### Importing the OD data

Next, we will import the downloaded Passenger Volume by Origin Destination Bus Stops dataset using the `read_csv()` function from the readr package.

```{r}
odbus <- read_csv("data/aspatial/origin_destination_bus_202407.csv")
glimpse(odbus)
```

A quick check of the **odbus** tibble data frame shows that the values in ORIGIN_PT_CODE and DESTINATION_PT_CODE are already in character data type. However, we will still convert these values into factors using the code chunk below, as it helps categorize the data for further analysis.

```{r}
odbus$ORIGIN_PT_CODE <- as.factor(odbus$ORIGIN_PT_CODE)
odbus$DESTINATION_PT_CODE <- as.factor(odbus$DESTINATION_PT_CODE) 
```

### Extracting the study data

For the purpose of this exercise, we will extract commuting flows on weekdays between 6:00 and 9:00 AM.

```{r}
odbus6_9 <- odbus %>%
  filter(DAY_TYPE == "WEEKDAY") %>%
  filter(TIME_PER_HOUR >= 6 &
           TIME_PER_HOUR <= 9) %>%
  group_by(ORIGIN_PT_CODE,
           DESTINATION_PT_CODE) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS))
```

We can use the **datatable** package to create interactive tables for the odbus6_9 data frame:

```{r}
datatable(odbus6_9)
```

We will save the output in RDS format for future use, and then re-import the saved RDS file into the R environment.

```{r}
write_rds(odbus6_9, "data/rds/odbus6_9.rds")
odbus6_9 <- read_rds("data/rds/odbus6_9.rds")
```

## Working with Geospatial Data

In this exercise, two geospatial datasets will be used:

-   `BusStop`: This dataset provides the locations of bus stops as of the last quarter of 2022.

-   `MPSZ-2019`: This dataset provides the sub-zone boundaries from the URA Master Plan 2019.

Both datasets are in ESRI shapefile format.

### Importing geospatial data

We'll import the geospatial datasets using the `st_read()` function.

```{r}
busstop <- st_read(dsn = "data/geospatial",
                   layer = "BusStop") %>%
  st_transform(crs = 3414)
```

```{r}
mpsz <- st_read(dsn = "data/geospatial",
                   layer = "MPSZ-2019") %>%
  st_transform(crs = 3414)
mpsz
```

Let's write mpsz sf tibble data frame into an rds file for future use.

```{r}
mpsz <- write_rds(mpsz, "data/rds/mpsz.rds")
```

### Visualize Bus Stop Location

```{r}
tm_shape(mpsz) +
  tm_polygons() +
tm_shape(busstop) +
  tm_dots(col="red") +
tm_layout(frame = F)
```

> We noticed there are some bus stops that are located outside of Singapore.

## Geospatial Data Wrangling

### Combining BusStop and mpsz

```{r}
busstop_mpsz <- st_intersection(busstop, mpsz) %>%
  select(BUS_STOP_N, SUBZONE_C) %>%
  st_drop_geometry()
```

> -   `st_intersection()` is used to perform point and polygon overly and the output will be in point sf object.
> -   `select()` of dplyr package is then use to retain only BUS_STOP_N and SUBZONE_C in the busstop_mpsz sf data frame.
> -   5 bus stops is dropped because it is outside MPSZ boundary (i.e. in Malaysia).

```{r}
datatable(busstop_mpsz)
```

Next, we will append the planning subzone code from the busstop_mpsz data frame onto the odbus6_9 data frame.

```{r}
od_data <- left_join(odbus6_9 , busstop_mpsz,
            by = c("ORIGIN_PT_CODE" = "BUS_STOP_N")) %>%
  rename(ORIGIN_BS = ORIGIN_PT_CODE,
         ORIGIN_SZ = SUBZONE_C,
         DESTIN_BS = DESTINATION_PT_CODE)
```

Let's check for duplicate records before moving forward with the analysis.

```{r}
duplicate <- od_data %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup()
duplicate
```

Because there are duplicate records, let's run following code chunk to retain the unique records.

```{r}
od_data <- unique(od_data)
```

Next, we will update od_data data frame with the planning subzone codes.

```{r}
od_data <- left_join(od_data , busstop_mpsz,
            by = c("DESTIN_BS" = "BUS_STOP_N")) 
```

Let's check for duplicate records before moving forward with the analysis.

```{r}
duplicate <- od_data %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup()
duplicate
```

Here we also got duplicate records, let's run following code chunk to retain the unique records.

```{r}
od_data <- unique(od_data)
```

```{r}
od_data <- od_data %>%
  rename(DESTIN_SZ = SUBZONE_C) %>%
  drop_na() %>%
  group_by(ORIGIN_SZ, DESTIN_SZ) %>%
  summarise(MORNING_PEAK = sum(TRIPS))
```

Let's save the output into an rds file format

```{r}
write_rds(od_data, "data/rds/od_data.rds")
od_data <- read_rds("data/rds/od_data.rds")
```

## Visualising Spatial Interaction

In this section, we will learn how to prepare a desire line by using **stplanr** package.

### Removing intra-zonal flows

We will not plot the intra-zonal flows. The code chunk below will be used to remove intra-zonal flows.

```{r}
od_data_fij <- od_data[od_data$ORIGIN_SZ!=od_data$DESTIN_SZ,]
write_rds(od_data_fij, "data/rds/od_data_fij.rds")
od_data_fij <- read_rds("data/rds/od_data_fij.rds")
```

### Creating desire lines

In this code chunk below, `od2line()` of **stplanr** package is used to create the desire lines.

```{r}
flowLine <- od2line(flow = od_data_fij, 
                    zones = mpsz,
                    zone_code = "SUBZONE_C")
write_rds(flowLine, "data/rds/flowLine.rds")
flowLine <- read_rds("data/rds/flowLine.rds")
```

### Visualising the desire lines

To visualise the resulting desire lines, let's run the code chunk below.

```{r}
tm_shape(mpsz) +
  tm_polygons() +
flowLine %>%  
tm_shape() +
  tm_lines(lwd = "MORNING_PEAK",
           style = "quantile",
           scale = c(0.1, 1, 3, 5, 7, 10),
           n = 6,
           alpha = 1)
```

When the flow data are very messy and highly skewed like the one shown above, it is wiser to focus on selected flows, for example flow greater than or equal to 5000 as shown below.

```{r}
tm_shape(mpsz) +
  tm_polygons() +
flowLine %>%  
  filter(MORNING_PEAK >= 5000) %>%
tm_shape() +
  tm_lines(lwd = "MORNING_PEAK",
           style = "quantile",
           scale = c(0.1, 1, 3, 5, 7, 10),
           n = 6,
           alpha = 1)
```

# Hands-on Exercise 10B

## The Packages

We will use following packages in this exercise

::: panel-tabset
## Packages

We will use following packages in this exercise:

+-----------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| **Package**                                                                       | **Description**                                                                                                                                                                                                   |
+===================================================================================+===================================================================================================================================================================================================================+
| [**sf**](https://r-spatial.github.io/sf/)                                         | Provides functions to manage, process, and manipulate **Simple Features**, a formal geospatial data standard that specifies a storage and access model of spatial geometries such as points, lines, and polygons. |
+-----------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| [**tidyverse**](https://www.tidyverse.org/)                                       | A collection of R packages for data science tasks such as importing, tidying, wrangling, and visualizing data.                                                                                                    |
+-----------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| [**tmap**](https://cran.r-project.org/web/packages/tmap/)                         | Provides functions for creating cartographic-quality static maps or interactive maps using the [leaflet](https://leafletjs.com/) API.                                                                             |
+-----------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| [**performance**](https://cran.r-project.org/web/packages/performance/index.html) | Provides functions for computing measures to assess model quality.                                                                                                                                                |
+-----------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| [**sp**](https://cran.r-project.org/web/packages/sp/index.html)                   | Provides classes and methods for Spatial Data.                                                                                                                                                                    |
+-----------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| [**reshape2**](https://cran.r-project.org/web/packages/reshape2/index.html)       | Provides functions to flexibly reshape data.                                                                                                                                                                      |
+-----------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| [**ggpubr**](https://rpkgs.datanovia.com/ggpubr/)                                 | A collection of 'ggplot2'-based functions to easily create and customize publication-ready plots.                                                                                                                 |
+-----------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

: {tbl-colwidths="\[15,85\]"}

## Code

To install and launch all R packages.

```{r}
pacman::p_load(tmap, sf, sp,
               performance, reshape2,
               ggpubr, tidyverse)
```
:::

## The Data

This exercise is a continuation of Hands-on Exercise 10a: Processing and Visualizing Flow Data. The following data will be used:

-   **od_data.rds**: Weekday morning peak passenger flows at the planning subzone level.

-   **mpsz.rds**: URA Master Plan 2019 Planning Subzone boundaries in simple feature tibble data frame format.

## Computing Distance Matrix

In spatial interaction, a distance matrix is a table that shows the distances between pairs of locations. In this section, we will learn how to compute a distance matrix using the URA Master Plan 2019 Planning Subzone boundary, which we have saved as `mpsz.rds`.

First, let us import `mpsz.rds` into the R environment using the code chunk below.

```{r}
mpsz <- read_rds("data/rds/mpsz.rds")
mpsz
```

> Note that it is an **sf** tibble data frame object.

### Converting from sf data.table to SpatialPolygonsDataFrame

There are at least two ways to compute the required distance matrix: one using **sf** and the other using **sp**. Past experience has shown that computing the distance matrix with **sf** functions takes relatively longer than the **sp** method, especially when dealing with large datasets. Therefore, the **sp** method is used in the code chunks below.

First, we will use [`as.Spatial()`](https://r-spatial.github.io/sf/reference/coerce-methods.html) to convert **mpsz** from an **sf** tibble data frame to a SpatialPolygonsDataFrame of the **sp** object, as shown in the code chunk below.

```{r}
mpsz_sp <- as(mpsz, "Spatial")
mpsz_sp
```

### Computing the distance matrix

Next, the [`spDists()`](https://www.rdocumentation.org/packages/sp/versions/2.1-1/topics/spDistsN1) function from the **sp** package will be used to compute the Euclidean distance between the centroids of the planning subzones.

```{r}
dist <- spDists(mpsz_sp, 
                longlat = FALSE)
head(dist, n=c(10, 10))
```

> Note that the output `dist` is a matrix object in R. Additionally, the column headers and row headers are not labeled with the planning subzone codes.

### Labelling column and row heanders of a distance matrix

First, we will create a list sorted according to the distance matrix by planning subzone code.

```{r}
sz_names <- mpsz$SUBZONE_C
```

Next, we will attach the `SUBZONE_C` values to the rows and columns of the distance matrix for proper matching.

```{r}
colnames(dist) <- paste0(sz_names)
rownames(dist) <- paste0(sz_names)
```

### Pivoting distance value by SUBZONE_C

Next, we will pivot the distance matrix into a long table, using the row and column subzone codes, as shown in the code chunk below.

```{r}
distPair <- melt(dist) %>%
  rename(dist = value)
head(distPair, 10)
```

> Notice that the within zone distance is 0.

### Updating intra-zonal distances

In this section, we will append a constant value to replace the intra-zonal distances of 0.

First, we will select and determine the minimum value of the distances using the `summary()` function.

```{r}
distPair %>%
  filter(dist > 0) %>%
  summary()
```

Next, a constant distance value of 50m is added into intra-zones distance.

```{r}
distPair$dist <- ifelse(distPair$dist == 0,
                        50, distPair$dist)
```

Let's check the result data frame.

```{r}
distPair %>%
  summary()
```

Next, we will rename the origin and destination fields and save the dataframe for future use.

```{r}
distPair <- distPair %>%
  rename(orig = Var1,
         dest = Var2)
write_rds(distPair, "data/rds/distPair.rds")
distPair <- read_rds("data/rds/distPair.rds")
```

## Preparing Flow Data

Let's import saved *od_data* from Hands-on Exercise 10a into R environment.

```{r}
od_data <- read_rds("data/rds/od_data.rds")
```

Next, we will compute the total passenger trips between and within planning subzones using the code chunk below. The output will be stored in flow_data.

```{r}
flow_data <- od_data %>%
  group_by(ORIGIN_SZ, DESTIN_SZ) %>% 
  summarize(TRIPS = sum(MORNING_PEAK))
head(flow_data, 10)
```

### Separating intra-flow from passenger volume df

Code chunk below is used to add three new fields in `flow_data` dataframe.

```{r}
flow_data$FlowNoIntra <- ifelse(
  flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ, 
  0, flow_data$TRIPS)
flow_data$offset <- ifelse(
  flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ, 
  0.000001, 1)
```

### Combining passenger volume data with distance value

Before we can join *flow_data* and *distPair*, we need to convert data value type of *ORIGIN_SZ* and *DESTIN_SZ* fields of flow_data dataframe into factor data type.

```{r}
flow_data$ORIGIN_SZ <- as.factor(flow_data$ORIGIN_SZ)
flow_data$DESTIN_SZ <- as.factor(flow_data$DESTIN_SZ)
```

Now, `left_join()` of **dplyr** will be used to *flow_data* dataframe and *distPair* dataframe. The output is called *flow_data1*.

```{r}
flow_data1 <- flow_data %>%
  left_join (distPair,
             by = c("ORIGIN_SZ" = "orig",
                    "DESTIN_SZ" = "dest"))
```

## Preparing Origin and Destination Attributes

### Importing population data

Firstly, we will import the population data.

```{r}
pop <- read_csv("data/aspatial/pop.csv")
```

### Geospatial data wrangling

Next, we will do a `left_join` to *pop* data frame with *mpsz.* The output will be a sf object where each polygon in *mpsz* will be assigned a population value.

```{r}
pop <- pop %>%
  left_join(mpsz,
            by = c("PA" = "PLN_AREA_N",
                   "SZ" = "SUBZONE_N")) %>%
  select(1:6) %>%
  rename(SZ_NAME = SZ,
         SZ = SUBZONE_C)
```

### Preparing origin attribute

Next, we will need to do another `left_join()` with *flow_data1* that we have prepared earlier to prepare both origin and destination attributes.

```{r}
flow_data1 <- flow_data1 %>%
  left_join(pop,
            by = c(ORIGIN_SZ = "SZ")) %>%
  rename(ORIGIN_AGE7_12 = AGE7_12,
         ORIGIN_AGE13_24 = AGE13_24,
         ORIGIN_AGE25_64 = AGE25_64) %>%
  select(-c(PA, SZ_NAME))
```

### Preparing destination attribute

```{r}
flow_data1 <- flow_data1 %>%
  left_join(pop,
            by = c(DESTIN_SZ = "SZ")) %>% #<< DESTIN_SZ
  rename(DESTIN_AGE7_12 = AGE7_12,
         DESTIN_AGE13_24 = AGE13_24,
         DESTIN_AGE25_64 = AGE25_64) %>%
  select(-c(PA, SZ_NAME))
```

We will called the output data file *SIM_data*. it is in rds data file format.

```{r}
write_rds(flow_data1, "data/rds/flow_data_6-9.rds")
SIM_data <- read_rds("data/rds/flow_data_6-9.rds")
```

## Calibrating Spatial Interaction Models

In this section, we will explore how to calibrate Spatial Interaction Models by using Poisson Regression method.

### Visualising the Dependent Variables

First, let us plot the distribution of the dependent variable (i.e., TRIPS) using a histogram, as shown in the code chunk below.

```{r}
ggplot(data = SIM_data,
       aes(x = TRIPS)) +
  geom_histogram()
```

Notice that the distribution is highly skewed and not resemble bell shape or also known as normal distribution.

Next, let us visualise the relation between the dependent variable and one of the key independent variable in Spatial Interaction Model, namely distance.

```{r}
ggplot(data = SIM_data,
       aes(x = dist,
           y = TRIPS)) +
  geom_point() +
  geom_smooth(method = lm)
```

Notice that their relationship hardly resemble linear relationship.

On the other hand, if we plot the scatter plot by using the log transformed version of both variables, we can see that their relationship is more resemble linear relationship.

```{r}
ggplot(data = SIM_data,
       aes(x = log(dist),
           y = log(TRIPS))) +
  geom_point() +
  geom_smooth(method = lm)
```

### Checking for variables with zero values

Since Poisson Regression is based of log and log 0 is undefined, it is important for us to ensure that no 0 values in the explanatory variables.

In the code chunk below, `summary()` of Base R is used to compute the summary statistics of all variables in *SIM_data* data frame.

```{r}
summary(SIM_data)
```

> The print report above reveals that variables ORIGIN_AGE7_12, ORIGIN_AGE13_24, ORIGIN_AGE25_64,DESTIN_AGE7_12, DESTIN_AGE13_24, DESTIN_AGE25_64 consist of 0 values.

In view of this, code chunk below will be used to replace zero values to 0.99.

```{r}
SIM_data$DESTIN_AGE7_12 <- ifelse(
  SIM_data$DESTIN_AGE7_12 == 0,
  0.99, SIM_data$DESTIN_AGE7_12)
SIM_data$DESTIN_AGE13_24 <- ifelse(
  SIM_data$DESTIN_AGE13_24 == 0,
  0.99, SIM_data$DESTIN_AGE13_24)
SIM_data$DESTIN_AGE25_64 <- ifelse(
  SIM_data$DESTIN_AGE25_64 == 0,
  0.99, SIM_data$DESTIN_AGE25_64)
SIM_data$ORIGIN_AGE7_12 <- ifelse(
  SIM_data$ORIGIN_AGE7_12 == 0,
  0.99, SIM_data$ORIGIN_AGE7_12)
SIM_data$ORIGIN_AGE13_24 <- ifelse(
  SIM_data$ORIGIN_AGE13_24 == 0,
  0.99, SIM_data$ORIGIN_AGE13_24)
SIM_data$ORIGIN_AGE25_64 <- ifelse(
  SIM_data$ORIGIN_AGE25_64 == 0,
  0.99, SIM_data$ORIGIN_AGE25_64)
```

Let's run the summary() again.

```{r}
summary(SIM_data)
```

> Notice that all the 0 values have been replaced by 0.99.

### Unconstrained Spatial Interaction Model

In this section, we will calibrate an unconstrained spatial interaction model by using `glm()` function. The explanatory variables are origin population by different age cohort, destination population by different age cohort (i.e. *ORIGIN_AGE25_64*) and distance between origin and destination in km (i.e. *dist*).

```{r}
uncSIM <- glm(formula = TRIPS ~ 
                log(ORIGIN_AGE25_64) + 
                log(DESTIN_AGE25_64) +
                log(dist),
              family = poisson(link = "log"),
              data = SIM_data,
              na.action = na.exclude)
uncSIM
```

### R-squared function

In order to measure how much variation of the trips can be accounted by the model we will write a function to calculate R-Squared value as shown below.

```{r}
CalcRSquared <- function(observed,estimated){
  r <- cor(observed,estimated)
  R2 <- r^2
  R2
}
```

Next, we will compute the R-squared of the unconstrained SIM by using the code chunk below.

```{r}
CalcRSquared(uncSIM$data$TRIPS, uncSIM$fitted.values)
```

```{r}
r2_mcfadden(uncSIM)
```

### Origin (Production) constrained SIM

In this section, we will calibrate an origin constrained SIM. For origin constrained SIM, only explanatory variables representing the attractiveness at the destinations will be used. This is because such models emphasize the limitations or capacities of the origins rather than the demand or attractiveness of the destinations. The capacity or limitation at the origin sites determines the potential for generating interactions or flows.

```{r}
orcSIM <- glm(formula = TRIPS ~ 
                 ORIGIN_SZ +
                 log(DESTIN_AGE25_64) +
                 log(dist),
              family = poisson(link = "log"),
              data = SIM_data,
              na.action = na.exclude)
summary(orcSIM)
```

We can examine how the constraints hold for destinations this time.

```{r}
CalcRSquared(orcSIM$data$TRIPS, orcSIM$fitted.values)
```

### Destination constrained

In this section, we will fit a destination constrained SIM by using the code chunk below.

```{r}
decSIM <- glm(formula = TRIPS ~ 
                DESTIN_SZ + 
                log(ORIGIN_AGE25_64) + 
                log(dist),
              family = poisson(link = "log"),
              data = SIM_data,
              na.action = na.exclude)
summary(decSIM)
```

We can examine how the constraints hold for destinations this time.

```{r}
CalcRSquared(decSIM$data$TRIPS, decSIM$fitted.values)
```

### Doubly constrained

In this section, we will fit a doubly constrained SIM by using the code chunk below.

```{r}
dbcSIM <- glm(formula = TRIPS ~ 
                ORIGIN_SZ + 
                DESTIN_SZ + 
                log(dist),
              family = poisson(link = "log"),
              data = SIM_data,
              na.action = na.exclude)
summary(dbcSIM)
```

We can examine how the constraints hold for destinations this time.

```{r}
CalcRSquared(dbcSIM$data$TRIPS, dbcSIM$fitted.values)
```

> Notice that there is a relatively greater improvement in the R\^2 value.

### Model comparison

Another useful model performance measure for continuous dependent variable is [Root Mean Squared Error](https://towardsdatascience.com/what-does-rmse-really-mean-806b65f2e48e). In this sub-section, we will learn how to use [`compare_performance()`](https://easystats.github.io/performance/reference/compare_performance.html) of [**performance**](https://easystats.github.io/performance/index.html) package

First of all, let us create a list called *model_list* by using the code chunk below.

```{r}
model_list <- list(unconstrained=uncSIM,
                   originConstrained=orcSIM,
                   destinationConstrained=decSIM,
                   doublyConstrained=dbcSIM)
```

Next, we will compute the RMSE of all the models in *model_list* file by using the code chunk below.

```{r}
compare_performance(model_list,
                    metrics = "RMSE")
```

> The print above reveals that doubly constrained SIM is the best model among all the four SIMs because it has the smallest RMSE value of 4616.169.

### Visualising fitted values

In this section, we will learn how to visualise the observed values and the fitted values.

Firstly we will extract the fitted values from each model by using the code chunk below.

```{r}
df <- as.data.frame(uncSIM$fitted.values) %>%
  round(digits = 0)
```

Next, we will join the values to *SIM_data* data frame.

```{r}
SIM_data <- SIM_data %>%
  cbind(df) %>%
  rename(uncTRIPS = "uncSIM$fitted.values")
```

Repeat the same step by for Origin Constrained SIM (i.e. orcSIM)

```{r}
df <- as.data.frame(orcSIM$fitted.values) %>%
  round(digits = 0)
SIM_data <- SIM_data %>%
  cbind(df) %>%
  rename(orcTRIPS = "orcSIM$fitted.values")
```

Repeat the same step by for Destination Constrained SIM (i.e. decSIM)

```{r}
df <- as.data.frame(decSIM$fitted.values) %>%
  round(digits = 0)
SIM_data <- SIM_data %>%
  cbind(df) %>%
  rename(decTRIPS = "decSIM$fitted.values")
```

Repeat the same step by for Doubly Constrained SIM (i.e. dbcSIM)

```{r}
df <- as.data.frame(dbcSIM$fitted.values) %>%
  round(digits = 0)
SIM_data <- SIM_data %>%
  cbind(df) %>%
  rename(dbcTRIPS = "dbcSIM$fitted.values")
```

```{r}
unc_p <- ggplot(data = SIM_data,
                aes(x = uncTRIPS,
                    y = TRIPS)) +
  geom_point() +
  geom_smooth(method = lm)

orc_p <- ggplot(data = SIM_data,
                aes(x = orcTRIPS,
                    y = TRIPS)) +
  geom_point() +
  geom_smooth(method = lm)

dec_p <- ggplot(data = SIM_data,
                aes(x = decTRIPS,
                    y = TRIPS)) +
  geom_point() +
  geom_smooth(method = lm)

dbc_p <- ggplot(data = SIM_data,
                aes(x = dbcTRIPS,
                    y = TRIPS)) +
  geom_point() +
  geom_smooth(method = lm)
```

Now, we will put all the graphs into a single visual for better comparison by using the code chunk below.

```{r}
ggarrange(unc_p, orc_p, dec_p, dbc_p,
          ncol = 2,
          nrow = 2)
```
