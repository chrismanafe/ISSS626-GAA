---
title: "Hands-on Exercise 10b: Calibrating Spatial Interaction Models with R"
author: "Christover Manafe"
date: "2024-10-22"
date-modified: "last-modified"
execute: 
  eval: true
  echo: true
  message: false
  freeze: true
format: 
  html:
    code-fold: false
    code-summary: "code chunk"
    number-sections: true
    number-depth: 4
---

# Overview

Spatial interaction modeling (or gravity models) is one of the most widely used analytical tools for studying interactions between social and economic agents in geographical space.

Spatial Interaction Models (SIMs) are mathematical models for estimating flows between spatial entities, first developed by Alan Wilson in the late 1960s and early 1970s. These models have since seen considerable uptake and refinement, particularly in transport modeling (Boyce and Williams, 2015). In general, SIMs describe and explain flows or movements between places based on (1) spatial separation, (2) complementarity, and (3) other intervening opportunities or spatial structures that can either enhance or reduce expected flows.

There are four main types of traditional SIMs:

1.  Unconstrained
2.  Production-constrained
3.  Attraction-constrained
4.  Doubly-constrained

Ordinary least squares (OLS), log-normal, Poisson, and negative binomial (NB) regression methods have been extensively used to calibrate OD flow models, processing flow data as different types of dependent variables. In this exercise, we will explore how to calibrate SIMs using these four regression methods in the R environment.

# The Packages

We will use following packages in this exercise

::: panel-tabset
## Packages

We will use following packages in this exercise:

| **Package**                                                                       | **Description**                                                                                                                                                                                                   |
|-----------------------|-------------------------------------------------|
| [**sf**](https://r-spatial.github.io/sf/)                                         | Provides functions to manage, process, and manipulate **Simple Features**, a formal geospatial data standard that specifies a storage and access model of spatial geometries such as points, lines, and polygons. |
| [**tidyverse**](https://www.tidyverse.org/)                                       | A collection of R packages for data science tasks such as importing, tidying, wrangling, and visualizing data.                                                                                                    |
| [**tmap**](https://cran.r-project.org/web/packages/tmap/)                         | Provides functions for creating cartographic-quality static maps or interactive maps using the [leaflet](https://leafletjs.com/) API.                                                                             |
| [**performance**](https://cran.r-project.org/web/packages/performance/index.html) | Provides functions for computing measures to assess model quality.                                                                                                                                                |
| [**sp**](https://cran.r-project.org/web/packages/sp/index.html)                   | Provides classes and methods for Spatial Data.                                                                                                                                                                    |
| [**reshape2**](https://cran.r-project.org/web/packages/reshape2/index.html)       | Provides functions to flexibly reshape data.                                                                                                                                                                      |
| [**ggpubr**](https://rpkgs.datanovia.com/ggpubr/)                                 | A collection of 'ggplot2'-based functions to easily create and customize publication-ready plots.                                                                                                                 |

: {tbl-colwidths="\[15,85\]"}

## Code

To install and launch all R packages.

```{r}
pacman::p_load(tmap, sf, sp,
               performance, reshape2,
               ggpubr, tidyverse)
```
:::

# The Data

This exercise is a continuation of Hands-on Exercise 10a: Processing and Visualizing Flow Data. The following data will be used:

-   **od_data.rds**: Weekday morning peak passenger flows at the planning subzone level.

-   **mpsz.rds**: URA Master Plan 2019 Planning Subzone boundaries in simple feature tibble data frame format.

# Computing Distance Matrix

In spatial interaction, a distance matrix is a table that shows the distances between pairs of locations. In this section, we will learn how to compute a distance matrix using the URA Master Plan 2019 Planning Subzone boundary, which we have saved as `mpsz.rds`.

First, let us import `mpsz.rds` into the R environment using the code chunk below.

```{r}
mpsz <- read_rds("data/rds/mpsz.rds")
mpsz
```

> Note that it is an **sf** tibble data frame object.

## Converting from sf data.table to SpatialPolygonsDataFrame

There are at least two ways to compute the required distance matrix: one using **sf** and the other using **sp**. Past experience has shown that computing the distance matrix with **sf** functions takes relatively longer than the **sp** method, especially when dealing with large datasets. Therefore, the **sp** method is used in the code chunks below.

First, we will use [`as.Spatial()`](https://r-spatial.github.io/sf/reference/coerce-methods.html) to convert **mpsz** from an **sf** tibble data frame to a SpatialPolygonsDataFrame of the **sp** object, as shown in the code chunk below.

```{r}
mpsz_sp <- as(mpsz, "Spatial")
mpsz_sp
```

## Computing the distance matrix

Next, the [`spDists()`](https://www.rdocumentation.org/packages/sp/versions/2.1-1/topics/spDistsN1) function from the **sp** package will be used to compute the Euclidean distance between the centroids of the planning subzones.

```{r}
dist <- spDists(mpsz_sp, 
                longlat = FALSE)
head(dist, n=c(10, 10))
```

> Note that the output `dist` is a matrix object in R. Additionally, the column headers and row headers are not labeled with the planning subzone codes.

## Labelling column and row heanders of a distance matrix

First, we will create a list sorted according to the distance matrix by planning subzone code.

```{r}
sz_names <- mpsz$SUBZONE_C
```

Next, we will attach the `SUBZONE_C` values to the rows and columns of the distance matrix for proper matching.

```{r}
colnames(dist) <- paste0(sz_names)
rownames(dist) <- paste0(sz_names)
```

## Pivoting distance value by SUBZONE_C

Next, we will pivot the distance matrix into a long table, using the row and column subzone codes, as shown in the code chunk below.

```{r}
distPair <- melt(dist) %>%
  rename(dist = value)
head(distPair, 10)
```

> Notice that the within zone distance is 0.

## Updating intra-zonal distances

In this section, we will append a constant value to replace the intra-zonal distances of 0.

First, we will select and determine the minimum value of the distances using the `summary()` function.

```{r}
distPair %>%
  filter(dist > 0) %>%
  summary()
```

Next, a constant distance value of 50m is added into intra-zones distance.

```{r}
distPair$dist <- ifelse(distPair$dist == 0,
                        50, distPair$dist)
```

Let's check the result data frame.

```{r}
distPair %>%
  summary()
```

Next, we will rename the origin and destination fields and save the dataframe for future use.

```{r}
distPair <- distPair %>%
  rename(orig = Var1,
         dest = Var2)
write_rds(distPair, "data/rds/distPair.rds")
distPair <- read_rds("data/rds/distPair.rds")
```

# Preparing Flow Data

Let's import saved *od_data* from Hands-on Exercise 10a into R environment.

```{r}
od_data <- read_rds("data/rds/od_data.rds")
```

Next, we will compute the total passenger trips between and within planning subzones using the code chunk below. The output will be stored in flow_data.

```{r}
flow_data <- od_data %>%
  group_by(ORIGIN_SZ, DESTIN_SZ) %>% 
  summarize(TRIPS = sum(MORNING_PEAK))
head(flow_data, 10)
```

## Separating intra-flow from passenger volume df

Code chunk below is used to add three new fields in `flow_data` dataframe.

```{r}
flow_data$FlowNoIntra <- ifelse(
  flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ, 
  0, flow_data$TRIPS)
flow_data$offset <- ifelse(
  flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ, 
  0.000001, 1)
```

## Combining passenger volume data with distance value

Before we can join *flow_data* and *distPair*, we need to convert data value type of *ORIGIN_SZ* and *DESTIN_SZ* fields of flow_data dataframe into factor data type.

```{r}
flow_data$ORIGIN_SZ <- as.factor(flow_data$ORIGIN_SZ)
flow_data$DESTIN_SZ <- as.factor(flow_data$DESTIN_SZ)
```

Now, `left_join()` of **dplyr** will be used to *flow_data* dataframe and *distPair* dataframe. The output is called *flow_data1*.

```{r}
flow_data1 <- flow_data %>%
  left_join (distPair,
             by = c("ORIGIN_SZ" = "orig",
                    "DESTIN_SZ" = "dest"))
```

# Preparing Origin and Destination Attributes

## Importing population data

Firstly, we will import the population data.

```{r}
pop <- read_csv("data/aspatial/pop.csv")
```

## Geospatial data wrangling

Next, we will do a `left_join` to *pop* data frame with *mpsz.* The output will be a sf object where each polygon in *mpsz* will be assigned a population value.

```{r}
pop <- pop %>%
  left_join(mpsz,
            by = c("PA" = "PLN_AREA_N",
                   "SZ" = "SUBZONE_N")) %>%
  select(1:6) %>%
  rename(SZ_NAME = SZ,
         SZ = SUBZONE_C)
```

## Preparing origin attribute

Next, we will need to do another `left_join()` with *flow_data1* that we have prepared earlier to prepare both origin and destination attributes.

```{r}
flow_data1 <- flow_data1 %>%
  left_join(pop,
            by = c(ORIGIN_SZ = "SZ")) %>%
  rename(ORIGIN_AGE7_12 = AGE7_12,
         ORIGIN_AGE13_24 = AGE13_24,
         ORIGIN_AGE25_64 = AGE25_64) %>%
  select(-c(PA, SZ_NAME))
```

## Preparing destination attribute

```{r}
flow_data1 <- flow_data1 %>%
  left_join(pop,
            by = c(DESTIN_SZ = "SZ")) %>% #<< DESTIN_SZ
  rename(DESTIN_AGE7_12 = AGE7_12,
         DESTIN_AGE13_24 = AGE13_24,
         DESTIN_AGE25_64 = AGE25_64) %>%
  select(-c(PA, SZ_NAME))
```

We will called the output data file *SIM_data*. it is in rds data file format.

```{r}
write_rds(flow_data1, "data/rds/flow_data_6-9.rds")
SIM_data <- read_rds("data/rds/flow_data_6-9.rds")
```

# Calibrating Spatial Interaction Models

In this section, we will explore how to calibrate Spatial Interaction Models by using Poisson Regression method.

## Visualising the Dependent Variables

First, let us plot the distribution of the dependent variable (i.e., TRIPS) using a histogram, as shown in the code chunk below.

```{r}
ggplot(data = SIM_data,
       aes(x = TRIPS)) +
  geom_histogram()
```

Notice that the distribution is highly skewed and not resemble bell shape or also known as normal distribution.

Next, let us visualise the relation between the dependent variable and one of the key independent variable in Spatial Interaction Model, namely distance.

```{r}
ggplot(data = SIM_data,
       aes(x = dist,
           y = TRIPS)) +
  geom_point() +
  geom_smooth(method = lm)
```

Notice that their relationship hardly resemble linear relationship.

On the other hand, if we plot the scatter plot by using the log transformed version of both variables, we can see that their relationship is more resemble linear relationship.

```{r}
ggplot(data = SIM_data,
       aes(x = log(dist),
           y = log(TRIPS))) +
  geom_point() +
  geom_smooth(method = lm)
```

## Checking for variables with zero values

Since Poisson Regression is based of log and log 0 is undefined, it is important for us to ensure that no 0 values in the explanatory variables.

In the code chunk below, `summary()` of Base R is used to compute the summary statistics of all variables in *SIM_data* data frame.

```{r}
summary(SIM_data)
```

> The print report above reveals that variables ORIGIN_AGE7_12, ORIGIN_AGE13_24, ORIGIN_AGE25_64,DESTIN_AGE7_12, DESTIN_AGE13_24, DESTIN_AGE25_64 consist of 0 values.

In view of this, code chunk below will be used to replace zero values to 0.99.

```{r}
SIM_data$DESTIN_AGE7_12 <- ifelse(
  SIM_data$DESTIN_AGE7_12 == 0,
  0.99, SIM_data$DESTIN_AGE7_12)
SIM_data$DESTIN_AGE13_24 <- ifelse(
  SIM_data$DESTIN_AGE13_24 == 0,
  0.99, SIM_data$DESTIN_AGE13_24)
SIM_data$DESTIN_AGE25_64 <- ifelse(
  SIM_data$DESTIN_AGE25_64 == 0,
  0.99, SIM_data$DESTIN_AGE25_64)
SIM_data$ORIGIN_AGE7_12 <- ifelse(
  SIM_data$ORIGIN_AGE7_12 == 0,
  0.99, SIM_data$ORIGIN_AGE7_12)
SIM_data$ORIGIN_AGE13_24 <- ifelse(
  SIM_data$ORIGIN_AGE13_24 == 0,
  0.99, SIM_data$ORIGIN_AGE13_24)
SIM_data$ORIGIN_AGE25_64 <- ifelse(
  SIM_data$ORIGIN_AGE25_64 == 0,
  0.99, SIM_data$ORIGIN_AGE25_64)
```

Let's run the summary() again.

```{r}
summary(SIM_data)
```

> Notice that all the 0 values have been replaced by 0.99.

## Unconstrained Spatial Interaction Model

In this section, we will calibrate an unconstrained spatial interaction model by using `glm()` function. The explanatory variables are origin population by different age cohort, destination population by different age cohort (i.e. *ORIGIN_AGE25_64*) and distance between origin and destination in km (i.e. *dist*).

```{r}
uncSIM <- glm(formula = TRIPS ~ 
                log(ORIGIN_AGE25_64) + 
                log(DESTIN_AGE25_64) +
                log(dist),
              family = poisson(link = "log"),
              data = SIM_data,
              na.action = na.exclude)
uncSIM
```

## R-squared function

In order to measure how much variation of the trips can be accounted by the model we will write a function to calculate R-Squared value as shown below.

```{r}
CalcRSquared <- function(observed,estimated){
  r <- cor(observed,estimated)
  R2 <- r^2
  R2
}
```

Next, we will compute the R-squared of the unconstrained SIM by using the code chunk below.

```{r}
CalcRSquared(uncSIM$data$TRIPS, uncSIM$fitted.values)
```

```{r}
r2_mcfadden(uncSIM)
```

## Origin (Production) constrained SIM

In this section, we will calibrate an origin constrained SIM. For origin constrained SIM, only explanatory variables representing the attractiveness at the destinations will be used. This is because such models emphasize the limitations or capacities of the origins rather than the demand or attractiveness of the destinations. The capacity or limitation at the origin sites determines the potential for generating interactions or flows.

```{r}
orcSIM <- glm(formula = TRIPS ~ 
                 ORIGIN_SZ +
                 log(DESTIN_AGE25_64) +
                 log(dist),
              family = poisson(link = "log"),
              data = SIM_data,
              na.action = na.exclude)
summary(orcSIM)
```

We can examine how the constraints hold for destinations this time.

```{r}
CalcRSquared(orcSIM$data$TRIPS, orcSIM$fitted.values)
```

## Destination constrained

In this section, we will fit a destination constrained SIM by using the code chunk below.

```{r}
decSIM <- glm(formula = TRIPS ~ 
                DESTIN_SZ + 
                log(ORIGIN_AGE25_64) + 
                log(dist),
              family = poisson(link = "log"),
              data = SIM_data,
              na.action = na.exclude)
summary(decSIM)
```

We can examine how the constraints hold for destinations this time.

```{r}
CalcRSquared(decSIM$data$TRIPS, decSIM$fitted.values)
```

## Doubly constrained

In this section, we will fit a doubly constrained SIM by using the code chunk below.

```{r}
dbcSIM <- glm(formula = TRIPS ~ 
                ORIGIN_SZ + 
                DESTIN_SZ + 
                log(dist),
              family = poisson(link = "log"),
              data = SIM_data,
              na.action = na.exclude)
summary(dbcSIM)
```

We can examine how the constraints hold for destinations this time.

```{r}
CalcRSquared(dbcSIM$data$TRIPS, dbcSIM$fitted.values)
```

> Notice that there is a relatively greater improvement in the R\^2 value.

## Model comparison

Another useful model performance measure for continuous dependent variable is [Root Mean Squared Error](https://towardsdatascience.com/what-does-rmse-really-mean-806b65f2e48e). In this sub-section, we will learn how to use [`compare_performance()`](https://easystats.github.io/performance/reference/compare_performance.html) of [**performance**](https://easystats.github.io/performance/index.html) package

First of all, let us create a list called *model_list* by using the code chunk below.

```{r}
model_list <- list(unconstrained=uncSIM,
                   originConstrained=orcSIM,
                   destinationConstrained=decSIM,
                   doublyConstrained=dbcSIM)
```

Next, we will compute the RMSE of all the models in *model_list* file by using the code chunk below.

```{r}
compare_performance(model_list,
                    metrics = "RMSE")
```

> The print above reveals that doubly constrained SIM is the best model among all the four SIMs because it has the smallest RMSE value of 4616.169.

## Visualising fitted values

In this section, we will learn how to visualise the observed values and the fitted values.

Firstly we will extract the fitted values from each model by using the code chunk below.

```{r}
df <- as.data.frame(uncSIM$fitted.values) %>%
  round(digits = 0)
```

Next, we will join the values to *SIM_data* data frame.

```{r}
SIM_data <- SIM_data %>%
  cbind(df) %>%
  rename(uncTRIPS = "uncSIM$fitted.values")
```

Repeat the same step by for Origin Constrained SIM (i.e. orcSIM)

```{r}
df <- as.data.frame(orcSIM$fitted.values) %>%
  round(digits = 0)
SIM_data <- SIM_data %>%
  cbind(df) %>%
  rename(orcTRIPS = "orcSIM$fitted.values")
```

Repeat the same step by for Destination Constrained SIM (i.e. decSIM)

```{r}
df <- as.data.frame(decSIM$fitted.values) %>%
  round(digits = 0)
SIM_data <- SIM_data %>%
  cbind(df) %>%
  rename(decTRIPS = "decSIM$fitted.values")
```

Repeat the same step by for Doubly Constrained SIM (i.e. dbcSIM)

```{r}
df <- as.data.frame(dbcSIM$fitted.values) %>%
  round(digits = 0)
SIM_data <- SIM_data %>%
  cbind(df) %>%
  rename(dbcTRIPS = "dbcSIM$fitted.values")
```

```{r}
unc_p <- ggplot(data = SIM_data,
                aes(x = uncTRIPS,
                    y = TRIPS)) +
  geom_point() +
  geom_smooth(method = lm)

orc_p <- ggplot(data = SIM_data,
                aes(x = orcTRIPS,
                    y = TRIPS)) +
  geom_point() +
  geom_smooth(method = lm)

dec_p <- ggplot(data = SIM_data,
                aes(x = decTRIPS,
                    y = TRIPS)) +
  geom_point() +
  geom_smooth(method = lm)

dbc_p <- ggplot(data = SIM_data,
                aes(x = dbcTRIPS,
                    y = TRIPS)) +
  geom_point() +
  geom_smooth(method = lm)
```

Now, we will put all the graphs into a single visual for better comparison by using the code chunk below.

```{r}
ggarrange(unc_p, orc_p, dec_p, dbc_p,
          ncol = 2,
          nrow = 2)
```

# Reference

Kam, T. S. Calibrating Spatial Interaction Models with R. *R for Geospatial Data Science and Analytics.* <https://r4gdsa.netlify.app/chap16>
