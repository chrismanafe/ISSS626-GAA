---
title: "Hands-on Exercise 10a: Processing and Visualising Flow Data"
author: "Christover Manafe"
date: "2024-10-22"
date-modified: "last-modified"
execute: 
  eval: true
  echo: true
  message: false
  freeze: true
format: 
  html:
    code-fold: false
    code-summary: "code chunk"
    number-sections: true
    number-depth: 4
---

# Overview

Spatial interaction refers to the flow of people, materials, or information between locations in geographical space. It encompasses everything from freight shipments, energy flows, and global trade in rare antiquities, to flight schedules, rush hour congestion, and pedestrian foot traffic.

Each spatial interaction, as an analogy for a set of movements, consists of a discrete origin/destination pair. Each pair can be represented as a cell in a matrix where the rows correspond to the locations (centroids) of origin and the columns correspond to the locations (centroids) of destination. This type of matrix is commonly known as an origin/destination (OD) matrix, or a spatial interaction matrix.

In this hands-on exercise, we will learn how to build an OD matrix using the Passenger Volume by Origin Destination Bus Stops dataset downloaded from [LTA DataMall](https://datamall.lta.gov.sg/content/datamall/en.html). By the end of this exercise, we will be able to:

-   Import and extract OD data for a selected time interval,

-   Import and save geospatial data (i.e., bus stops and mpsz) into sf tibble data frame objects,

-   Populate planning subzone codes into the bus stops sf tibble data frame,

-   Construct desire lines geospatial data from the OD data, and

-   Visualize passenger volume by origin and destination bus stops using the desire lines data.

# The Packages

We will use following packages in this exercise

::: panel-tabset
## Packages

We will use following packages in this exercise:

+-----------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| **Package**                                               | **Description**                                                                                                                                                                                                   |
+===========================================================+===================================================================================================================================================================================================================+
| [**sf**](https://r-spatial.github.io/sf/)                 | Provides functions to manage, process, and manipulate **Simple Features**, a formal geospatial data standard that specifies a storage and access model of spatial geometries such as points, lines, and polygons. |
+-----------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| [**tidyverse**](https://www.tidyverse.org/)               | A collection of R packages for data science tasks such as importing, tidying, wrangling, and visualizing data.                                                                                                    |
+-----------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| [**tmap**](https://cran.r-project.org/web/packages/tmap/) | Provides functions for creating cartographic-quality static maps or interactive maps using the [leaflet](https://leafletjs.com/) API.                                                                             |
+-----------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| [**DT**](https://rstudio.github.io/DT/)                   | Provides an R interface to the JavaScript library DataTables.                                                                                                                                                     |
+-----------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| [**stplanr**](https://docs.ropensci.org/stplanr/)         | Provides functions for solving common problems in transport planning and modelling.                                                                                                                               |
+-----------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

: {tbl-colwidths="\[15,85\]"}

## Code

To install and launch all R packages.

```{r}
pacman::p_load(tmap, sf, DT, stplanr, tidyverse)
```
:::

# Preparing the Flow Data

## Downloading the OD data

First, we would need to download the OD data from LTA DataMall. We can follow these steps to do so.

+------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Step | Description                                                                                                                                                                                                                                        |
+======+====================================================================================================================================================================================================================================================+
| 1    | Request API Access from [LTA DataMall website](https://datamall.lta.gov.sg/content/datamall/en/dynamic-data.html) and complete the request form.                                                                                                   |
+------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| 2    | Install [Postman](https://www.postman.com/downloads/) and follow instructions from [API User Guide](https://datamall.lta.gov.sg/content/dam/datamall/datasets/LTA_DataMall_API_User_Guide.pdf).                                                    |
+------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| 3    | Search for `Passenger Volume by Origin Destination Bus Stops` in [API User Guide](https://datamall.lta.gov.sg/content/dam/datamall/datasets/LTA_DataMall_API_User_Guide.pdf), then use the URL from the documentation into Postman                 |
+------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| 4    | Set Http request in Postman to `GET`, then add following parameters:                                                                                                                                                                               |
|      |                                                                                                                                                                                                                                                    |
|      | -   Under `Params` tab:                                                                                                                                                                                                                            |
|      |                                                                                                                                                                                                                                                    |
|      |     -   Key: `Date`                                                                                                                                                                                                                                |
|      |                                                                                                                                                                                                                                                    |
|      |     -   Value: `202407`                                                                                                                                                                                                                            |
|      |                                                                                                                                                                                                                                                    |
|      |         The data is updated monthly by the 10th, with passenger volumes for the previous month. Since it's currently October, the most recent available data covers July, August, and September. For this analysis, I am using the data from July. |
|      |                                                                                                                                                                                                                                                    |
|      | -   Under `Headers` tab:                                                                                                                                                                                                                           |
|      |                                                                                                                                                                                                                                                    |
|      |     -   Key: `AccountKey`                                                                                                                                                                                                                          |
|      |                                                                                                                                                                                                                                                    |
|      |     -   Value: Use the API Account Key that is sent to our email.                                                                                                                                                                                  |
+------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| 5    | Click `Send` button on the postman, and the API will return a URL in the response that can be used to download the file.                                                                                                                           |
|      |                                                                                                                                                                                                                                                    |
|      | The URL will remain active for 5 minutes.                                                                                                                                                                                                          |
+------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

## Importing the OD data

Next, we will import the downloaded Passenger Volume by Origin Destination Bus Stops dataset using the `read_csv()` function from the readr package.

```{r}
odbus <- read_csv("data/aspatial/origin_destination_bus_202407.csv")
glimpse(odbus)
```

A quick check of the **odbus** tibble data frame shows that the values in ORIGIN_PT_CODE and DESTINATION_PT_CODE are already in character data type. However, we will still convert these values into factors using the code chunk below, as it helps categorize the data for further analysis.

```{r}
odbus$ORIGIN_PT_CODE <- as.factor(odbus$ORIGIN_PT_CODE)
odbus$DESTINATION_PT_CODE <- as.factor(odbus$DESTINATION_PT_CODE) 
```

## Extracting the study data

For the purpose of this exercise, we will extract commuting flows on weekdays between 6:00 and 9:00 AM.

```{r}
odbus6_9 <- odbus %>%
  filter(DAY_TYPE == "WEEKDAY") %>%
  filter(TIME_PER_HOUR >= 6 &
           TIME_PER_HOUR <= 9) %>%
  group_by(ORIGIN_PT_CODE,
           DESTINATION_PT_CODE) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS))
```

We can use the **datatable** package to create interactive tables for the odbus6_9 data frame:

```{r}
datatable(odbus6_9)
```

We will save the output in RDS format for future use, and then re-import the saved RDS file into the R environment.

```{r}
write_rds(odbus6_9, "data/rds/odbus6_9.rds")
odbus6_9 <- read_rds("data/rds/odbus6_9.rds")
```

# Working with Geospatial Data

In this exercise, two geospatial datasets will be used:

-   `BusStop`: This dataset provides the locations of bus stops as of the last quarter of 2022.

-   `MPSZ-2019`: This dataset provides the sub-zone boundaries from the URA Master Plan 2019.

Both datasets are in ESRI shapefile format.

## Importing geospatial data

We'll import the geospatial datasets using the `st_read()` function.

```{r}
busstop <- st_read(dsn = "data/geospatial",
                   layer = "BusStop") %>%
  st_transform(crs = 3414)
```

```{r}
mpsz <- st_read(dsn = "data/geospatial",
                   layer = "MPSZ-2019") %>%
  st_transform(crs = 3414)
mpsz
```

Let's write mpsz sf tibble data frame into an rds file for future use.

```{r}
mpsz <- write_rds(mpsz, "data/rds/mpsz.rds")
```

## Visualize Bus Stop Location

```{r}
tm_shape(mpsz) +
  tm_polygons() +
tm_shape(busstop) +
  tm_dots(col="red") +
tm_layout(frame = F)
```

> We noticed there are some bus stops that are located outside of Singapore.

# Geospatial Data Wrangling

## Combining BusStop and mpsz

```{r}
busstop_mpsz <- st_intersection(busstop, mpsz) %>%
  select(BUS_STOP_N, SUBZONE_C) %>%
  st_drop_geometry()
```

> -   `st_intersection()` is used to perform point and polygon overly and the output will be in point sf object.
> -   `select()` of dplyr package is then use to retain only BUS_STOP_N and SUBZONE_C in the busstop_mpsz sf data frame.
> -   5 bus stops is dropped because it is outside MPSZ boundary (i.e. in Malaysia).

```{r}
datatable(busstop_mpsz)
```

Next, we will append the planning subzone code from the busstop_mpsz data frame onto the odbus6_9 data frame.

```{r}
od_data <- left_join(odbus6_9 , busstop_mpsz,
            by = c("ORIGIN_PT_CODE" = "BUS_STOP_N")) %>%
  rename(ORIGIN_BS = ORIGIN_PT_CODE,
         ORIGIN_SZ = SUBZONE_C,
         DESTIN_BS = DESTINATION_PT_CODE)
```

Let's check for duplicate records before moving forward with the analysis.

```{r}
duplicate <- od_data %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup()
duplicate
```

Because there are duplicate records, let's run following code chunk to retain the unique records.

```{r}
od_data <- unique(od_data)
```

Next, we will update od_data data frame with the planning subzone codes.

```{r}
od_data <- left_join(od_data , busstop_mpsz,
            by = c("DESTIN_BS" = "BUS_STOP_N")) 
```

Let's check for duplicate records before moving forward with the analysis.

```{r}
duplicate <- od_data %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup()
duplicate
```

Here we also got duplicate records, let's run following code chunk to retain the unique records.

```{r}
od_data <- unique(od_data)
```

```{r}
od_data <- od_data %>%
  rename(DESTIN_SZ = SUBZONE_C) %>%
  drop_na() %>%
  group_by(ORIGIN_SZ, DESTIN_SZ) %>%
  summarise(MORNING_PEAK = sum(TRIPS))
```

Let's save the output into an rds file format

```{r}
write_rds(od_data, "data/rds/od_data.rds")
od_data <- read_rds("data/rds/od_data.rds")
```

# Visualising Spatial Interaction

In this section, we will learn how to prepare a desire line by using **stplanr** package.

## Removing intra-zonal flows

We will not plot the intra-zonal flows. The code chunk below will be used to remove intra-zonal flows.

```{r}
od_data_fij <- od_data[od_data$ORIGIN_SZ!=od_data$DESTIN_SZ,]
write_rds(od_data_fij, "data/rds/od_data_fij.rds")
od_data_fij <- read_rds("data/rds/od_data_fij.rds")
```

## Creating desire lines

In this code chunk below, `od2line()` of **stplanr** package is used to create the desire lines.

```{r}
flowLine <- od2line(flow = od_data_fij, 
                    zones = mpsz,
                    zone_code = "SUBZONE_C")
write_rds(flowLine, "data/rds/flowLine.rds")
flowLine <- read_rds("data/rds/flowLine.rds")
```

## Visualising the desire lines

To visualise the resulting desire lines, let's run the code chunk below.

```{r}
tm_shape(mpsz) +
  tm_polygons() +
flowLine %>%  
tm_shape() +
  tm_lines(lwd = "MORNING_PEAK",
           style = "quantile",
           scale = c(0.1, 1, 3, 5, 7, 10),
           n = 6,
           alpha = 1)
```

When the flow data are very messy and highly skewed like the one shown above, it is wiser to focus on selected flows, for example flow greater than or equal to 5000 as shown below.

```{r}
tm_shape(mpsz) +
  tm_polygons() +
flowLine %>%  
  filter(MORNING_PEAK >= 5000) %>%
tm_shape() +
  tm_lines(lwd = "MORNING_PEAK",
           style = "quantile",
           scale = c(0.1, 1, 3, 5, 7, 10),
           n = 6,
           alpha = 1)
```

# Reference

Kam, T. S. Processing and Visualising Flow Data. *R for Geospatial Data Science and Analytics.* <https://r4gdsa.netlify.app/chap15.html>
